{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j03m/lstm-price-predictor/blob/main/Coin_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H8K_tenSjC-"
      },
      "source": [
        "# Current Todo:\n",
        "\n",
        "\n",
        "Some ideas here: \n",
        "\n",
        "* Use pandas_ta to attach technical data to timeseries then use random forest to see if any features are super good.\n",
        "\n",
        "* Use vector_bt to back test your models\n",
        "\n",
        "* Integrate the different time granularity models, 15m etc into the core configs\n",
        "\n",
        "* Fix coinbase - we can't filter on volume amount without extra work\n",
        "\n",
        "* Add TA fields, use random forest to check which fields are the best, verify with mean square error (this could take a while)\n",
        "\n",
        "* Move to an \"always\" on model where we more closely monitor exits and entries. We can constantly check predictions and refine entry/exit points. Can we pick a better entry point? We had at some point discussed trying to predict all 4 values which would help. \n",
        "\n",
        "* Can we monitor and alarm/email the 15 min chart of an entry and see if it is\n",
        "move toward or away from our target?\n",
        "\n",
        "* pandas_ta strategy/back testers look interesting?\n",
        "\n",
        "Read me: https://www.kaggle.com/code/vuhuyduongnia/vn30-stock-prediction-by-lstm-model-accuracy-90\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n66xj4BGKWM"
      },
      "source": [
        "#IMPORT DATASETS AND LIBRARIES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sPZpiBGYcYB",
        "outputId": "d4b72298-6304-4186-f409-351eeb5a6eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0,'/content/drive/My Drive/ml-trde-notebooks')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "xfz5XUwxV8WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ***** WARNING : Install deps - This will BUILD TALib and takes a while!\n",
        "%run -i '/content/drive/My Drive/ml-trde-notebooks/installs.ipynb'"
      ],
      "metadata": {
        "id": "9KxDC9gpOMp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281a3cc7-fd15-4017-8bd7-a05560a7210e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-22 13:34:26--  http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
            "Resolving prdownloads.sourceforge.net (prdownloads.sourceforge.net)... 204.68.111.105\n",
            "Connecting to prdownloads.sourceforge.net (prdownloads.sourceforge.net)|204.68.111.105|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz [following]\n",
            "--2023-01-22 13:34:26--  http://downloads.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 204.68.111.105\n",
            "Reusing existing connection to prdownloads.sourceforge.net:80.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://onboardcloud.dl.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz [following]\n",
            "--2023-01-22 13:34:26--  http://onboardcloud.dl.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz\n",
            "Resolving onboardcloud.dl.sourceforge.net (onboardcloud.dl.sourceforge.net)... 202.79.184.253\n",
            "Connecting to onboardcloud.dl.sourceforge.net (onboardcloud.dl.sourceforge.net)|202.79.184.253|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1330299 (1.3M) [application/x-gzip]\n",
            "Saving to: ‘ta-lib-0.4.0-src.tar.gz’\n",
            "\n",
            "ta-lib-0.4.0-src.ta 100%[===================>]   1.27M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-01-22 13:34:26 (75.7 MB/s) - ‘ta-lib-0.4.0-src.tar.gz’ saved [1330299/1330299]\n",
            "\n",
            "ta-lib/\n",
            "ta-lib/config.sub\n",
            "ta-lib/aclocal.m4\n",
            "ta-lib/CHANGELOG.TXT\n",
            "ta-lib/include/\n",
            "ta-lib/include/ta_abstract.h\n",
            "ta-lib/include/ta_func.h\n",
            "ta-lib/include/ta_common.h\n",
            "ta-lib/include/ta_config.h.in\n",
            "ta-lib/include/Makefile.am\n",
            "ta-lib/include/ta_libc.h\n",
            "ta-lib/include/ta_defs.h\n",
            "ta-lib/missing\n",
            "ta-lib/ta-lib.spec.in\n",
            "ta-lib/config.guess\n",
            "ta-lib/Makefile.in\n",
            "ta-lib/ta-lib.dpkg.in\n",
            "ta-lib/Makefile.am\n",
            "ta-lib/autogen.sh\n",
            "ta-lib/install-sh\n",
            "ta-lib/configure\n",
            "ta-lib/depcomp\n",
            "ta-lib/HISTORY.TXT\n",
            "ta-lib/configure.in\n",
            "ta-lib/autom4te.cache/\n",
            "ta-lib/autom4te.cache/output.0\n",
            "ta-lib/autom4te.cache/requests\n",
            "ta-lib/autom4te.cache/output.1\n",
            "ta-lib/autom4te.cache/traces.0\n",
            "ta-lib/autom4te.cache/traces.1\n",
            "ta-lib/ltmain.sh\n",
            "ta-lib/ta-lib-config.in\n",
            "ta-lib/src/\n",
            "ta-lib/src/ta_func/\n",
            "ta-lib/src/ta_func/ta_MACDFIX.c\n",
            "ta-lib/src/ta_func/ta_CDLPIERCING.c\n",
            "ta-lib/src/ta_func/ta_DIV.c\n",
            "ta-lib/src/ta_func/ta_ROCR100.c\n",
            "ta-lib/src/ta_func/ta_ADXR.c\n",
            "ta-lib/src/ta_func/ta_MAVP.c\n",
            "ta-lib/src/ta_func/ta_CDLCLOSINGMARUBOZU.c\n",
            "ta-lib/src/ta_func/ta_COSH.c\n",
            "ta-lib/src/ta_func/ta_EXP.c\n",
            "ta-lib/src/ta_func/ta_MINMAXINDEX.c\n",
            "ta-lib/src/ta_func/ta_SQRT.c\n",
            "ta-lib/src/ta_func/ta_FLOOR.c\n",
            "ta-lib/src/ta_func/ta_CDLCONCEALBABYSWALL.c\n",
            "ta-lib/src/ta_func/ta_NATR.c\n",
            "ta-lib/src/ta_func/ta_CDLHARAMICROSS.c\n",
            "ta-lib/src/ta_func/ta_MINUS_DM.c\n",
            "ta-lib/src/ta_func/ta_LOG10.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG_ANGLE.c\n",
            "ta-lib/src/ta_func/ta_RSI.c\n",
            "ta-lib/src/ta_func/ta_CDLABANDONEDBABY.c\n",
            "ta-lib/src/ta_func/ta_SAR.c\n",
            "ta-lib/src/ta_func/ta_CDLBREAKAWAY.c\n",
            "ta-lib/src/ta_func/ta_CDLDRAGONFLYDOJI.c\n",
            "ta-lib/src/ta_func/ta_CDLHIGHWAVE.c\n",
            "ta-lib/src/ta_func/ta_CDLKICKING.c\n",
            "ta-lib/src/ta_func/ta_CDLDOJISTAR.c\n",
            "ta-lib/src/ta_func/ta_VAR.c\n",
            "ta-lib/src/ta_func/ta_CDLMATCHINGLOW.c\n",
            "ta-lib/src/ta_func/ta_CDLGAPSIDESIDEWHITE.c\n",
            "ta-lib/src/ta_func/ta_CDLMARUBOZU.c\n",
            "ta-lib/src/ta_func/ta_AROONOSC.c\n",
            "ta-lib/src/ta_func/ta_WCLPRICE.c\n",
            "ta-lib/src/ta_func/ta_CDLEVENINGDOJISTAR.c\n",
            "ta-lib/src/ta_func/ta_CDL3INSIDE.c\n",
            "ta-lib/src/ta_func/ta_OBV.c\n",
            "ta-lib/src/ta_func/ta_AROON.c\n",
            "ta-lib/src/ta_func/ta_CDLBELTHOLD.c\n",
            "ta-lib/src/ta_func/ta_CDLSPINNINGTOP.c\n",
            "ta-lib/src/ta_func/ta_AD.c\n",
            "ta-lib/src/ta_func/ta_MAX.c\n",
            "ta-lib/src/ta_func/ta_CDLENGULFING.c\n",
            "ta-lib/src/ta_func/ta_MINMAX.c\n",
            "ta-lib/src/ta_func/ta_CDLINNECK.c\n",
            "ta-lib/src/ta_func/ta_STDDEV.c\n",
            "ta-lib/src/ta_func/ta_NVI.c\n",
            "ta-lib/src/ta_func/ta_CDLHAMMER.c\n",
            "ta-lib/src/ta_func/ta_ASIN.c\n",
            "ta-lib/src/ta_func/ta_SUM.c\n",
            "ta-lib/src/ta_func/ta_STOCH.c\n",
            "ta-lib/src/ta_func/ta_CDLLONGLEGGEDDOJI.c\n",
            "ta-lib/src/ta_func/ta_MEDPRICE.c\n",
            "ta-lib/src/ta_func/ta_CDL3STARSINSOUTH.c\n",
            "ta-lib/src/ta_func/ta_HT_TRENDMODE.c\n",
            "ta-lib/src/ta_func/ta_BBANDS.c\n",
            "ta-lib/src/ta_func/ta_CDLMORNINGSTAR.c\n",
            "ta-lib/src/ta_func/ta_HT_DCPHASE.c\n",
            "ta-lib/src/ta_func/ta_CDLLONGLINE.c\n",
            "ta-lib/src/ta_func/ta_TAN.c\n",
            "ta-lib/src/ta_func/ta_SMA.c\n",
            "ta-lib/src/ta_func/ta_DX.c\n",
            "ta-lib/src/ta_func/ta_MIDPOINT.c\n",
            "ta-lib/src/ta_func/ta_CDL2CROWS.c\n",
            "ta-lib/src/ta_func/ta_CORREL.c\n",
            "ta-lib/src/ta_func/ta_CDL3BLACKCROWS.c\n",
            "ta-lib/src/ta_func/ta_ADD.c\n",
            "ta-lib/src/ta_func/Makefile.in\n",
            "ta-lib/src/ta_func/ta_CDLTHRUSTING.c\n",
            "ta-lib/src/ta_func/ta_SUB.c\n",
            "ta-lib/src/ta_func/ta_CDLSTALLEDPATTERN.c\n",
            "ta-lib/src/ta_func/ta_CDLTRISTAR.c\n",
            "ta-lib/src/ta_func/ta_MA.c\n",
            "ta-lib/src/ta_func/ta_HT_SINE.c\n",
            "ta-lib/src/ta_func/ta_ACOS.c\n",
            "ta-lib/src/ta_func/ta_CDLSTICKSANDWICH.c\n",
            "ta-lib/src/ta_func/ta_SINH.c\n",
            "ta-lib/src/ta_func/ta_utility.h\n",
            "ta-lib/src/ta_func/ta_CDLSHORTLINE.c\n",
            "ta-lib/src/ta_func/ta_ATAN.c\n",
            "ta-lib/src/ta_func/ta_CDLADVANCEBLOCK.c\n",
            "ta-lib/src/ta_func/ta_CDLKICKINGBYLENGTH.c\n",
            "ta-lib/src/ta_func/ta_CDLSHOOTINGSTAR.c\n",
            "ta-lib/src/ta_func/ta_ROCR.c\n",
            "ta-lib/src/ta_func/ta_WMA.c\n",
            "ta-lib/src/ta_func/ta_CDLDARKCLOUDCOVER.c\n",
            "ta-lib/src/ta_func/ta_CDLXSIDEGAP3METHODS.c\n",
            "ta-lib/src/ta_func/ta_TYPPRICE.c\n",
            "ta-lib/src/ta_func/ta_CDL3WHITESOLDIERS.c\n",
            "ta-lib/src/ta_func/Makefile.am\n",
            "ta-lib/src/ta_func/ta_MACDEXT.c\n",
            "ta-lib/src/ta_func/ta_ADX.c\n",
            "ta-lib/src/ta_func/ta_PLUS_DM.c\n",
            "ta-lib/src/ta_func/ta_CDLUPSIDEGAP2CROWS.c\n",
            "ta-lib/src/ta_func/ta_LN.c\n",
            "ta-lib/src/ta_func/ta_DEMA.c\n",
            "ta-lib/src/ta_func/ta_CDL3OUTSIDE.c\n",
            "ta-lib/src/ta_func/ta_CDLTASUKIGAP.c\n",
            "ta-lib/src/ta_func/ta_MAMA.c\n",
            "ta-lib/src/ta_func/ta_CDLMORNINGDOJISTAR.c\n",
            "ta-lib/src/ta_func/ta_PLUS_DI.c\n",
            "ta-lib/src/ta_func/ta_MININDEX.c\n",
            "ta-lib/src/ta_func/ta_COS.c\n",
            "ta-lib/src/ta_func/ta_HT_TRENDLINE.c\n",
            "ta-lib/src/ta_func/ta_MIDPRICE.c\n",
            "ta-lib/src/ta_func/ta_CEIL.c\n",
            "ta-lib/src/ta_func/ta_TRIMA.c\n",
            "ta-lib/src/ta_func/ta_CDLSEPARATINGLINES.c\n",
            "ta-lib/src/ta_func/ta_ROCP.c\n",
            "ta-lib/src/ta_func/ta_CDLHOMINGPIGEON.c\n",
            "ta-lib/src/ta_func/ta_CDLHANGINGMAN.c\n",
            "ta-lib/src/ta_func/ta_AVGPRICE.c\n",
            "ta-lib/src/ta_func/ta_APO.c\n",
            "ta-lib/src/ta_func/ta_CDLRISEFALL3METHODS.c\n",
            "ta-lib/src/ta_func/ta_TRANGE.c\n",
            "ta-lib/src/ta_func/ta_TSF.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG.c\n",
            "ta-lib/src/ta_func/ta_PVI.c\n",
            "ta-lib/src/ta_func/ta_CDLHIKKAKEMOD.c\n",
            "ta-lib/src/ta_func/ta_MFI.c\n",
            "ta-lib/src/ta_func/ta_CDLHARAMI.c\n",
            "ta-lib/src/ta_func/ta_MACD.c\n",
            "ta-lib/src/ta_func/ta_BETA.c\n",
            "ta-lib/src/ta_func/ta_CDLINVERTEDHAMMER.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG_SLOPE.c\n",
            "ta-lib/src/ta_func/ta_STOCHF.c\n",
            "ta-lib/src/ta_func/ta_MIN.c\n",
            "ta-lib/src/ta_func/ta_CDLIDENTICAL3CROWS.c\n",
            "ta-lib/src/ta_func/ta_CDLRICKSHAWMAN.c\n",
            "ta-lib/src/ta_func/ta_T3.c\n",
            "ta-lib/src/ta_func/ta_CDLMATHOLD.c\n",
            "ta-lib/src/ta_func/ta_CDLUNIQUE3RIVER.c\n",
            "ta-lib/src/ta_func/ta_ADOSC.c\n",
            "ta-lib/src/ta_func/ta_MAXINDEX.c\n",
            "ta-lib/src/ta_func/ta_ULTOSC.c\n",
            "ta-lib/src/ta_func/ta_TRIX.c\n",
            "ta-lib/src/ta_func/ta_MOM.c\n",
            "ta-lib/src/ta_func/ta_CDLDOJI.c\n",
            "ta-lib/src/ta_func/ta_EMA.c\n",
            "ta-lib/src/ta_func/ta_STOCHRSI.c\n",
            "ta-lib/src/ta_func/ta_ROC.c\n",
            "ta-lib/src/ta_func/ta_CDLEVENINGSTAR.c\n",
            "ta-lib/src/ta_func/ta_CDLCOUNTERATTACK.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG_INTERCEPT.c\n",
            "ta-lib/src/ta_func/ta_SAREXT.c\n",
            "ta-lib/src/ta_func/ta_WILLR.c\n",
            "ta-lib/src/ta_func/ta_MULT.c\n",
            "ta-lib/src/ta_func/ta_ATR.c\n",
            "ta-lib/src/ta_func/ta_BOP.c\n",
            "ta-lib/src/ta_func/ta_CMO.c\n",
            "ta-lib/src/ta_func/ta_CDLONNECK.c\n",
            "ta-lib/src/ta_func/ta_CCI.c\n",
            "ta-lib/src/ta_func/ta_CDLLADDERBOTTOM.c\n",
            "ta-lib/src/ta_func/ta_HT_PHASOR.c\n",
            "ta-lib/src/ta_func/ta_utility.c\n",
            "ta-lib/src/ta_func/ta_PPO.c\n",
            "ta-lib/src/ta_func/ta_CDLHIKKAKE.c\n",
            "ta-lib/src/ta_func/ta_HT_DCPERIOD.c\n",
            "ta-lib/src/ta_func/ta_CDL3LINESTRIKE.c\n",
            "ta-lib/src/ta_func/ta_TEMA.c\n",
            "ta-lib/src/ta_func/ta_SIN.c\n",
            "ta-lib/src/ta_func/ta_MINUS_DI.c\n",
            "ta-lib/src/ta_func/ta_KAMA.c\n",
            "ta-lib/src/ta_func/ta_TANH.c\n",
            "ta-lib/src/ta_func/ta_CDLTAKURI.c\n",
            "ta-lib/src/ta_func/ta_CDLGRAVESTONEDOJI.c\n",
            "ta-lib/src/ta_common/\n",
            "ta-lib/src/ta_common/ta_pragma.h\n",
            "ta-lib/src/ta_common/ta_magic_nb.h\n",
            "ta-lib/src/ta_common/ta_retcode.csv\n",
            "ta-lib/src/ta_common/Makefile.in\n",
            "ta-lib/src/ta_common/Makefile.am\n",
            "ta-lib/src/ta_common/ta_memory.h\n",
            "ta-lib/src/ta_common/ta_version.c\n",
            "ta-lib/src/ta_common/ta_global.h\n",
            "ta-lib/src/ta_common/ta_global.c\n",
            "ta-lib/src/ta_common/ta_retcode.c\n",
            "ta-lib/src/Makefile.in\n",
            "ta-lib/src/ta_abstract/\n",
            "ta-lib/src/ta_abstract/frames/\n",
            "ta-lib/src/ta_abstract/frames/ta_frame.c\n",
            "ta-lib/src/ta_abstract/frames/ta_frame.h\n",
            "ta-lib/src/ta_abstract/excel_glue.c\n",
            "ta-lib/src/ta_abstract/ta_frame_priv.h\n",
            "ta-lib/src/ta_abstract/ta_func_api.c\n",
            "ta-lib/src/ta_abstract/Makefile.in\n",
            "ta-lib/src/ta_abstract/ta_def_ui.h\n",
            "ta-lib/src/ta_abstract/Makefile.am\n",
            "ta-lib/src/ta_abstract/ta_abstract.c\n",
            "ta-lib/src/ta_abstract/ta_group_idx.c\n",
            "ta-lib/src/ta_abstract/tables/\n",
            "ta-lib/src/ta_abstract/tables/table_u.c\n",
            "ta-lib/src/ta_abstract/tables/table_x.c\n",
            "ta-lib/src/ta_abstract/tables/table_r.c\n",
            "ta-lib/src/ta_abstract/tables/table_f.c\n",
            "ta-lib/src/ta_abstract/tables/table_j.c\n",
            "ta-lib/src/ta_abstract/tables/table_e.c\n",
            "ta-lib/src/ta_abstract/tables/table_t.c\n",
            "ta-lib/src/ta_abstract/tables/table_n.c\n",
            "ta-lib/src/ta_abstract/tables/table_i.c\n",
            "ta-lib/src/ta_abstract/tables/table_c.c\n",
            "ta-lib/src/ta_abstract/tables/table_l.c\n",
            "ta-lib/src/ta_abstract/tables/table_k.c\n",
            "ta-lib/src/ta_abstract/tables/table_g.c\n",
            "ta-lib/src/ta_abstract/tables/table_d.c\n",
            "ta-lib/src/ta_abstract/tables/table_h.c\n",
            "ta-lib/src/ta_abstract/tables/table_o.c\n",
            "ta-lib/src/ta_abstract/tables/table_b.c\n",
            "ta-lib/src/ta_abstract/tables/table_q.c\n",
            "ta-lib/src/ta_abstract/tables/table_v.c\n",
            "ta-lib/src/ta_abstract/tables/table_m.c\n",
            "ta-lib/src/ta_abstract/tables/table_s.c\n",
            "ta-lib/src/ta_abstract/tables/table_y.c\n",
            "ta-lib/src/ta_abstract/tables/table_p.c\n",
            "ta-lib/src/ta_abstract/tables/table_z.c\n",
            "ta-lib/src/ta_abstract/tables/table_a.c\n",
            "ta-lib/src/ta_abstract/tables/table_w.c\n",
            "ta-lib/src/ta_abstract/ta_def_ui.c\n",
            "ta-lib/src/ta_abstract/templates/\n",
            "ta-lib/src/ta_abstract/templates/ta_x.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_java_defs.h.template\n",
            "ta-lib/src/ta_abstract/templates/excel_glue.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_group_idx.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_frame.c.template\n",
            "ta-lib/src/ta_abstract/templates/CoreAnnotated.java.template\n",
            "ta-lib/src/ta_abstract/templates/ta_func.h.template\n",
            "ta-lib/src/ta_abstract/templates/ta_frame.h.template\n",
            "ta-lib/src/ta_abstract/templates/Makefile.am.template\n",
            "ta-lib/src/ta_abstract/templates/ta_func_api.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_func.swg.template\n",
            "ta-lib/src/ta_abstract/templates/ta_retcode.c.template\n",
            "ta-lib/src/ta_abstract/ta_java_defs.h\n",
            "ta-lib/src/Makefile.am\n",
            "ta-lib/src/tools/\n",
            "ta-lib/src/tools/ta_regtest/\n",
            "ta-lib/src/tools/ta_regtest/test_util.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func.h\n",
            "ta-lib/src/tools/ta_regtest/test_data.c\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataHigh.c\n",
            "ta-lib/src/tools/ta_regtest/Makefile.in\n",
            "ta-lib/src/tools/ta_regtest/test_internals.c\n",
            "ta-lib/src/tools/ta_regtest/Makefile.am\n",
            "ta-lib/src/tools/ta_regtest/ta_regtest.c\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataOpen.c\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataClose.c\n",
            "ta-lib/src/tools/ta_regtest/test_abstract.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_bbands.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_stddev.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_1in_2out.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_sar.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_1in_1out.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_trange.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_macd.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_po.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_hlc.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_mom.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_ohlc.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_adx.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_candlestick.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_rsi.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_ema.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_minmax.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_hlcv.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_hl.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_stoch.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_ma.c\n",
            "ta-lib/src/tools/ta_regtest/ta_error_number.h\n",
            "ta-lib/src/tools/ta_regtest/ta_test_priv.h\n",
            "ta-lib/src/tools/ta_regtest/ReadMe.txt\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataLow.c\n",
            "ta-lib/src/tools/Makefile.in\n",
            "ta-lib/src/tools/Makefile.am\n",
            "ta-lib/src/tools/gen_code/\n",
            "ta-lib/src/tools/gen_code/java/\n",
            "ta-lib/src/tools/gen_code/java/PrettyCode.java\n",
            "ta-lib/src/tools/gen_code/java/Main.java\n",
            "ta-lib/src/tools/gen_code/gen_code.c\n",
            "ta-lib/src/tools/gen_code/Makefile.in\n",
            "ta-lib/src/tools/gen_code/Makefile.am\n",
            "ta-lib/src/tools/gen_code/mcpp.exe\n",
            "/content/ta-lib\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking for C compiler default output file name... a.out\n",
            "checking whether the C compiler works... yes\n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of executables... \n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... gcc3\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking for a sed that does not truncate output... /usr/bin/sed\n",
            "checking for grep that handles long lines and -e... /usr/bin/grep\n",
            "checking for egrep... /usr/bin/grep -E\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for BSD-compatible nm... /usr/bin/nm -B\n",
            "checking whether ln -s works... yes\n",
            "checking how to recognise dependent libraries... pass_all\n",
            "./configure: line 4349: /usr/bin/file: No such file or directory\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking dlfcn.h usability... yes\n",
            "checking dlfcn.h presence... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... gcc3\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for g77... no\n",
            "checking for xlf... no\n",
            "checking for f77... f77\n",
            "checking whether we are using the GNU Fortran 77 compiler... yes\n",
            "checking whether f77 accepts -g... yes\n",
            "checking the maximum length of command line arguments... 32768\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for objdir... .libs\n",
            "checking for ar... ar\n",
            "checking for ranlib... ranlib\n",
            "checking for strip... strip\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC\n",
            "checking if gcc PIC flag -fPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "configure: creating libtool\n",
            "appending configuration tag \"CXX\" to libtool\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC\n",
            "checking if g++ PIC flag -fPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "appending configuration tag \"F77\" to libtool\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking for f77 option to produce PIC... -fPIC\n",
            "checking if f77 PIC flag -fPIC works... yes\n",
            "checking if f77 static flag -static works... yes\n",
            "checking if f77 supports -c -o file.o... yes\n",
            "checking whether the f77 linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for dlopen in -ldl... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking float.h usability... yes\n",
            "checking float.h presence... yes\n",
            "checking for float.h... yes\n",
            "checking for inttypes.h... (cached) yes\n",
            "checking limits.h usability... yes\n",
            "checking limits.h presence... yes\n",
            "checking for limits.h... yes\n",
            "checking locale.h usability... yes\n",
            "checking locale.h presence... yes\n",
            "checking for locale.h... yes\n",
            "checking stddef.h usability... yes\n",
            "checking stddef.h presence... yes\n",
            "checking for stddef.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for string.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking wchar.h usability... yes\n",
            "checking wchar.h presence... yes\n",
            "checking for wchar.h... yes\n",
            "checking wctype.h usability... yes\n",
            "checking wctype.h presence... yes\n",
            "checking for wctype.h... yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking for size_t... yes\n",
            "checking whether struct tm is in sys/time.h or time.h... time.h\n",
            "checking for working volatile... yes\n",
            "checking for ptrdiff_t... yes\n",
            "checking return type of signal handlers... void\n",
            "checking for working strcoll... yes\n",
            "checking for strftime... yes\n",
            "checking for working strtod... yes\n",
            "checking for vprintf... yes\n",
            "checking for _doprnt... no\n",
            "checking for floor... no\n",
            "checking for isascii... yes\n",
            "checking for localeconv... yes\n",
            "checking for mblen... yes\n",
            "checking for memmove... yes\n",
            "checking for memset... yes\n",
            "checking for modf... yes\n",
            "checking for pow... no\n",
            "checking for sqrt... no\n",
            "checking for strcasecmp... yes\n",
            "checking for strchr... yes\n",
            "checking for strerror... yes\n",
            "checking for strncasecmp... yes\n",
            "checking for strrchr... yes\n",
            "checking for strstr... yes\n",
            "checking for strtol... yes\n",
            "checking for strtoul... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/ta_abstract/Makefile\n",
            "config.status: creating src/ta_common/Makefile\n",
            "config.status: creating src/ta_func/Makefile\n",
            "config.status: creating src/tools/Makefile\n",
            "config.status: creating src/tools/gen_code/Makefile\n",
            "config.status: creating src/tools/ta_regtest/Makefile\n",
            "config.status: creating ta-lib-config\n",
            "config.status: creating ta-lib.spec\n",
            "config.status: creating ta-lib.dpkg\n",
            "config.status: creating include/ta_config.h\n",
            "config.status: executing depfiles commands\n",
            "Making all in src\n",
            "make[1]: Entering directory '/content/ta-lib/src'\n",
            "Making all in ta_abstract\n",
            "make[2]: Entering directory '/content/ta-lib/src/ta_abstract'\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-ta_group_idx.lo -MD -MP -MF .deps/libta_abstract_la-ta_group_idx.Tpo -c -o libta_abstract_la-ta_group_idx.lo `test -f 'ta_group_idx.c' || echo './'`ta_group_idx.c\n",
            "mkdir .libs\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_group_idx.lo -MD -MP -MF .deps/libta_abstract_la-ta_group_idx.Tpo -c ta_group_idx.c  -fPIC -DPIC -o .libs/libta_abstract_la-ta_group_idx.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_group_idx.lo -MD -MP -MF .deps/libta_abstract_la-ta_group_idx.Tpo -c ta_group_idx.c -o libta_abstract_la-ta_group_idx.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-ta_group_idx.Tpo .deps/libta_abstract_la-ta_group_idx.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-ta_def_ui.lo -MD -MP -MF .deps/libta_abstract_la-ta_def_ui.Tpo -c -o libta_abstract_la-ta_def_ui.lo `test -f 'ta_def_ui.c' || echo './'`ta_def_ui.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_def_ui.lo -MD -MP -MF .deps/libta_abstract_la-ta_def_ui.Tpo -c ta_def_ui.c  -fPIC -DPIC -o .libs/libta_abstract_la-ta_def_ui.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_def_ui.lo -MD -MP -MF .deps/libta_abstract_la-ta_def_ui.Tpo -c ta_def_ui.c -o libta_abstract_la-ta_def_ui.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-ta_def_ui.Tpo .deps/libta_abstract_la-ta_def_ui.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-ta_abstract.lo -MD -MP -MF .deps/libta_abstract_la-ta_abstract.Tpo -c -o libta_abstract_la-ta_abstract.lo `test -f 'ta_abstract.c' || echo './'`ta_abstract.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_abstract.lo -MD -MP -MF .deps/libta_abstract_la-ta_abstract.Tpo -c ta_abstract.c  -fPIC -DPIC -o .libs/libta_abstract_la-ta_abstract.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_abstract.lo -MD -MP -MF .deps/libta_abstract_la-ta_abstract.Tpo -c ta_abstract.c -o libta_abstract_la-ta_abstract.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-ta_abstract.Tpo .deps/libta_abstract_la-ta_abstract.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-ta_func_api.lo -MD -MP -MF .deps/libta_abstract_la-ta_func_api.Tpo -c -o libta_abstract_la-ta_func_api.lo `test -f 'ta_func_api.c' || echo './'`ta_func_api.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_func_api.lo -MD -MP -MF .deps/libta_abstract_la-ta_func_api.Tpo -c ta_func_api.c  -fPIC -DPIC -o .libs/libta_abstract_la-ta_func_api.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_func_api.lo -MD -MP -MF .deps/libta_abstract_la-ta_func_api.Tpo -c ta_func_api.c -o libta_abstract_la-ta_func_api.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-ta_func_api.Tpo .deps/libta_abstract_la-ta_func_api.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-ta_frame.lo -MD -MP -MF .deps/libta_abstract_la-ta_frame.Tpo -c -o libta_abstract_la-ta_frame.lo `test -f 'frames/ta_frame.c' || echo './'`frames/ta_frame.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_frame.lo -MD -MP -MF .deps/libta_abstract_la-ta_frame.Tpo -c frames/ta_frame.c  -fPIC -DPIC -o .libs/libta_abstract_la-ta_frame.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-ta_frame.lo -MD -MP -MF .deps/libta_abstract_la-ta_frame.Tpo -c frames/ta_frame.c -o libta_abstract_la-ta_frame.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-ta_frame.Tpo .deps/libta_abstract_la-ta_frame.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_a.lo -MD -MP -MF .deps/libta_abstract_la-table_a.Tpo -c -o libta_abstract_la-table_a.lo `test -f 'tables/table_a.c' || echo './'`tables/table_a.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_a.lo -MD -MP -MF .deps/libta_abstract_la-table_a.Tpo -c tables/table_a.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_a.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_a.lo -MD -MP -MF .deps/libta_abstract_la-table_a.Tpo -c tables/table_a.c -o libta_abstract_la-table_a.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_a.Tpo .deps/libta_abstract_la-table_a.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_b.lo -MD -MP -MF .deps/libta_abstract_la-table_b.Tpo -c -o libta_abstract_la-table_b.lo `test -f 'tables/table_b.c' || echo './'`tables/table_b.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_b.lo -MD -MP -MF .deps/libta_abstract_la-table_b.Tpo -c tables/table_b.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_b.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_b.lo -MD -MP -MF .deps/libta_abstract_la-table_b.Tpo -c tables/table_b.c -o libta_abstract_la-table_b.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_b.Tpo .deps/libta_abstract_la-table_b.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_c.lo -MD -MP -MF .deps/libta_abstract_la-table_c.Tpo -c -o libta_abstract_la-table_c.lo `test -f 'tables/table_c.c' || echo './'`tables/table_c.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_c.lo -MD -MP -MF .deps/libta_abstract_la-table_c.Tpo -c tables/table_c.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_c.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_c.lo -MD -MP -MF .deps/libta_abstract_la-table_c.Tpo -c tables/table_c.c -o libta_abstract_la-table_c.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_c.Tpo .deps/libta_abstract_la-table_c.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_d.lo -MD -MP -MF .deps/libta_abstract_la-table_d.Tpo -c -o libta_abstract_la-table_d.lo `test -f 'tables/table_d.c' || echo './'`tables/table_d.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_d.lo -MD -MP -MF .deps/libta_abstract_la-table_d.Tpo -c tables/table_d.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_d.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_d.lo -MD -MP -MF .deps/libta_abstract_la-table_d.Tpo -c tables/table_d.c -o libta_abstract_la-table_d.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_d.Tpo .deps/libta_abstract_la-table_d.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_e.lo -MD -MP -MF .deps/libta_abstract_la-table_e.Tpo -c -o libta_abstract_la-table_e.lo `test -f 'tables/table_e.c' || echo './'`tables/table_e.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_e.lo -MD -MP -MF .deps/libta_abstract_la-table_e.Tpo -c tables/table_e.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_e.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_e.lo -MD -MP -MF .deps/libta_abstract_la-table_e.Tpo -c tables/table_e.c -o libta_abstract_la-table_e.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_e.Tpo .deps/libta_abstract_la-table_e.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_f.lo -MD -MP -MF .deps/libta_abstract_la-table_f.Tpo -c -o libta_abstract_la-table_f.lo `test -f 'tables/table_f.c' || echo './'`tables/table_f.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_f.lo -MD -MP -MF .deps/libta_abstract_la-table_f.Tpo -c tables/table_f.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_f.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_f.lo -MD -MP -MF .deps/libta_abstract_la-table_f.Tpo -c tables/table_f.c -o libta_abstract_la-table_f.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_f.Tpo .deps/libta_abstract_la-table_f.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_g.lo -MD -MP -MF .deps/libta_abstract_la-table_g.Tpo -c -o libta_abstract_la-table_g.lo `test -f 'tables/table_g.c' || echo './'`tables/table_g.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_g.lo -MD -MP -MF .deps/libta_abstract_la-table_g.Tpo -c tables/table_g.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_g.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_g.lo -MD -MP -MF .deps/libta_abstract_la-table_g.Tpo -c tables/table_g.c -o libta_abstract_la-table_g.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_g.Tpo .deps/libta_abstract_la-table_g.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_h.lo -MD -MP -MF .deps/libta_abstract_la-table_h.Tpo -c -o libta_abstract_la-table_h.lo `test -f 'tables/table_h.c' || echo './'`tables/table_h.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_h.lo -MD -MP -MF .deps/libta_abstract_la-table_h.Tpo -c tables/table_h.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_h.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_h.lo -MD -MP -MF .deps/libta_abstract_la-table_h.Tpo -c tables/table_h.c -o libta_abstract_la-table_h.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_h.Tpo .deps/libta_abstract_la-table_h.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_i.lo -MD -MP -MF .deps/libta_abstract_la-table_i.Tpo -c -o libta_abstract_la-table_i.lo `test -f 'tables/table_i.c' || echo './'`tables/table_i.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_i.lo -MD -MP -MF .deps/libta_abstract_la-table_i.Tpo -c tables/table_i.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_i.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_i.lo -MD -MP -MF .deps/libta_abstract_la-table_i.Tpo -c tables/table_i.c -o libta_abstract_la-table_i.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_i.Tpo .deps/libta_abstract_la-table_i.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_j.lo -MD -MP -MF .deps/libta_abstract_la-table_j.Tpo -c -o libta_abstract_la-table_j.lo `test -f 'tables/table_j.c' || echo './'`tables/table_j.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_j.lo -MD -MP -MF .deps/libta_abstract_la-table_j.Tpo -c tables/table_j.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_j.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_j.lo -MD -MP -MF .deps/libta_abstract_la-table_j.Tpo -c tables/table_j.c -o libta_abstract_la-table_j.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_j.Tpo .deps/libta_abstract_la-table_j.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_k.lo -MD -MP -MF .deps/libta_abstract_la-table_k.Tpo -c -o libta_abstract_la-table_k.lo `test -f 'tables/table_k.c' || echo './'`tables/table_k.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_k.lo -MD -MP -MF .deps/libta_abstract_la-table_k.Tpo -c tables/table_k.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_k.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_k.lo -MD -MP -MF .deps/libta_abstract_la-table_k.Tpo -c tables/table_k.c -o libta_abstract_la-table_k.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_k.Tpo .deps/libta_abstract_la-table_k.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_l.lo -MD -MP -MF .deps/libta_abstract_la-table_l.Tpo -c -o libta_abstract_la-table_l.lo `test -f 'tables/table_l.c' || echo './'`tables/table_l.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_l.lo -MD -MP -MF .deps/libta_abstract_la-table_l.Tpo -c tables/table_l.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_l.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_l.lo -MD -MP -MF .deps/libta_abstract_la-table_l.Tpo -c tables/table_l.c -o libta_abstract_la-table_l.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_l.Tpo .deps/libta_abstract_la-table_l.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_m.lo -MD -MP -MF .deps/libta_abstract_la-table_m.Tpo -c -o libta_abstract_la-table_m.lo `test -f 'tables/table_m.c' || echo './'`tables/table_m.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_m.lo -MD -MP -MF .deps/libta_abstract_la-table_m.Tpo -c tables/table_m.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_m.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_m.lo -MD -MP -MF .deps/libta_abstract_la-table_m.Tpo -c tables/table_m.c -o libta_abstract_la-table_m.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_m.Tpo .deps/libta_abstract_la-table_m.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_n.lo -MD -MP -MF .deps/libta_abstract_la-table_n.Tpo -c -o libta_abstract_la-table_n.lo `test -f 'tables/table_n.c' || echo './'`tables/table_n.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_n.lo -MD -MP -MF .deps/libta_abstract_la-table_n.Tpo -c tables/table_n.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_n.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_n.lo -MD -MP -MF .deps/libta_abstract_la-table_n.Tpo -c tables/table_n.c -o libta_abstract_la-table_n.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_n.Tpo .deps/libta_abstract_la-table_n.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_o.lo -MD -MP -MF .deps/libta_abstract_la-table_o.Tpo -c -o libta_abstract_la-table_o.lo `test -f 'tables/table_o.c' || echo './'`tables/table_o.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_o.lo -MD -MP -MF .deps/libta_abstract_la-table_o.Tpo -c tables/table_o.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_o.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_o.lo -MD -MP -MF .deps/libta_abstract_la-table_o.Tpo -c tables/table_o.c -o libta_abstract_la-table_o.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_o.Tpo .deps/libta_abstract_la-table_o.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_p.lo -MD -MP -MF .deps/libta_abstract_la-table_p.Tpo -c -o libta_abstract_la-table_p.lo `test -f 'tables/table_p.c' || echo './'`tables/table_p.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_p.lo -MD -MP -MF .deps/libta_abstract_la-table_p.Tpo -c tables/table_p.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_p.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_p.lo -MD -MP -MF .deps/libta_abstract_la-table_p.Tpo -c tables/table_p.c -o libta_abstract_la-table_p.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_p.Tpo .deps/libta_abstract_la-table_p.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_q.lo -MD -MP -MF .deps/libta_abstract_la-table_q.Tpo -c -o libta_abstract_la-table_q.lo `test -f 'tables/table_q.c' || echo './'`tables/table_q.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_q.lo -MD -MP -MF .deps/libta_abstract_la-table_q.Tpo -c tables/table_q.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_q.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_q.lo -MD -MP -MF .deps/libta_abstract_la-table_q.Tpo -c tables/table_q.c -o libta_abstract_la-table_q.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_q.Tpo .deps/libta_abstract_la-table_q.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_r.lo -MD -MP -MF .deps/libta_abstract_la-table_r.Tpo -c -o libta_abstract_la-table_r.lo `test -f 'tables/table_r.c' || echo './'`tables/table_r.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_r.lo -MD -MP -MF .deps/libta_abstract_la-table_r.Tpo -c tables/table_r.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_r.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_r.lo -MD -MP -MF .deps/libta_abstract_la-table_r.Tpo -c tables/table_r.c -o libta_abstract_la-table_r.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_r.Tpo .deps/libta_abstract_la-table_r.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_s.lo -MD -MP -MF .deps/libta_abstract_la-table_s.Tpo -c -o libta_abstract_la-table_s.lo `test -f 'tables/table_s.c' || echo './'`tables/table_s.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_s.lo -MD -MP -MF .deps/libta_abstract_la-table_s.Tpo -c tables/table_s.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_s.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_s.lo -MD -MP -MF .deps/libta_abstract_la-table_s.Tpo -c tables/table_s.c -o libta_abstract_la-table_s.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_s.Tpo .deps/libta_abstract_la-table_s.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_t.lo -MD -MP -MF .deps/libta_abstract_la-table_t.Tpo -c -o libta_abstract_la-table_t.lo `test -f 'tables/table_t.c' || echo './'`tables/table_t.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_t.lo -MD -MP -MF .deps/libta_abstract_la-table_t.Tpo -c tables/table_t.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_t.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_t.lo -MD -MP -MF .deps/libta_abstract_la-table_t.Tpo -c tables/table_t.c -o libta_abstract_la-table_t.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_t.Tpo .deps/libta_abstract_la-table_t.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_u.lo -MD -MP -MF .deps/libta_abstract_la-table_u.Tpo -c -o libta_abstract_la-table_u.lo `test -f 'tables/table_u.c' || echo './'`tables/table_u.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_u.lo -MD -MP -MF .deps/libta_abstract_la-table_u.Tpo -c tables/table_u.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_u.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_u.lo -MD -MP -MF .deps/libta_abstract_la-table_u.Tpo -c tables/table_u.c -o libta_abstract_la-table_u.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_u.Tpo .deps/libta_abstract_la-table_u.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_v.lo -MD -MP -MF .deps/libta_abstract_la-table_v.Tpo -c -o libta_abstract_la-table_v.lo `test -f 'tables/table_v.c' || echo './'`tables/table_v.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_v.lo -MD -MP -MF .deps/libta_abstract_la-table_v.Tpo -c tables/table_v.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_v.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_v.lo -MD -MP -MF .deps/libta_abstract_la-table_v.Tpo -c tables/table_v.c -o libta_abstract_la-table_v.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_v.Tpo .deps/libta_abstract_la-table_v.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_w.lo -MD -MP -MF .deps/libta_abstract_la-table_w.Tpo -c -o libta_abstract_la-table_w.lo `test -f 'tables/table_w.c' || echo './'`tables/table_w.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_w.lo -MD -MP -MF .deps/libta_abstract_la-table_w.Tpo -c tables/table_w.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_w.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_w.lo -MD -MP -MF .deps/libta_abstract_la-table_w.Tpo -c tables/table_w.c -o libta_abstract_la-table_w.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_w.Tpo .deps/libta_abstract_la-table_w.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_x.lo -MD -MP -MF .deps/libta_abstract_la-table_x.Tpo -c -o libta_abstract_la-table_x.lo `test -f 'tables/table_x.c' || echo './'`tables/table_x.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_x.lo -MD -MP -MF .deps/libta_abstract_la-table_x.Tpo -c tables/table_x.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_x.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_x.lo -MD -MP -MF .deps/libta_abstract_la-table_x.Tpo -c tables/table_x.c -o libta_abstract_la-table_x.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_x.Tpo .deps/libta_abstract_la-table_x.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_y.lo -MD -MP -MF .deps/libta_abstract_la-table_y.Tpo -c -o libta_abstract_la-table_y.lo `test -f 'tables/table_y.c' || echo './'`tables/table_y.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_y.lo -MD -MP -MF .deps/libta_abstract_la-table_y.Tpo -c tables/table_y.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_y.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_y.lo -MD -MP -MF .deps/libta_abstract_la-table_y.Tpo -c tables/table_y.c -o libta_abstract_la-table_y.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_y.Tpo .deps/libta_abstract_la-table_y.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_la-table_z.lo -MD -MP -MF .deps/libta_abstract_la-table_z.Tpo -c -o libta_abstract_la-table_z.lo `test -f 'tables/table_z.c' || echo './'`tables/table_z.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_z.lo -MD -MP -MF .deps/libta_abstract_la-table_z.Tpo -c tables/table_z.c  -fPIC -DPIC -o .libs/libta_abstract_la-table_z.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_la-table_z.lo -MD -MP -MF .deps/libta_abstract_la-table_z.Tpo -c tables/table_z.c -o libta_abstract_la-table_z.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_la-table_z.Tpo .deps/libta_abstract_la-table_z.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=link gcc  -g -O2 -version-info 0:0:0  -o libta_abstract.la  libta_abstract_la-ta_group_idx.lo libta_abstract_la-ta_def_ui.lo libta_abstract_la-ta_abstract.lo libta_abstract_la-ta_func_api.lo libta_abstract_la-ta_frame.lo libta_abstract_la-table_a.lo libta_abstract_la-table_b.lo libta_abstract_la-table_c.lo libta_abstract_la-table_d.lo libta_abstract_la-table_e.lo libta_abstract_la-table_f.lo libta_abstract_la-table_g.lo libta_abstract_la-table_h.lo libta_abstract_la-table_i.lo libta_abstract_la-table_j.lo libta_abstract_la-table_k.lo libta_abstract_la-table_l.lo libta_abstract_la-table_m.lo libta_abstract_la-table_n.lo libta_abstract_la-table_o.lo libta_abstract_la-table_p.lo libta_abstract_la-table_q.lo libta_abstract_la-table_r.lo libta_abstract_la-table_s.lo libta_abstract_la-table_t.lo libta_abstract_la-table_u.lo libta_abstract_la-table_v.lo libta_abstract_la-table_w.lo libta_abstract_la-table_x.lo libta_abstract_la-table_y.lo libta_abstract_la-table_z.lo  -lpthread -ldl \n",
            "libtool: link: warning: `-version-info/-version-number' is ignored for convenience libraries\n",
            "ar cru .libs/libta_abstract.a .libs/libta_abstract_la-ta_group_idx.o .libs/libta_abstract_la-ta_def_ui.o .libs/libta_abstract_la-ta_abstract.o .libs/libta_abstract_la-ta_func_api.o .libs/libta_abstract_la-ta_frame.o .libs/libta_abstract_la-table_a.o .libs/libta_abstract_la-table_b.o .libs/libta_abstract_la-table_c.o .libs/libta_abstract_la-table_d.o .libs/libta_abstract_la-table_e.o .libs/libta_abstract_la-table_f.o .libs/libta_abstract_la-table_g.o .libs/libta_abstract_la-table_h.o .libs/libta_abstract_la-table_i.o .libs/libta_abstract_la-table_j.o .libs/libta_abstract_la-table_k.o .libs/libta_abstract_la-table_l.o .libs/libta_abstract_la-table_m.o .libs/libta_abstract_la-table_n.o .libs/libta_abstract_la-table_o.o .libs/libta_abstract_la-table_p.o .libs/libta_abstract_la-table_q.o .libs/libta_abstract_la-table_r.o .libs/libta_abstract_la-table_s.o .libs/libta_abstract_la-table_t.o .libs/libta_abstract_la-table_u.o .libs/libta_abstract_la-table_v.o .libs/libta_abstract_la-table_w.o .libs/libta_abstract_la-table_x.o .libs/libta_abstract_la-table_y.o .libs/libta_abstract_la-table_z.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "ranlib .libs/libta_abstract.a\n",
            "creating libta_abstract.la\n",
            "(cd .libs && rm -f libta_abstract.la && ln -s ../libta_abstract.la libta_abstract.la)\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-ta_group_idx.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_group_idx.Tpo -c -o libta_abstract_gc_la-ta_group_idx.lo `test -f 'ta_group_idx.c' || echo './'`ta_group_idx.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_group_idx.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_group_idx.Tpo -c ta_group_idx.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-ta_group_idx.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_group_idx.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_group_idx.Tpo -c ta_group_idx.c -o libta_abstract_gc_la-ta_group_idx.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-ta_group_idx.Tpo .deps/libta_abstract_gc_la-ta_group_idx.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-ta_def_ui.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_def_ui.Tpo -c -o libta_abstract_gc_la-ta_def_ui.lo `test -f 'ta_def_ui.c' || echo './'`ta_def_ui.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_def_ui.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_def_ui.Tpo -c ta_def_ui.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-ta_def_ui.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_def_ui.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_def_ui.Tpo -c ta_def_ui.c -o libta_abstract_gc_la-ta_def_ui.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-ta_def_ui.Tpo .deps/libta_abstract_gc_la-ta_def_ui.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-ta_abstract.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_abstract.Tpo -c -o libta_abstract_gc_la-ta_abstract.lo `test -f 'ta_abstract.c' || echo './'`ta_abstract.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_abstract.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_abstract.Tpo -c ta_abstract.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-ta_abstract.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_abstract.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_abstract.Tpo -c ta_abstract.c -o libta_abstract_gc_la-ta_abstract.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-ta_abstract.Tpo .deps/libta_abstract_gc_la-ta_abstract.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-ta_func_api.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_func_api.Tpo -c -o libta_abstract_gc_la-ta_func_api.lo `test -f 'ta_func_api.c' || echo './'`ta_func_api.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_func_api.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_func_api.Tpo -c ta_func_api.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-ta_func_api.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_func_api.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_func_api.Tpo -c ta_func_api.c -o libta_abstract_gc_la-ta_func_api.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-ta_func_api.Tpo .deps/libta_abstract_gc_la-ta_func_api.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-ta_frame.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_frame.Tpo -c -o libta_abstract_gc_la-ta_frame.lo `test -f 'frames/ta_frame.c' || echo './'`frames/ta_frame.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_frame.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_frame.Tpo -c frames/ta_frame.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-ta_frame.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-ta_frame.lo -MD -MP -MF .deps/libta_abstract_gc_la-ta_frame.Tpo -c frames/ta_frame.c -o libta_abstract_gc_la-ta_frame.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-ta_frame.Tpo .deps/libta_abstract_gc_la-ta_frame.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_a.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_a.Tpo -c -o libta_abstract_gc_la-table_a.lo `test -f 'tables/table_a.c' || echo './'`tables/table_a.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_a.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_a.Tpo -c tables/table_a.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_a.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_a.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_a.Tpo -c tables/table_a.c -o libta_abstract_gc_la-table_a.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_a.Tpo .deps/libta_abstract_gc_la-table_a.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_b.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_b.Tpo -c -o libta_abstract_gc_la-table_b.lo `test -f 'tables/table_b.c' || echo './'`tables/table_b.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_b.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_b.Tpo -c tables/table_b.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_b.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_b.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_b.Tpo -c tables/table_b.c -o libta_abstract_gc_la-table_b.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_b.Tpo .deps/libta_abstract_gc_la-table_b.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_c.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_c.Tpo -c -o libta_abstract_gc_la-table_c.lo `test -f 'tables/table_c.c' || echo './'`tables/table_c.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_c.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_c.Tpo -c tables/table_c.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_c.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_c.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_c.Tpo -c tables/table_c.c -o libta_abstract_gc_la-table_c.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_c.Tpo .deps/libta_abstract_gc_la-table_c.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_d.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_d.Tpo -c -o libta_abstract_gc_la-table_d.lo `test -f 'tables/table_d.c' || echo './'`tables/table_d.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_d.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_d.Tpo -c tables/table_d.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_d.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_d.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_d.Tpo -c tables/table_d.c -o libta_abstract_gc_la-table_d.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_d.Tpo .deps/libta_abstract_gc_la-table_d.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_e.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_e.Tpo -c -o libta_abstract_gc_la-table_e.lo `test -f 'tables/table_e.c' || echo './'`tables/table_e.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_e.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_e.Tpo -c tables/table_e.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_e.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_e.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_e.Tpo -c tables/table_e.c -o libta_abstract_gc_la-table_e.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_e.Tpo .deps/libta_abstract_gc_la-table_e.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_f.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_f.Tpo -c -o libta_abstract_gc_la-table_f.lo `test -f 'tables/table_f.c' || echo './'`tables/table_f.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_f.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_f.Tpo -c tables/table_f.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_f.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_f.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_f.Tpo -c tables/table_f.c -o libta_abstract_gc_la-table_f.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_f.Tpo .deps/libta_abstract_gc_la-table_f.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_g.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_g.Tpo -c -o libta_abstract_gc_la-table_g.lo `test -f 'tables/table_g.c' || echo './'`tables/table_g.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_g.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_g.Tpo -c tables/table_g.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_g.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_g.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_g.Tpo -c tables/table_g.c -o libta_abstract_gc_la-table_g.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_g.Tpo .deps/libta_abstract_gc_la-table_g.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_h.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_h.Tpo -c -o libta_abstract_gc_la-table_h.lo `test -f 'tables/table_h.c' || echo './'`tables/table_h.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_h.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_h.Tpo -c tables/table_h.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_h.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_h.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_h.Tpo -c tables/table_h.c -o libta_abstract_gc_la-table_h.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_h.Tpo .deps/libta_abstract_gc_la-table_h.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_i.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_i.Tpo -c -o libta_abstract_gc_la-table_i.lo `test -f 'tables/table_i.c' || echo './'`tables/table_i.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_i.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_i.Tpo -c tables/table_i.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_i.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_i.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_i.Tpo -c tables/table_i.c -o libta_abstract_gc_la-table_i.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_i.Tpo .deps/libta_abstract_gc_la-table_i.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_j.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_j.Tpo -c -o libta_abstract_gc_la-table_j.lo `test -f 'tables/table_j.c' || echo './'`tables/table_j.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_j.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_j.Tpo -c tables/table_j.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_j.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_j.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_j.Tpo -c tables/table_j.c -o libta_abstract_gc_la-table_j.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_j.Tpo .deps/libta_abstract_gc_la-table_j.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_k.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_k.Tpo -c -o libta_abstract_gc_la-table_k.lo `test -f 'tables/table_k.c' || echo './'`tables/table_k.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_k.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_k.Tpo -c tables/table_k.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_k.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_k.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_k.Tpo -c tables/table_k.c -o libta_abstract_gc_la-table_k.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_k.Tpo .deps/libta_abstract_gc_la-table_k.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_l.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_l.Tpo -c -o libta_abstract_gc_la-table_l.lo `test -f 'tables/table_l.c' || echo './'`tables/table_l.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_l.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_l.Tpo -c tables/table_l.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_l.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_l.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_l.Tpo -c tables/table_l.c -o libta_abstract_gc_la-table_l.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_l.Tpo .deps/libta_abstract_gc_la-table_l.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_m.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_m.Tpo -c -o libta_abstract_gc_la-table_m.lo `test -f 'tables/table_m.c' || echo './'`tables/table_m.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_m.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_m.Tpo -c tables/table_m.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_m.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_m.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_m.Tpo -c tables/table_m.c -o libta_abstract_gc_la-table_m.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_m.Tpo .deps/libta_abstract_gc_la-table_m.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_n.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_n.Tpo -c -o libta_abstract_gc_la-table_n.lo `test -f 'tables/table_n.c' || echo './'`tables/table_n.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_n.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_n.Tpo -c tables/table_n.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_n.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_n.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_n.Tpo -c tables/table_n.c -o libta_abstract_gc_la-table_n.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_n.Tpo .deps/libta_abstract_gc_la-table_n.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_o.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_o.Tpo -c -o libta_abstract_gc_la-table_o.lo `test -f 'tables/table_o.c' || echo './'`tables/table_o.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_o.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_o.Tpo -c tables/table_o.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_o.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_o.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_o.Tpo -c tables/table_o.c -o libta_abstract_gc_la-table_o.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_o.Tpo .deps/libta_abstract_gc_la-table_o.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_p.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_p.Tpo -c -o libta_abstract_gc_la-table_p.lo `test -f 'tables/table_p.c' || echo './'`tables/table_p.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_p.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_p.Tpo -c tables/table_p.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_p.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_p.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_p.Tpo -c tables/table_p.c -o libta_abstract_gc_la-table_p.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_p.Tpo .deps/libta_abstract_gc_la-table_p.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_q.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_q.Tpo -c -o libta_abstract_gc_la-table_q.lo `test -f 'tables/table_q.c' || echo './'`tables/table_q.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_q.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_q.Tpo -c tables/table_q.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_q.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_q.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_q.Tpo -c tables/table_q.c -o libta_abstract_gc_la-table_q.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_q.Tpo .deps/libta_abstract_gc_la-table_q.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_r.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_r.Tpo -c -o libta_abstract_gc_la-table_r.lo `test -f 'tables/table_r.c' || echo './'`tables/table_r.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_r.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_r.Tpo -c tables/table_r.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_r.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_r.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_r.Tpo -c tables/table_r.c -o libta_abstract_gc_la-table_r.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_r.Tpo .deps/libta_abstract_gc_la-table_r.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_s.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_s.Tpo -c -o libta_abstract_gc_la-table_s.lo `test -f 'tables/table_s.c' || echo './'`tables/table_s.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_s.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_s.Tpo -c tables/table_s.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_s.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_s.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_s.Tpo -c tables/table_s.c -o libta_abstract_gc_la-table_s.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_s.Tpo .deps/libta_abstract_gc_la-table_s.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_t.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_t.Tpo -c -o libta_abstract_gc_la-table_t.lo `test -f 'tables/table_t.c' || echo './'`tables/table_t.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_t.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_t.Tpo -c tables/table_t.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_t.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_t.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_t.Tpo -c tables/table_t.c -o libta_abstract_gc_la-table_t.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_t.Tpo .deps/libta_abstract_gc_la-table_t.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_u.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_u.Tpo -c -o libta_abstract_gc_la-table_u.lo `test -f 'tables/table_u.c' || echo './'`tables/table_u.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_u.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_u.Tpo -c tables/table_u.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_u.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_u.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_u.Tpo -c tables/table_u.c -o libta_abstract_gc_la-table_u.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_u.Tpo .deps/libta_abstract_gc_la-table_u.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_v.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_v.Tpo -c -o libta_abstract_gc_la-table_v.lo `test -f 'tables/table_v.c' || echo './'`tables/table_v.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_v.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_v.Tpo -c tables/table_v.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_v.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_v.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_v.Tpo -c tables/table_v.c -o libta_abstract_gc_la-table_v.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_v.Tpo .deps/libta_abstract_gc_la-table_v.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_w.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_w.Tpo -c -o libta_abstract_gc_la-table_w.lo `test -f 'tables/table_w.c' || echo './'`tables/table_w.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_w.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_w.Tpo -c tables/table_w.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_w.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_w.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_w.Tpo -c tables/table_w.c -o libta_abstract_gc_la-table_w.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_w.Tpo .deps/libta_abstract_gc_la-table_w.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_x.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_x.Tpo -c -o libta_abstract_gc_la-table_x.lo `test -f 'tables/table_x.c' || echo './'`tables/table_x.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_x.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_x.Tpo -c tables/table_x.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_x.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_x.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_x.Tpo -c tables/table_x.c -o libta_abstract_gc_la-table_x.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_x.Tpo .deps/libta_abstract_gc_la-table_x.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_y.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_y.Tpo -c -o libta_abstract_gc_la-table_y.lo `test -f 'tables/table_y.c' || echo './'`tables/table_y.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_y.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_y.Tpo -c tables/table_y.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_y.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_y.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_y.Tpo -c tables/table_y.c -o libta_abstract_gc_la-table_y.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_y.Tpo .deps/libta_abstract_gc_la-table_y.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -DTA_GEN_CODE -I../ta_common/ -Iframes/   -g -O2 -MT libta_abstract_gc_la-table_z.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_z.Tpo -c -o libta_abstract_gc_la-table_z.lo `test -f 'tables/table_z.c' || echo './'`tables/table_z.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_z.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_z.Tpo -c tables/table_z.c  -fPIC -DPIC -o .libs/libta_abstract_gc_la-table_z.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -DTA_GEN_CODE -I../ta_common/ -Iframes/ -g -O2 -MT libta_abstract_gc_la-table_z.lo -MD -MP -MF .deps/libta_abstract_gc_la-table_z.Tpo -c tables/table_z.c -o libta_abstract_gc_la-table_z.o >/dev/null 2>&1\n",
            "mv -f .deps/libta_abstract_gc_la-table_z.Tpo .deps/libta_abstract_gc_la-table_z.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=link gcc  -g -O2 -version-info 0:0:0  -o libta_abstract_gc.la  libta_abstract_gc_la-ta_group_idx.lo libta_abstract_gc_la-ta_def_ui.lo libta_abstract_gc_la-ta_abstract.lo libta_abstract_gc_la-ta_func_api.lo libta_abstract_gc_la-ta_frame.lo libta_abstract_gc_la-table_a.lo libta_abstract_gc_la-table_b.lo libta_abstract_gc_la-table_c.lo libta_abstract_gc_la-table_d.lo libta_abstract_gc_la-table_e.lo libta_abstract_gc_la-table_f.lo libta_abstract_gc_la-table_g.lo libta_abstract_gc_la-table_h.lo libta_abstract_gc_la-table_i.lo libta_abstract_gc_la-table_j.lo libta_abstract_gc_la-table_k.lo libta_abstract_gc_la-table_l.lo libta_abstract_gc_la-table_m.lo libta_abstract_gc_la-table_n.lo libta_abstract_gc_la-table_o.lo libta_abstract_gc_la-table_p.lo libta_abstract_gc_la-table_q.lo libta_abstract_gc_la-table_r.lo libta_abstract_gc_la-table_s.lo libta_abstract_gc_la-table_t.lo libta_abstract_gc_la-table_u.lo libta_abstract_gc_la-table_v.lo libta_abstract_gc_la-table_w.lo libta_abstract_gc_la-table_x.lo libta_abstract_gc_la-table_y.lo libta_abstract_gc_la-table_z.lo  -lpthread -ldl \n",
            "libtool: link: warning: `-version-info/-version-number' is ignored for convenience libraries\n",
            "ar cru .libs/libta_abstract_gc.a .libs/libta_abstract_gc_la-ta_group_idx.o .libs/libta_abstract_gc_la-ta_def_ui.o .libs/libta_abstract_gc_la-ta_abstract.o .libs/libta_abstract_gc_la-ta_func_api.o .libs/libta_abstract_gc_la-ta_frame.o .libs/libta_abstract_gc_la-table_a.o .libs/libta_abstract_gc_la-table_b.o .libs/libta_abstract_gc_la-table_c.o .libs/libta_abstract_gc_la-table_d.o .libs/libta_abstract_gc_la-table_e.o .libs/libta_abstract_gc_la-table_f.o .libs/libta_abstract_gc_la-table_g.o .libs/libta_abstract_gc_la-table_h.o .libs/libta_abstract_gc_la-table_i.o .libs/libta_abstract_gc_la-table_j.o .libs/libta_abstract_gc_la-table_k.o .libs/libta_abstract_gc_la-table_l.o .libs/libta_abstract_gc_la-table_m.o .libs/libta_abstract_gc_la-table_n.o .libs/libta_abstract_gc_la-table_o.o .libs/libta_abstract_gc_la-table_p.o .libs/libta_abstract_gc_la-table_q.o .libs/libta_abstract_gc_la-table_r.o .libs/libta_abstract_gc_la-table_s.o .libs/libta_abstract_gc_la-table_t.o .libs/libta_abstract_gc_la-table_u.o .libs/libta_abstract_gc_la-table_v.o .libs/libta_abstract_gc_la-table_w.o .libs/libta_abstract_gc_la-table_x.o .libs/libta_abstract_gc_la-table_y.o .libs/libta_abstract_gc_la-table_z.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "ranlib .libs/libta_abstract_gc.a\n",
            "creating libta_abstract_gc.la\n",
            "(cd .libs && rm -f libta_abstract_gc.la && ln -s ../libta_abstract_gc.la libta_abstract_gc.la)\n",
            "make[2]: Leaving directory '/content/ta-lib/src/ta_abstract'\n",
            "Making all in ta_common\n",
            "make[2]: Entering directory '/content/ta-lib/src/ta_common'\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_global.lo -MD -MP -MF .deps/ta_global.Tpo -c -o ta_global.lo ta_global.c\n",
            "mkdir .libs\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_global.lo -MD -MP -MF .deps/ta_global.Tpo -c ta_global.c  -fPIC -DPIC -o .libs/ta_global.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_global.lo -MD -MP -MF .deps/ta_global.Tpo -c ta_global.c -o ta_global.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_global.Tpo .deps/ta_global.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_retcode.lo -MD -MP -MF .deps/ta_retcode.Tpo -c -o ta_retcode.lo ta_retcode.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_retcode.lo -MD -MP -MF .deps/ta_retcode.Tpo -c ta_retcode.c  -fPIC -DPIC -o .libs/ta_retcode.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_retcode.lo -MD -MP -MF .deps/ta_retcode.Tpo -c ta_retcode.c -o ta_retcode.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_retcode.Tpo .deps/ta_retcode.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_version.lo -MD -MP -MF .deps/ta_version.Tpo -c -o ta_version.lo ta_version.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_version.lo -MD -MP -MF .deps/ta_version.Tpo -c ta_version.c  -fPIC -DPIC -o .libs/ta_version.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_version.lo -MD -MP -MF .deps/ta_version.Tpo -c ta_version.c -o ta_version.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_version.Tpo .deps/ta_version.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=link gcc  -g -O2 -version-info 0:0:0  -o libta_common.la  ta_global.lo ta_retcode.lo ta_version.lo  -lpthread -ldl \n",
            "libtool: link: warning: `-version-info/-version-number' is ignored for convenience libraries\n",
            "ar cru .libs/libta_common.a .libs/ta_global.o .libs/ta_retcode.o .libs/ta_version.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "ranlib .libs/libta_common.a\n",
            "creating libta_common.la\n",
            "(cd .libs && rm -f libta_common.la && ln -s ../libta_common.la libta_common.la)\n",
            "make[2]: Leaving directory '/content/ta-lib/src/ta_common'\n",
            "Making all in ta_func\n",
            "make[2]: Entering directory '/content/ta-lib/src/ta_func'\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_utility.lo -MD -MP -MF .deps/ta_utility.Tpo -c -o ta_utility.lo ta_utility.c\n",
            "mkdir .libs\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_utility.lo -MD -MP -MF .deps/ta_utility.Tpo -c ta_utility.c  -fPIC -DPIC -o .libs/ta_utility.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_utility.lo -MD -MP -MF .deps/ta_utility.Tpo -c ta_utility.c -o ta_utility.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_utility.Tpo .deps/ta_utility.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ACOS.lo -MD -MP -MF .deps/ta_ACOS.Tpo -c -o ta_ACOS.lo ta_ACOS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ACOS.lo -MD -MP -MF .deps/ta_ACOS.Tpo -c ta_ACOS.c  -fPIC -DPIC -o .libs/ta_ACOS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ACOS.lo -MD -MP -MF .deps/ta_ACOS.Tpo -c ta_ACOS.c -o ta_ACOS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ACOS.Tpo .deps/ta_ACOS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_AD.lo -MD -MP -MF .deps/ta_AD.Tpo -c -o ta_AD.lo ta_AD.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AD.lo -MD -MP -MF .deps/ta_AD.Tpo -c ta_AD.c  -fPIC -DPIC -o .libs/ta_AD.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AD.lo -MD -MP -MF .deps/ta_AD.Tpo -c ta_AD.c -o ta_AD.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_AD.Tpo .deps/ta_AD.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ADD.lo -MD -MP -MF .deps/ta_ADD.Tpo -c -o ta_ADD.lo ta_ADD.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADD.lo -MD -MP -MF .deps/ta_ADD.Tpo -c ta_ADD.c  -fPIC -DPIC -o .libs/ta_ADD.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADD.lo -MD -MP -MF .deps/ta_ADD.Tpo -c ta_ADD.c -o ta_ADD.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ADD.Tpo .deps/ta_ADD.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ADOSC.lo -MD -MP -MF .deps/ta_ADOSC.Tpo -c -o ta_ADOSC.lo ta_ADOSC.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADOSC.lo -MD -MP -MF .deps/ta_ADOSC.Tpo -c ta_ADOSC.c  -fPIC -DPIC -o .libs/ta_ADOSC.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADOSC.lo -MD -MP -MF .deps/ta_ADOSC.Tpo -c ta_ADOSC.c -o ta_ADOSC.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ADOSC.Tpo .deps/ta_ADOSC.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ADX.lo -MD -MP -MF .deps/ta_ADX.Tpo -c -o ta_ADX.lo ta_ADX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADX.lo -MD -MP -MF .deps/ta_ADX.Tpo -c ta_ADX.c  -fPIC -DPIC -o .libs/ta_ADX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADX.lo -MD -MP -MF .deps/ta_ADX.Tpo -c ta_ADX.c -o ta_ADX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ADX.Tpo .deps/ta_ADX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ADXR.lo -MD -MP -MF .deps/ta_ADXR.Tpo -c -o ta_ADXR.lo ta_ADXR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADXR.lo -MD -MP -MF .deps/ta_ADXR.Tpo -c ta_ADXR.c  -fPIC -DPIC -o .libs/ta_ADXR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ADXR.lo -MD -MP -MF .deps/ta_ADXR.Tpo -c ta_ADXR.c -o ta_ADXR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ADXR.Tpo .deps/ta_ADXR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_APO.lo -MD -MP -MF .deps/ta_APO.Tpo -c -o ta_APO.lo ta_APO.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_APO.lo -MD -MP -MF .deps/ta_APO.Tpo -c ta_APO.c  -fPIC -DPIC -o .libs/ta_APO.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_APO.lo -MD -MP -MF .deps/ta_APO.Tpo -c ta_APO.c -o ta_APO.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_APO.Tpo .deps/ta_APO.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_AROON.lo -MD -MP -MF .deps/ta_AROON.Tpo -c -o ta_AROON.lo ta_AROON.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AROON.lo -MD -MP -MF .deps/ta_AROON.Tpo -c ta_AROON.c  -fPIC -DPIC -o .libs/ta_AROON.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AROON.lo -MD -MP -MF .deps/ta_AROON.Tpo -c ta_AROON.c -o ta_AROON.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_AROON.Tpo .deps/ta_AROON.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_AROONOSC.lo -MD -MP -MF .deps/ta_AROONOSC.Tpo -c -o ta_AROONOSC.lo ta_AROONOSC.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AROONOSC.lo -MD -MP -MF .deps/ta_AROONOSC.Tpo -c ta_AROONOSC.c  -fPIC -DPIC -o .libs/ta_AROONOSC.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AROONOSC.lo -MD -MP -MF .deps/ta_AROONOSC.Tpo -c ta_AROONOSC.c -o ta_AROONOSC.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_AROONOSC.Tpo .deps/ta_AROONOSC.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ASIN.lo -MD -MP -MF .deps/ta_ASIN.Tpo -c -o ta_ASIN.lo ta_ASIN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ASIN.lo -MD -MP -MF .deps/ta_ASIN.Tpo -c ta_ASIN.c  -fPIC -DPIC -o .libs/ta_ASIN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ASIN.lo -MD -MP -MF .deps/ta_ASIN.Tpo -c ta_ASIN.c -o ta_ASIN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ASIN.Tpo .deps/ta_ASIN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ATAN.lo -MD -MP -MF .deps/ta_ATAN.Tpo -c -o ta_ATAN.lo ta_ATAN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ATAN.lo -MD -MP -MF .deps/ta_ATAN.Tpo -c ta_ATAN.c  -fPIC -DPIC -o .libs/ta_ATAN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ATAN.lo -MD -MP -MF .deps/ta_ATAN.Tpo -c ta_ATAN.c -o ta_ATAN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ATAN.Tpo .deps/ta_ATAN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ATR.lo -MD -MP -MF .deps/ta_ATR.Tpo -c -o ta_ATR.lo ta_ATR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ATR.lo -MD -MP -MF .deps/ta_ATR.Tpo -c ta_ATR.c  -fPIC -DPIC -o .libs/ta_ATR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ATR.lo -MD -MP -MF .deps/ta_ATR.Tpo -c ta_ATR.c -o ta_ATR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ATR.Tpo .deps/ta_ATR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_AVGPRICE.lo -MD -MP -MF .deps/ta_AVGPRICE.Tpo -c -o ta_AVGPRICE.lo ta_AVGPRICE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AVGPRICE.lo -MD -MP -MF .deps/ta_AVGPRICE.Tpo -c ta_AVGPRICE.c  -fPIC -DPIC -o .libs/ta_AVGPRICE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_AVGPRICE.lo -MD -MP -MF .deps/ta_AVGPRICE.Tpo -c ta_AVGPRICE.c -o ta_AVGPRICE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_AVGPRICE.Tpo .deps/ta_AVGPRICE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_BBANDS.lo -MD -MP -MF .deps/ta_BBANDS.Tpo -c -o ta_BBANDS.lo ta_BBANDS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_BBANDS.lo -MD -MP -MF .deps/ta_BBANDS.Tpo -c ta_BBANDS.c  -fPIC -DPIC -o .libs/ta_BBANDS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_BBANDS.lo -MD -MP -MF .deps/ta_BBANDS.Tpo -c ta_BBANDS.c -o ta_BBANDS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_BBANDS.Tpo .deps/ta_BBANDS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_BETA.lo -MD -MP -MF .deps/ta_BETA.Tpo -c -o ta_BETA.lo ta_BETA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_BETA.lo -MD -MP -MF .deps/ta_BETA.Tpo -c ta_BETA.c  -fPIC -DPIC -o .libs/ta_BETA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_BETA.lo -MD -MP -MF .deps/ta_BETA.Tpo -c ta_BETA.c -o ta_BETA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_BETA.Tpo .deps/ta_BETA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_BOP.lo -MD -MP -MF .deps/ta_BOP.Tpo -c -o ta_BOP.lo ta_BOP.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_BOP.lo -MD -MP -MF .deps/ta_BOP.Tpo -c ta_BOP.c  -fPIC -DPIC -o .libs/ta_BOP.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_BOP.lo -MD -MP -MF .deps/ta_BOP.Tpo -c ta_BOP.c -o ta_BOP.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_BOP.Tpo .deps/ta_BOP.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CCI.lo -MD -MP -MF .deps/ta_CCI.Tpo -c -o ta_CCI.lo ta_CCI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CCI.lo -MD -MP -MF .deps/ta_CCI.Tpo -c ta_CCI.c  -fPIC -DPIC -o .libs/ta_CCI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CCI.lo -MD -MP -MF .deps/ta_CCI.Tpo -c ta_CCI.c -o ta_CCI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CCI.Tpo .deps/ta_CCI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDL2CROWS.lo -MD -MP -MF .deps/ta_CDL2CROWS.Tpo -c -o ta_CDL2CROWS.lo ta_CDL2CROWS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL2CROWS.lo -MD -MP -MF .deps/ta_CDL2CROWS.Tpo -c ta_CDL2CROWS.c  -fPIC -DPIC -o .libs/ta_CDL2CROWS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL2CROWS.lo -MD -MP -MF .deps/ta_CDL2CROWS.Tpo -c ta_CDL2CROWS.c -o ta_CDL2CROWS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDL2CROWS.Tpo .deps/ta_CDL2CROWS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDL3BLACKCROWS.lo -MD -MP -MF .deps/ta_CDL3BLACKCROWS.Tpo -c -o ta_CDL3BLACKCROWS.lo ta_CDL3BLACKCROWS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3BLACKCROWS.lo -MD -MP -MF .deps/ta_CDL3BLACKCROWS.Tpo -c ta_CDL3BLACKCROWS.c  -fPIC -DPIC -o .libs/ta_CDL3BLACKCROWS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3BLACKCROWS.lo -MD -MP -MF .deps/ta_CDL3BLACKCROWS.Tpo -c ta_CDL3BLACKCROWS.c -o ta_CDL3BLACKCROWS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDL3BLACKCROWS.Tpo .deps/ta_CDL3BLACKCROWS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDL3INSIDE.lo -MD -MP -MF .deps/ta_CDL3INSIDE.Tpo -c -o ta_CDL3INSIDE.lo ta_CDL3INSIDE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3INSIDE.lo -MD -MP -MF .deps/ta_CDL3INSIDE.Tpo -c ta_CDL3INSIDE.c  -fPIC -DPIC -o .libs/ta_CDL3INSIDE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3INSIDE.lo -MD -MP -MF .deps/ta_CDL3INSIDE.Tpo -c ta_CDL3INSIDE.c -o ta_CDL3INSIDE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDL3INSIDE.Tpo .deps/ta_CDL3INSIDE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDL3LINESTRIKE.lo -MD -MP -MF .deps/ta_CDL3LINESTRIKE.Tpo -c -o ta_CDL3LINESTRIKE.lo ta_CDL3LINESTRIKE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3LINESTRIKE.lo -MD -MP -MF .deps/ta_CDL3LINESTRIKE.Tpo -c ta_CDL3LINESTRIKE.c  -fPIC -DPIC -o .libs/ta_CDL3LINESTRIKE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3LINESTRIKE.lo -MD -MP -MF .deps/ta_CDL3LINESTRIKE.Tpo -c ta_CDL3LINESTRIKE.c -o ta_CDL3LINESTRIKE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDL3LINESTRIKE.Tpo .deps/ta_CDL3LINESTRIKE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDL3OUTSIDE.lo -MD -MP -MF .deps/ta_CDL3OUTSIDE.Tpo -c -o ta_CDL3OUTSIDE.lo ta_CDL3OUTSIDE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3OUTSIDE.lo -MD -MP -MF .deps/ta_CDL3OUTSIDE.Tpo -c ta_CDL3OUTSIDE.c  -fPIC -DPIC -o .libs/ta_CDL3OUTSIDE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3OUTSIDE.lo -MD -MP -MF .deps/ta_CDL3OUTSIDE.Tpo -c ta_CDL3OUTSIDE.c -o ta_CDL3OUTSIDE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDL3OUTSIDE.Tpo .deps/ta_CDL3OUTSIDE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDL3STARSINSOUTH.lo -MD -MP -MF .deps/ta_CDL3STARSINSOUTH.Tpo -c -o ta_CDL3STARSINSOUTH.lo ta_CDL3STARSINSOUTH.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3STARSINSOUTH.lo -MD -MP -MF .deps/ta_CDL3STARSINSOUTH.Tpo -c ta_CDL3STARSINSOUTH.c  -fPIC -DPIC -o .libs/ta_CDL3STARSINSOUTH.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3STARSINSOUTH.lo -MD -MP -MF .deps/ta_CDL3STARSINSOUTH.Tpo -c ta_CDL3STARSINSOUTH.c -o ta_CDL3STARSINSOUTH.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDL3STARSINSOUTH.Tpo .deps/ta_CDL3STARSINSOUTH.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDL3WHITESOLDIERS.lo -MD -MP -MF .deps/ta_CDL3WHITESOLDIERS.Tpo -c -o ta_CDL3WHITESOLDIERS.lo ta_CDL3WHITESOLDIERS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3WHITESOLDIERS.lo -MD -MP -MF .deps/ta_CDL3WHITESOLDIERS.Tpo -c ta_CDL3WHITESOLDIERS.c  -fPIC -DPIC -o .libs/ta_CDL3WHITESOLDIERS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDL3WHITESOLDIERS.lo -MD -MP -MF .deps/ta_CDL3WHITESOLDIERS.Tpo -c ta_CDL3WHITESOLDIERS.c -o ta_CDL3WHITESOLDIERS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDL3WHITESOLDIERS.Tpo .deps/ta_CDL3WHITESOLDIERS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLABANDONEDBABY.lo -MD -MP -MF .deps/ta_CDLABANDONEDBABY.Tpo -c -o ta_CDLABANDONEDBABY.lo ta_CDLABANDONEDBABY.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLABANDONEDBABY.lo -MD -MP -MF .deps/ta_CDLABANDONEDBABY.Tpo -c ta_CDLABANDONEDBABY.c  -fPIC -DPIC -o .libs/ta_CDLABANDONEDBABY.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLABANDONEDBABY.lo -MD -MP -MF .deps/ta_CDLABANDONEDBABY.Tpo -c ta_CDLABANDONEDBABY.c -o ta_CDLABANDONEDBABY.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLABANDONEDBABY.Tpo .deps/ta_CDLABANDONEDBABY.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLADVANCEBLOCK.lo -MD -MP -MF .deps/ta_CDLADVANCEBLOCK.Tpo -c -o ta_CDLADVANCEBLOCK.lo ta_CDLADVANCEBLOCK.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLADVANCEBLOCK.lo -MD -MP -MF .deps/ta_CDLADVANCEBLOCK.Tpo -c ta_CDLADVANCEBLOCK.c  -fPIC -DPIC -o .libs/ta_CDLADVANCEBLOCK.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLADVANCEBLOCK.lo -MD -MP -MF .deps/ta_CDLADVANCEBLOCK.Tpo -c ta_CDLADVANCEBLOCK.c -o ta_CDLADVANCEBLOCK.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLADVANCEBLOCK.Tpo .deps/ta_CDLADVANCEBLOCK.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLBELTHOLD.lo -MD -MP -MF .deps/ta_CDLBELTHOLD.Tpo -c -o ta_CDLBELTHOLD.lo ta_CDLBELTHOLD.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLBELTHOLD.lo -MD -MP -MF .deps/ta_CDLBELTHOLD.Tpo -c ta_CDLBELTHOLD.c  -fPIC -DPIC -o .libs/ta_CDLBELTHOLD.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLBELTHOLD.lo -MD -MP -MF .deps/ta_CDLBELTHOLD.Tpo -c ta_CDLBELTHOLD.c -o ta_CDLBELTHOLD.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLBELTHOLD.Tpo .deps/ta_CDLBELTHOLD.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLBREAKAWAY.lo -MD -MP -MF .deps/ta_CDLBREAKAWAY.Tpo -c -o ta_CDLBREAKAWAY.lo ta_CDLBREAKAWAY.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLBREAKAWAY.lo -MD -MP -MF .deps/ta_CDLBREAKAWAY.Tpo -c ta_CDLBREAKAWAY.c  -fPIC -DPIC -o .libs/ta_CDLBREAKAWAY.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLBREAKAWAY.lo -MD -MP -MF .deps/ta_CDLBREAKAWAY.Tpo -c ta_CDLBREAKAWAY.c -o ta_CDLBREAKAWAY.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLBREAKAWAY.Tpo .deps/ta_CDLBREAKAWAY.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLCLOSINGMARUBOZU.lo -MD -MP -MF .deps/ta_CDLCLOSINGMARUBOZU.Tpo -c -o ta_CDLCLOSINGMARUBOZU.lo ta_CDLCLOSINGMARUBOZU.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLCLOSINGMARUBOZU.lo -MD -MP -MF .deps/ta_CDLCLOSINGMARUBOZU.Tpo -c ta_CDLCLOSINGMARUBOZU.c  -fPIC -DPIC -o .libs/ta_CDLCLOSINGMARUBOZU.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLCLOSINGMARUBOZU.lo -MD -MP -MF .deps/ta_CDLCLOSINGMARUBOZU.Tpo -c ta_CDLCLOSINGMARUBOZU.c -o ta_CDLCLOSINGMARUBOZU.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLCLOSINGMARUBOZU.Tpo .deps/ta_CDLCLOSINGMARUBOZU.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLCONCEALBABYSWALL.lo -MD -MP -MF .deps/ta_CDLCONCEALBABYSWALL.Tpo -c -o ta_CDLCONCEALBABYSWALL.lo ta_CDLCONCEALBABYSWALL.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLCONCEALBABYSWALL.lo -MD -MP -MF .deps/ta_CDLCONCEALBABYSWALL.Tpo -c ta_CDLCONCEALBABYSWALL.c  -fPIC -DPIC -o .libs/ta_CDLCONCEALBABYSWALL.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLCONCEALBABYSWALL.lo -MD -MP -MF .deps/ta_CDLCONCEALBABYSWALL.Tpo -c ta_CDLCONCEALBABYSWALL.c -o ta_CDLCONCEALBABYSWALL.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLCONCEALBABYSWALL.Tpo .deps/ta_CDLCONCEALBABYSWALL.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLCOUNTERATTACK.lo -MD -MP -MF .deps/ta_CDLCOUNTERATTACK.Tpo -c -o ta_CDLCOUNTERATTACK.lo ta_CDLCOUNTERATTACK.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLCOUNTERATTACK.lo -MD -MP -MF .deps/ta_CDLCOUNTERATTACK.Tpo -c ta_CDLCOUNTERATTACK.c  -fPIC -DPIC -o .libs/ta_CDLCOUNTERATTACK.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLCOUNTERATTACK.lo -MD -MP -MF .deps/ta_CDLCOUNTERATTACK.Tpo -c ta_CDLCOUNTERATTACK.c -o ta_CDLCOUNTERATTACK.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLCOUNTERATTACK.Tpo .deps/ta_CDLCOUNTERATTACK.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLDARKCLOUDCOVER.lo -MD -MP -MF .deps/ta_CDLDARKCLOUDCOVER.Tpo -c -o ta_CDLDARKCLOUDCOVER.lo ta_CDLDARKCLOUDCOVER.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDARKCLOUDCOVER.lo -MD -MP -MF .deps/ta_CDLDARKCLOUDCOVER.Tpo -c ta_CDLDARKCLOUDCOVER.c  -fPIC -DPIC -o .libs/ta_CDLDARKCLOUDCOVER.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDARKCLOUDCOVER.lo -MD -MP -MF .deps/ta_CDLDARKCLOUDCOVER.Tpo -c ta_CDLDARKCLOUDCOVER.c -o ta_CDLDARKCLOUDCOVER.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLDARKCLOUDCOVER.Tpo .deps/ta_CDLDARKCLOUDCOVER.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLDOJI.lo -MD -MP -MF .deps/ta_CDLDOJI.Tpo -c -o ta_CDLDOJI.lo ta_CDLDOJI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDOJI.lo -MD -MP -MF .deps/ta_CDLDOJI.Tpo -c ta_CDLDOJI.c  -fPIC -DPIC -o .libs/ta_CDLDOJI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDOJI.lo -MD -MP -MF .deps/ta_CDLDOJI.Tpo -c ta_CDLDOJI.c -o ta_CDLDOJI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLDOJI.Tpo .deps/ta_CDLDOJI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLDOJISTAR.lo -MD -MP -MF .deps/ta_CDLDOJISTAR.Tpo -c -o ta_CDLDOJISTAR.lo ta_CDLDOJISTAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDOJISTAR.lo -MD -MP -MF .deps/ta_CDLDOJISTAR.Tpo -c ta_CDLDOJISTAR.c  -fPIC -DPIC -o .libs/ta_CDLDOJISTAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDOJISTAR.lo -MD -MP -MF .deps/ta_CDLDOJISTAR.Tpo -c ta_CDLDOJISTAR.c -o ta_CDLDOJISTAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLDOJISTAR.Tpo .deps/ta_CDLDOJISTAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLDRAGONFLYDOJI.lo -MD -MP -MF .deps/ta_CDLDRAGONFLYDOJI.Tpo -c -o ta_CDLDRAGONFLYDOJI.lo ta_CDLDRAGONFLYDOJI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDRAGONFLYDOJI.lo -MD -MP -MF .deps/ta_CDLDRAGONFLYDOJI.Tpo -c ta_CDLDRAGONFLYDOJI.c  -fPIC -DPIC -o .libs/ta_CDLDRAGONFLYDOJI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLDRAGONFLYDOJI.lo -MD -MP -MF .deps/ta_CDLDRAGONFLYDOJI.Tpo -c ta_CDLDRAGONFLYDOJI.c -o ta_CDLDRAGONFLYDOJI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLDRAGONFLYDOJI.Tpo .deps/ta_CDLDRAGONFLYDOJI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLENGULFING.lo -MD -MP -MF .deps/ta_CDLENGULFING.Tpo -c -o ta_CDLENGULFING.lo ta_CDLENGULFING.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLENGULFING.lo -MD -MP -MF .deps/ta_CDLENGULFING.Tpo -c ta_CDLENGULFING.c  -fPIC -DPIC -o .libs/ta_CDLENGULFING.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLENGULFING.lo -MD -MP -MF .deps/ta_CDLENGULFING.Tpo -c ta_CDLENGULFING.c -o ta_CDLENGULFING.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLENGULFING.Tpo .deps/ta_CDLENGULFING.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLEVENINGDOJISTAR.lo -MD -MP -MF .deps/ta_CDLEVENINGDOJISTAR.Tpo -c -o ta_CDLEVENINGDOJISTAR.lo ta_CDLEVENINGDOJISTAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLEVENINGDOJISTAR.lo -MD -MP -MF .deps/ta_CDLEVENINGDOJISTAR.Tpo -c ta_CDLEVENINGDOJISTAR.c  -fPIC -DPIC -o .libs/ta_CDLEVENINGDOJISTAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLEVENINGDOJISTAR.lo -MD -MP -MF .deps/ta_CDLEVENINGDOJISTAR.Tpo -c ta_CDLEVENINGDOJISTAR.c -o ta_CDLEVENINGDOJISTAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLEVENINGDOJISTAR.Tpo .deps/ta_CDLEVENINGDOJISTAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLEVENINGSTAR.lo -MD -MP -MF .deps/ta_CDLEVENINGSTAR.Tpo -c -o ta_CDLEVENINGSTAR.lo ta_CDLEVENINGSTAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLEVENINGSTAR.lo -MD -MP -MF .deps/ta_CDLEVENINGSTAR.Tpo -c ta_CDLEVENINGSTAR.c  -fPIC -DPIC -o .libs/ta_CDLEVENINGSTAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLEVENINGSTAR.lo -MD -MP -MF .deps/ta_CDLEVENINGSTAR.Tpo -c ta_CDLEVENINGSTAR.c -o ta_CDLEVENINGSTAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLEVENINGSTAR.Tpo .deps/ta_CDLEVENINGSTAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLGAPSIDESIDEWHITE.lo -MD -MP -MF .deps/ta_CDLGAPSIDESIDEWHITE.Tpo -c -o ta_CDLGAPSIDESIDEWHITE.lo ta_CDLGAPSIDESIDEWHITE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLGAPSIDESIDEWHITE.lo -MD -MP -MF .deps/ta_CDLGAPSIDESIDEWHITE.Tpo -c ta_CDLGAPSIDESIDEWHITE.c  -fPIC -DPIC -o .libs/ta_CDLGAPSIDESIDEWHITE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLGAPSIDESIDEWHITE.lo -MD -MP -MF .deps/ta_CDLGAPSIDESIDEWHITE.Tpo -c ta_CDLGAPSIDESIDEWHITE.c -o ta_CDLGAPSIDESIDEWHITE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLGAPSIDESIDEWHITE.Tpo .deps/ta_CDLGAPSIDESIDEWHITE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLGRAVESTONEDOJI.lo -MD -MP -MF .deps/ta_CDLGRAVESTONEDOJI.Tpo -c -o ta_CDLGRAVESTONEDOJI.lo ta_CDLGRAVESTONEDOJI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLGRAVESTONEDOJI.lo -MD -MP -MF .deps/ta_CDLGRAVESTONEDOJI.Tpo -c ta_CDLGRAVESTONEDOJI.c  -fPIC -DPIC -o .libs/ta_CDLGRAVESTONEDOJI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLGRAVESTONEDOJI.lo -MD -MP -MF .deps/ta_CDLGRAVESTONEDOJI.Tpo -c ta_CDLGRAVESTONEDOJI.c -o ta_CDLGRAVESTONEDOJI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLGRAVESTONEDOJI.Tpo .deps/ta_CDLGRAVESTONEDOJI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHAMMER.lo -MD -MP -MF .deps/ta_CDLHAMMER.Tpo -c -o ta_CDLHAMMER.lo ta_CDLHAMMER.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHAMMER.lo -MD -MP -MF .deps/ta_CDLHAMMER.Tpo -c ta_CDLHAMMER.c  -fPIC -DPIC -o .libs/ta_CDLHAMMER.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHAMMER.lo -MD -MP -MF .deps/ta_CDLHAMMER.Tpo -c ta_CDLHAMMER.c -o ta_CDLHAMMER.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHAMMER.Tpo .deps/ta_CDLHAMMER.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHANGINGMAN.lo -MD -MP -MF .deps/ta_CDLHANGINGMAN.Tpo -c -o ta_CDLHANGINGMAN.lo ta_CDLHANGINGMAN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHANGINGMAN.lo -MD -MP -MF .deps/ta_CDLHANGINGMAN.Tpo -c ta_CDLHANGINGMAN.c  -fPIC -DPIC -o .libs/ta_CDLHANGINGMAN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHANGINGMAN.lo -MD -MP -MF .deps/ta_CDLHANGINGMAN.Tpo -c ta_CDLHANGINGMAN.c -o ta_CDLHANGINGMAN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHANGINGMAN.Tpo .deps/ta_CDLHANGINGMAN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHARAMI.lo -MD -MP -MF .deps/ta_CDLHARAMI.Tpo -c -o ta_CDLHARAMI.lo ta_CDLHARAMI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHARAMI.lo -MD -MP -MF .deps/ta_CDLHARAMI.Tpo -c ta_CDLHARAMI.c  -fPIC -DPIC -o .libs/ta_CDLHARAMI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHARAMI.lo -MD -MP -MF .deps/ta_CDLHARAMI.Tpo -c ta_CDLHARAMI.c -o ta_CDLHARAMI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHARAMI.Tpo .deps/ta_CDLHARAMI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHARAMICROSS.lo -MD -MP -MF .deps/ta_CDLHARAMICROSS.Tpo -c -o ta_CDLHARAMICROSS.lo ta_CDLHARAMICROSS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHARAMICROSS.lo -MD -MP -MF .deps/ta_CDLHARAMICROSS.Tpo -c ta_CDLHARAMICROSS.c  -fPIC -DPIC -o .libs/ta_CDLHARAMICROSS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHARAMICROSS.lo -MD -MP -MF .deps/ta_CDLHARAMICROSS.Tpo -c ta_CDLHARAMICROSS.c -o ta_CDLHARAMICROSS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHARAMICROSS.Tpo .deps/ta_CDLHARAMICROSS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHIGHWAVE.lo -MD -MP -MF .deps/ta_CDLHIGHWAVE.Tpo -c -o ta_CDLHIGHWAVE.lo ta_CDLHIGHWAVE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHIGHWAVE.lo -MD -MP -MF .deps/ta_CDLHIGHWAVE.Tpo -c ta_CDLHIGHWAVE.c  -fPIC -DPIC -o .libs/ta_CDLHIGHWAVE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHIGHWAVE.lo -MD -MP -MF .deps/ta_CDLHIGHWAVE.Tpo -c ta_CDLHIGHWAVE.c -o ta_CDLHIGHWAVE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHIGHWAVE.Tpo .deps/ta_CDLHIGHWAVE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHIKKAKE.lo -MD -MP -MF .deps/ta_CDLHIKKAKE.Tpo -c -o ta_CDLHIKKAKE.lo ta_CDLHIKKAKE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHIKKAKE.lo -MD -MP -MF .deps/ta_CDLHIKKAKE.Tpo -c ta_CDLHIKKAKE.c  -fPIC -DPIC -o .libs/ta_CDLHIKKAKE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHIKKAKE.lo -MD -MP -MF .deps/ta_CDLHIKKAKE.Tpo -c ta_CDLHIKKAKE.c -o ta_CDLHIKKAKE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHIKKAKE.Tpo .deps/ta_CDLHIKKAKE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHIKKAKEMOD.lo -MD -MP -MF .deps/ta_CDLHIKKAKEMOD.Tpo -c -o ta_CDLHIKKAKEMOD.lo ta_CDLHIKKAKEMOD.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHIKKAKEMOD.lo -MD -MP -MF .deps/ta_CDLHIKKAKEMOD.Tpo -c ta_CDLHIKKAKEMOD.c  -fPIC -DPIC -o .libs/ta_CDLHIKKAKEMOD.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHIKKAKEMOD.lo -MD -MP -MF .deps/ta_CDLHIKKAKEMOD.Tpo -c ta_CDLHIKKAKEMOD.c -o ta_CDLHIKKAKEMOD.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHIKKAKEMOD.Tpo .deps/ta_CDLHIKKAKEMOD.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLHOMINGPIGEON.lo -MD -MP -MF .deps/ta_CDLHOMINGPIGEON.Tpo -c -o ta_CDLHOMINGPIGEON.lo ta_CDLHOMINGPIGEON.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHOMINGPIGEON.lo -MD -MP -MF .deps/ta_CDLHOMINGPIGEON.Tpo -c ta_CDLHOMINGPIGEON.c  -fPIC -DPIC -o .libs/ta_CDLHOMINGPIGEON.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLHOMINGPIGEON.lo -MD -MP -MF .deps/ta_CDLHOMINGPIGEON.Tpo -c ta_CDLHOMINGPIGEON.c -o ta_CDLHOMINGPIGEON.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLHOMINGPIGEON.Tpo .deps/ta_CDLHOMINGPIGEON.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLIDENTICAL3CROWS.lo -MD -MP -MF .deps/ta_CDLIDENTICAL3CROWS.Tpo -c -o ta_CDLIDENTICAL3CROWS.lo ta_CDLIDENTICAL3CROWS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLIDENTICAL3CROWS.lo -MD -MP -MF .deps/ta_CDLIDENTICAL3CROWS.Tpo -c ta_CDLIDENTICAL3CROWS.c  -fPIC -DPIC -o .libs/ta_CDLIDENTICAL3CROWS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLIDENTICAL3CROWS.lo -MD -MP -MF .deps/ta_CDLIDENTICAL3CROWS.Tpo -c ta_CDLIDENTICAL3CROWS.c -o ta_CDLIDENTICAL3CROWS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLIDENTICAL3CROWS.Tpo .deps/ta_CDLIDENTICAL3CROWS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLINNECK.lo -MD -MP -MF .deps/ta_CDLINNECK.Tpo -c -o ta_CDLINNECK.lo ta_CDLINNECK.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLINNECK.lo -MD -MP -MF .deps/ta_CDLINNECK.Tpo -c ta_CDLINNECK.c  -fPIC -DPIC -o .libs/ta_CDLINNECK.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLINNECK.lo -MD -MP -MF .deps/ta_CDLINNECK.Tpo -c ta_CDLINNECK.c -o ta_CDLINNECK.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLINNECK.Tpo .deps/ta_CDLINNECK.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLINVERTEDHAMMER.lo -MD -MP -MF .deps/ta_CDLINVERTEDHAMMER.Tpo -c -o ta_CDLINVERTEDHAMMER.lo ta_CDLINVERTEDHAMMER.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLINVERTEDHAMMER.lo -MD -MP -MF .deps/ta_CDLINVERTEDHAMMER.Tpo -c ta_CDLINVERTEDHAMMER.c  -fPIC -DPIC -o .libs/ta_CDLINVERTEDHAMMER.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLINVERTEDHAMMER.lo -MD -MP -MF .deps/ta_CDLINVERTEDHAMMER.Tpo -c ta_CDLINVERTEDHAMMER.c -o ta_CDLINVERTEDHAMMER.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLINVERTEDHAMMER.Tpo .deps/ta_CDLINVERTEDHAMMER.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLKICKING.lo -MD -MP -MF .deps/ta_CDLKICKING.Tpo -c -o ta_CDLKICKING.lo ta_CDLKICKING.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLKICKING.lo -MD -MP -MF .deps/ta_CDLKICKING.Tpo -c ta_CDLKICKING.c  -fPIC -DPIC -o .libs/ta_CDLKICKING.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLKICKING.lo -MD -MP -MF .deps/ta_CDLKICKING.Tpo -c ta_CDLKICKING.c -o ta_CDLKICKING.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLKICKING.Tpo .deps/ta_CDLKICKING.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLKICKINGBYLENGTH.lo -MD -MP -MF .deps/ta_CDLKICKINGBYLENGTH.Tpo -c -o ta_CDLKICKINGBYLENGTH.lo ta_CDLKICKINGBYLENGTH.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLKICKINGBYLENGTH.lo -MD -MP -MF .deps/ta_CDLKICKINGBYLENGTH.Tpo -c ta_CDLKICKINGBYLENGTH.c  -fPIC -DPIC -o .libs/ta_CDLKICKINGBYLENGTH.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLKICKINGBYLENGTH.lo -MD -MP -MF .deps/ta_CDLKICKINGBYLENGTH.Tpo -c ta_CDLKICKINGBYLENGTH.c -o ta_CDLKICKINGBYLENGTH.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLKICKINGBYLENGTH.Tpo .deps/ta_CDLKICKINGBYLENGTH.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLLADDERBOTTOM.lo -MD -MP -MF .deps/ta_CDLLADDERBOTTOM.Tpo -c -o ta_CDLLADDERBOTTOM.lo ta_CDLLADDERBOTTOM.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLLADDERBOTTOM.lo -MD -MP -MF .deps/ta_CDLLADDERBOTTOM.Tpo -c ta_CDLLADDERBOTTOM.c  -fPIC -DPIC -o .libs/ta_CDLLADDERBOTTOM.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLLADDERBOTTOM.lo -MD -MP -MF .deps/ta_CDLLADDERBOTTOM.Tpo -c ta_CDLLADDERBOTTOM.c -o ta_CDLLADDERBOTTOM.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLLADDERBOTTOM.Tpo .deps/ta_CDLLADDERBOTTOM.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLLONGLEGGEDDOJI.lo -MD -MP -MF .deps/ta_CDLLONGLEGGEDDOJI.Tpo -c -o ta_CDLLONGLEGGEDDOJI.lo ta_CDLLONGLEGGEDDOJI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLLONGLEGGEDDOJI.lo -MD -MP -MF .deps/ta_CDLLONGLEGGEDDOJI.Tpo -c ta_CDLLONGLEGGEDDOJI.c  -fPIC -DPIC -o .libs/ta_CDLLONGLEGGEDDOJI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLLONGLEGGEDDOJI.lo -MD -MP -MF .deps/ta_CDLLONGLEGGEDDOJI.Tpo -c ta_CDLLONGLEGGEDDOJI.c -o ta_CDLLONGLEGGEDDOJI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLLONGLEGGEDDOJI.Tpo .deps/ta_CDLLONGLEGGEDDOJI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLLONGLINE.lo -MD -MP -MF .deps/ta_CDLLONGLINE.Tpo -c -o ta_CDLLONGLINE.lo ta_CDLLONGLINE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLLONGLINE.lo -MD -MP -MF .deps/ta_CDLLONGLINE.Tpo -c ta_CDLLONGLINE.c  -fPIC -DPIC -o .libs/ta_CDLLONGLINE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLLONGLINE.lo -MD -MP -MF .deps/ta_CDLLONGLINE.Tpo -c ta_CDLLONGLINE.c -o ta_CDLLONGLINE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLLONGLINE.Tpo .deps/ta_CDLLONGLINE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLMARUBOZU.lo -MD -MP -MF .deps/ta_CDLMARUBOZU.Tpo -c -o ta_CDLMARUBOZU.lo ta_CDLMARUBOZU.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMARUBOZU.lo -MD -MP -MF .deps/ta_CDLMARUBOZU.Tpo -c ta_CDLMARUBOZU.c  -fPIC -DPIC -o .libs/ta_CDLMARUBOZU.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMARUBOZU.lo -MD -MP -MF .deps/ta_CDLMARUBOZU.Tpo -c ta_CDLMARUBOZU.c -o ta_CDLMARUBOZU.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLMARUBOZU.Tpo .deps/ta_CDLMARUBOZU.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLMATCHINGLOW.lo -MD -MP -MF .deps/ta_CDLMATCHINGLOW.Tpo -c -o ta_CDLMATCHINGLOW.lo ta_CDLMATCHINGLOW.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMATCHINGLOW.lo -MD -MP -MF .deps/ta_CDLMATCHINGLOW.Tpo -c ta_CDLMATCHINGLOW.c  -fPIC -DPIC -o .libs/ta_CDLMATCHINGLOW.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMATCHINGLOW.lo -MD -MP -MF .deps/ta_CDLMATCHINGLOW.Tpo -c ta_CDLMATCHINGLOW.c -o ta_CDLMATCHINGLOW.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLMATCHINGLOW.Tpo .deps/ta_CDLMATCHINGLOW.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLMATHOLD.lo -MD -MP -MF .deps/ta_CDLMATHOLD.Tpo -c -o ta_CDLMATHOLD.lo ta_CDLMATHOLD.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMATHOLD.lo -MD -MP -MF .deps/ta_CDLMATHOLD.Tpo -c ta_CDLMATHOLD.c  -fPIC -DPIC -o .libs/ta_CDLMATHOLD.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMATHOLD.lo -MD -MP -MF .deps/ta_CDLMATHOLD.Tpo -c ta_CDLMATHOLD.c -o ta_CDLMATHOLD.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLMATHOLD.Tpo .deps/ta_CDLMATHOLD.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLMORNINGDOJISTAR.lo -MD -MP -MF .deps/ta_CDLMORNINGDOJISTAR.Tpo -c -o ta_CDLMORNINGDOJISTAR.lo ta_CDLMORNINGDOJISTAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMORNINGDOJISTAR.lo -MD -MP -MF .deps/ta_CDLMORNINGDOJISTAR.Tpo -c ta_CDLMORNINGDOJISTAR.c  -fPIC -DPIC -o .libs/ta_CDLMORNINGDOJISTAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMORNINGDOJISTAR.lo -MD -MP -MF .deps/ta_CDLMORNINGDOJISTAR.Tpo -c ta_CDLMORNINGDOJISTAR.c -o ta_CDLMORNINGDOJISTAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLMORNINGDOJISTAR.Tpo .deps/ta_CDLMORNINGDOJISTAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLMORNINGSTAR.lo -MD -MP -MF .deps/ta_CDLMORNINGSTAR.Tpo -c -o ta_CDLMORNINGSTAR.lo ta_CDLMORNINGSTAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMORNINGSTAR.lo -MD -MP -MF .deps/ta_CDLMORNINGSTAR.Tpo -c ta_CDLMORNINGSTAR.c  -fPIC -DPIC -o .libs/ta_CDLMORNINGSTAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLMORNINGSTAR.lo -MD -MP -MF .deps/ta_CDLMORNINGSTAR.Tpo -c ta_CDLMORNINGSTAR.c -o ta_CDLMORNINGSTAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLMORNINGSTAR.Tpo .deps/ta_CDLMORNINGSTAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLONNECK.lo -MD -MP -MF .deps/ta_CDLONNECK.Tpo -c -o ta_CDLONNECK.lo ta_CDLONNECK.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLONNECK.lo -MD -MP -MF .deps/ta_CDLONNECK.Tpo -c ta_CDLONNECK.c  -fPIC -DPIC -o .libs/ta_CDLONNECK.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLONNECK.lo -MD -MP -MF .deps/ta_CDLONNECK.Tpo -c ta_CDLONNECK.c -o ta_CDLONNECK.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLONNECK.Tpo .deps/ta_CDLONNECK.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLPIERCING.lo -MD -MP -MF .deps/ta_CDLPIERCING.Tpo -c -o ta_CDLPIERCING.lo ta_CDLPIERCING.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLPIERCING.lo -MD -MP -MF .deps/ta_CDLPIERCING.Tpo -c ta_CDLPIERCING.c  -fPIC -DPIC -o .libs/ta_CDLPIERCING.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLPIERCING.lo -MD -MP -MF .deps/ta_CDLPIERCING.Tpo -c ta_CDLPIERCING.c -o ta_CDLPIERCING.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLPIERCING.Tpo .deps/ta_CDLPIERCING.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLRICKSHAWMAN.lo -MD -MP -MF .deps/ta_CDLRICKSHAWMAN.Tpo -c -o ta_CDLRICKSHAWMAN.lo ta_CDLRICKSHAWMAN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLRICKSHAWMAN.lo -MD -MP -MF .deps/ta_CDLRICKSHAWMAN.Tpo -c ta_CDLRICKSHAWMAN.c  -fPIC -DPIC -o .libs/ta_CDLRICKSHAWMAN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLRICKSHAWMAN.lo -MD -MP -MF .deps/ta_CDLRICKSHAWMAN.Tpo -c ta_CDLRICKSHAWMAN.c -o ta_CDLRICKSHAWMAN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLRICKSHAWMAN.Tpo .deps/ta_CDLRICKSHAWMAN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLRISEFALL3METHODS.lo -MD -MP -MF .deps/ta_CDLRISEFALL3METHODS.Tpo -c -o ta_CDLRISEFALL3METHODS.lo ta_CDLRISEFALL3METHODS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLRISEFALL3METHODS.lo -MD -MP -MF .deps/ta_CDLRISEFALL3METHODS.Tpo -c ta_CDLRISEFALL3METHODS.c  -fPIC -DPIC -o .libs/ta_CDLRISEFALL3METHODS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLRISEFALL3METHODS.lo -MD -MP -MF .deps/ta_CDLRISEFALL3METHODS.Tpo -c ta_CDLRISEFALL3METHODS.c -o ta_CDLRISEFALL3METHODS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLRISEFALL3METHODS.Tpo .deps/ta_CDLRISEFALL3METHODS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLSEPARATINGLINES.lo -MD -MP -MF .deps/ta_CDLSEPARATINGLINES.Tpo -c -o ta_CDLSEPARATINGLINES.lo ta_CDLSEPARATINGLINES.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSEPARATINGLINES.lo -MD -MP -MF .deps/ta_CDLSEPARATINGLINES.Tpo -c ta_CDLSEPARATINGLINES.c  -fPIC -DPIC -o .libs/ta_CDLSEPARATINGLINES.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSEPARATINGLINES.lo -MD -MP -MF .deps/ta_CDLSEPARATINGLINES.Tpo -c ta_CDLSEPARATINGLINES.c -o ta_CDLSEPARATINGLINES.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLSEPARATINGLINES.Tpo .deps/ta_CDLSEPARATINGLINES.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLSHOOTINGSTAR.lo -MD -MP -MF .deps/ta_CDLSHOOTINGSTAR.Tpo -c -o ta_CDLSHOOTINGSTAR.lo ta_CDLSHOOTINGSTAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSHOOTINGSTAR.lo -MD -MP -MF .deps/ta_CDLSHOOTINGSTAR.Tpo -c ta_CDLSHOOTINGSTAR.c  -fPIC -DPIC -o .libs/ta_CDLSHOOTINGSTAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSHOOTINGSTAR.lo -MD -MP -MF .deps/ta_CDLSHOOTINGSTAR.Tpo -c ta_CDLSHOOTINGSTAR.c -o ta_CDLSHOOTINGSTAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLSHOOTINGSTAR.Tpo .deps/ta_CDLSHOOTINGSTAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLSHORTLINE.lo -MD -MP -MF .deps/ta_CDLSHORTLINE.Tpo -c -o ta_CDLSHORTLINE.lo ta_CDLSHORTLINE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSHORTLINE.lo -MD -MP -MF .deps/ta_CDLSHORTLINE.Tpo -c ta_CDLSHORTLINE.c  -fPIC -DPIC -o .libs/ta_CDLSHORTLINE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSHORTLINE.lo -MD -MP -MF .deps/ta_CDLSHORTLINE.Tpo -c ta_CDLSHORTLINE.c -o ta_CDLSHORTLINE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLSHORTLINE.Tpo .deps/ta_CDLSHORTLINE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLSPINNINGTOP.lo -MD -MP -MF .deps/ta_CDLSPINNINGTOP.Tpo -c -o ta_CDLSPINNINGTOP.lo ta_CDLSPINNINGTOP.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSPINNINGTOP.lo -MD -MP -MF .deps/ta_CDLSPINNINGTOP.Tpo -c ta_CDLSPINNINGTOP.c  -fPIC -DPIC -o .libs/ta_CDLSPINNINGTOP.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSPINNINGTOP.lo -MD -MP -MF .deps/ta_CDLSPINNINGTOP.Tpo -c ta_CDLSPINNINGTOP.c -o ta_CDLSPINNINGTOP.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLSPINNINGTOP.Tpo .deps/ta_CDLSPINNINGTOP.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLSTALLEDPATTERN.lo -MD -MP -MF .deps/ta_CDLSTALLEDPATTERN.Tpo -c -o ta_CDLSTALLEDPATTERN.lo ta_CDLSTALLEDPATTERN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSTALLEDPATTERN.lo -MD -MP -MF .deps/ta_CDLSTALLEDPATTERN.Tpo -c ta_CDLSTALLEDPATTERN.c  -fPIC -DPIC -o .libs/ta_CDLSTALLEDPATTERN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSTALLEDPATTERN.lo -MD -MP -MF .deps/ta_CDLSTALLEDPATTERN.Tpo -c ta_CDLSTALLEDPATTERN.c -o ta_CDLSTALLEDPATTERN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLSTALLEDPATTERN.Tpo .deps/ta_CDLSTALLEDPATTERN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLSTICKSANDWICH.lo -MD -MP -MF .deps/ta_CDLSTICKSANDWICH.Tpo -c -o ta_CDLSTICKSANDWICH.lo ta_CDLSTICKSANDWICH.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSTICKSANDWICH.lo -MD -MP -MF .deps/ta_CDLSTICKSANDWICH.Tpo -c ta_CDLSTICKSANDWICH.c  -fPIC -DPIC -o .libs/ta_CDLSTICKSANDWICH.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLSTICKSANDWICH.lo -MD -MP -MF .deps/ta_CDLSTICKSANDWICH.Tpo -c ta_CDLSTICKSANDWICH.c -o ta_CDLSTICKSANDWICH.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLSTICKSANDWICH.Tpo .deps/ta_CDLSTICKSANDWICH.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLTAKURI.lo -MD -MP -MF .deps/ta_CDLTAKURI.Tpo -c -o ta_CDLTAKURI.lo ta_CDLTAKURI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTAKURI.lo -MD -MP -MF .deps/ta_CDLTAKURI.Tpo -c ta_CDLTAKURI.c  -fPIC -DPIC -o .libs/ta_CDLTAKURI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTAKURI.lo -MD -MP -MF .deps/ta_CDLTAKURI.Tpo -c ta_CDLTAKURI.c -o ta_CDLTAKURI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLTAKURI.Tpo .deps/ta_CDLTAKURI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLTASUKIGAP.lo -MD -MP -MF .deps/ta_CDLTASUKIGAP.Tpo -c -o ta_CDLTASUKIGAP.lo ta_CDLTASUKIGAP.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTASUKIGAP.lo -MD -MP -MF .deps/ta_CDLTASUKIGAP.Tpo -c ta_CDLTASUKIGAP.c  -fPIC -DPIC -o .libs/ta_CDLTASUKIGAP.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTASUKIGAP.lo -MD -MP -MF .deps/ta_CDLTASUKIGAP.Tpo -c ta_CDLTASUKIGAP.c -o ta_CDLTASUKIGAP.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLTASUKIGAP.Tpo .deps/ta_CDLTASUKIGAP.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLTHRUSTING.lo -MD -MP -MF .deps/ta_CDLTHRUSTING.Tpo -c -o ta_CDLTHRUSTING.lo ta_CDLTHRUSTING.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTHRUSTING.lo -MD -MP -MF .deps/ta_CDLTHRUSTING.Tpo -c ta_CDLTHRUSTING.c  -fPIC -DPIC -o .libs/ta_CDLTHRUSTING.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTHRUSTING.lo -MD -MP -MF .deps/ta_CDLTHRUSTING.Tpo -c ta_CDLTHRUSTING.c -o ta_CDLTHRUSTING.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLTHRUSTING.Tpo .deps/ta_CDLTHRUSTING.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLTRISTAR.lo -MD -MP -MF .deps/ta_CDLTRISTAR.Tpo -c -o ta_CDLTRISTAR.lo ta_CDLTRISTAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTRISTAR.lo -MD -MP -MF .deps/ta_CDLTRISTAR.Tpo -c ta_CDLTRISTAR.c  -fPIC -DPIC -o .libs/ta_CDLTRISTAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLTRISTAR.lo -MD -MP -MF .deps/ta_CDLTRISTAR.Tpo -c ta_CDLTRISTAR.c -o ta_CDLTRISTAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLTRISTAR.Tpo .deps/ta_CDLTRISTAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLUNIQUE3RIVER.lo -MD -MP -MF .deps/ta_CDLUNIQUE3RIVER.Tpo -c -o ta_CDLUNIQUE3RIVER.lo ta_CDLUNIQUE3RIVER.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLUNIQUE3RIVER.lo -MD -MP -MF .deps/ta_CDLUNIQUE3RIVER.Tpo -c ta_CDLUNIQUE3RIVER.c  -fPIC -DPIC -o .libs/ta_CDLUNIQUE3RIVER.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLUNIQUE3RIVER.lo -MD -MP -MF .deps/ta_CDLUNIQUE3RIVER.Tpo -c ta_CDLUNIQUE3RIVER.c -o ta_CDLUNIQUE3RIVER.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLUNIQUE3RIVER.Tpo .deps/ta_CDLUNIQUE3RIVER.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLUPSIDEGAP2CROWS.lo -MD -MP -MF .deps/ta_CDLUPSIDEGAP2CROWS.Tpo -c -o ta_CDLUPSIDEGAP2CROWS.lo ta_CDLUPSIDEGAP2CROWS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLUPSIDEGAP2CROWS.lo -MD -MP -MF .deps/ta_CDLUPSIDEGAP2CROWS.Tpo -c ta_CDLUPSIDEGAP2CROWS.c  -fPIC -DPIC -o .libs/ta_CDLUPSIDEGAP2CROWS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLUPSIDEGAP2CROWS.lo -MD -MP -MF .deps/ta_CDLUPSIDEGAP2CROWS.Tpo -c ta_CDLUPSIDEGAP2CROWS.c -o ta_CDLUPSIDEGAP2CROWS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLUPSIDEGAP2CROWS.Tpo .deps/ta_CDLUPSIDEGAP2CROWS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CDLXSIDEGAP3METHODS.lo -MD -MP -MF .deps/ta_CDLXSIDEGAP3METHODS.Tpo -c -o ta_CDLXSIDEGAP3METHODS.lo ta_CDLXSIDEGAP3METHODS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLXSIDEGAP3METHODS.lo -MD -MP -MF .deps/ta_CDLXSIDEGAP3METHODS.Tpo -c ta_CDLXSIDEGAP3METHODS.c  -fPIC -DPIC -o .libs/ta_CDLXSIDEGAP3METHODS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CDLXSIDEGAP3METHODS.lo -MD -MP -MF .deps/ta_CDLXSIDEGAP3METHODS.Tpo -c ta_CDLXSIDEGAP3METHODS.c -o ta_CDLXSIDEGAP3METHODS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CDLXSIDEGAP3METHODS.Tpo .deps/ta_CDLXSIDEGAP3METHODS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CEIL.lo -MD -MP -MF .deps/ta_CEIL.Tpo -c -o ta_CEIL.lo ta_CEIL.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CEIL.lo -MD -MP -MF .deps/ta_CEIL.Tpo -c ta_CEIL.c  -fPIC -DPIC -o .libs/ta_CEIL.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CEIL.lo -MD -MP -MF .deps/ta_CEIL.Tpo -c ta_CEIL.c -o ta_CEIL.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CEIL.Tpo .deps/ta_CEIL.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CMO.lo -MD -MP -MF .deps/ta_CMO.Tpo -c -o ta_CMO.lo ta_CMO.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CMO.lo -MD -MP -MF .deps/ta_CMO.Tpo -c ta_CMO.c  -fPIC -DPIC -o .libs/ta_CMO.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CMO.lo -MD -MP -MF .deps/ta_CMO.Tpo -c ta_CMO.c -o ta_CMO.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CMO.Tpo .deps/ta_CMO.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_CORREL.lo -MD -MP -MF .deps/ta_CORREL.Tpo -c -o ta_CORREL.lo ta_CORREL.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CORREL.lo -MD -MP -MF .deps/ta_CORREL.Tpo -c ta_CORREL.c  -fPIC -DPIC -o .libs/ta_CORREL.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_CORREL.lo -MD -MP -MF .deps/ta_CORREL.Tpo -c ta_CORREL.c -o ta_CORREL.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_CORREL.Tpo .deps/ta_CORREL.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_COS.lo -MD -MP -MF .deps/ta_COS.Tpo -c -o ta_COS.lo ta_COS.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_COS.lo -MD -MP -MF .deps/ta_COS.Tpo -c ta_COS.c  -fPIC -DPIC -o .libs/ta_COS.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_COS.lo -MD -MP -MF .deps/ta_COS.Tpo -c ta_COS.c -o ta_COS.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_COS.Tpo .deps/ta_COS.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_COSH.lo -MD -MP -MF .deps/ta_COSH.Tpo -c -o ta_COSH.lo ta_COSH.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_COSH.lo -MD -MP -MF .deps/ta_COSH.Tpo -c ta_COSH.c  -fPIC -DPIC -o .libs/ta_COSH.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_COSH.lo -MD -MP -MF .deps/ta_COSH.Tpo -c ta_COSH.c -o ta_COSH.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_COSH.Tpo .deps/ta_COSH.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_DEMA.lo -MD -MP -MF .deps/ta_DEMA.Tpo -c -o ta_DEMA.lo ta_DEMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_DEMA.lo -MD -MP -MF .deps/ta_DEMA.Tpo -c ta_DEMA.c  -fPIC -DPIC -o .libs/ta_DEMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_DEMA.lo -MD -MP -MF .deps/ta_DEMA.Tpo -c ta_DEMA.c -o ta_DEMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_DEMA.Tpo .deps/ta_DEMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_DIV.lo -MD -MP -MF .deps/ta_DIV.Tpo -c -o ta_DIV.lo ta_DIV.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_DIV.lo -MD -MP -MF .deps/ta_DIV.Tpo -c ta_DIV.c  -fPIC -DPIC -o .libs/ta_DIV.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_DIV.lo -MD -MP -MF .deps/ta_DIV.Tpo -c ta_DIV.c -o ta_DIV.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_DIV.Tpo .deps/ta_DIV.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_DX.lo -MD -MP -MF .deps/ta_DX.Tpo -c -o ta_DX.lo ta_DX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_DX.lo -MD -MP -MF .deps/ta_DX.Tpo -c ta_DX.c  -fPIC -DPIC -o .libs/ta_DX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_DX.lo -MD -MP -MF .deps/ta_DX.Tpo -c ta_DX.c -o ta_DX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_DX.Tpo .deps/ta_DX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_EMA.lo -MD -MP -MF .deps/ta_EMA.Tpo -c -o ta_EMA.lo ta_EMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_EMA.lo -MD -MP -MF .deps/ta_EMA.Tpo -c ta_EMA.c  -fPIC -DPIC -o .libs/ta_EMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_EMA.lo -MD -MP -MF .deps/ta_EMA.Tpo -c ta_EMA.c -o ta_EMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_EMA.Tpo .deps/ta_EMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_EXP.lo -MD -MP -MF .deps/ta_EXP.Tpo -c -o ta_EXP.lo ta_EXP.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_EXP.lo -MD -MP -MF .deps/ta_EXP.Tpo -c ta_EXP.c  -fPIC -DPIC -o .libs/ta_EXP.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_EXP.lo -MD -MP -MF .deps/ta_EXP.Tpo -c ta_EXP.c -o ta_EXP.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_EXP.Tpo .deps/ta_EXP.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_FLOOR.lo -MD -MP -MF .deps/ta_FLOOR.Tpo -c -o ta_FLOOR.lo ta_FLOOR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_FLOOR.lo -MD -MP -MF .deps/ta_FLOOR.Tpo -c ta_FLOOR.c  -fPIC -DPIC -o .libs/ta_FLOOR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_FLOOR.lo -MD -MP -MF .deps/ta_FLOOR.Tpo -c ta_FLOOR.c -o ta_FLOOR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_FLOOR.Tpo .deps/ta_FLOOR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_HT_DCPERIOD.lo -MD -MP -MF .deps/ta_HT_DCPERIOD.Tpo -c -o ta_HT_DCPERIOD.lo ta_HT_DCPERIOD.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_DCPERIOD.lo -MD -MP -MF .deps/ta_HT_DCPERIOD.Tpo -c ta_HT_DCPERIOD.c  -fPIC -DPIC -o .libs/ta_HT_DCPERIOD.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_DCPERIOD.lo -MD -MP -MF .deps/ta_HT_DCPERIOD.Tpo -c ta_HT_DCPERIOD.c -o ta_HT_DCPERIOD.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_HT_DCPERIOD.Tpo .deps/ta_HT_DCPERIOD.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_HT_DCPHASE.lo -MD -MP -MF .deps/ta_HT_DCPHASE.Tpo -c -o ta_HT_DCPHASE.lo ta_HT_DCPHASE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_DCPHASE.lo -MD -MP -MF .deps/ta_HT_DCPHASE.Tpo -c ta_HT_DCPHASE.c  -fPIC -DPIC -o .libs/ta_HT_DCPHASE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_DCPHASE.lo -MD -MP -MF .deps/ta_HT_DCPHASE.Tpo -c ta_HT_DCPHASE.c -o ta_HT_DCPHASE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_HT_DCPHASE.Tpo .deps/ta_HT_DCPHASE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_HT_PHASOR.lo -MD -MP -MF .deps/ta_HT_PHASOR.Tpo -c -o ta_HT_PHASOR.lo ta_HT_PHASOR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_PHASOR.lo -MD -MP -MF .deps/ta_HT_PHASOR.Tpo -c ta_HT_PHASOR.c  -fPIC -DPIC -o .libs/ta_HT_PHASOR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_PHASOR.lo -MD -MP -MF .deps/ta_HT_PHASOR.Tpo -c ta_HT_PHASOR.c -o ta_HT_PHASOR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_HT_PHASOR.Tpo .deps/ta_HT_PHASOR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_HT_SINE.lo -MD -MP -MF .deps/ta_HT_SINE.Tpo -c -o ta_HT_SINE.lo ta_HT_SINE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_SINE.lo -MD -MP -MF .deps/ta_HT_SINE.Tpo -c ta_HT_SINE.c  -fPIC -DPIC -o .libs/ta_HT_SINE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_SINE.lo -MD -MP -MF .deps/ta_HT_SINE.Tpo -c ta_HT_SINE.c -o ta_HT_SINE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_HT_SINE.Tpo .deps/ta_HT_SINE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_HT_TRENDLINE.lo -MD -MP -MF .deps/ta_HT_TRENDLINE.Tpo -c -o ta_HT_TRENDLINE.lo ta_HT_TRENDLINE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_TRENDLINE.lo -MD -MP -MF .deps/ta_HT_TRENDLINE.Tpo -c ta_HT_TRENDLINE.c  -fPIC -DPIC -o .libs/ta_HT_TRENDLINE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_TRENDLINE.lo -MD -MP -MF .deps/ta_HT_TRENDLINE.Tpo -c ta_HT_TRENDLINE.c -o ta_HT_TRENDLINE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_HT_TRENDLINE.Tpo .deps/ta_HT_TRENDLINE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_HT_TRENDMODE.lo -MD -MP -MF .deps/ta_HT_TRENDMODE.Tpo -c -o ta_HT_TRENDMODE.lo ta_HT_TRENDMODE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_TRENDMODE.lo -MD -MP -MF .deps/ta_HT_TRENDMODE.Tpo -c ta_HT_TRENDMODE.c  -fPIC -DPIC -o .libs/ta_HT_TRENDMODE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_HT_TRENDMODE.lo -MD -MP -MF .deps/ta_HT_TRENDMODE.Tpo -c ta_HT_TRENDMODE.c -o ta_HT_TRENDMODE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_HT_TRENDMODE.Tpo .deps/ta_HT_TRENDMODE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_KAMA.lo -MD -MP -MF .deps/ta_KAMA.Tpo -c -o ta_KAMA.lo ta_KAMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_KAMA.lo -MD -MP -MF .deps/ta_KAMA.Tpo -c ta_KAMA.c  -fPIC -DPIC -o .libs/ta_KAMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_KAMA.lo -MD -MP -MF .deps/ta_KAMA.Tpo -c ta_KAMA.c -o ta_KAMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_KAMA.Tpo .deps/ta_KAMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_LINEARREG.lo -MD -MP -MF .deps/ta_LINEARREG.Tpo -c -o ta_LINEARREG.lo ta_LINEARREG.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG.lo -MD -MP -MF .deps/ta_LINEARREG.Tpo -c ta_LINEARREG.c  -fPIC -DPIC -o .libs/ta_LINEARREG.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG.lo -MD -MP -MF .deps/ta_LINEARREG.Tpo -c ta_LINEARREG.c -o ta_LINEARREG.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_LINEARREG.Tpo .deps/ta_LINEARREG.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_LINEARREG_ANGLE.lo -MD -MP -MF .deps/ta_LINEARREG_ANGLE.Tpo -c -o ta_LINEARREG_ANGLE.lo ta_LINEARREG_ANGLE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG_ANGLE.lo -MD -MP -MF .deps/ta_LINEARREG_ANGLE.Tpo -c ta_LINEARREG_ANGLE.c  -fPIC -DPIC -o .libs/ta_LINEARREG_ANGLE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG_ANGLE.lo -MD -MP -MF .deps/ta_LINEARREG_ANGLE.Tpo -c ta_LINEARREG_ANGLE.c -o ta_LINEARREG_ANGLE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_LINEARREG_ANGLE.Tpo .deps/ta_LINEARREG_ANGLE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_LINEARREG_INTERCEPT.lo -MD -MP -MF .deps/ta_LINEARREG_INTERCEPT.Tpo -c -o ta_LINEARREG_INTERCEPT.lo ta_LINEARREG_INTERCEPT.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG_INTERCEPT.lo -MD -MP -MF .deps/ta_LINEARREG_INTERCEPT.Tpo -c ta_LINEARREG_INTERCEPT.c  -fPIC -DPIC -o .libs/ta_LINEARREG_INTERCEPT.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG_INTERCEPT.lo -MD -MP -MF .deps/ta_LINEARREG_INTERCEPT.Tpo -c ta_LINEARREG_INTERCEPT.c -o ta_LINEARREG_INTERCEPT.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_LINEARREG_INTERCEPT.Tpo .deps/ta_LINEARREG_INTERCEPT.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_LINEARREG_SLOPE.lo -MD -MP -MF .deps/ta_LINEARREG_SLOPE.Tpo -c -o ta_LINEARREG_SLOPE.lo ta_LINEARREG_SLOPE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG_SLOPE.lo -MD -MP -MF .deps/ta_LINEARREG_SLOPE.Tpo -c ta_LINEARREG_SLOPE.c  -fPIC -DPIC -o .libs/ta_LINEARREG_SLOPE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LINEARREG_SLOPE.lo -MD -MP -MF .deps/ta_LINEARREG_SLOPE.Tpo -c ta_LINEARREG_SLOPE.c -o ta_LINEARREG_SLOPE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_LINEARREG_SLOPE.Tpo .deps/ta_LINEARREG_SLOPE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_LN.lo -MD -MP -MF .deps/ta_LN.Tpo -c -o ta_LN.lo ta_LN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LN.lo -MD -MP -MF .deps/ta_LN.Tpo -c ta_LN.c  -fPIC -DPIC -o .libs/ta_LN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LN.lo -MD -MP -MF .deps/ta_LN.Tpo -c ta_LN.c -o ta_LN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_LN.Tpo .deps/ta_LN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_LOG10.lo -MD -MP -MF .deps/ta_LOG10.Tpo -c -o ta_LOG10.lo ta_LOG10.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LOG10.lo -MD -MP -MF .deps/ta_LOG10.Tpo -c ta_LOG10.c  -fPIC -DPIC -o .libs/ta_LOG10.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_LOG10.lo -MD -MP -MF .deps/ta_LOG10.Tpo -c ta_LOG10.c -o ta_LOG10.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_LOG10.Tpo .deps/ta_LOG10.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MA.lo -MD -MP -MF .deps/ta_MA.Tpo -c -o ta_MA.lo ta_MA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MA.lo -MD -MP -MF .deps/ta_MA.Tpo -c ta_MA.c  -fPIC -DPIC -o .libs/ta_MA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MA.lo -MD -MP -MF .deps/ta_MA.Tpo -c ta_MA.c -o ta_MA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MA.Tpo .deps/ta_MA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MACD.lo -MD -MP -MF .deps/ta_MACD.Tpo -c -o ta_MACD.lo ta_MACD.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MACD.lo -MD -MP -MF .deps/ta_MACD.Tpo -c ta_MACD.c  -fPIC -DPIC -o .libs/ta_MACD.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MACD.lo -MD -MP -MF .deps/ta_MACD.Tpo -c ta_MACD.c -o ta_MACD.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MACD.Tpo .deps/ta_MACD.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MACDEXT.lo -MD -MP -MF .deps/ta_MACDEXT.Tpo -c -o ta_MACDEXT.lo ta_MACDEXT.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MACDEXT.lo -MD -MP -MF .deps/ta_MACDEXT.Tpo -c ta_MACDEXT.c  -fPIC -DPIC -o .libs/ta_MACDEXT.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MACDEXT.lo -MD -MP -MF .deps/ta_MACDEXT.Tpo -c ta_MACDEXT.c -o ta_MACDEXT.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MACDEXT.Tpo .deps/ta_MACDEXT.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MACDFIX.lo -MD -MP -MF .deps/ta_MACDFIX.Tpo -c -o ta_MACDFIX.lo ta_MACDFIX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MACDFIX.lo -MD -MP -MF .deps/ta_MACDFIX.Tpo -c ta_MACDFIX.c  -fPIC -DPIC -o .libs/ta_MACDFIX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MACDFIX.lo -MD -MP -MF .deps/ta_MACDFIX.Tpo -c ta_MACDFIX.c -o ta_MACDFIX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MACDFIX.Tpo .deps/ta_MACDFIX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MAMA.lo -MD -MP -MF .deps/ta_MAMA.Tpo -c -o ta_MAMA.lo ta_MAMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAMA.lo -MD -MP -MF .deps/ta_MAMA.Tpo -c ta_MAMA.c  -fPIC -DPIC -o .libs/ta_MAMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAMA.lo -MD -MP -MF .deps/ta_MAMA.Tpo -c ta_MAMA.c -o ta_MAMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MAMA.Tpo .deps/ta_MAMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MAVP.lo -MD -MP -MF .deps/ta_MAVP.Tpo -c -o ta_MAVP.lo ta_MAVP.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAVP.lo -MD -MP -MF .deps/ta_MAVP.Tpo -c ta_MAVP.c  -fPIC -DPIC -o .libs/ta_MAVP.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAVP.lo -MD -MP -MF .deps/ta_MAVP.Tpo -c ta_MAVP.c -o ta_MAVP.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MAVP.Tpo .deps/ta_MAVP.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MAX.lo -MD -MP -MF .deps/ta_MAX.Tpo -c -o ta_MAX.lo ta_MAX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAX.lo -MD -MP -MF .deps/ta_MAX.Tpo -c ta_MAX.c  -fPIC -DPIC -o .libs/ta_MAX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAX.lo -MD -MP -MF .deps/ta_MAX.Tpo -c ta_MAX.c -o ta_MAX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MAX.Tpo .deps/ta_MAX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MAXINDEX.lo -MD -MP -MF .deps/ta_MAXINDEX.Tpo -c -o ta_MAXINDEX.lo ta_MAXINDEX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAXINDEX.lo -MD -MP -MF .deps/ta_MAXINDEX.Tpo -c ta_MAXINDEX.c  -fPIC -DPIC -o .libs/ta_MAXINDEX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MAXINDEX.lo -MD -MP -MF .deps/ta_MAXINDEX.Tpo -c ta_MAXINDEX.c -o ta_MAXINDEX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MAXINDEX.Tpo .deps/ta_MAXINDEX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MEDPRICE.lo -MD -MP -MF .deps/ta_MEDPRICE.Tpo -c -o ta_MEDPRICE.lo ta_MEDPRICE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MEDPRICE.lo -MD -MP -MF .deps/ta_MEDPRICE.Tpo -c ta_MEDPRICE.c  -fPIC -DPIC -o .libs/ta_MEDPRICE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MEDPRICE.lo -MD -MP -MF .deps/ta_MEDPRICE.Tpo -c ta_MEDPRICE.c -o ta_MEDPRICE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MEDPRICE.Tpo .deps/ta_MEDPRICE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MFI.lo -MD -MP -MF .deps/ta_MFI.Tpo -c -o ta_MFI.lo ta_MFI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MFI.lo -MD -MP -MF .deps/ta_MFI.Tpo -c ta_MFI.c  -fPIC -DPIC -o .libs/ta_MFI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MFI.lo -MD -MP -MF .deps/ta_MFI.Tpo -c ta_MFI.c -o ta_MFI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MFI.Tpo .deps/ta_MFI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MIDPOINT.lo -MD -MP -MF .deps/ta_MIDPOINT.Tpo -c -o ta_MIDPOINT.lo ta_MIDPOINT.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MIDPOINT.lo -MD -MP -MF .deps/ta_MIDPOINT.Tpo -c ta_MIDPOINT.c  -fPIC -DPIC -o .libs/ta_MIDPOINT.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MIDPOINT.lo -MD -MP -MF .deps/ta_MIDPOINT.Tpo -c ta_MIDPOINT.c -o ta_MIDPOINT.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MIDPOINT.Tpo .deps/ta_MIDPOINT.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MIDPRICE.lo -MD -MP -MF .deps/ta_MIDPRICE.Tpo -c -o ta_MIDPRICE.lo ta_MIDPRICE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MIDPRICE.lo -MD -MP -MF .deps/ta_MIDPRICE.Tpo -c ta_MIDPRICE.c  -fPIC -DPIC -o .libs/ta_MIDPRICE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MIDPRICE.lo -MD -MP -MF .deps/ta_MIDPRICE.Tpo -c ta_MIDPRICE.c -o ta_MIDPRICE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MIDPRICE.Tpo .deps/ta_MIDPRICE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MIN.lo -MD -MP -MF .deps/ta_MIN.Tpo -c -o ta_MIN.lo ta_MIN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MIN.lo -MD -MP -MF .deps/ta_MIN.Tpo -c ta_MIN.c  -fPIC -DPIC -o .libs/ta_MIN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MIN.lo -MD -MP -MF .deps/ta_MIN.Tpo -c ta_MIN.c -o ta_MIN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MIN.Tpo .deps/ta_MIN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MININDEX.lo -MD -MP -MF .deps/ta_MININDEX.Tpo -c -o ta_MININDEX.lo ta_MININDEX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MININDEX.lo -MD -MP -MF .deps/ta_MININDEX.Tpo -c ta_MININDEX.c  -fPIC -DPIC -o .libs/ta_MININDEX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MININDEX.lo -MD -MP -MF .deps/ta_MININDEX.Tpo -c ta_MININDEX.c -o ta_MININDEX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MININDEX.Tpo .deps/ta_MININDEX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MINMAX.lo -MD -MP -MF .deps/ta_MINMAX.Tpo -c -o ta_MINMAX.lo ta_MINMAX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINMAX.lo -MD -MP -MF .deps/ta_MINMAX.Tpo -c ta_MINMAX.c  -fPIC -DPIC -o .libs/ta_MINMAX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINMAX.lo -MD -MP -MF .deps/ta_MINMAX.Tpo -c ta_MINMAX.c -o ta_MINMAX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MINMAX.Tpo .deps/ta_MINMAX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MINMAXINDEX.lo -MD -MP -MF .deps/ta_MINMAXINDEX.Tpo -c -o ta_MINMAXINDEX.lo ta_MINMAXINDEX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINMAXINDEX.lo -MD -MP -MF .deps/ta_MINMAXINDEX.Tpo -c ta_MINMAXINDEX.c  -fPIC -DPIC -o .libs/ta_MINMAXINDEX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINMAXINDEX.lo -MD -MP -MF .deps/ta_MINMAXINDEX.Tpo -c ta_MINMAXINDEX.c -o ta_MINMAXINDEX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MINMAXINDEX.Tpo .deps/ta_MINMAXINDEX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MINUS_DI.lo -MD -MP -MF .deps/ta_MINUS_DI.Tpo -c -o ta_MINUS_DI.lo ta_MINUS_DI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINUS_DI.lo -MD -MP -MF .deps/ta_MINUS_DI.Tpo -c ta_MINUS_DI.c  -fPIC -DPIC -o .libs/ta_MINUS_DI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINUS_DI.lo -MD -MP -MF .deps/ta_MINUS_DI.Tpo -c ta_MINUS_DI.c -o ta_MINUS_DI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MINUS_DI.Tpo .deps/ta_MINUS_DI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MINUS_DM.lo -MD -MP -MF .deps/ta_MINUS_DM.Tpo -c -o ta_MINUS_DM.lo ta_MINUS_DM.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINUS_DM.lo -MD -MP -MF .deps/ta_MINUS_DM.Tpo -c ta_MINUS_DM.c  -fPIC -DPIC -o .libs/ta_MINUS_DM.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MINUS_DM.lo -MD -MP -MF .deps/ta_MINUS_DM.Tpo -c ta_MINUS_DM.c -o ta_MINUS_DM.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MINUS_DM.Tpo .deps/ta_MINUS_DM.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MOM.lo -MD -MP -MF .deps/ta_MOM.Tpo -c -o ta_MOM.lo ta_MOM.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MOM.lo -MD -MP -MF .deps/ta_MOM.Tpo -c ta_MOM.c  -fPIC -DPIC -o .libs/ta_MOM.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MOM.lo -MD -MP -MF .deps/ta_MOM.Tpo -c ta_MOM.c -o ta_MOM.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MOM.Tpo .deps/ta_MOM.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_MULT.lo -MD -MP -MF .deps/ta_MULT.Tpo -c -o ta_MULT.lo ta_MULT.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MULT.lo -MD -MP -MF .deps/ta_MULT.Tpo -c ta_MULT.c  -fPIC -DPIC -o .libs/ta_MULT.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_MULT.lo -MD -MP -MF .deps/ta_MULT.Tpo -c ta_MULT.c -o ta_MULT.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_MULT.Tpo .deps/ta_MULT.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_NATR.lo -MD -MP -MF .deps/ta_NATR.Tpo -c -o ta_NATR.lo ta_NATR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_NATR.lo -MD -MP -MF .deps/ta_NATR.Tpo -c ta_NATR.c  -fPIC -DPIC -o .libs/ta_NATR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_NATR.lo -MD -MP -MF .deps/ta_NATR.Tpo -c ta_NATR.c -o ta_NATR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_NATR.Tpo .deps/ta_NATR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_OBV.lo -MD -MP -MF .deps/ta_OBV.Tpo -c -o ta_OBV.lo ta_OBV.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_OBV.lo -MD -MP -MF .deps/ta_OBV.Tpo -c ta_OBV.c  -fPIC -DPIC -o .libs/ta_OBV.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_OBV.lo -MD -MP -MF .deps/ta_OBV.Tpo -c ta_OBV.c -o ta_OBV.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_OBV.Tpo .deps/ta_OBV.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_PLUS_DI.lo -MD -MP -MF .deps/ta_PLUS_DI.Tpo -c -o ta_PLUS_DI.lo ta_PLUS_DI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_PLUS_DI.lo -MD -MP -MF .deps/ta_PLUS_DI.Tpo -c ta_PLUS_DI.c  -fPIC -DPIC -o .libs/ta_PLUS_DI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_PLUS_DI.lo -MD -MP -MF .deps/ta_PLUS_DI.Tpo -c ta_PLUS_DI.c -o ta_PLUS_DI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_PLUS_DI.Tpo .deps/ta_PLUS_DI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_PLUS_DM.lo -MD -MP -MF .deps/ta_PLUS_DM.Tpo -c -o ta_PLUS_DM.lo ta_PLUS_DM.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_PLUS_DM.lo -MD -MP -MF .deps/ta_PLUS_DM.Tpo -c ta_PLUS_DM.c  -fPIC -DPIC -o .libs/ta_PLUS_DM.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_PLUS_DM.lo -MD -MP -MF .deps/ta_PLUS_DM.Tpo -c ta_PLUS_DM.c -o ta_PLUS_DM.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_PLUS_DM.Tpo .deps/ta_PLUS_DM.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_PPO.lo -MD -MP -MF .deps/ta_PPO.Tpo -c -o ta_PPO.lo ta_PPO.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_PPO.lo -MD -MP -MF .deps/ta_PPO.Tpo -c ta_PPO.c  -fPIC -DPIC -o .libs/ta_PPO.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_PPO.lo -MD -MP -MF .deps/ta_PPO.Tpo -c ta_PPO.c -o ta_PPO.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_PPO.Tpo .deps/ta_PPO.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ROC.lo -MD -MP -MF .deps/ta_ROC.Tpo -c -o ta_ROC.lo ta_ROC.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROC.lo -MD -MP -MF .deps/ta_ROC.Tpo -c ta_ROC.c  -fPIC -DPIC -o .libs/ta_ROC.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROC.lo -MD -MP -MF .deps/ta_ROC.Tpo -c ta_ROC.c -o ta_ROC.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ROC.Tpo .deps/ta_ROC.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ROCP.lo -MD -MP -MF .deps/ta_ROCP.Tpo -c -o ta_ROCP.lo ta_ROCP.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROCP.lo -MD -MP -MF .deps/ta_ROCP.Tpo -c ta_ROCP.c  -fPIC -DPIC -o .libs/ta_ROCP.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROCP.lo -MD -MP -MF .deps/ta_ROCP.Tpo -c ta_ROCP.c -o ta_ROCP.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ROCP.Tpo .deps/ta_ROCP.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ROCR.lo -MD -MP -MF .deps/ta_ROCR.Tpo -c -o ta_ROCR.lo ta_ROCR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROCR.lo -MD -MP -MF .deps/ta_ROCR.Tpo -c ta_ROCR.c  -fPIC -DPIC -o .libs/ta_ROCR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROCR.lo -MD -MP -MF .deps/ta_ROCR.Tpo -c ta_ROCR.c -o ta_ROCR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ROCR.Tpo .deps/ta_ROCR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ROCR100.lo -MD -MP -MF .deps/ta_ROCR100.Tpo -c -o ta_ROCR100.lo ta_ROCR100.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROCR100.lo -MD -MP -MF .deps/ta_ROCR100.Tpo -c ta_ROCR100.c  -fPIC -DPIC -o .libs/ta_ROCR100.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ROCR100.lo -MD -MP -MF .deps/ta_ROCR100.Tpo -c ta_ROCR100.c -o ta_ROCR100.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ROCR100.Tpo .deps/ta_ROCR100.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_RSI.lo -MD -MP -MF .deps/ta_RSI.Tpo -c -o ta_RSI.lo ta_RSI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_RSI.lo -MD -MP -MF .deps/ta_RSI.Tpo -c ta_RSI.c  -fPIC -DPIC -o .libs/ta_RSI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_RSI.lo -MD -MP -MF .deps/ta_RSI.Tpo -c ta_RSI.c -o ta_RSI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_RSI.Tpo .deps/ta_RSI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SAR.lo -MD -MP -MF .deps/ta_SAR.Tpo -c -o ta_SAR.lo ta_SAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SAR.lo -MD -MP -MF .deps/ta_SAR.Tpo -c ta_SAR.c  -fPIC -DPIC -o .libs/ta_SAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SAR.lo -MD -MP -MF .deps/ta_SAR.Tpo -c ta_SAR.c -o ta_SAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SAR.Tpo .deps/ta_SAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SAREXT.lo -MD -MP -MF .deps/ta_SAREXT.Tpo -c -o ta_SAREXT.lo ta_SAREXT.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SAREXT.lo -MD -MP -MF .deps/ta_SAREXT.Tpo -c ta_SAREXT.c  -fPIC -DPIC -o .libs/ta_SAREXT.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SAREXT.lo -MD -MP -MF .deps/ta_SAREXT.Tpo -c ta_SAREXT.c -o ta_SAREXT.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SAREXT.Tpo .deps/ta_SAREXT.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SIN.lo -MD -MP -MF .deps/ta_SIN.Tpo -c -o ta_SIN.lo ta_SIN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SIN.lo -MD -MP -MF .deps/ta_SIN.Tpo -c ta_SIN.c  -fPIC -DPIC -o .libs/ta_SIN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SIN.lo -MD -MP -MF .deps/ta_SIN.Tpo -c ta_SIN.c -o ta_SIN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SIN.Tpo .deps/ta_SIN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SINH.lo -MD -MP -MF .deps/ta_SINH.Tpo -c -o ta_SINH.lo ta_SINH.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SINH.lo -MD -MP -MF .deps/ta_SINH.Tpo -c ta_SINH.c  -fPIC -DPIC -o .libs/ta_SINH.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SINH.lo -MD -MP -MF .deps/ta_SINH.Tpo -c ta_SINH.c -o ta_SINH.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SINH.Tpo .deps/ta_SINH.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SMA.lo -MD -MP -MF .deps/ta_SMA.Tpo -c -o ta_SMA.lo ta_SMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SMA.lo -MD -MP -MF .deps/ta_SMA.Tpo -c ta_SMA.c  -fPIC -DPIC -o .libs/ta_SMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SMA.lo -MD -MP -MF .deps/ta_SMA.Tpo -c ta_SMA.c -o ta_SMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SMA.Tpo .deps/ta_SMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SQRT.lo -MD -MP -MF .deps/ta_SQRT.Tpo -c -o ta_SQRT.lo ta_SQRT.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SQRT.lo -MD -MP -MF .deps/ta_SQRT.Tpo -c ta_SQRT.c  -fPIC -DPIC -o .libs/ta_SQRT.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SQRT.lo -MD -MP -MF .deps/ta_SQRT.Tpo -c ta_SQRT.c -o ta_SQRT.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SQRT.Tpo .deps/ta_SQRT.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_STDDEV.lo -MD -MP -MF .deps/ta_STDDEV.Tpo -c -o ta_STDDEV.lo ta_STDDEV.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STDDEV.lo -MD -MP -MF .deps/ta_STDDEV.Tpo -c ta_STDDEV.c  -fPIC -DPIC -o .libs/ta_STDDEV.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STDDEV.lo -MD -MP -MF .deps/ta_STDDEV.Tpo -c ta_STDDEV.c -o ta_STDDEV.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_STDDEV.Tpo .deps/ta_STDDEV.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_STOCH.lo -MD -MP -MF .deps/ta_STOCH.Tpo -c -o ta_STOCH.lo ta_STOCH.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STOCH.lo -MD -MP -MF .deps/ta_STOCH.Tpo -c ta_STOCH.c  -fPIC -DPIC -o .libs/ta_STOCH.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STOCH.lo -MD -MP -MF .deps/ta_STOCH.Tpo -c ta_STOCH.c -o ta_STOCH.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_STOCH.Tpo .deps/ta_STOCH.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_STOCHF.lo -MD -MP -MF .deps/ta_STOCHF.Tpo -c -o ta_STOCHF.lo ta_STOCHF.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STOCHF.lo -MD -MP -MF .deps/ta_STOCHF.Tpo -c ta_STOCHF.c  -fPIC -DPIC -o .libs/ta_STOCHF.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STOCHF.lo -MD -MP -MF .deps/ta_STOCHF.Tpo -c ta_STOCHF.c -o ta_STOCHF.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_STOCHF.Tpo .deps/ta_STOCHF.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_STOCHRSI.lo -MD -MP -MF .deps/ta_STOCHRSI.Tpo -c -o ta_STOCHRSI.lo ta_STOCHRSI.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STOCHRSI.lo -MD -MP -MF .deps/ta_STOCHRSI.Tpo -c ta_STOCHRSI.c  -fPIC -DPIC -o .libs/ta_STOCHRSI.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_STOCHRSI.lo -MD -MP -MF .deps/ta_STOCHRSI.Tpo -c ta_STOCHRSI.c -o ta_STOCHRSI.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_STOCHRSI.Tpo .deps/ta_STOCHRSI.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SUB.lo -MD -MP -MF .deps/ta_SUB.Tpo -c -o ta_SUB.lo ta_SUB.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SUB.lo -MD -MP -MF .deps/ta_SUB.Tpo -c ta_SUB.c  -fPIC -DPIC -o .libs/ta_SUB.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SUB.lo -MD -MP -MF .deps/ta_SUB.Tpo -c ta_SUB.c -o ta_SUB.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SUB.Tpo .deps/ta_SUB.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_SUM.lo -MD -MP -MF .deps/ta_SUM.Tpo -c -o ta_SUM.lo ta_SUM.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SUM.lo -MD -MP -MF .deps/ta_SUM.Tpo -c ta_SUM.c  -fPIC -DPIC -o .libs/ta_SUM.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_SUM.lo -MD -MP -MF .deps/ta_SUM.Tpo -c ta_SUM.c -o ta_SUM.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_SUM.Tpo .deps/ta_SUM.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_T3.lo -MD -MP -MF .deps/ta_T3.Tpo -c -o ta_T3.lo ta_T3.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_T3.lo -MD -MP -MF .deps/ta_T3.Tpo -c ta_T3.c  -fPIC -DPIC -o .libs/ta_T3.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_T3.lo -MD -MP -MF .deps/ta_T3.Tpo -c ta_T3.c -o ta_T3.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_T3.Tpo .deps/ta_T3.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TAN.lo -MD -MP -MF .deps/ta_TAN.Tpo -c -o ta_TAN.lo ta_TAN.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TAN.lo -MD -MP -MF .deps/ta_TAN.Tpo -c ta_TAN.c  -fPIC -DPIC -o .libs/ta_TAN.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TAN.lo -MD -MP -MF .deps/ta_TAN.Tpo -c ta_TAN.c -o ta_TAN.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TAN.Tpo .deps/ta_TAN.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TANH.lo -MD -MP -MF .deps/ta_TANH.Tpo -c -o ta_TANH.lo ta_TANH.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TANH.lo -MD -MP -MF .deps/ta_TANH.Tpo -c ta_TANH.c  -fPIC -DPIC -o .libs/ta_TANH.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TANH.lo -MD -MP -MF .deps/ta_TANH.Tpo -c ta_TANH.c -o ta_TANH.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TANH.Tpo .deps/ta_TANH.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TEMA.lo -MD -MP -MF .deps/ta_TEMA.Tpo -c -o ta_TEMA.lo ta_TEMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TEMA.lo -MD -MP -MF .deps/ta_TEMA.Tpo -c ta_TEMA.c  -fPIC -DPIC -o .libs/ta_TEMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TEMA.lo -MD -MP -MF .deps/ta_TEMA.Tpo -c ta_TEMA.c -o ta_TEMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TEMA.Tpo .deps/ta_TEMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TRANGE.lo -MD -MP -MF .deps/ta_TRANGE.Tpo -c -o ta_TRANGE.lo ta_TRANGE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TRANGE.lo -MD -MP -MF .deps/ta_TRANGE.Tpo -c ta_TRANGE.c  -fPIC -DPIC -o .libs/ta_TRANGE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TRANGE.lo -MD -MP -MF .deps/ta_TRANGE.Tpo -c ta_TRANGE.c -o ta_TRANGE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TRANGE.Tpo .deps/ta_TRANGE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TRIMA.lo -MD -MP -MF .deps/ta_TRIMA.Tpo -c -o ta_TRIMA.lo ta_TRIMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TRIMA.lo -MD -MP -MF .deps/ta_TRIMA.Tpo -c ta_TRIMA.c  -fPIC -DPIC -o .libs/ta_TRIMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TRIMA.lo -MD -MP -MF .deps/ta_TRIMA.Tpo -c ta_TRIMA.c -o ta_TRIMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TRIMA.Tpo .deps/ta_TRIMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TRIX.lo -MD -MP -MF .deps/ta_TRIX.Tpo -c -o ta_TRIX.lo ta_TRIX.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TRIX.lo -MD -MP -MF .deps/ta_TRIX.Tpo -c ta_TRIX.c  -fPIC -DPIC -o .libs/ta_TRIX.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TRIX.lo -MD -MP -MF .deps/ta_TRIX.Tpo -c ta_TRIX.c -o ta_TRIX.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TRIX.Tpo .deps/ta_TRIX.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TSF.lo -MD -MP -MF .deps/ta_TSF.Tpo -c -o ta_TSF.lo ta_TSF.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TSF.lo -MD -MP -MF .deps/ta_TSF.Tpo -c ta_TSF.c  -fPIC -DPIC -o .libs/ta_TSF.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TSF.lo -MD -MP -MF .deps/ta_TSF.Tpo -c ta_TSF.c -o ta_TSF.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TSF.Tpo .deps/ta_TSF.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_TYPPRICE.lo -MD -MP -MF .deps/ta_TYPPRICE.Tpo -c -o ta_TYPPRICE.lo ta_TYPPRICE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TYPPRICE.lo -MD -MP -MF .deps/ta_TYPPRICE.Tpo -c ta_TYPPRICE.c  -fPIC -DPIC -o .libs/ta_TYPPRICE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_TYPPRICE.lo -MD -MP -MF .deps/ta_TYPPRICE.Tpo -c ta_TYPPRICE.c -o ta_TYPPRICE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_TYPPRICE.Tpo .deps/ta_TYPPRICE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_ULTOSC.lo -MD -MP -MF .deps/ta_ULTOSC.Tpo -c -o ta_ULTOSC.lo ta_ULTOSC.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ULTOSC.lo -MD -MP -MF .deps/ta_ULTOSC.Tpo -c ta_ULTOSC.c  -fPIC -DPIC -o .libs/ta_ULTOSC.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_ULTOSC.lo -MD -MP -MF .deps/ta_ULTOSC.Tpo -c ta_ULTOSC.c -o ta_ULTOSC.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_ULTOSC.Tpo .deps/ta_ULTOSC.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_VAR.lo -MD -MP -MF .deps/ta_VAR.Tpo -c -o ta_VAR.lo ta_VAR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_VAR.lo -MD -MP -MF .deps/ta_VAR.Tpo -c ta_VAR.c  -fPIC -DPIC -o .libs/ta_VAR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_VAR.lo -MD -MP -MF .deps/ta_VAR.Tpo -c ta_VAR.c -o ta_VAR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_VAR.Tpo .deps/ta_VAR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_WCLPRICE.lo -MD -MP -MF .deps/ta_WCLPRICE.Tpo -c -o ta_WCLPRICE.lo ta_WCLPRICE.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_WCLPRICE.lo -MD -MP -MF .deps/ta_WCLPRICE.Tpo -c ta_WCLPRICE.c  -fPIC -DPIC -o .libs/ta_WCLPRICE.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_WCLPRICE.lo -MD -MP -MF .deps/ta_WCLPRICE.Tpo -c ta_WCLPRICE.c -o ta_WCLPRICE.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_WCLPRICE.Tpo .deps/ta_WCLPRICE.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_WILLR.lo -MD -MP -MF .deps/ta_WILLR.Tpo -c -o ta_WILLR.lo ta_WILLR.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_WILLR.lo -MD -MP -MF .deps/ta_WILLR.Tpo -c ta_WILLR.c  -fPIC -DPIC -o .libs/ta_WILLR.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_WILLR.lo -MD -MP -MF .deps/ta_WILLR.Tpo -c ta_WILLR.c -o ta_WILLR.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_WILLR.Tpo .deps/ta_WILLR.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I. -I../../include  -I../ta_common/   -g -O2 -MT ta_WMA.lo -MD -MP -MF .deps/ta_WMA.Tpo -c -o ta_WMA.lo ta_WMA.c\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_WMA.lo -MD -MP -MF .deps/ta_WMA.Tpo -c ta_WMA.c  -fPIC -DPIC -o .libs/ta_WMA.o\n",
            " gcc -DHAVE_CONFIG_H -I. -I../../include -I../ta_common/ -g -O2 -MT ta_WMA.lo -MD -MP -MF .deps/ta_WMA.Tpo -c ta_WMA.c -o ta_WMA.o >/dev/null 2>&1\n",
            "mv -f .deps/ta_WMA.Tpo .deps/ta_WMA.Plo\n",
            "/bin/bash ../../libtool --tag=CC   --mode=link gcc  -g -O2 -version-info 0:0:0  -o libta_func.la  ta_utility.lo ta_ACOS.lo ta_AD.lo ta_ADD.lo ta_ADOSC.lo ta_ADX.lo ta_ADXR.lo ta_APO.lo ta_AROON.lo ta_AROONOSC.lo ta_ASIN.lo ta_ATAN.lo ta_ATR.lo ta_AVGPRICE.lo ta_BBANDS.lo ta_BETA.lo ta_BOP.lo ta_CCI.lo ta_CDL2CROWS.lo ta_CDL3BLACKCROWS.lo ta_CDL3INSIDE.lo ta_CDL3LINESTRIKE.lo ta_CDL3OUTSIDE.lo ta_CDL3STARSINSOUTH.lo ta_CDL3WHITESOLDIERS.lo ta_CDLABANDONEDBABY.lo ta_CDLADVANCEBLOCK.lo ta_CDLBELTHOLD.lo ta_CDLBREAKAWAY.lo ta_CDLCLOSINGMARUBOZU.lo ta_CDLCONCEALBABYSWALL.lo ta_CDLCOUNTERATTACK.lo ta_CDLDARKCLOUDCOVER.lo ta_CDLDOJI.lo ta_CDLDOJISTAR.lo ta_CDLDRAGONFLYDOJI.lo ta_CDLENGULFING.lo ta_CDLEVENINGDOJISTAR.lo ta_CDLEVENINGSTAR.lo ta_CDLGAPSIDESIDEWHITE.lo ta_CDLGRAVESTONEDOJI.lo ta_CDLHAMMER.lo ta_CDLHANGINGMAN.lo ta_CDLHARAMI.lo ta_CDLHARAMICROSS.lo ta_CDLHIGHWAVE.lo ta_CDLHIKKAKE.lo ta_CDLHIKKAKEMOD.lo ta_CDLHOMINGPIGEON.lo ta_CDLIDENTICAL3CROWS.lo ta_CDLINNECK.lo ta_CDLINVERTEDHAMMER.lo ta_CDLKICKING.lo ta_CDLKICKINGBYLENGTH.lo ta_CDLLADDERBOTTOM.lo ta_CDLLONGLEGGEDDOJI.lo ta_CDLLONGLINE.lo ta_CDLMARUBOZU.lo ta_CDLMATCHINGLOW.lo ta_CDLMATHOLD.lo ta_CDLMORNINGDOJISTAR.lo ta_CDLMORNINGSTAR.lo ta_CDLONNECK.lo ta_CDLPIERCING.lo ta_CDLRICKSHAWMAN.lo ta_CDLRISEFALL3METHODS.lo ta_CDLSEPARATINGLINES.lo ta_CDLSHOOTINGSTAR.lo ta_CDLSHORTLINE.lo ta_CDLSPINNINGTOP.lo ta_CDLSTALLEDPATTERN.lo ta_CDLSTICKSANDWICH.lo ta_CDLTAKURI.lo ta_CDLTASUKIGAP.lo ta_CDLTHRUSTING.lo ta_CDLTRISTAR.lo ta_CDLUNIQUE3RIVER.lo ta_CDLUPSIDEGAP2CROWS.lo ta_CDLXSIDEGAP3METHODS.lo ta_CEIL.lo ta_CMO.lo ta_CORREL.lo ta_COS.lo ta_COSH.lo ta_DEMA.lo ta_DIV.lo ta_DX.lo ta_EMA.lo ta_EXP.lo ta_FLOOR.lo ta_HT_DCPERIOD.lo ta_HT_DCPHASE.lo ta_HT_PHASOR.lo ta_HT_SINE.lo ta_HT_TRENDLINE.lo ta_HT_TRENDMODE.lo ta_KAMA.lo ta_LINEARREG.lo ta_LINEARREG_ANGLE.lo ta_LINEARREG_INTERCEPT.lo ta_LINEARREG_SLOPE.lo ta_LN.lo ta_LOG10.lo ta_MA.lo ta_MACD.lo ta_MACDEXT.lo ta_MACDFIX.lo ta_MAMA.lo ta_MAVP.lo ta_MAX.lo ta_MAXINDEX.lo ta_MEDPRICE.lo ta_MFI.lo ta_MIDPOINT.lo ta_MIDPRICE.lo ta_MIN.lo ta_MININDEX.lo ta_MINMAX.lo ta_MINMAXINDEX.lo ta_MINUS_DI.lo ta_MINUS_DM.lo ta_MOM.lo ta_MULT.lo ta_NATR.lo ta_OBV.lo ta_PLUS_DI.lo ta_PLUS_DM.lo ta_PPO.lo ta_ROC.lo ta_ROCP.lo ta_ROCR.lo ta_ROCR100.lo ta_RSI.lo ta_SAR.lo ta_SAREXT.lo ta_SIN.lo ta_SINH.lo ta_SMA.lo ta_SQRT.lo ta_STDDEV.lo ta_STOCH.lo ta_STOCHF.lo ta_STOCHRSI.lo ta_SUB.lo ta_SUM.lo ta_T3.lo ta_TAN.lo ta_TANH.lo ta_TEMA.lo ta_TRANGE.lo ta_TRIMA.lo ta_TRIX.lo ta_TSF.lo ta_TYPPRICE.lo ta_ULTOSC.lo ta_VAR.lo ta_WCLPRICE.lo ta_WILLR.lo ta_WMA.lo  -lpthread -ldl \n",
            "libtool: link: warning: `-version-info/-version-number' is ignored for convenience libraries\n",
            "ar cru .libs/libta_func.a .libs/ta_utility.o .libs/ta_ACOS.o .libs/ta_AD.o .libs/ta_ADD.o .libs/ta_ADOSC.o .libs/ta_ADX.o .libs/ta_ADXR.o .libs/ta_APO.o .libs/ta_AROON.o .libs/ta_AROONOSC.o .libs/ta_ASIN.o .libs/ta_ATAN.o .libs/ta_ATR.o .libs/ta_AVGPRICE.o .libs/ta_BBANDS.o .libs/ta_BETA.o .libs/ta_BOP.o .libs/ta_CCI.o .libs/ta_CDL2CROWS.o .libs/ta_CDL3BLACKCROWS.o .libs/ta_CDL3INSIDE.o .libs/ta_CDL3LINESTRIKE.o .libs/ta_CDL3OUTSIDE.o .libs/ta_CDL3STARSINSOUTH.o .libs/ta_CDL3WHITESOLDIERS.o .libs/ta_CDLABANDONEDBABY.o .libs/ta_CDLADVANCEBLOCK.o .libs/ta_CDLBELTHOLD.o .libs/ta_CDLBREAKAWAY.o .libs/ta_CDLCLOSINGMARUBOZU.o .libs/ta_CDLCONCEALBABYSWALL.o .libs/ta_CDLCOUNTERATTACK.o .libs/ta_CDLDARKCLOUDCOVER.o .libs/ta_CDLDOJI.o .libs/ta_CDLDOJISTAR.o .libs/ta_CDLDRAGONFLYDOJI.o .libs/ta_CDLENGULFING.o .libs/ta_CDLEVENINGDOJISTAR.o .libs/ta_CDLEVENINGSTAR.o .libs/ta_CDLGAPSIDESIDEWHITE.o .libs/ta_CDLGRAVESTONEDOJI.o .libs/ta_CDLHAMMER.o .libs/ta_CDLHANGINGMAN.o .libs/ta_CDLHARAMI.o .libs/ta_CDLHARAMICROSS.o .libs/ta_CDLHIGHWAVE.o .libs/ta_CDLHIKKAKE.o .libs/ta_CDLHIKKAKEMOD.o .libs/ta_CDLHOMINGPIGEON.o .libs/ta_CDLIDENTICAL3CROWS.o .libs/ta_CDLINNECK.o .libs/ta_CDLINVERTEDHAMMER.o .libs/ta_CDLKICKING.o .libs/ta_CDLKICKINGBYLENGTH.o .libs/ta_CDLLADDERBOTTOM.o .libs/ta_CDLLONGLEGGEDDOJI.o .libs/ta_CDLLONGLINE.o .libs/ta_CDLMARUBOZU.o .libs/ta_CDLMATCHINGLOW.o .libs/ta_CDLMATHOLD.o .libs/ta_CDLMORNINGDOJISTAR.o .libs/ta_CDLMORNINGSTAR.o .libs/ta_CDLONNECK.o .libs/ta_CDLPIERCING.o .libs/ta_CDLRICKSHAWMAN.o .libs/ta_CDLRISEFALL3METHODS.o .libs/ta_CDLSEPARATINGLINES.o .libs/ta_CDLSHOOTINGSTAR.o .libs/ta_CDLSHORTLINE.o .libs/ta_CDLSPINNINGTOP.o .libs/ta_CDLSTALLEDPATTERN.o .libs/ta_CDLSTICKSANDWICH.o .libs/ta_CDLTAKURI.o .libs/ta_CDLTASUKIGAP.o .libs/ta_CDLTHRUSTING.o .libs/ta_CDLTRISTAR.o .libs/ta_CDLUNIQUE3RIVER.o .libs/ta_CDLUPSIDEGAP2CROWS.o .libs/ta_CDLXSIDEGAP3METHODS.o .libs/ta_CEIL.o .libs/ta_CMO.o .libs/ta_CORREL.o .libs/ta_COS.o .libs/ta_COSH.o .libs/ta_DEMA.o .libs/ta_DIV.o .libs/ta_DX.o .libs/ta_EMA.o .libs/ta_EXP.o .libs/ta_FLOOR.o .libs/ta_HT_DCPERIOD.o .libs/ta_HT_DCPHASE.o .libs/ta_HT_PHASOR.o .libs/ta_HT_SINE.o .libs/ta_HT_TRENDLINE.o .libs/ta_HT_TRENDMODE.o .libs/ta_KAMA.o .libs/ta_LINEARREG.o .libs/ta_LINEARREG_ANGLE.o .libs/ta_LINEARREG_INTERCEPT.o .libs/ta_LINEARREG_SLOPE.o .libs/ta_LN.o .libs/ta_LOG10.o .libs/ta_MA.o .libs/ta_MACD.o .libs/ta_MACDEXT.o .libs/ta_MACDFIX.o .libs/ta_MAMA.o .libs/ta_MAVP.o .libs/ta_MAX.o .libs/ta_MAXINDEX.o .libs/ta_MEDPRICE.o .libs/ta_MFI.o .libs/ta_MIDPOINT.o .libs/ta_MIDPRICE.o .libs/ta_MIN.o .libs/ta_MININDEX.o .libs/ta_MINMAX.o .libs/ta_MINMAXINDEX.o .libs/ta_MINUS_DI.o .libs/ta_MINUS_DM.o .libs/ta_MOM.o .libs/ta_MULT.o .libs/ta_NATR.o .libs/ta_OBV.o .libs/ta_PLUS_DI.o .libs/ta_PLUS_DM.o .libs/ta_PPO.o .libs/ta_ROC.o .libs/ta_ROCP.o .libs/ta_ROCR.o .libs/ta_ROCR100.o .libs/ta_RSI.o .libs/ta_SAR.o .libs/ta_SAREXT.o .libs/ta_SIN.o .libs/ta_SINH.o .libs/ta_SMA.o .libs/ta_SQRT.o .libs/ta_STDDEV.o .libs/ta_STOCH.o .libs/ta_STOCHF.o .libs/ta_STOCHRSI.o .libs/ta_SUB.o .libs/ta_SUM.o .libs/ta_T3.o .libs/ta_TAN.o .libs/ta_TANH.o .libs/ta_TEMA.o .libs/ta_TRANGE.o .libs/ta_TRIMA.o .libs/ta_TRIX.o .libs/ta_TSF.o .libs/ta_TYPPRICE.o .libs/ta_ULTOSC.o .libs/ta_VAR.o .libs/ta_WCLPRICE.o .libs/ta_WILLR.o .libs/ta_WMA.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "ranlib .libs/libta_func.a\n",
            "creating libta_func.la\n",
            "(cd .libs && rm -f libta_func.la && ln -s ../libta_func.la libta_func.la)\n",
            "make[2]: Leaving directory '/content/ta-lib/src/ta_func'\n",
            "make[2]: Entering directory '/content/ta-lib/src'\n",
            "/bin/bash ../libtool --tag=CC   --mode=link gcc  -g -O2 -version-info 0:0:0  -o libta_lib.la -rpath /usr/lib  ta_abstract/libta_abstract.la ta_func/libta_func.la ta_common/libta_common.la -lpthread -ldl \n",
            "mkdir .libs\n",
            "gcc -shared  -Wl,--whole-archive ta_abstract/.libs/libta_abstract.a ta_func/.libs/libta_func.a ta_common/.libs/libta_common.a -Wl,--no-whole-archive  -lpthread -ldl  -Wl,-soname -Wl,libta_lib.so.0 -o .libs/libta_lib.so.0.0.0\n",
            "(cd .libs && rm -f libta_lib.so.0 && ln -s libta_lib.so.0.0.0 libta_lib.so.0)\n",
            "(cd .libs && rm -f libta_lib.so && ln -s libta_lib.so.0.0.0 libta_lib.so)\n",
            "rm -fr .libs/libta_lib.lax\n",
            "mkdir .libs/libta_lib.lax\n",
            "rm -fr .libs/libta_lib.lax/libta_abstract.a\n",
            "mkdir .libs/libta_lib.lax/libta_abstract.a\n",
            "(cd .libs/libta_lib.lax/libta_abstract.a && ar x /content/ta-lib/src/ta_abstract/.libs/libta_abstract.a)\n",
            "rm -fr .libs/libta_lib.lax/libta_func.a\n",
            "mkdir .libs/libta_lib.lax/libta_func.a\n",
            "(cd .libs/libta_lib.lax/libta_func.a && ar x /content/ta-lib/src/ta_func/.libs/libta_func.a)\n",
            "rm -fr .libs/libta_lib.lax/libta_common.a\n",
            "mkdir .libs/libta_lib.lax/libta_common.a\n",
            "(cd .libs/libta_lib.lax/libta_common.a && ar x /content/ta-lib/src/ta_common/.libs/libta_common.a)\n",
            "ar cru .libs/libta_lib.a   .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_g.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_n.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_j.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_z.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-ta_frame.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_i.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_h.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-ta_def_ui.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_y.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-ta_abstract.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_m.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_o.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_b.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_x.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_p.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_k.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_l.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_c.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_d.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_q.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_f.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_u.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_t.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_a.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_s.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-ta_group_idx.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_e.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-ta_func_api.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_r.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_w.o .libs/libta_lib.lax/libta_abstract.a/libta_abstract_la-table_v.o  .libs/libta_lib.lax/libta_func.a/ta_CDLTRISTAR.o .libs/libta_lib.lax/libta_func.a/ta_HT_DCPERIOD.o .libs/libta_lib.lax/libta_func.a/ta_AROON.o .libs/libta_lib.lax/libta_func.a/ta_CDLLONGLEGGEDDOJI.o .libs/libta_lib.lax/libta_func.a/ta_HT_TRENDLINE.o .libs/libta_lib.lax/libta_func.a/ta_ADXR.o .libs/libta_lib.lax/libta_func.a/ta_BOP.o .libs/libta_lib.lax/libta_func.a/ta_CDLBREAKAWAY.o .libs/libta_lib.lax/libta_func.a/ta_MINUS_DM.o .libs/libta_lib.lax/libta_func.a/ta_STOCHF.o .libs/libta_lib.lax/libta_func.a/ta_LINEARREG.o .libs/libta_lib.lax/libta_func.a/ta_SINH.o .libs/libta_lib.lax/libta_func.a/ta_CDLCONCEALBABYSWALL.o .libs/libta_lib.lax/libta_func.a/ta_CDLSHOOTINGSTAR.o .libs/libta_lib.lax/libta_func.a/ta_CDLDOJISTAR.o .libs/libta_lib.lax/libta_func.a/ta_SMA.o .libs/libta_lib.lax/libta_func.a/ta_utility.o .libs/libta_lib.lax/libta_func.a/ta_CDLTHRUSTING.o .libs/libta_lib.lax/libta_func.a/ta_MFI.o .libs/libta_lib.lax/libta_func.a/ta_MINMAXINDEX.o .libs/libta_lib.lax/libta_func.a/ta_CDLSTICKSANDWICH.o .libs/libta_lib.lax/libta_func.a/ta_MULT.o .libs/libta_lib.lax/libta_func.a/ta_PLUS_DM.o .libs/libta_lib.lax/libta_func.a/ta_CDLIDENTICAL3CROWS.o .libs/libta_lib.lax/libta_func.a/ta_LINEARREG_SLOPE.o .libs/libta_lib.lax/libta_func.a/ta_CDLBELTHOLD.o .libs/libta_lib.lax/libta_func.a/ta_ADD.o .libs/libta_lib.lax/libta_func.a/ta_CDL2CROWS.o .libs/libta_lib.lax/libta_func.a/ta_MAVP.o .libs/libta_lib.lax/libta_func.a/ta_CDLHIKKAKE.o .libs/libta_lib.lax/libta_func.a/ta_LINEARREG_ANGLE.o .libs/libta_lib.lax/libta_func.a/ta_CDLTASUKIGAP.o .libs/libta_lib.lax/libta_func.a/ta_AD.o .libs/libta_lib.lax/libta_func.a/ta_ACOS.o .libs/libta_lib.lax/libta_func.a/ta_CMO.o .libs/libta_lib.lax/libta_func.a/ta_HT_PHASOR.o .libs/libta_lib.lax/libta_func.a/ta_CDLHIGHWAVE.o .libs/libta_lib.lax/libta_func.a/ta_COS.o .libs/libta_lib.lax/libta_func.a/ta_CDLCLOSINGMARUBOZU.o .libs/libta_lib.lax/libta_func.a/ta_MOM.o .libs/libta_lib.lax/libta_func.a/ta_TAN.o .libs/libta_lib.lax/libta_func.a/ta_MAX.o .libs/libta_lib.lax/libta_func.a/ta_CDLRICKSHAWMAN.o .libs/libta_lib.lax/libta_func.a/ta_CDLEVENINGSTAR.o .libs/libta_lib.lax/libta_func.a/ta_TRIX.o .libs/libta_lib.lax/libta_func.a/ta_CCI.o .libs/libta_lib.lax/libta_func.a/ta_LINEARREG_INTERCEPT.o .libs/libta_lib.lax/libta_func.a/ta_FLOOR.o .libs/libta_lib.lax/libta_func.a/ta_CDLEVENINGDOJISTAR.o .libs/libta_lib.lax/libta_func.a/ta_CDLSPINNINGTOP.o .libs/libta_lib.lax/libta_func.a/ta_DX.o .libs/libta_lib.lax/libta_func.a/ta_CDLMARUBOZU.o .libs/libta_lib.lax/libta_func.a/ta_CDLKICKINGBYLENGTH.o .libs/libta_lib.lax/libta_func.a/ta_SAR.o .libs/libta_lib.lax/libta_func.a/ta_CDLLADDERBOTTOM.o .libs/libta_lib.lax/libta_func.a/ta_CDLINVERTEDHAMMER.o .libs/libta_lib.lax/libta_func.a/ta_CDLMATHOLD.o .libs/libta_lib.lax/libta_func.a/ta_MININDEX.o .libs/libta_lib.lax/libta_func.a/ta_HT_DCPHASE.o .libs/libta_lib.lax/libta_func.a/ta_CDLONNECK.o .libs/libta_lib.lax/libta_func.a/ta_CDLGRAVESTONEDOJI.o .libs/libta_lib.lax/libta_func.a/ta_HT_TRENDMODE.o .libs/libta_lib.lax/libta_func.a/ta_KAMA.o .libs/libta_lib.lax/libta_func.a/ta_VAR.o .libs/libta_lib.lax/libta_func.a/ta_APO.o .libs/libta_lib.lax/libta_func.a/ta_CDLTAKURI.o .libs/libta_lib.lax/libta_func.a/ta_SUB.o .libs/libta_lib.lax/libta_func.a/ta_TEMA.o .libs/libta_lib.lax/libta_func.a/ta_AROONOSC.o .libs/libta_lib.lax/libta_func.a/ta_NATR.o .libs/libta_lib.lax/libta_func.a/ta_SAREXT.o .libs/libta_lib.lax/libta_func.a/ta_MINUS_DI.o .libs/libta_lib.lax/libta_func.a/ta_TRIMA.o .libs/libta_lib.lax/libta_func.a/ta_ADX.o .libs/libta_lib.lax/libta_func.a/ta_RSI.o .libs/libta_lib.lax/libta_func.a/ta_CDLMORNINGDOJISTAR.o .libs/libta_lib.lax/libta_func.a/ta_MACDEXT.o .libs/libta_lib.lax/libta_func.a/ta_MACD.o .libs/libta_lib.lax/libta_func.a/ta_WCLPRICE.o .libs/libta_lib.lax/libta_func.a/ta_PLUS_DI.o .libs/libta_lib.lax/libta_func.a/ta_TANH.o .libs/libta_lib.lax/libta_func.a/ta_ROCP.o .libs/libta_lib.lax/libta_func.a/ta_PPO.o .libs/libta_lib.lax/libta_func.a/ta_TRANGE.o .libs/libta_lib.lax/libta_func.a/ta_WILLR.o .libs/libta_lib.lax/libta_func.a/ta_CDLENGULFING.o .libs/libta_lib.lax/libta_func.a/ta_CORREL.o .libs/libta_lib.lax/libta_func.a/ta_CDLMORNINGSTAR.o .libs/libta_lib.lax/libta_func.a/ta_DEMA.o .libs/libta_lib.lax/libta_func.a/ta_CDLADVANCEBLOCK.o .libs/libta_lib.lax/libta_func.a/ta_T3.o .libs/libta_lib.lax/libta_func.a/ta_MIDPRICE.o .libs/libta_lib.lax/libta_func.a/ta_ROCR100.o .libs/libta_lib.lax/libta_func.a/ta_CDLABANDONEDBABY.o .libs/libta_lib.lax/libta_func.a/ta_CDLUPSIDEGAP2CROWS.o .libs/libta_lib.lax/libta_func.a/ta_MEDPRICE.o .libs/libta_lib.lax/libta_func.a/ta_ULTOSC.o .libs/libta_lib.lax/libta_func.a/ta_CDLKICKING.o .libs/libta_lib.lax/libta_func.a/ta_CDLRISEFALL3METHODS.o .libs/libta_lib.lax/libta_func.a/ta_ATR.o .libs/libta_lib.lax/libta_func.a/ta_TYPPRICE.o .libs/libta_lib.lax/libta_func.a/ta_CDL3OUTSIDE.o .libs/libta_lib.lax/libta_func.a/ta_CDL3WHITESOLDIERS.o .libs/libta_lib.lax/libta_func.a/ta_BETA.o .libs/libta_lib.lax/libta_func.a/ta_LOG10.o .libs/libta_lib.lax/libta_func.a/ta_COSH.o .libs/libta_lib.lax/libta_func.a/ta_STOCH.o .libs/libta_lib.lax/libta_func.a/ta_ADOSC.o .libs/libta_lib.lax/libta_func.a/ta_CDL3LINESTRIKE.o .libs/libta_lib.lax/libta_func.a/ta_CDLHAMMER.o .libs/libta_lib.lax/libta_func.a/ta_CDLSHORTLINE.o .libs/libta_lib.lax/libta_func.a/ta_CDLLONGLINE.o .libs/libta_lib.lax/libta_func.a/ta_CDLSEPARATINGLINES.o .libs/libta_lib.lax/libta_func.a/ta_CDLHIKKAKEMOD.o .libs/libta_lib.lax/libta_func.a/ta_CDLXSIDEGAP3METHODS.o .libs/libta_lib.lax/libta_func.a/ta_LN.o .libs/libta_lib.lax/libta_func.a/ta_STOCHRSI.o .libs/libta_lib.lax/libta_func.a/ta_CDLUNIQUE3RIVER.o .libs/libta_lib.lax/libta_func.a/ta_CDLSTALLEDPATTERN.o .libs/libta_lib.lax/libta_func.a/ta_MA.o .libs/libta_lib.lax/libta_func.a/ta_ASIN.o .libs/libta_lib.lax/libta_func.a/ta_MAXINDEX.o .libs/libta_lib.lax/libta_func.a/ta_CDLHANGINGMAN.o .libs/libta_lib.lax/libta_func.a/ta_SQRT.o .libs/libta_lib.lax/libta_func.a/ta_CEIL.o .libs/libta_lib.lax/libta_func.a/ta_MACDFIX.o .libs/libta_lib.lax/libta_func.a/ta_CDLGAPSIDESIDEWHITE.o .libs/libta_lib.lax/libta_func.a/ta_EMA.o .libs/libta_lib.lax/libta_func.a/ta_CDLHOMINGPIGEON.o .libs/libta_lib.lax/libta_func.a/ta_CDL3INSIDE.o .libs/libta_lib.lax/libta_func.a/ta_DIV.o .libs/libta_lib.lax/libta_func.a/ta_EXP.o .libs/libta_lib.lax/libta_func.a/ta_CDLCOUNTERATTACK.o .libs/libta_lib.lax/libta_func.a/ta_MINMAX.o .libs/libta_lib.lax/libta_func.a/ta_CDL3BLACKCROWS.o .libs/libta_lib.lax/libta_func.a/ta_MIN.o .libs/libta_lib.lax/libta_func.a/ta_WMA.o .libs/libta_lib.lax/libta_func.a/ta_MAMA.o .libs/libta_lib.lax/libta_func.a/ta_CDL3STARSINSOUTH.o .libs/libta_lib.lax/libta_func.a/ta_CDLDRAGONFLYDOJI.o .libs/libta_lib.lax/libta_func.a/ta_AVGPRICE.o .libs/libta_lib.lax/libta_func.a/ta_CDLHARAMI.o .libs/libta_lib.lax/libta_func.a/ta_OBV.o .libs/libta_lib.lax/libta_func.a/ta_SIN.o .libs/libta_lib.lax/libta_func.a/ta_ATAN.o .libs/libta_lib.lax/libta_func.a/ta_ROCR.o .libs/libta_lib.lax/libta_func.a/ta_CDLPIERCING.o .libs/libta_lib.lax/libta_func.a/ta_CDLDOJI.o .libs/libta_lib.lax/libta_func.a/ta_HT_SINE.o .libs/libta_lib.lax/libta_func.a/ta_ROC.o .libs/libta_lib.lax/libta_func.a/ta_CDLDARKCLOUDCOVER.o .libs/libta_lib.lax/libta_func.a/ta_CDLHARAMICROSS.o .libs/libta_lib.lax/libta_func.a/ta_TSF.o .libs/libta_lib.lax/libta_func.a/ta_STDDEV.o .libs/libta_lib.lax/libta_func.a/ta_MIDPOINT.o .libs/libta_lib.lax/libta_func.a/ta_SUM.o .libs/libta_lib.lax/libta_func.a/ta_CDLMATCHINGLOW.o .libs/libta_lib.lax/libta_func.a/ta_BBANDS.o .libs/libta_lib.lax/libta_func.a/ta_CDLINNECK.o  .libs/libta_lib.lax/libta_common.a/ta_version.o .libs/libta_lib.lax/libta_common.a/ta_global.o .libs/libta_lib.lax/libta_common.a/ta_retcode.o \n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "ranlib .libs/libta_lib.a\n",
            "rm -fr .libs/libta_lib.lax\n",
            "creating libta_lib.la\n",
            "(cd .libs && rm -f libta_lib.la && ln -s ../libta_lib.la libta_lib.la)\n",
            "make[2]: Leaving directory '/content/ta-lib/src'\n",
            "make[1]: Leaving directory '/content/ta-lib/src'\n",
            "Making all in src/tools\n",
            "make[1]: Entering directory '/content/ta-lib/src/tools'\n",
            "Making all in gen_code\n",
            "make[2]: Entering directory '/content/ta-lib/src/tools/gen_code'\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_common   -g -O2 -MT gen_code-gen_code.o -MD -MP -MF .deps/gen_code-gen_code.Tpo -c -o gen_code-gen_code.o `test -f 'gen_code.c' || echo './'`gen_code.c\n",
            "\u001b[01m\u001b[Kgen_code.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KprintFuncHeaderDoc\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kgen_code.c:3456:4:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat not a string literal and no format arguments [\u001b[01;35m\u001b[K-Wformat-security\u001b[m\u001b[K]\n",
            " 3456 |    \u001b[01;35m\u001b[Kfprintf\u001b[m\u001b[K( out, prefix );\n",
            "      |    \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "mv -f .deps/gen_code-gen_code.Tpo .deps/gen_code-gen_code.Po\n",
            "/bin/bash ../../../libtool --tag=CC   --mode=link gcc  -g -O2 -L../../ta_common -L../../ta_abstract -L../../ta_func  -o gen_code gen_code-gen_code.o -lta_common -lta_abstract_gc -lta_func -lm -lpthread -ldl \n",
            "mkdir .libs\n",
            "gcc -g -O2 -o gen_code gen_code-gen_code.o  -L/content/ta-lib/src/ta_common -L/content/ta-lib/src/ta_abstract -L/content/ta-lib/src/ta_func /content/ta-lib/src/ta_common/.libs/libta_common.a /content/ta-lib/src/ta_abstract/.libs/libta_abstract_gc.a /content/ta-lib/src/ta_func/.libs/libta_func.a -lm -lpthread -ldl\n",
            "make  gen_code\n",
            "make[3]: Entering directory '/content/ta-lib/src/tools/gen_code'\n",
            "make[3]: 'gen_code' is up to date.\n",
            "make[3]: Leaving directory '/content/ta-lib/src/tools/gen_code'\n",
            "cp gen_code ../../../bin\n",
            "make[2]: Leaving directory '/content/ta-lib/src/tools/gen_code'\n",
            "Making all in ta_regtest\n",
            "make[2]: Entering directory '/content/ta-lib/src/tools/ta_regtest'\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-ta_regtest.o -MD -MP -MF .deps/ta_regtest-ta_regtest.Tpo -c -o ta_regtest-ta_regtest.o `test -f 'ta_regtest.c' || echo './'`ta_regtest.c\n",
            "mv -f .deps/ta_regtest-ta_regtest.Tpo .deps/ta_regtest-ta_regtest.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_data.o -MD -MP -MF .deps/ta_regtest-test_data.Tpo -c -o ta_regtest-test_data.o `test -f 'test_data.c' || echo './'`test_data.c\n",
            "mv -f .deps/ta_regtest-test_data.Tpo .deps/ta_regtest-test_data.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_util.o -MD -MP -MF .deps/ta_regtest-test_util.Tpo -c -o ta_regtest-test_util.o `test -f 'test_util.c' || echo './'`test_util.c\n",
            "mv -f .deps/ta_regtest-test_util.Tpo .deps/ta_regtest-test_util.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_abstract.o -MD -MP -MF .deps/ta_regtest-test_abstract.Tpo -c -o ta_regtest-test_abstract.o `test -f 'test_abstract.c' || echo './'`test_abstract.c\n",
            "mv -f .deps/ta_regtest-test_abstract.Tpo .deps/ta_regtest-test_abstract.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_adx.o -MD -MP -MF .deps/ta_regtest-test_adx.Tpo -c -o ta_regtest-test_adx.o `test -f 'ta_test_func/test_adx.c' || echo './'`ta_test_func/test_adx.c\n",
            "mv -f .deps/ta_regtest-test_adx.Tpo .deps/ta_regtest-test_adx.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_mom.o -MD -MP -MF .deps/ta_regtest-test_mom.Tpo -c -o ta_regtest-test_mom.o `test -f 'ta_test_func/test_mom.c' || echo './'`ta_test_func/test_mom.c\n",
            "mv -f .deps/ta_regtest-test_mom.Tpo .deps/ta_regtest-test_mom.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_sar.o -MD -MP -MF .deps/ta_regtest-test_sar.Tpo -c -o ta_regtest-test_sar.o `test -f 'ta_test_func/test_sar.c' || echo './'`ta_test_func/test_sar.c\n",
            "mv -f .deps/ta_regtest-test_sar.Tpo .deps/ta_regtest-test_sar.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_rsi.o -MD -MP -MF .deps/ta_regtest-test_rsi.Tpo -c -o ta_regtest-test_rsi.o `test -f 'ta_test_func/test_rsi.c' || echo './'`ta_test_func/test_rsi.c\n",
            "mv -f .deps/ta_regtest-test_rsi.Tpo .deps/ta_regtest-test_rsi.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_candlestick.o -MD -MP -MF .deps/ta_regtest-test_candlestick.Tpo -c -o ta_regtest-test_candlestick.o `test -f 'ta_test_func/test_candlestick.c' || echo './'`ta_test_func/test_candlestick.c\n",
            "mv -f .deps/ta_regtest-test_candlestick.Tpo .deps/ta_regtest-test_candlestick.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_per_ema.o -MD -MP -MF .deps/ta_regtest-test_per_ema.Tpo -c -o ta_regtest-test_per_ema.o `test -f 'ta_test_func/test_per_ema.c' || echo './'`ta_test_func/test_per_ema.c\n",
            "mv -f .deps/ta_regtest-test_per_ema.Tpo .deps/ta_regtest-test_per_ema.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_per_hlc.o -MD -MP -MF .deps/ta_regtest-test_per_hlc.Tpo -c -o ta_regtest-test_per_hlc.o `test -f 'ta_test_func/test_per_hlc.c' || echo './'`ta_test_func/test_per_hlc.c\n",
            "mv -f .deps/ta_regtest-test_per_hlc.Tpo .deps/ta_regtest-test_per_hlc.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_stoch.o -MD -MP -MF .deps/ta_regtest-test_stoch.Tpo -c -o ta_regtest-test_stoch.o `test -f 'ta_test_func/test_stoch.c' || echo './'`ta_test_func/test_stoch.c\n",
            "mv -f .deps/ta_regtest-test_stoch.Tpo .deps/ta_regtest-test_stoch.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_macd.o -MD -MP -MF .deps/ta_regtest-test_macd.Tpo -c -o ta_regtest-test_macd.o `test -f 'ta_test_func/test_macd.c' || echo './'`ta_test_func/test_macd.c\n",
            "mv -f .deps/ta_regtest-test_macd.Tpo .deps/ta_regtest-test_macd.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_minmax.o -MD -MP -MF .deps/ta_regtest-test_minmax.Tpo -c -o ta_regtest-test_minmax.o `test -f 'ta_test_func/test_minmax.c' || echo './'`ta_test_func/test_minmax.c\n",
            "mv -f .deps/ta_regtest-test_minmax.Tpo .deps/ta_regtest-test_minmax.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_per_hlcv.o -MD -MP -MF .deps/ta_regtest-test_per_hlcv.Tpo -c -o ta_regtest-test_per_hlcv.o `test -f 'ta_test_func/test_per_hlcv.c' || echo './'`ta_test_func/test_per_hlcv.c\n",
            "mv -f .deps/ta_regtest-test_per_hlcv.Tpo .deps/ta_regtest-test_per_hlcv.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_1in_1out.o -MD -MP -MF .deps/ta_regtest-test_1in_1out.Tpo -c -o ta_regtest-test_1in_1out.o `test -f 'ta_test_func/test_1in_1out.c' || echo './'`ta_test_func/test_1in_1out.c\n",
            "mv -f .deps/ta_regtest-test_1in_1out.Tpo .deps/ta_regtest-test_1in_1out.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_1in_2out.o -MD -MP -MF .deps/ta_regtest-test_1in_2out.Tpo -c -o ta_regtest-test_1in_2out.o `test -f 'ta_test_func/test_1in_2out.c' || echo './'`ta_test_func/test_1in_2out.c\n",
            "mv -f .deps/ta_regtest-test_1in_2out.Tpo .deps/ta_regtest-test_1in_2out.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_per_ohlc.o -MD -MP -MF .deps/ta_regtest-test_per_ohlc.Tpo -c -o ta_regtest-test_per_ohlc.o `test -f 'ta_test_func/test_per_ohlc.c' || echo './'`ta_test_func/test_per_ohlc.c\n",
            "mv -f .deps/ta_regtest-test_per_ohlc.Tpo .deps/ta_regtest-test_per_ohlc.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_stddev.o -MD -MP -MF .deps/ta_regtest-test_stddev.Tpo -c -o ta_regtest-test_stddev.o `test -f 'ta_test_func/test_stddev.c' || echo './'`ta_test_func/test_stddev.c\n",
            "mv -f .deps/ta_regtest-test_stddev.Tpo .deps/ta_regtest-test_stddev.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_bbands.o -MD -MP -MF .deps/ta_regtest-test_bbands.Tpo -c -o ta_regtest-test_bbands.o `test -f 'ta_test_func/test_bbands.c' || echo './'`ta_test_func/test_bbands.c\n",
            "mv -f .deps/ta_regtest-test_bbands.Tpo .deps/ta_regtest-test_bbands.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_ma.o -MD -MP -MF .deps/ta_regtest-test_ma.Tpo -c -o ta_regtest-test_ma.o `test -f 'ta_test_func/test_ma.c' || echo './'`ta_test_func/test_ma.c\n",
            "mv -f .deps/ta_regtest-test_ma.Tpo .deps/ta_regtest-test_ma.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_po.o -MD -MP -MF .deps/ta_regtest-test_po.Tpo -c -o ta_regtest-test_po.o `test -f 'ta_test_func/test_po.c' || echo './'`ta_test_func/test_po.c\n",
            "mv -f .deps/ta_regtest-test_po.Tpo .deps/ta_regtest-test_po.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_per_hl.o -MD -MP -MF .deps/ta_regtest-test_per_hl.Tpo -c -o ta_regtest-test_per_hl.o `test -f 'ta_test_func/test_per_hl.c' || echo './'`ta_test_func/test_per_hl.c\n",
            "mv -f .deps/ta_regtest-test_per_hl.Tpo .deps/ta_regtest-test_per_hl.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_trange.o -MD -MP -MF .deps/ta_regtest-test_trange.Tpo -c -o ta_regtest-test_trange.o `test -f 'ta_test_func/test_trange.c' || echo './'`ta_test_func/test_trange.c\n",
            "mv -f .deps/ta_regtest-test_trange.Tpo .deps/ta_regtest-test_trange.Po\n",
            "gcc -DHAVE_CONFIG_H -I. -I../../../include  -I../../ta_func -I../../ta_common/trio -I../../ta_common/mt -I../../ta_common -I../../ta_abstract   -g -O2 -MT ta_regtest-test_internals.o -MD -MP -MF .deps/ta_regtest-test_internals.Tpo -c -o ta_regtest-test_internals.o `test -f 'test_internals.c' || echo './'`test_internals.c\n",
            "mv -f .deps/ta_regtest-test_internals.Tpo .deps/ta_regtest-test_internals.Po\n",
            "/bin/bash ../../../libtool --tag=CC   --mode=link gcc  -g -O2 -L../.. -lta_lib -lm  -o ta_regtest ta_regtest-ta_regtest.o ta_regtest-test_data.o ta_regtest-test_util.o ta_regtest-test_abstract.o ta_regtest-test_adx.o ta_regtest-test_mom.o ta_regtest-test_sar.o ta_regtest-test_rsi.o ta_regtest-test_candlestick.o ta_regtest-test_per_ema.o ta_regtest-test_per_hlc.o ta_regtest-test_stoch.o ta_regtest-test_macd.o ta_regtest-test_minmax.o ta_regtest-test_per_hlcv.o ta_regtest-test_1in_1out.o ta_regtest-test_1in_2out.o ta_regtest-test_per_ohlc.o ta_regtest-test_stddev.o ta_regtest-test_bbands.o ta_regtest-test_ma.o ta_regtest-test_po.o ta_regtest-test_per_hl.o ta_regtest-test_trange.o ta_regtest-test_internals.o  -lpthread -ldl \n",
            "mkdir .libs\n",
            "gcc -g -O2 -o .libs/ta_regtest ta_regtest-ta_regtest.o ta_regtest-test_data.o ta_regtest-test_util.o ta_regtest-test_abstract.o ta_regtest-test_adx.o ta_regtest-test_mom.o ta_regtest-test_sar.o ta_regtest-test_rsi.o ta_regtest-test_candlestick.o ta_regtest-test_per_ema.o ta_regtest-test_per_hlc.o ta_regtest-test_stoch.o ta_regtest-test_macd.o ta_regtest-test_minmax.o ta_regtest-test_per_hlcv.o ta_regtest-test_1in_1out.o ta_regtest-test_1in_2out.o ta_regtest-test_per_ohlc.o ta_regtest-test_stddev.o ta_regtest-test_bbands.o ta_regtest-test_ma.o ta_regtest-test_po.o ta_regtest-test_per_hl.o ta_regtest-test_trange.o ta_regtest-test_internals.o  -L/content/ta-lib/src /content/ta-lib/src/.libs/libta_lib.so -lm -lpthread -ldl\n",
            "creating ta_regtest\n",
            "make[2]: Leaving directory '/content/ta-lib/src/tools/ta_regtest'\n",
            "make[2]: Entering directory '/content/ta-lib/src/tools'\n",
            "make[2]: Nothing to be done for 'all-am'.\n",
            "make[2]: Leaving directory '/content/ta-lib/src/tools'\n",
            "make[1]: Leaving directory '/content/ta-lib/src/tools'\n",
            "make[1]: Entering directory '/content/ta-lib'\n",
            "make[1]: Nothing to be done for 'all-am'.\n",
            "make[1]: Leaving directory '/content/ta-lib'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/content/ta-lib/src'\n",
            "Making install in ta_abstract\n",
            "make[2]: Entering directory '/content/ta-lib/src/ta_abstract'\n",
            "make[3]: Entering directory '/content/ta-lib/src/ta_abstract'\n",
            "make[3]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/include/ta-lib/\" || /usr/bin/mkdir -p \"/usr/include/ta-lib/\"\n",
            " /usr/bin/install -c -m 644 '../../include/ta_defs.h' '/usr/include/ta-lib//ta_defs.h'\n",
            " /usr/bin/install -c -m 644 '../../include/ta_libc.h' '/usr/include/ta-lib//ta_libc.h'\n",
            " /usr/bin/install -c -m 644 '../../include/ta_abstract.h' '/usr/include/ta-lib//ta_abstract.h'\n",
            "make[3]: Leaving directory '/content/ta-lib/src/ta_abstract'\n",
            "make[2]: Leaving directory '/content/ta-lib/src/ta_abstract'\n",
            "Making install in ta_common\n",
            "make[2]: Entering directory '/content/ta-lib/src/ta_common'\n",
            "make[3]: Entering directory '/content/ta-lib/src/ta_common'\n",
            "make[3]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/include/ta-lib/\" || /usr/bin/mkdir -p \"/usr/include/ta-lib/\"\n",
            " /usr/bin/install -c -m 644 '../../include/ta_defs.h' '/usr/include/ta-lib//ta_defs.h'\n",
            " /usr/bin/install -c -m 644 '../../include/ta_libc.h' '/usr/include/ta-lib//ta_libc.h'\n",
            " /usr/bin/install -c -m 644 '../../include/ta_common.h' '/usr/include/ta-lib//ta_common.h'\n",
            "make[3]: Leaving directory '/content/ta-lib/src/ta_common'\n",
            "make[2]: Leaving directory '/content/ta-lib/src/ta_common'\n",
            "Making install in ta_func\n",
            "make[2]: Entering directory '/content/ta-lib/src/ta_func'\n",
            "make[3]: Entering directory '/content/ta-lib/src/ta_func'\n",
            "make[3]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/include/ta-lib/\" || /usr/bin/mkdir -p \"/usr/include/ta-lib/\"\n",
            " /usr/bin/install -c -m 644 '../../include/ta_defs.h' '/usr/include/ta-lib//ta_defs.h'\n",
            " /usr/bin/install -c -m 644 '../../include/ta_libc.h' '/usr/include/ta-lib//ta_libc.h'\n",
            " /usr/bin/install -c -m 644 '../../include/ta_func.h' '/usr/include/ta-lib//ta_func.h'\n",
            "make[3]: Leaving directory '/content/ta-lib/src/ta_func'\n",
            "make[2]: Leaving directory '/content/ta-lib/src/ta_func'\n",
            "make[2]: Entering directory '/content/ta-lib/src'\n",
            "make[3]: Entering directory '/content/ta-lib/src'\n",
            "test -z \"/usr/lib\" || /usr/bin/mkdir -p \"/usr/lib\"\n",
            " /bin/bash ../libtool --mode=install /usr/bin/install -c  'libta_lib.la' '/usr/lib/libta_lib.la'\n",
            "/usr/bin/install -c .libs/libta_lib.so.0.0.0 /usr/lib/libta_lib.so.0.0.0\n",
            "(cd /usr/lib && { ln -s -f libta_lib.so.0.0.0 libta_lib.so.0 || { rm -f libta_lib.so.0 && ln -s libta_lib.so.0.0.0 libta_lib.so.0; }; })\n",
            "(cd /usr/lib && { ln -s -f libta_lib.so.0.0.0 libta_lib.so || { rm -f libta_lib.so && ln -s libta_lib.so.0.0.0 libta_lib.so; }; })\n",
            "/usr/bin/install -c .libs/libta_lib.lai /usr/lib/libta_lib.la\n",
            "/usr/bin/install -c .libs/libta_lib.a /usr/lib/libta_lib.a\n",
            "chmod 644 /usr/lib/libta_lib.a\n",
            "ranlib /usr/lib/libta_lib.a\n",
            "PATH=\"$PATH:/sbin\" ldconfig -n /usr/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,--rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "make[3]: Nothing to be done for 'install-data-am'.\n",
            "make[3]: Leaving directory '/content/ta-lib/src'\n",
            "make[2]: Leaving directory '/content/ta-lib/src'\n",
            "make[1]: Leaving directory '/content/ta-lib/src'\n",
            "Making install in src/tools\n",
            "make[1]: Entering directory '/content/ta-lib/src/tools'\n",
            "Making install in gen_code\n",
            "make[2]: Entering directory '/content/ta-lib/src/tools/gen_code'\n",
            "make  gen_code\n",
            "make[3]: Entering directory '/content/ta-lib/src/tools/gen_code'\n",
            "make[3]: 'gen_code' is up to date.\n",
            "make[3]: Leaving directory '/content/ta-lib/src/tools/gen_code'\n",
            "cp gen_code ../../../bin\n",
            "make[3]: Entering directory '/content/ta-lib/src/tools/gen_code'\n",
            "make[3]: Nothing to be done for 'install-exec-am'.\n",
            "make[3]: Nothing to be done for 'install-data-am'.\n",
            "make[3]: Leaving directory '/content/ta-lib/src/tools/gen_code'\n",
            "make[2]: Leaving directory '/content/ta-lib/src/tools/gen_code'\n",
            "Making install in ta_regtest\n",
            "make[2]: Entering directory '/content/ta-lib/src/tools/ta_regtest'\n",
            "make[3]: Entering directory '/content/ta-lib/src/tools/ta_regtest'\n",
            "make[3]: Nothing to be done for 'install-exec-am'.\n",
            "make[3]: Nothing to be done for 'install-data-am'.\n",
            "make[3]: Leaving directory '/content/ta-lib/src/tools/ta_regtest'\n",
            "make[2]: Leaving directory '/content/ta-lib/src/tools/ta_regtest'\n",
            "make[2]: Entering directory '/content/ta-lib/src/tools'\n",
            "make[3]: Entering directory '/content/ta-lib/src/tools'\n",
            "make[3]: Nothing to be done for 'install-exec-am'.\n",
            "make[3]: Nothing to be done for 'install-data-am'.\n",
            "make[3]: Leaving directory '/content/ta-lib/src/tools'\n",
            "make[2]: Leaving directory '/content/ta-lib/src/tools'\n",
            "make[1]: Leaving directory '/content/ta-lib/src/tools'\n",
            "make[1]: Entering directory '/content/ta-lib'\n",
            "make[2]: Entering directory '/content/ta-lib'\n",
            "test -z \"/usr/bin\" || /usr/bin/mkdir -p \"/usr/bin\"\n",
            " /usr/bin/install -c 'ta-lib-config' '/usr/bin/ta-lib-config'\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/content/ta-lib'\n",
            "make[1]: Leaving directory '/content/ta-lib'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Ta-Lib\n",
            "  Downloading TA-Lib-0.4.25.tar.gz (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.0/272.0 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from Ta-Lib) (1.21.6)\n",
            "Building wheels for collected packages: Ta-Lib\n",
            "  Building wheel for Ta-Lib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Ta-Lib: filename=TA_Lib-0.4.25-cp38-cp38-linux_x86_64.whl size=2510037 sha256=44f1fec53c1091a32eac94f01aefd026c13db8d06ab5145b7b67894859e4f259\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/72/bf/464831127ee8d6d9a5b76340a6a2f115182e159309dc3067ca\n",
            "Successfully built Ta-Lib\n",
            "Installing collected packages: Ta-Lib\n",
            "Successfully installed Ta-Lib-0.4.25\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pandas_ta) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2022.7)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->pandas_ta) (1.15.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218923 sha256=0775cac0c74d41ca567466779f145d8d77769e08c885292669aa621da54c776f\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/4a/75/06b8e63fce6f6d2c1baae5c208edb18eca128407b0c96e1153\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.4-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2022.7)\n",
            "Collecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.21.6)\n",
            "Collecting cryptography>=3.3.2\n",
            "  Downloading cryptography-39.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Installing collected packages: soupsieve, requests, html5lib, frozendict, cryptography, beautifulsoup4, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: html5lib\n",
            "    Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.11.1 cryptography-39.0.0 frozendict-2.3.4 html5lib-1.1 requests-2.28.2 soupsieve-2.3.2.post1 yfinance-0.2.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting backtesting\n",
            "  Downloading Backtesting-0.3.3.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from backtesting) (1.21.6)\n",
            "Requirement already satisfied: pandas!=0.25.0,>=0.25.0 in /usr/local/lib/python3.8/dist-packages (from backtesting) (1.3.5)\n",
            "Requirement already satisfied: bokeh>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from backtesting) (2.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from bokeh>=1.4.0->backtesting) (4.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from bokeh>=1.4.0->backtesting) (2.8.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.8/dist-packages (from bokeh>=1.4.0->backtesting) (6.0.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from bokeh>=1.4.0->backtesting) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.8/dist-packages (from bokeh>=1.4.0->backtesting) (21.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.8/dist-packages (from bokeh>=1.4.0->backtesting) (6.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.8/dist-packages (from bokeh>=1.4.0->backtesting) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2022.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.9->bokeh>=1.4.0->backtesting) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=16.8->bokeh>=1.4.0->backtesting) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->bokeh>=1.4.0->backtesting) (1.15.0)\n",
            "Building wheels for collected packages: backtesting\n",
            "  Building wheel for backtesting (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for backtesting: filename=Backtesting-0.3.3-py3-none-any.whl size=173819 sha256=9f708ef815a0f9d1eff8bac91095e247e7c706ee30a22a6f1a4a7483ca43caf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/5c/f7/aafe95c37f8b07f838fb0a8cb3177de23a38c09cbd10b447b8\n",
            "Successfully built backtesting\n",
            "Installing collected packages: backtesting\n",
            "Successfully installed backtesting-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HbxX37RAYEXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e55d92-df9c-4124-cee6-8256e02c3bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified\n",
            "1674346972\n",
            "1674346972.0\n",
            "1674346972.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/backtesting/_plotting.py:50: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support (e.g. PyCharm, Spyder IDE). Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
            "  warnings.warn('Jupyter Notebook detected. '\n"
          ]
        }
      ],
      "source": [
        "# Executes this notebook in our space, making all of its functions/globals available\n",
        "%run -i '/content/drive/My Drive/ml-trde-notebooks/common.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}"
      ],
      "metadata": {
        "id": "nKPW15n5N_-J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlOVO-Erbhlq"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FwBf9SLJbfPT"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "  #we don't need 15 right now because they get loaded in the train, that will prob need to be more sophisticated soon\n",
        "  #all_stock_df_15 = []\n",
        "  for ticker in tickers:\n",
        "    print(\"load:\", ticker)\n",
        "    df = sort_date(pd.read_csv(data_path +'/' + ticker + '.csv'))\n",
        "    df[\"Date\"] = pd.to_datetime(df['Date'], utc=True)\n",
        "    all_stock_dfs.append(df)\n",
        "    #df2 = sort_date(pd.read_csv(data_path + '/' + ticker + '-15.csv').rename(columns={\"Datetime\":\"Date\"}))\n",
        "  print(\"all dfs:\", len(all_stock_dfs))\n",
        "  #for coin in coins:\n",
        "  #  print(\"load:\", coin)\n",
        "  #  df = sort_date(pd.read_csv(data_path +'/' + coin + '.csv'))\n",
        "  #  all_coin_dfs.append(df)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training/Loading"
      ],
      "metadata": {
        "id": "Vg1itz6lUFpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "build_and_stash_all_config_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSmRUKsEUILb",
        "outputId": "ece7b257-869b-43a5-a024-083721115f67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build model: lstm_cv  features: 2\n",
            "build model: lstm_coins_cv  features: 2\n",
            "build model: lstm_att_cv  features: 2\n",
            "build model: lstm_att_ohlcv  features: 5\n",
            "build model: lstm_cv_rvi  features: 3\n",
            "build model: lstm_cv_vwap  features: 4\n",
            "build model: lstm_ohlc  features: 5\n",
            "build model: svm_cv  features: 2\n",
            "build model: svm_cv_vwap  features: 4\n",
            "build model: lstm_xgb_cols  features: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCNok5EX8ax_"
      },
      "source": [
        "## Load all models from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIKMLKIaF7Hr",
        "outputId": "2a286327-465e-4ac0-b89f-ea996901da7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not loading\n"
          ]
        }
      ],
      "source": [
        "if load_models:\n",
        "  training_filter = model_config[\"training_filter\"]\n",
        "  for name in model_config[\"day_bar_models\"]:\n",
        "    if (name in training_filter): #skip training models\n",
        "      print(\"skipping: \", name)\n",
        "      continue\n",
        "    print(\"loading:\", name)\n",
        "    if name in model_config[\"load_type\"] and model_config[\"load_type\"][name] == \"joblib\":\n",
        "      models[name] = joblib.load(model_path + \"/\" + name  + \"-\" + model_version_token + \".joblib\") \n",
        "    else:\n",
        "      models[name] = keras.models.load_model(model_path + \"/\" + name + \"-\" + model_version_token + \".h15\")\n",
        "  lstm_15m = keras.models.load_model(model_path + \"/lstm_15m.h15\")\n",
        "  print (\"models loaded\")  \n",
        "\n",
        "else:\n",
        "  print (\"Not loading\")\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TvKViYBGL2Z"
      },
      "source": [
        "## Train and Save Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KWY1rDnX9_-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f500d6fb-3ff1-4df8-b080-6e0bcbddbfc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load: SPY\n",
            "load: TSLA\n",
            "load: AAPL\n",
            "load: IBM\n",
            "load: F\n",
            "load: CAT\n",
            "load: BAC\n",
            "load: B\n",
            "load: META\n",
            "load: AMZN\n",
            "load: XOM\n",
            "load: BP\n",
            "load: CHK\n",
            "load: GME\n",
            "load: MRNA\n",
            "load: BA\n",
            "load: PG\n",
            "load: NEE\n",
            "load: FCX\n",
            "load: Z\n",
            "load: NVDA\n",
            "load: PFE\n",
            "load: WMT\n",
            "load: NOK\n",
            "load: T\n",
            "load: BABA\n",
            "load: AMC\n",
            "load: SQ\n",
            "load: SCCO\n",
            "load: GOOGL\n",
            "load: GOOG\n",
            "load: GE\n",
            "load: CVX\n",
            "load: CSCO\n",
            "load: CMCSA\n",
            "load: CL\n",
            "load: CBRE\n",
            "load: CB\n",
            "load: DAL\n",
            "load: D\n",
            "load: EBAY\n",
            "load: EBAY\n",
            "load: EMR\n",
            "load: PBF\n",
            "load: NEM\n",
            "load: FCX\n",
            "load: AA\n",
            "load: VZ\n",
            "load: T\n",
            "load: DVN\n",
            "load: CHK\n",
            "load: HIMX\n",
            "load: AMD\n",
            "load: NXPI\n",
            "load: PFE\n",
            "all dfs: 55\n",
            "build model: lstm_cv  features: 2\n",
            "training:  lstm_cv\n",
            "lstm_cv  should train on stocks\n",
            "training dfs: 55\n",
            "training:  lstm_cv  df:  0\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "189/189 [==============================] - 11s 13ms/step - loss: 0.0052 - val_loss: 0.2855\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.2425e-04 - val_loss: 0.2584\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.6333e-04 - val_loss: 0.1672\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.3237e-04 - val_loss: 0.0386\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.4637e-04 - val_loss: 0.0137\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.4349e-04 - val_loss: 0.0076\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.5265e-04 - val_loss: 0.0080\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.9893e-04 - val_loss: 0.0119\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.1442e-04 - val_loss: 0.0134\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.9544e-04 - val_loss: 0.0045\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.4448e-04 - val_loss: 0.0074\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.7300e-04 - val_loss: 0.0155\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.6585e-04 - val_loss: 0.0028\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.1149e-04 - val_loss: 0.0115\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.1962e-04 - val_loss: 0.0041\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.1458e-04 - val_loss: 0.0130\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.1656e-04 - val_loss: 0.0065\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.3305e-04 - val_loss: 0.0059\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.9567e-04 - val_loss: 0.0093\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.2291e-04 - val_loss: 0.0155\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.7578e-04 - val_loss: 0.0095\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.9012e-04 - val_loss: 0.0169\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.9039e-04 - val_loss: 0.0155\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.3659e-04 - val_loss: 0.0246\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.2875e-04 - val_loss: 0.0169\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.7384e-04 - val_loss: 0.0142\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.7320e-04 - val_loss: 0.0222\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.6843e-04 - val_loss: 0.0091\n",
            "training:  lstm_cv  df:  1\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/80 [==>...........................] - ETA: 0s - loss: 2.7810e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5155e-04 - val_loss: 0.0500\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 9.6547e-05 - val_loss: 0.0208\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.3378e-05 - val_loss: 0.0077\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.4857e-05 - val_loss: 0.0056\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.5979e-05 - val_loss: 0.0091\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6785e-04 - val_loss: 0.0055\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.1634e-05 - val_loss: 0.0137\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.9017e-05 - val_loss: 0.0144\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.3588e-05 - val_loss: 0.0238\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.7997e-05 - val_loss: 0.0491\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.9365e-05 - val_loss: 0.0596\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.7303e-05 - val_loss: 0.0583\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.9880e-05 - val_loss: 0.0331\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.2986e-05 - val_loss: 0.0634\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.8004e-05 - val_loss: 0.0448\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.3890e-05 - val_loss: 0.0378\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.0534e-05 - val_loss: 0.0754\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.6455e-05 - val_loss: 0.0555\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.5159e-05 - val_loss: 0.0923\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.9080e-05 - val_loss: 0.0716\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.4495e-05 - val_loss: 0.0548\n",
            "training:  lstm_cv  df:  2\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 6.4314e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 8ms/step - loss: 1.5671e-05 - val_loss: 0.0924\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0674e-05 - val_loss: 0.1108\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0821e-05 - val_loss: 0.1052\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.1653e-05 - val_loss: 0.1232\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.3909e-05 - val_loss: 0.1346\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0736e-05 - val_loss: 0.1360\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0960e-05 - val_loss: 0.1423\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0861e-05 - val_loss: 0.1375\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 8.5052e-06 - val_loss: 0.1324\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0393e-05 - val_loss: 0.1405\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0365e-05 - val_loss: 0.1310\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0649e-05 - val_loss: 0.1258\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0488e-05 - val_loss: 0.1202\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 9.2259e-06 - val_loss: 0.1361\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 9.0499e-06 - val_loss: 0.1238\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0090e-05 - val_loss: 0.1127\n",
            "training:  lstm_cv  df:  3\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6685e-04 - val_loss: 0.0239\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.8104e-04 - val_loss: 0.0156\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8550e-04 - val_loss: 0.0197\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4900e-04 - val_loss: 0.0155\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4797e-04 - val_loss: 0.0154\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2641e-04 - val_loss: 0.0155\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3937e-04 - val_loss: 0.0178\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2590e-04 - val_loss: 0.0145\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4047e-04 - val_loss: 0.0205\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1530e-04 - val_loss: 0.0161\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2019e-04 - val_loss: 0.0136\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1016e-04 - val_loss: 0.0131\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0334e-04 - val_loss: 0.0175\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0621e-04 - val_loss: 0.0174\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0365e-04 - val_loss: 0.0155\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1142e-04 - val_loss: 0.0148\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0305e-04 - val_loss: 0.0109\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1031e-04 - val_loss: 0.0102\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.9633e-05 - val_loss: 0.0107\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.8845e-05 - val_loss: 0.0133\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7048e-05 - val_loss: 0.0112\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.5745e-05 - val_loss: 0.0124\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0411e-04 - val_loss: 0.0126\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9315e-05 - val_loss: 0.0131\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7192e-05 - val_loss: 0.0101\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0832e-05 - val_loss: 0.0109\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3534e-05 - val_loss: 0.0128\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7747e-05 - val_loss: 0.0110\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3400e-05 - val_loss: 0.0115\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6049e-05 - val_loss: 0.0163\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.8200e-05 - val_loss: 0.0119\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2648e-05 - val_loss: 0.0116\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6409e-05 - val_loss: 0.0093\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1706e-05 - val_loss: 0.0161\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3583e-05 - val_loss: 0.0116\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5774e-05 - val_loss: 0.0104\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1456e-05 - val_loss: 0.0194\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4184e-05 - val_loss: 0.0112\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1346e-05 - val_loss: 0.0092\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2991e-05 - val_loss: 0.0083\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4456e-05 - val_loss: 0.0136\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5942e-05 - val_loss: 0.0151\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1219e-05 - val_loss: 0.0114\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1263e-05 - val_loss: 0.0131\n",
            "Epoch 45/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8559e-05 - val_loss: 0.0102\n",
            "Epoch 46/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4005e-05 - val_loss: 0.0093\n",
            "Epoch 47/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8556e-05 - val_loss: 0.0115\n",
            "Epoch 48/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2064e-05 - val_loss: 0.0127\n",
            "Epoch 49/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.9078e-05 - val_loss: 0.0128\n",
            "Epoch 50/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9474e-05 - val_loss: 0.0132\n",
            "Epoch 51/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.8677e-05 - val_loss: 0.0102\n",
            "Epoch 52/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1712e-05 - val_loss: 0.0108\n",
            "Epoch 53/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9911e-05 - val_loss: 0.0104\n",
            "Epoch 54/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3293e-05 - val_loss: 0.0108\n",
            "Epoch 55/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4004e-05 - val_loss: 0.0117\n",
            "training:  lstm_cv  df:  4\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8552e-04 - val_loss: 7.2105e-05\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.5238e-04 - val_loss: 6.1009e-05\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.5198e-04 - val_loss: 1.2971e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.5323e-04 - val_loss: 8.7367e-05\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4525e-04 - val_loss: 1.4329e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4071e-04 - val_loss: 7.2690e-05\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.5048e-04 - val_loss: 8.6318e-05\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3609e-04 - val_loss: 9.0548e-05\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3362e-04 - val_loss: 7.9789e-05\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2544e-04 - val_loss: 7.4116e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.3652e-04 - val_loss: 7.5041e-05\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3000e-04 - val_loss: 1.5498e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4285e-04 - val_loss: 9.2888e-05\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3637e-04 - val_loss: 6.1458e-05\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2277e-04 - val_loss: 8.1722e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2320e-04 - val_loss: 9.3023e-05\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2159e-04 - val_loss: 8.6872e-05\n",
            "training:  lstm_cv  df:  5\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2841e-05 - val_loss: 2.9655e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.6701e-05 - val_loss: 3.3380e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4996e-05 - val_loss: 5.6545e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2603e-05 - val_loss: 5.8118e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4177e-05 - val_loss: 9.0153e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1621e-05 - val_loss: 0.0014\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1400e-05 - val_loss: 0.0014\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1531e-05 - val_loss: 0.0024\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1074e-05 - val_loss: 0.0027\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0941e-05 - val_loss: 0.0037\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0258e-05 - val_loss: 0.0035\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1727e-05 - val_loss: 0.0025\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9599e-05 - val_loss: 0.0034\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8265e-05 - val_loss: 0.0057\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8786e-05 - val_loss: 0.0055\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6957e-05 - val_loss: 0.0045\n",
            "training:  lstm_cv  df:  6\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 3.5332e-04 - val_loss: 2.9849e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.9342e-04 - val_loss: 1.4695e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.7294e-04 - val_loss: 1.1396e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.6084e-04 - val_loss: 1.7073e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.7188e-04 - val_loss: 9.5808e-05\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4836e-04 - val_loss: 9.1901e-05\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5801e-04 - val_loss: 1.0848e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5074e-04 - val_loss: 1.4570e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5748e-04 - val_loss: 1.4666e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5813e-04 - val_loss: 1.0107e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4887e-04 - val_loss: 1.0834e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4580e-04 - val_loss: 1.1711e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4718e-04 - val_loss: 2.5523e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5326e-04 - val_loss: 9.9547e-05\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3925e-04 - val_loss: 1.5600e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4625e-04 - val_loss: 9.9965e-05\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4423e-04 - val_loss: 1.4309e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3820e-04 - val_loss: 1.0887e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4803e-04 - val_loss: 1.4756e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4964e-04 - val_loss: 1.2213e-04\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3371e-04 - val_loss: 1.1397e-04\n",
            "training:  lstm_cv  df:  7\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 8.4820e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 7.6543e-05 - val_loss: 2.6702e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 6.6174e-05 - val_loss: 3.0713e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 6.0229e-05 - val_loss: 3.4942e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.8406e-05 - val_loss: 3.9575e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.5264e-05 - val_loss: 5.2217e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.0999e-05 - val_loss: 6.6725e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.1561e-05 - val_loss: 8.3566e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9225e-05 - val_loss: 9.5847e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9533e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9671e-05 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.6860e-05 - val_loss: 0.0012\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.8502e-05 - val_loss: 0.0014\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.6718e-05 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.0786e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.6868e-05 - val_loss: 0.0020\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.5934e-05 - val_loss: 0.0026\n",
            "training:  lstm_cv  df:  8\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/68 [==>...........................] - ETA: 0s - loss: 1.5953e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 1.7322e-04 - val_loss: 0.0054\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.7059e-04 - val_loss: 0.0053\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.5373e-04 - val_loss: 0.0057\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4157e-04 - val_loss: 0.0052\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3234e-04 - val_loss: 0.0047\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2287e-04 - val_loss: 0.0048\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2584e-04 - val_loss: 0.0049\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3682e-04 - val_loss: 0.0062\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3057e-04 - val_loss: 0.0050\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1715e-04 - val_loss: 0.0054\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2936e-04 - val_loss: 0.0034\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 2.3184e-04 - val_loss: 0.0042\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2098e-04 - val_loss: 0.0046\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3842e-04 - val_loss: 0.0060\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2676e-04 - val_loss: 0.0046\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3092e-04 - val_loss: 0.0067\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2105e-04 - val_loss: 0.0045\n",
            "Epoch 18/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1903e-04 - val_loss: 0.0051\n",
            "Epoch 19/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2008e-04 - val_loss: 0.0053\n",
            "Epoch 20/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2498e-04 - val_loss: 0.0058\n",
            "Epoch 21/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1379e-04 - val_loss: 0.0062\n",
            "Epoch 22/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1952e-04 - val_loss: 0.0059\n",
            "Epoch 23/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2106e-04 - val_loss: 0.0049\n",
            "Epoch 24/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2798e-04 - val_loss: 0.0063\n",
            "Epoch 25/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3701e-04 - val_loss: 0.0071\n",
            "Epoch 26/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1950e-04 - val_loss: 0.0059\n",
            "training:  lstm_cv  df:  9\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/162 [..............................] - ETA: 1s - loss: 5.7376e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 5.8876e-05 - val_loss: 0.0045\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.4816e-05 - val_loss: 0.0047\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.4637e-05 - val_loss: 0.0050\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.2018e-05 - val_loss: 0.0050\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.1004e-05 - val_loss: 0.0052\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.0627e-05 - val_loss: 0.0054\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8193e-05 - val_loss: 0.0056\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.0765e-05 - val_loss: 0.0059\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8140e-05 - val_loss: 0.0065\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.7750e-05 - val_loss: 0.0069\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6225e-05 - val_loss: 0.0073\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.7937e-05 - val_loss: 0.0075\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6669e-05 - val_loss: 0.0079\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.5363e-05 - val_loss: 0.0087\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6075e-05 - val_loss: 0.0093\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6409e-05 - val_loss: 0.0099\n",
            "training:  lstm_cv  df:  10\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3260e-05 - val_loss: 7.5395e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8770e-05 - val_loss: 6.2488e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.7319e-05 - val_loss: 7.5945e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5171e-05 - val_loss: 6.5079e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1952e-05 - val_loss: 6.9933e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3997e-05 - val_loss: 9.0893e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1686e-05 - val_loss: 7.8066e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8376e-05 - val_loss: 7.1656e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0270e-05 - val_loss: 0.0012\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9582e-05 - val_loss: 8.7477e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0468e-05 - val_loss: 9.6197e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2229e-05 - val_loss: 5.9582e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9138e-05 - val_loss: 5.8874e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6952e-05 - val_loss: 7.9712e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4085e-05 - val_loss: 7.6735e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0316e-05 - val_loss: 8.0200e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0949e-05 - val_loss: 7.0755e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8265e-05 - val_loss: 8.7163e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4901e-05 - val_loss: 7.8581e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6246e-05 - val_loss: 5.5112e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8283e-05 - val_loss: 6.8177e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8077e-05 - val_loss: 4.5836e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6372e-05 - val_loss: 0.0010\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7846e-05 - val_loss: 9.7358e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8748e-05 - val_loss: 8.0805e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9523e-05 - val_loss: 8.5528e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2364e-05 - val_loss: 9.0357e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8660e-05 - val_loss: 7.1981e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9301e-05 - val_loss: 8.4701e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1640e-05 - val_loss: 6.8028e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6465e-05 - val_loss: 7.1269e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2796e-05 - val_loss: 6.9230e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1562e-05 - val_loss: 8.0078e-04\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6531e-05 - val_loss: 7.7494e-04\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5563e-05 - val_loss: 6.3159e-04\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7233e-05 - val_loss: 9.6132e-04\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1230e-05 - val_loss: 9.1290e-04\n",
            "training:  lstm_cv  df:  11\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3037e-04 - val_loss: 8.3945e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1235e-04 - val_loss: 7.7053e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0205e-04 - val_loss: 1.5241e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.9806e-05 - val_loss: 9.7895e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6435e-05 - val_loss: 6.7285e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7260e-05 - val_loss: 8.9807e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6825e-05 - val_loss: 1.4840e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0061e-04 - val_loss: 8.2428e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0899e-05 - val_loss: 1.1689e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0232e-04 - val_loss: 1.3794e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7663e-05 - val_loss: 1.3711e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9108e-05 - val_loss: 7.2253e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3405e-05 - val_loss: 9.0603e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7602e-05 - val_loss: 1.2260e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3072e-05 - val_loss: 8.9480e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9249e-05 - val_loss: 6.7855e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1192e-05 - val_loss: 1.0969e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3436e-05 - val_loss: 6.7884e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2792e-04 - val_loss: 6.5811e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9055e-05 - val_loss: 1.6514e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3924e-05 - val_loss: 8.1374e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0400e-05 - val_loss: 1.1357e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7332e-05 - val_loss: 7.9385e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7145e-05 - val_loss: 1.0029e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6722e-05 - val_loss: 6.7753e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7234e-05 - val_loss: 8.0284e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8844e-05 - val_loss: 1.1673e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3468e-05 - val_loss: 8.3059e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0035e-05 - val_loss: 9.5337e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1646e-05 - val_loss: 1.1818e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2506e-05 - val_loss: 1.3318e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6496e-05 - val_loss: 1.2638e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9740e-05 - val_loss: 7.5162e-05\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4443e-05 - val_loss: 1.7778e-04\n",
            "training:  lstm_cv  df:  12\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0023\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7712e-04 - val_loss: 0.0018\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "training:  lstm_cv  df:  13\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/132 [..............................] - ETA: 1s - loss: 3.6499e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 8ms/step - loss: 5.9260e-05 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.9747e-05 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.4928e-05 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.1237e-05 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.1083e-05 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.0134e-05 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.2067e-05 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9325e-05 - val_loss: 0.0017\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9069e-05 - val_loss: 0.0017\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8096e-05 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7604e-05 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6987e-05 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6292e-05 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6338e-05 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7295e-05 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6194e-05 - val_loss: 0.0017\n",
            "training:  lstm_cv  df:  14\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/26 [=========>....................] - ETA: 0s - loss: 7.5803e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 9ms/step - loss: 5.7258e-04 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 5.1029e-04 - val_loss: 2.9737e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1241e-04 - val_loss: 3.9065e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.2559e-04 - val_loss: 3.1869e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3719e-04 - val_loss: 3.1641e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.2547e-04 - val_loss: 2.1629e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3397e-04 - val_loss: 2.3861e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8394e-04 - val_loss: 2.1200e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1695e-04 - val_loss: 2.0231e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8353e-04 - val_loss: 2.3241e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6485e-04 - val_loss: 2.4049e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6685e-04 - val_loss: 2.1010e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8427e-04 - val_loss: 2.4421e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8827e-04 - val_loss: 2.2704e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.4981e-04 - val_loss: 2.2224e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.0644e-04 - val_loss: 2.3228e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2152e-04 - val_loss: 2.0870e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6839e-04 - val_loss: 2.1941e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.3965e-04 - val_loss: 2.3447e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.5632e-04 - val_loss: 2.0343e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6463e-04 - val_loss: 2.7010e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8749e-04 - val_loss: 2.4703e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7694e-04 - val_loss: 4.3114e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8123e-04 - val_loss: 2.6370e-04\n",
            "training:  lstm_cv  df:  15\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0690e-05 - val_loss: 6.0376e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5116e-05 - val_loss: 6.5861e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4939e-05 - val_loss: 7.4878e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3349e-05 - val_loss: 8.6477e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2979e-05 - val_loss: 9.8378e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3096e-05 - val_loss: 9.5121e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2538e-05 - val_loss: 0.0011\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2125e-05 - val_loss: 0.0011\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1926e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2209e-05 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1242e-05 - val_loss: 0.0010\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1255e-05 - val_loss: 0.0012\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0995e-05 - val_loss: 0.0010\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0918e-05 - val_loss: 0.0011\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0476e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1215e-05 - val_loss: 0.0012\n",
            "training:  lstm_cv  df:  16\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8795e-05 - val_loss: 0.0047\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.5679e-05 - val_loss: 0.0047\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4044e-05 - val_loss: 0.0055\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4831e-05 - val_loss: 0.0064\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1429e-05 - val_loss: 0.0063\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2189e-05 - val_loss: 0.0082\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1447e-05 - val_loss: 0.0103\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1098e-05 - val_loss: 0.0109\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0292e-05 - val_loss: 0.0125\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0779e-05 - val_loss: 0.0137\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0813e-05 - val_loss: 0.0138\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9363e-05 - val_loss: 0.0132\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0698e-05 - val_loss: 0.0170\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0003e-05 - val_loss: 0.0166\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8914e-05 - val_loss: 0.0172\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9477e-05 - val_loss: 0.0174\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9679e-05 - val_loss: 0.0176\n",
            "training:  lstm_cv  df:  17\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2570e-05 - val_loss: 0.0153\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.0507e-05 - val_loss: 0.0170\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.0351e-05 - val_loss: 0.0179\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 9.6292e-06 - val_loss: 0.0190\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 9.3755e-06 - val_loss: 0.0212\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 8.7734e-06 - val_loss: 0.0238\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 8.3158e-06 - val_loss: 0.0264\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 8.5916e-06 - val_loss: 0.0261\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.6636e-06 - val_loss: 0.0295\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.9299e-06 - val_loss: 0.0282\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.7616e-06 - val_loss: 0.0306\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.8681e-06 - val_loss: 0.0343\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.2043e-06 - val_loss: 0.0368\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.7792e-06 - val_loss: 0.0380\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 8.1496e-06 - val_loss: 0.0409\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.0756e-06 - val_loss: 0.0430\n",
            "training:  lstm_cv  df:  18\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/174 [..............................] - ETA: 1s - loss: 0.0560"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 8.7249e-04 - val_loss: 1.9239e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.7595e-04 - val_loss: 2.0080e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3448e-04 - val_loss: 1.8714e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3888e-04 - val_loss: 1.8738e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3508e-04 - val_loss: 2.5620e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2275e-04 - val_loss: 1.8558e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2463e-04 - val_loss: 1.9648e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1722e-04 - val_loss: 2.0445e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2292e-04 - val_loss: 1.8150e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1872e-04 - val_loss: 2.0229e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2261e-04 - val_loss: 1.8247e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2119e-04 - val_loss: 1.8668e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1616e-04 - val_loss: 1.7938e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3171e-04 - val_loss: 1.7994e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2298e-04 - val_loss: 1.9222e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1783e-04 - val_loss: 2.1611e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1714e-04 - val_loss: 1.9857e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2103e-04 - val_loss: 1.8093e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1159e-04 - val_loss: 1.8519e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1354e-04 - val_loss: 1.9583e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2317e-04 - val_loss: 2.2105e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1141e-04 - val_loss: 1.9645e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1351e-04 - val_loss: 1.8897e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0928e-04 - val_loss: 1.9311e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1343e-04 - val_loss: 1.8863e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1716e-04 - val_loss: 2.1207e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1335e-04 - val_loss: 1.9456e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2430e-04 - val_loss: 1.7956e-04\n",
            "training:  lstm_cv  df:  19\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 8/47 [====>.........................] - ETA: 0s - loss: 1.4889e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9179e-04 - val_loss: 2.0899e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0036e-04 - val_loss: 1.7811e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8920e-04 - val_loss: 2.1211e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8909e-04 - val_loss: 1.8374e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0074e-04 - val_loss: 2.0029e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8742e-04 - val_loss: 1.7233e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8700e-04 - val_loss: 1.7857e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0019e-04 - val_loss: 1.7372e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0324e-04 - val_loss: 1.9509e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9591e-04 - val_loss: 1.7880e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8326e-04 - val_loss: 1.7156e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8941e-04 - val_loss: 1.8743e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0040e-04 - val_loss: 1.8495e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8632e-04 - val_loss: 1.9788e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7894e-04 - val_loss: 1.6990e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8426e-04 - val_loss: 1.7533e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8244e-04 - val_loss: 1.8117e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8172e-04 - val_loss: 2.6044e-04\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9635e-04 - val_loss: 1.7058e-04\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8653e-04 - val_loss: 2.0828e-04\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9347e-04 - val_loss: 1.7592e-04\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9173e-04 - val_loss: 1.6869e-04\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8179e-04 - val_loss: 1.8447e-04\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7370e-04 - val_loss: 1.8502e-04\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8767e-04 - val_loss: 1.8748e-04\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7681e-04 - val_loss: 1.8406e-04\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0299e-04 - val_loss: 1.8878e-04\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1251e-04 - val_loss: 2.5010e-04\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0023e-04 - val_loss: 1.7942e-04\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8164e-04 - val_loss: 1.9679e-04\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7295e-04 - val_loss: 1.9894e-04\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8759e-04 - val_loss: 1.7127e-04\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.8597e-04 - val_loss: 1.8341e-04\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9003e-04 - val_loss: 1.7650e-04\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8639e-04 - val_loss: 1.9269e-04\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8731e-04 - val_loss: 1.6267e-04\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9470e-04 - val_loss: 2.4906e-04\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9520e-04 - val_loss: 2.4014e-04\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8849e-04 - val_loss: 1.8995e-04\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9837e-04 - val_loss: 2.6378e-04\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0213e-04 - val_loss: 1.7190e-04\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9151e-04 - val_loss: 1.8297e-04\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8044e-04 - val_loss: 2.0298e-04\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9667e-04 - val_loss: 1.7767e-04\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0065e-04 - val_loss: 2.3324e-04\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9968e-04 - val_loss: 2.3767e-04\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8069e-04 - val_loss: 1.7626e-04\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9302e-04 - val_loss: 1.8683e-04\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8133e-04 - val_loss: 1.7072e-04\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9107e-04 - val_loss: 1.8433e-04\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8159e-04 - val_loss: 2.2934e-04\n",
            "training:  lstm_cv  df:  20\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  5/151 [..............................] - ETA: 1s - loss: 0.0010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 7.2376e-05 - val_loss: 4.8460e-04\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.4415e-05 - val_loss: 4.8327e-04\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.1518e-05 - val_loss: 4.6503e-04\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.0164e-05 - val_loss: 4.7696e-04\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.4945e-06 - val_loss: 4.5074e-04\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.1858e-06 - val_loss: 4.7123e-04\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.9237e-06 - val_loss: 4.9800e-04\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.5262e-06 - val_loss: 5.0058e-04\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.2559e-06 - val_loss: 4.8424e-04\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.3679e-06 - val_loss: 4.8807e-04\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.8387e-06 - val_loss: 5.2545e-04\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.6753e-06 - val_loss: 4.8249e-04\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.7248e-06 - val_loss: 4.8618e-04\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.0755e-06 - val_loss: 5.0431e-04\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.3106e-06 - val_loss: 5.3571e-04\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.9615e-06 - val_loss: 5.3128e-04\n",
            "Epoch 17/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.0418e-06 - val_loss: 5.3458e-04\n",
            "Epoch 18/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.8356e-06 - val_loss: 5.3729e-04\n",
            "Epoch 19/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.0435e-06 - val_loss: 5.4612e-04\n",
            "Epoch 20/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.7565e-06 - val_loss: 5.7306e-04\n",
            "training:  lstm_cv  df:  21\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 9.0419e-05 - val_loss: 3.4601e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.8254e-05 - val_loss: 1.6510e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.9708e-05 - val_loss: 1.6800e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.3266e-05 - val_loss: 1.4714e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.4501e-05 - val_loss: 1.7817e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.4269e-05 - val_loss: 1.5687e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.2715e-05 - val_loss: 2.8631e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.1183e-05 - val_loss: 1.7076e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.5020e-05 - val_loss: 2.0066e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9435e-05 - val_loss: 1.9119e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.2778e-05 - val_loss: 2.2952e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.7291e-05 - val_loss: 1.8361e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9546e-05 - val_loss: 2.1492e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.8244e-05 - val_loss: 1.6036e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9162e-05 - val_loss: 1.5235e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9435e-05 - val_loss: 2.3357e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8762e-05 - val_loss: 1.5605e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.8068e-05 - val_loss: 1.5247e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9152e-05 - val_loss: 3.1881e-04\n",
            "training:  lstm_cv  df:  22\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 2s 8ms/step - loss: 3.3722e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 3.0334e-05 - val_loss: 0.0012\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 3.0372e-05 - val_loss: 0.0011\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 3.1584e-05 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.9428e-05 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6528e-05 - val_loss: 0.0026\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.7378e-05 - val_loss: 0.0028\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6591e-05 - val_loss: 0.0036\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.5866e-05 - val_loss: 0.0035\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.5368e-05 - val_loss: 0.0040\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.5664e-05 - val_loss: 0.0050\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6832e-05 - val_loss: 0.0055\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6433e-05 - val_loss: 0.0056\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6428e-05 - val_loss: 0.0055\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6626e-05 - val_loss: 0.0065\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.6258e-05 - val_loss: 0.0072\n",
            "Epoch 17/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.4469e-05 - val_loss: 0.0094\n",
            "Epoch 18/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.4644e-05 - val_loss: 0.0091\n",
            "training:  lstm_cv  df:  23\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 0.0030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.4170e-04 - val_loss: 8.3771e-06\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.8513e-04 - val_loss: 1.7284e-05\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6397e-04 - val_loss: 6.3184e-06\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5945e-04 - val_loss: 7.1907e-06\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6410e-04 - val_loss: 8.2202e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6642e-04 - val_loss: 7.3274e-06\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6501e-04 - val_loss: 1.3775e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6034e-04 - val_loss: 9.0455e-06\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5953e-04 - val_loss: 8.1413e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5601e-04 - val_loss: 2.4128e-05\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5237e-04 - val_loss: 7.0803e-06\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5906e-04 - val_loss: 1.1413e-05\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5473e-04 - val_loss: 2.1919e-05\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5498e-04 - val_loss: 6.1127e-06\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5044e-04 - val_loss: 6.3014e-06\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4642e-04 - val_loss: 6.5138e-06\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4865e-04 - val_loss: 1.9775e-05\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4626e-04 - val_loss: 5.2655e-05\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5517e-04 - val_loss: 1.7091e-05\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4927e-04 - val_loss: 1.5375e-05\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4861e-04 - val_loss: 1.6605e-05\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5420e-04 - val_loss: 9.4522e-06\n",
            "Epoch 23/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4639e-04 - val_loss: 8.6738e-06\n",
            "Epoch 24/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5827e-04 - val_loss: 1.5827e-05\n",
            "Epoch 25/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5086e-04 - val_loss: 6.0756e-06\n",
            "Epoch 26/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5541e-04 - val_loss: 6.6659e-06\n",
            "Epoch 27/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4616e-04 - val_loss: 6.7512e-06\n",
            "Epoch 28/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4530e-04 - val_loss: 1.2355e-05\n",
            "Epoch 29/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4873e-04 - val_loss: 1.6606e-05\n",
            "Epoch 30/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4922e-04 - val_loss: 8.5669e-06\n",
            "Epoch 31/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5545e-04 - val_loss: 1.5967e-05\n",
            "Epoch 32/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5227e-04 - val_loss: 9.1395e-06\n",
            "Epoch 33/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5028e-04 - val_loss: 1.1483e-05\n",
            "Epoch 34/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5688e-04 - val_loss: 1.7292e-05\n",
            "Epoch 35/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5103e-04 - val_loss: 8.2166e-06\n",
            "Epoch 36/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5417e-04 - val_loss: 1.6004e-05\n",
            "Epoch 37/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4731e-04 - val_loss: 9.8346e-06\n",
            "Epoch 38/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4807e-04 - val_loss: 1.4691e-05\n",
            "Epoch 39/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5469e-04 - val_loss: 7.6020e-06\n",
            "Epoch 40/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4757e-04 - val_loss: 9.9986e-06\n",
            "training:  lstm_cv  df:  24\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 3.3353e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.6538e-04 - val_loss: 1.0922e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4749e-04 - val_loss: 1.0589e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.5100e-04 - val_loss: 1.3733e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4146e-04 - val_loss: 1.1345e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4421e-04 - val_loss: 9.2886e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4144e-04 - val_loss: 7.9657e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4164e-04 - val_loss: 7.5779e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3654e-04 - val_loss: 7.9119e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3999e-04 - val_loss: 9.9908e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3680e-04 - val_loss: 8.5183e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3249e-04 - val_loss: 7.2925e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3444e-04 - val_loss: 7.6121e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3243e-04 - val_loss: 7.6935e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3473e-04 - val_loss: 9.2536e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3973e-04 - val_loss: 8.7696e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3397e-04 - val_loss: 8.6860e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3619e-04 - val_loss: 9.1724e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3414e-04 - val_loss: 7.9932e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3623e-04 - val_loss: 1.1988e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3550e-04 - val_loss: 8.6517e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3350e-04 - val_loss: 1.0909e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4329e-04 - val_loss: 8.1241e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3517e-04 - val_loss: 1.2132e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3881e-04 - val_loss: 9.4229e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3611e-04 - val_loss: 1.0552e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3327e-04 - val_loss: 9.4985e-05\n",
            "training:  lstm_cv  df:  25\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/53 [====>.........................] - ETA: 0s - loss: 2.4799e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6896e-04 - val_loss: 3.2153e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5011e-04 - val_loss: 3.3720e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5320e-04 - val_loss: 3.4647e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6530e-04 - val_loss: 3.9083e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.7163e-04 - val_loss: 3.8115e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6301e-04 - val_loss: 3.2656e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6249e-04 - val_loss: 3.2735e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4934e-04 - val_loss: 3.0665e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4984e-04 - val_loss: 3.0233e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4650e-04 - val_loss: 3.2095e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5409e-04 - val_loss: 3.3211e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6401e-04 - val_loss: 3.1694e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3825e-04 - val_loss: 3.3488e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6299e-04 - val_loss: 3.1529e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5720e-04 - val_loss: 3.2415e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5653e-04 - val_loss: 3.1295e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4713e-04 - val_loss: 3.1077e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4994e-04 - val_loss: 3.0593e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3903e-04 - val_loss: 3.2131e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5847e-04 - val_loss: 3.2236e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5648e-04 - val_loss: 3.0996e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4824e-04 - val_loss: 3.1659e-04\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5008e-04 - val_loss: 3.4344e-04\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4502e-04 - val_loss: 3.1033e-04\n",
            "training:  lstm_cv  df:  26\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/58 [===>..........................] - ETA: 0s - loss: 1.2950e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7739e-04 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6194e-04 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6412e-04 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.9415e-04 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5141e-04 - val_loss: 0.0016\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5363e-04 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4974e-04 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4951e-04 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5084e-04 - val_loss: 0.0016\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5262e-04 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5023e-04 - val_loss: 0.0016\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3071e-04 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2734e-04 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3423e-04 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3680e-04 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3961e-04 - val_loss: 0.0016\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2914e-04 - val_loss: 0.0016\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3060e-04 - val_loss: 0.0015\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3642e-04 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3408e-04 - val_loss: 0.0016\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3496e-04 - val_loss: 0.0015\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3195e-04 - val_loss: 0.0016\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3189e-04 - val_loss: 0.0016\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2604e-04 - val_loss: 0.0016\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2053e-04 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3487e-04 - val_loss: 0.0015\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2170e-04 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2459e-04 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4631e-04 - val_loss: 0.0016\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2179e-04 - val_loss: 0.0016\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1853e-04 - val_loss: 0.0015\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2642e-04 - val_loss: 0.0015\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2974e-04 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2032e-04 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3027e-04 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2350e-04 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2266e-04 - val_loss: 0.0016\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1597e-04 - val_loss: 0.0016\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2308e-04 - val_loss: 0.0016\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3158e-04 - val_loss: 0.0016\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3167e-04 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2427e-04 - val_loss: 0.0016\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2914e-04 - val_loss: 0.0015\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2720e-04 - val_loss: 0.0015\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3049e-04 - val_loss: 0.0015\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2893e-04 - val_loss: 0.0015\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2429e-04 - val_loss: 0.0015\n",
            "training:  lstm_cv  df:  27\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/46 [====>.........................] - ETA: 0s - loss: 5.2141e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 9ms/step - loss: 3.9594e-04 - val_loss: 4.9163e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6823e-04 - val_loss: 5.3056e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8291e-04 - val_loss: 5.6087e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4426e-04 - val_loss: 5.7305e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2154e-04 - val_loss: 5.2352e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4727e-04 - val_loss: 4.8801e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5395e-04 - val_loss: 4.6229e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3293e-04 - val_loss: 5.4051e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2402e-04 - val_loss: 4.4194e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3615e-04 - val_loss: 8.2860e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.4121e-04 - val_loss: 5.6973e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3004e-04 - val_loss: 6.0188e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2585e-04 - val_loss: 4.2105e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3535e-04 - val_loss: 4.8259e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1094e-04 - val_loss: 4.7920e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5390e-04 - val_loss: 4.5163e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2590e-04 - val_loss: 4.7000e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2295e-04 - val_loss: 4.1890e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.2119e-04 - val_loss: 5.1156e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2004e-04 - val_loss: 4.5289e-04\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1863e-04 - val_loss: 4.4134e-04\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9790e-04 - val_loss: 4.7037e-04\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2773e-04 - val_loss: 4.9270e-04\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1167e-04 - val_loss: 5.8928e-04\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2378e-04 - val_loss: 5.3152e-04\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3522e-04 - val_loss: 4.8773e-04\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4215e-04 - val_loss: 5.0290e-04\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4699e-04 - val_loss: 5.0706e-04\n",
            "Epoch 29/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6131e-04 - val_loss: 4.3532e-04\n",
            "Epoch 30/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0826e-04 - val_loss: 4.7154e-04\n",
            "Epoch 31/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2531e-04 - val_loss: 4.1891e-04\n",
            "Epoch 32/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1991e-04 - val_loss: 5.3684e-04\n",
            "Epoch 33/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0026e-04 - val_loss: 4.3136e-04\n",
            "training:  lstm_cv  df:  28\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/171 [..............................] - ETA: 1s - loss: 2.4571e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 8ms/step - loss: 9.1243e-05 - val_loss: 3.5240e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.7988e-05 - val_loss: 2.6145e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.9167e-05 - val_loss: 3.4128e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.5097e-05 - val_loss: 2.5956e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.6121e-05 - val_loss: 2.5582e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.6646e-05 - val_loss: 2.4886e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.4682e-05 - val_loss: 2.8885e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3642e-05 - val_loss: 2.6098e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9605e-05 - val_loss: 2.7050e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3516e-05 - val_loss: 2.9692e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.2931e-05 - val_loss: 2.6297e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.2851e-05 - val_loss: 2.5684e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.2778e-05 - val_loss: 2.7476e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.1559e-05 - val_loss: 2.7184e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8556e-05 - val_loss: 2.6681e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.4365e-05 - val_loss: 2.6799e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.2614e-05 - val_loss: 2.7487e-04\n",
            "Epoch 18/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3369e-05 - val_loss: 2.7390e-04\n",
            "Epoch 19/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9051e-05 - val_loss: 2.8815e-04\n",
            "Epoch 20/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.1522e-05 - val_loss: 2.8960e-04\n",
            "Epoch 21/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.0339e-05 - val_loss: 2.8265e-04\n",
            "training:  lstm_cv  df:  29\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 5.6884e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 4.2024e-05 - val_loss: 6.6135e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 3.6922e-05 - val_loss: 7.0945e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 3.3114e-05 - val_loss: 8.3047e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.9403e-05 - val_loss: 8.3284e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.8558e-05 - val_loss: 8.5023e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6294e-05 - val_loss: 9.3694e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.8239e-05 - val_loss: 0.0010\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.7615e-05 - val_loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5009e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5370e-05 - val_loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6956e-05 - val_loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6116e-05 - val_loss: 0.0013\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5248e-05 - val_loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5165e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5381e-05 - val_loss: 0.0014\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6332e-05 - val_loss: 0.0014\n",
            "training:  lstm_cv  df:  30\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 1.9641e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2833e-05 - val_loss: 0.0014\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.4751e-05 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3642e-05 - val_loss: 0.0015\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.4058e-05 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5971e-05 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5142e-05 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5093e-05 - val_loss: 0.0023\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3565e-05 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3417e-05 - val_loss: 0.0024\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3374e-05 - val_loss: 0.0022\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2918e-05 - val_loss: 0.0025\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2454e-05 - val_loss: 0.0025\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2398e-05 - val_loss: 0.0024\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.4231e-05 - val_loss: 0.0028\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.7193e-05 - val_loss: 0.0027\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3456e-05 - val_loss: 0.0028\n",
            "training:  lstm_cv  df:  31\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7249e-05 - val_loss: 3.3352e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1907e-05 - val_loss: 4.4136e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.7840e-05 - val_loss: 3.3885e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5110e-05 - val_loss: 3.8945e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3463e-05 - val_loss: 3.8466e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.4451e-05 - val_loss: 3.8975e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.4418e-05 - val_loss: 5.0366e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.4915e-05 - val_loss: 2.9131e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1292e-05 - val_loss: 6.0223e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1495e-05 - val_loss: 3.8233e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3739e-05 - val_loss: 4.1788e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8779e-05 - val_loss: 4.7385e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2521e-05 - val_loss: 7.2531e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.4254e-05 - val_loss: 3.9540e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2269e-05 - val_loss: 4.9595e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1972e-05 - val_loss: 2.8477e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2606e-05 - val_loss: 6.1180e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1581e-05 - val_loss: 3.0476e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1528e-05 - val_loss: 3.4341e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0458e-05 - val_loss: 3.5685e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3082e-05 - val_loss: 3.1186e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1745e-05 - val_loss: 6.0501e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2032e-05 - val_loss: 3.7737e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2729e-05 - val_loss: 4.3730e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9191e-05 - val_loss: 3.5765e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8525e-05 - val_loss: 5.1109e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9108e-05 - val_loss: 3.0426e-05\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9278e-05 - val_loss: 4.3688e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1369e-05 - val_loss: 3.8803e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7114e-05 - val_loss: 2.9037e-05\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0489e-05 - val_loss: 5.7959e-05\n",
            "training:  lstm_cv  df:  32\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.0922e-05 - val_loss: 2.0578e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.8372e-05 - val_loss: 1.8626e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.7341e-05 - val_loss: 2.0679e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.7089e-05 - val_loss: 2.2888e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.6983e-05 - val_loss: 1.8672e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4621e-05 - val_loss: 1.8223e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.7094e-05 - val_loss: 2.4012e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.5099e-05 - val_loss: 2.5165e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4226e-05 - val_loss: 3.5697e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4980e-05 - val_loss: 5.2508e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4190e-05 - val_loss: 6.8429e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4960e-05 - val_loss: 8.7199e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.3584e-05 - val_loss: 0.0012\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.5440e-05 - val_loss: 6.8101e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.3989e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.3421e-05 - val_loss: 5.1851e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.3959e-05 - val_loss: 0.0012\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3352e-05 - val_loss: 0.0011\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5055e-05 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2976e-05 - val_loss: 0.0013\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2845e-05 - val_loss: 0.0016\n",
            "training:  lstm_cv  df:  33\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 1.4045e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 8ms/step - loss: 1.2770e-04 - val_loss: 2.4460e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.1688e-04 - val_loss: 4.0956e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 1.1290e-04 - val_loss: 2.1380e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.9331e-05 - val_loss: 5.3993e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.8833e-05 - val_loss: 5.6906e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.6386e-05 - val_loss: 2.8359e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4192e-05 - val_loss: 5.8852e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.9056e-05 - val_loss: 4.5101e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.7285e-05 - val_loss: 4.8008e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3349e-05 - val_loss: 1.7086e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.6659e-05 - val_loss: 2.2064e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0781e-05 - val_loss: 2.1836e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4872e-05 - val_loss: 3.8908e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3351e-05 - val_loss: 8.4342e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.4381e-05 - val_loss: 4.1552e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0616e-05 - val_loss: 2.5278e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.4248e-05 - val_loss: 2.3906e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.1078e-05 - val_loss: 2.1036e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1119e-05 - val_loss: 5.4255e-04\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4209e-05 - val_loss: 3.0612e-04\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1436e-05 - val_loss: 1.4700e-04\n",
            "Epoch 22/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3289e-05 - val_loss: 1.7802e-04\n",
            "Epoch 23/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4255e-05 - val_loss: 0.0013\n",
            "Epoch 24/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1020e-05 - val_loss: 3.0858e-04\n",
            "Epoch 25/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9890e-05 - val_loss: 4.2136e-04\n",
            "Epoch 26/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9375e-05 - val_loss: 2.5639e-04\n",
            "Epoch 27/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1128e-05 - val_loss: 2.2686e-04\n",
            "Epoch 28/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0258e-05 - val_loss: 1.6392e-04\n",
            "Epoch 29/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.6759e-05 - val_loss: 6.8427e-04\n",
            "Epoch 30/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2170e-05 - val_loss: 2.5900e-04\n",
            "Epoch 31/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.4919e-05 - val_loss: 2.5244e-04\n",
            "Epoch 32/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.5767e-05 - val_loss: 3.6625e-04\n",
            "Epoch 33/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2017e-05 - val_loss: 1.7344e-04\n",
            "Epoch 34/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0812e-05 - val_loss: 4.0761e-04\n",
            "Epoch 35/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0961e-05 - val_loss: 3.8799e-04\n",
            "Epoch 36/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4818e-05 - val_loss: 2.2014e-04\n",
            "training:  lstm_cv  df:  34\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 5.9984e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 2.9884e-05 - val_loss: 5.9156e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.5598e-05 - val_loss: 6.4128e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.4081e-05 - val_loss: 7.4092e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.3716e-05 - val_loss: 5.7450e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2869e-05 - val_loss: 7.5150e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1620e-05 - val_loss: 6.2722e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2780e-05 - val_loss: 5.6238e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2084e-05 - val_loss: 5.1764e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1825e-05 - val_loss: 7.5188e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2026e-05 - val_loss: 8.9017e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2079e-05 - val_loss: 6.0092e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0971e-05 - val_loss: 7.8390e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0411e-05 - val_loss: 6.4240e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0451e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0867e-05 - val_loss: 0.0013\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0433e-05 - val_loss: 0.0015\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2832e-05 - val_loss: 0.0015\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0657e-05 - val_loss: 0.0011\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1765e-05 - val_loss: 0.0013\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8926e-05 - val_loss: 0.0014\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0196e-05 - val_loss: 9.8940e-04\n",
            "Epoch 22/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0368e-05 - val_loss: 0.0012\n",
            "Epoch 23/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0806e-05 - val_loss: 0.0014\n",
            "training:  lstm_cv  df:  35\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 3.9629e-05 - val_loss: 6.0391e-04\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 3.4748e-05 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 3.1880e-05 - val_loss: 0.0028\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.9907e-05 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9242e-05 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9119e-05 - val_loss: 0.0033\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8303e-05 - val_loss: 0.0031\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6601e-05 - val_loss: 0.0023\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9108e-05 - val_loss: 0.0027\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9851e-05 - val_loss: 0.0046\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7386e-05 - val_loss: 0.0057\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7419e-05 - val_loss: 0.0057\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.7790e-05 - val_loss: 0.0069\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6203e-05 - val_loss: 0.0060\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.5549e-05 - val_loss: 0.0070\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.5954e-05 - val_loss: 0.0058\n",
            "training:  lstm_cv  df:  36\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/118 [=>............................] - ETA: 0s - loss: 6.5801e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 5.5577e-05 - val_loss: 0.0041\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 5.0699e-05 - val_loss: 0.0046\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.6483e-05 - val_loss: 0.0047\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.5725e-05 - val_loss: 0.0058\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3300e-05 - val_loss: 0.0062\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5734e-05 - val_loss: 0.0073\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2859e-05 - val_loss: 0.0082\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3720e-05 - val_loss: 0.0083\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2324e-05 - val_loss: 0.0093\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5398e-05 - val_loss: 0.0084\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5521e-05 - val_loss: 0.0078\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0944e-05 - val_loss: 0.0079\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0996e-05 - val_loss: 0.0079\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2872e-05 - val_loss: 0.0084\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2058e-05 - val_loss: 0.0094\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4104e-05 - val_loss: 0.0093\n",
            "training:  lstm_cv  df:  37\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 1s - loss: 8.8720e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 1s 8ms/step - loss: 3.7179e-05 - val_loss: 0.0101\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1823e-05 - val_loss: 0.0101\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.3065e-05 - val_loss: 0.0093\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1871e-05 - val_loss: 0.0094\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.2288e-05 - val_loss: 0.0081\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1335e-05 - val_loss: 0.0089\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0555e-05 - val_loss: 0.0084\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0673e-05 - val_loss: 0.0086\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0955e-05 - val_loss: 0.0100\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9551e-05 - val_loss: 0.0098\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0406e-05 - val_loss: 0.0088\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8759e-05 - val_loss: 0.0075\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0514e-05 - val_loss: 0.0063\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0608e-05 - val_loss: 0.0070\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1042e-05 - val_loss: 0.0072\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.2056e-05 - val_loss: 0.0076\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0143e-05 - val_loss: 0.0067\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9857e-05 - val_loss: 0.0073\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9603e-05 - val_loss: 0.0063\n",
            "Epoch 20/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.3298e-05 - val_loss: 0.0070\n",
            "Epoch 21/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9489e-05 - val_loss: 0.0068\n",
            "Epoch 22/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0852e-05 - val_loss: 0.0065\n",
            "Epoch 23/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9881e-05 - val_loss: 0.0064\n",
            "Epoch 24/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8601e-05 - val_loss: 0.0070\n",
            "Epoch 25/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7846e-05 - val_loss: 0.0083\n",
            "Epoch 26/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9614e-05 - val_loss: 0.0061\n",
            "Epoch 27/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8738e-05 - val_loss: 0.0066\n",
            "Epoch 28/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9731e-05 - val_loss: 0.0077\n",
            "Epoch 29/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9045e-05 - val_loss: 0.0075\n",
            "Epoch 30/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9078e-05 - val_loss: 0.0081\n",
            "Epoch 31/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0188e-05 - val_loss: 0.0077\n",
            "Epoch 32/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9740e-05 - val_loss: 0.0062\n",
            "Epoch 33/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9357e-05 - val_loss: 0.0057\n",
            "Epoch 34/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.8530e-05 - val_loss: 0.0077\n",
            "Epoch 35/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7671e-05 - val_loss: 0.0069\n",
            "Epoch 36/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8393e-05 - val_loss: 0.0074\n",
            "Epoch 37/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9771e-05 - val_loss: 0.0079\n",
            "Epoch 38/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8336e-05 - val_loss: 0.0081\n",
            "Epoch 39/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9818e-05 - val_loss: 0.0083\n",
            "Epoch 40/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7832e-05 - val_loss: 0.0106\n",
            "Epoch 41/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8322e-05 - val_loss: 0.0089\n",
            "Epoch 42/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9456e-05 - val_loss: 0.0097\n",
            "Epoch 43/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0190e-05 - val_loss: 0.0106\n",
            "Epoch 44/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.8586e-05 - val_loss: 0.0107\n",
            "Epoch 45/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9845e-05 - val_loss: 0.0123\n",
            "Epoch 46/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0478e-05 - val_loss: 0.0085\n",
            "Epoch 47/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9182e-05 - val_loss: 0.0077\n",
            "Epoch 48/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9494e-05 - val_loss: 0.0095\n",
            "training:  lstm_cv  df:  38\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/99 [=>............................] - ETA: 0s - loss: 0.0042"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 9.0280e-04 - val_loss: 5.2421e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 2.1267e-04 - val_loss: 4.4576e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 2.0046e-04 - val_loss: 4.6513e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8747e-04 - val_loss: 4.7839e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8403e-04 - val_loss: 4.3145e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7886e-04 - val_loss: 4.3694e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6813e-04 - val_loss: 4.8090e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7859e-04 - val_loss: 4.3454e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7353e-04 - val_loss: 4.3715e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6917e-04 - val_loss: 4.2129e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6989e-04 - val_loss: 4.4110e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7134e-04 - val_loss: 4.4544e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7033e-04 - val_loss: 4.4253e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7021e-04 - val_loss: 4.4426e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7364e-04 - val_loss: 4.4075e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6071e-04 - val_loss: 4.5975e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6733e-04 - val_loss: 4.7184e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6291e-04 - val_loss: 4.7412e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6297e-04 - val_loss: 4.4826e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6514e-04 - val_loss: 4.9120e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6678e-04 - val_loss: 4.3645e-04\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6018e-04 - val_loss: 4.6184e-04\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6563e-04 - val_loss: 4.4076e-04\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7034e-04 - val_loss: 4.7150e-04\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6371e-04 - val_loss: 4.7184e-04\n",
            "training:  lstm_cv  df:  39\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 5.5094e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 4.7820e-05 - val_loss: 1.6350e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.0641e-05 - val_loss: 1.9220e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.1245e-05 - val_loss: 2.0619e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.4479e-05 - val_loss: 1.7680e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.0406e-05 - val_loss: 2.3860e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8667e-05 - val_loss: 1.7931e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 4.1180e-05 - val_loss: 1.8872e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.9068e-05 - val_loss: 1.9631e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.7541e-05 - val_loss: 1.8473e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9356e-05 - val_loss: 2.1741e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.7628e-05 - val_loss: 3.0300e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6084e-05 - val_loss: 2.8946e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6633e-05 - val_loss: 2.2070e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.5896e-05 - val_loss: 2.4545e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8749e-05 - val_loss: 4.6108e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 5.5552e-05 - val_loss: 3.4586e-04\n",
            "training:  lstm_cv  df:  40\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 1s - loss: 5.4607e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 4.4549e-05 - val_loss: 2.0537e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.9674e-05 - val_loss: 2.5328e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.9252e-05 - val_loss: 3.3622e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.9604e-05 - val_loss: 2.6747e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.8669e-05 - val_loss: 2.9490e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.8477e-05 - val_loss: 3.6934e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6656e-05 - val_loss: 3.3821e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7215e-05 - val_loss: 4.2171e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5608e-05 - val_loss: 3.7050e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6544e-05 - val_loss: 3.2476e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7333e-05 - val_loss: 3.4156e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7187e-05 - val_loss: 3.4895e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6342e-05 - val_loss: 2.7979e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5291e-05 - val_loss: 2.8391e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6012e-05 - val_loss: 3.0892e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5925e-05 - val_loss: 2.9128e-04\n",
            "training:  lstm_cv  df:  41\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 0s - loss: 3.8066e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6648e-05 - val_loss: 2.7840e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7807e-05 - val_loss: 3.5742e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5180e-05 - val_loss: 4.5982e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5588e-05 - val_loss: 5.0317e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6053e-05 - val_loss: 4.7628e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6302e-05 - val_loss: 3.8352e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5604e-05 - val_loss: 3.9706e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5868e-05 - val_loss: 3.0136e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5187e-05 - val_loss: 4.3269e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7441e-05 - val_loss: 4.1137e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7940e-05 - val_loss: 5.2826e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4461e-05 - val_loss: 2.9737e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5364e-05 - val_loss: 3.0741e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7011e-05 - val_loss: 4.2192e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6587e-05 - val_loss: 4.7309e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4261e-05 - val_loss: 3.8452e-04\n",
            "training:  lstm_cv  df:  42\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 1.2502e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6101e-05 - val_loss: 5.7860e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.6990e-05 - val_loss: 4.9783e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5970e-05 - val_loss: 6.0626e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5873e-05 - val_loss: 7.7931e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4415e-05 - val_loss: 0.0010\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4056e-05 - val_loss: 0.0020\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.5814e-05 - val_loss: 0.0011\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4427e-05 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3529e-05 - val_loss: 0.0013\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4508e-05 - val_loss: 0.0021\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3040e-05 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.4363e-05 - val_loss: 0.0023\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.3930e-05 - val_loss: 0.0020\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.2708e-05 - val_loss: 0.0022\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.2248e-05 - val_loss: 0.0024\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.3597e-05 - val_loss: 0.0031\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.3850e-05 - val_loss: 0.0040\n",
            "training:  lstm_cv  df:  43\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/64 [===>..........................] - ETA: 0s - loss: 0.0010    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 8ms/step - loss: 5.6811e-04 - val_loss: 6.9898e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.7238e-04 - val_loss: 7.4758e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.4326e-04 - val_loss: 8.9378e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.4720e-04 - val_loss: 7.9172e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.3341e-04 - val_loss: 8.6989e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.2144e-04 - val_loss: 8.0156e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.3003e-04 - val_loss: 0.0011\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3146e-04 - val_loss: 9.6505e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.3151e-04 - val_loss: 8.8794e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.2071e-04 - val_loss: 7.5258e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1397e-04 - val_loss: 8.3532e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1380e-04 - val_loss: 7.0017e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.3469e-04 - val_loss: 8.6209e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0827e-04 - val_loss: 7.6609e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1406e-04 - val_loss: 8.4967e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1125e-04 - val_loss: 7.1942e-04\n",
            "training:  lstm_cv  df:  44\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 1.8094e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4743e-04 - val_loss: 1.7495e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4496e-04 - val_loss: 1.9216e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4289e-04 - val_loss: 1.7251e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4074e-04 - val_loss: 1.7530e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4396e-04 - val_loss: 1.9226e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4143e-04 - val_loss: 1.9077e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4054e-04 - val_loss: 2.2193e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4106e-04 - val_loss: 1.8094e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4199e-04 - val_loss: 1.6958e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4115e-04 - val_loss: 1.9118e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4470e-04 - val_loss: 1.9247e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3926e-04 - val_loss: 1.8270e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3874e-04 - val_loss: 1.7823e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3891e-04 - val_loss: 1.9720e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4015e-04 - val_loss: 2.4568e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3974e-04 - val_loss: 2.4751e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4103e-04 - val_loss: 2.0789e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3999e-04 - val_loss: 2.9698e-04\n",
            "Epoch 19/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4481e-04 - val_loss: 2.0713e-04\n",
            "Epoch 20/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4147e-04 - val_loss: 1.9714e-04\n",
            "Epoch 21/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4029e-04 - val_loss: 2.6356e-04\n",
            "Epoch 22/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4269e-04 - val_loss: 2.2897e-04\n",
            "Epoch 23/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3928e-04 - val_loss: 2.0900e-04\n",
            "Epoch 24/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4081e-04 - val_loss: 2.2480e-04\n",
            "training:  lstm_cv  df:  45\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/174 [..............................] - ETA: 1s - loss: 8.0503e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3004e-04 - val_loss: 2.3285e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1045e-04 - val_loss: 2.1937e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9415e-04 - val_loss: 2.1511e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0541e-04 - val_loss: 1.8018e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0599e-04 - val_loss: 2.0285e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9313e-04 - val_loss: 2.0196e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9590e-04 - val_loss: 1.8053e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9191e-04 - val_loss: 1.8926e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9452e-04 - val_loss: 1.9155e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0105e-04 - val_loss: 1.9076e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9634e-04 - val_loss: 2.0836e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9102e-04 - val_loss: 2.0351e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8820e-04 - val_loss: 1.8027e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8600e-04 - val_loss: 1.8893e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9083e-04 - val_loss: 2.1236e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9667e-04 - val_loss: 1.8304e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9380e-04 - val_loss: 1.8065e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9362e-04 - val_loss: 1.7909e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9133e-04 - val_loss: 1.8289e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8999e-04 - val_loss: 1.7430e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8710e-04 - val_loss: 1.7556e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8849e-04 - val_loss: 2.0134e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9095e-04 - val_loss: 2.0534e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8676e-04 - val_loss: 1.8241e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9358e-04 - val_loss: 1.8684e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9608e-04 - val_loss: 2.1473e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9032e-04 - val_loss: 2.0556e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8592e-04 - val_loss: 1.9304e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9519e-04 - val_loss: 1.8900e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8232e-04 - val_loss: 1.9070e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8804e-04 - val_loss: 2.1156e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8594e-04 - val_loss: 2.0412e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8835e-04 - val_loss: 1.8107e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8788e-04 - val_loss: 1.9691e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8951e-04 - val_loss: 1.8027e-04\n",
            "training:  lstm_cv  df:  46\n",
            "Training model: lstm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6359e-05 - val_loss: 9.9582e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4141e-05 - val_loss: 1.0694e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3310e-05 - val_loss: 1.0923e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2061e-05 - val_loss: 1.0183e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9102e-05 - val_loss: 1.2153e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0864e-05 - val_loss: 1.0700e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6893e-05 - val_loss: 1.1299e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1864e-05 - val_loss: 1.0137e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9228e-05 - val_loss: 1.1065e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2847e-05 - val_loss: 1.1292e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8883e-05 - val_loss: 1.0846e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.3072e-05 - val_loss: 1.1918e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9869e-05 - val_loss: 1.0318e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.3085e-05 - val_loss: 1.2751e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8442e-05 - val_loss: 1.0698e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7744e-05 - val_loss: 1.1309e-04\n",
            "training:  lstm_cv  df:  47\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.3126e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4931e-04 - val_loss: 2.4905e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3768e-04 - val_loss: 2.3070e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3576e-04 - val_loss: 5.1176e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3624e-04 - val_loss: 2.6813e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2958e-04 - val_loss: 2.2327e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3741e-04 - val_loss: 2.2158e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3140e-04 - val_loss: 2.5894e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3432e-04 - val_loss: 2.0427e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3217e-04 - val_loss: 1.9873e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3139e-04 - val_loss: 1.9246e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3229e-04 - val_loss: 3.1435e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2872e-04 - val_loss: 2.3073e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3179e-04 - val_loss: 2.1247e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3280e-04 - val_loss: 2.3745e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2829e-04 - val_loss: 1.7165e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3115e-04 - val_loss: 2.3466e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3157e-04 - val_loss: 1.8373e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3341e-04 - val_loss: 2.0291e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2825e-04 - val_loss: 2.1565e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3264e-04 - val_loss: 2.1603e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2789e-04 - val_loss: 1.8833e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2847e-04 - val_loss: 2.0579e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2802e-04 - val_loss: 2.1536e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3030e-04 - val_loss: 2.1291e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3041e-04 - val_loss: 1.8716e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2735e-04 - val_loss: 2.0726e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2597e-04 - val_loss: 2.5225e-04\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2900e-04 - val_loss: 1.7623e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2557e-04 - val_loss: 1.8879e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2878e-04 - val_loss: 1.8638e-04\n",
            "training:  lstm_cv  df:  48\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 9.6172e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2612e-04 - val_loss: 8.1573e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2053e-04 - val_loss: 8.1490e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2369e-04 - val_loss: 8.4590e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2633e-04 - val_loss: 7.4433e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2060e-04 - val_loss: 8.1690e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1835e-04 - val_loss: 8.0533e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2225e-04 - val_loss: 7.3754e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2041e-04 - val_loss: 7.6081e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2369e-04 - val_loss: 8.8961e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2221e-04 - val_loss: 9.6404e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2319e-04 - val_loss: 7.4574e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2034e-04 - val_loss: 7.4270e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2103e-04 - val_loss: 7.8564e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2102e-04 - val_loss: 8.5554e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1525e-04 - val_loss: 7.4446e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2098e-04 - val_loss: 7.6391e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1838e-04 - val_loss: 8.1653e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1779e-04 - val_loss: 9.9526e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2507e-04 - val_loss: 1.0247e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1862e-04 - val_loss: 7.4819e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1895e-04 - val_loss: 7.5558e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2139e-04 - val_loss: 1.2160e-04\n",
            "training:  lstm_cv  df:  49\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 1.9322e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 9.7892e-05 - val_loss: 9.3314e-05\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.2591e-05 - val_loss: 9.5243e-05\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.2275e-05 - val_loss: 1.0975e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.4383e-05 - val_loss: 1.0111e-04\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1704e-05 - val_loss: 9.3776e-05\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2695e-05 - val_loss: 9.5318e-05\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1263e-05 - val_loss: 9.5156e-05\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.0351e-05 - val_loss: 9.9120e-05\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9702e-05 - val_loss: 9.6503e-05\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9219e-05 - val_loss: 1.0582e-04\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.7059e-05 - val_loss: 1.0669e-04\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.5345e-05 - val_loss: 9.9948e-05\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.0335e-05 - val_loss: 1.0556e-04\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.1527e-05 - val_loss: 1.0470e-04\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1634e-05 - val_loss: 1.0009e-04\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1888e-05 - val_loss: 1.0182e-04\n",
            "training:  lstm_cv  df:  50\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 8/13 [=================>............] - ETA: 0s - loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9825e-04 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7759e-04 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0023\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5979e-04 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6762e-04 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6878e-04 - val_loss: 0.0019\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9276e-04 - val_loss: 0.0019\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9192e-04 - val_loss: 0.0018\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5489e-04 - val_loss: 0.0018\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "training:  lstm_cv  df:  51\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  8/106 [=>............................] - ETA: 0s - loss: 4.2874e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.6947e-04 - val_loss: 6.7018e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.4146e-04 - val_loss: 6.7244e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3188e-04 - val_loss: 6.6822e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3129e-04 - val_loss: 6.6775e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2994e-04 - val_loss: 6.8859e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3029e-04 - val_loss: 6.8227e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3308e-04 - val_loss: 7.4884e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3488e-04 - val_loss: 6.9043e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2981e-04 - val_loss: 6.9772e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2985e-04 - val_loss: 7.1248e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3039e-04 - val_loss: 7.6579e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3075e-04 - val_loss: 7.3571e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2978e-04 - val_loss: 6.8868e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3053e-04 - val_loss: 6.9744e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2540e-04 - val_loss: 7.1012e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3206e-04 - val_loss: 6.8851e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2823e-04 - val_loss: 7.0681e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2360e-04 - val_loss: 6.6512e-04\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3039e-04 - val_loss: 7.4744e-04\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3184e-04 - val_loss: 6.9438e-04\n",
            "Epoch 21/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3229e-04 - val_loss: 6.8633e-04\n",
            "Epoch 22/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2697e-04 - val_loss: 6.7922e-04\n",
            "Epoch 23/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2277e-04 - val_loss: 6.7793e-04\n",
            "Epoch 24/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2260e-04 - val_loss: 6.8624e-04\n",
            "Epoch 25/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2640e-04 - val_loss: 6.9756e-04\n",
            "Epoch 26/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2844e-04 - val_loss: 7.4461e-04\n",
            "Epoch 27/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3109e-04 - val_loss: 6.7960e-04\n",
            "Epoch 28/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3040e-04 - val_loss: 7.2022e-04\n",
            "Epoch 29/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3546e-04 - val_loss: 6.8717e-04\n",
            "Epoch 30/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1766e-04 - val_loss: 6.9541e-04\n",
            "Epoch 31/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2857e-04 - val_loss: 6.5830e-04\n",
            "Epoch 32/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3465e-04 - val_loss: 6.5270e-04\n",
            "Epoch 33/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2715e-04 - val_loss: 7.0100e-04\n",
            "Epoch 34/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2183e-04 - val_loss: 6.8016e-04\n",
            "Epoch 35/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1561e-04 - val_loss: 6.9380e-04\n",
            "Epoch 36/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2768e-04 - val_loss: 6.9581e-04\n",
            "Epoch 37/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2743e-04 - val_loss: 6.9932e-04\n",
            "Epoch 38/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3814e-04 - val_loss: 7.2001e-04\n",
            "Epoch 39/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2717e-04 - val_loss: 7.0357e-04\n",
            "Epoch 40/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3298e-04 - val_loss: 6.8767e-04\n",
            "Epoch 41/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1928e-04 - val_loss: 8.5248e-04\n",
            "Epoch 42/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2410e-04 - val_loss: 6.8136e-04\n",
            "Epoch 43/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3024e-04 - val_loss: 7.5195e-04\n",
            "Epoch 44/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3295e-04 - val_loss: 7.0994e-04\n",
            "Epoch 45/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2658e-04 - val_loss: 6.7308e-04\n",
            "Epoch 46/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2302e-04 - val_loss: 6.7627e-04\n",
            "Epoch 47/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2519e-04 - val_loss: 7.0865e-04\n",
            "training:  lstm_cv  df:  52\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 7.5173e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 3.1791e-05 - val_loss: 2.7293e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.5248e-05 - val_loss: 2.8716e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.3327e-05 - val_loss: 3.2144e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2711e-05 - val_loss: 3.0961e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1855e-05 - val_loss: 3.2600e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0852e-05 - val_loss: 3.5703e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2408e-05 - val_loss: 3.4447e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1675e-05 - val_loss: 4.2005e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0953e-05 - val_loss: 4.2210e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0836e-05 - val_loss: 4.0577e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1002e-05 - val_loss: 4.8278e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2260e-05 - val_loss: 4.8294e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0246e-05 - val_loss: 4.9556e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9119e-05 - val_loss: 5.0570e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9907e-05 - val_loss: 5.4594e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9624e-05 - val_loss: 6.2220e-04\n",
            "training:  lstm_cv  df:  53\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/79 [==>...........................] - ETA: 0s - loss: 1.9033e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 1.1677e-04 - val_loss: 0.0011\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 1.0037e-04 - val_loss: 0.0011\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.7735e-05 - val_loss: 8.2583e-04\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.8004e-05 - val_loss: 0.0012\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0231e-05 - val_loss: 0.0014\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.6732e-05 - val_loss: 0.0012\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.7940e-05 - val_loss: 0.0010\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.1509e-05 - val_loss: 9.5045e-04\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3551e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3090e-05 - val_loss: 0.0013\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.2334e-05 - val_loss: 0.0012\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2658e-05 - val_loss: 0.0011\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4211e-05 - val_loss: 0.0010\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.3368e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4320e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2634e-05 - val_loss: 0.0012\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3062e-05 - val_loss: 0.0012\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1209e-05 - val_loss: 0.0012\n",
            "training:  lstm_cv  df:  54\n",
            "Training model: lstm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 6.1711e-05 - val_loss: 2.1910e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.8812e-05 - val_loss: 2.4836e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2335e-05 - val_loss: 1.7121e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0915e-05 - val_loss: 3.0957e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8933e-05 - val_loss: 2.8188e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0426e-05 - val_loss: 2.4036e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0186e-05 - val_loss: 1.7668e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0056e-05 - val_loss: 2.8793e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9569e-05 - val_loss: 3.8058e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9811e-05 - val_loss: 2.3676e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8585e-05 - val_loss: 2.6938e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8240e-05 - val_loss: 2.2869e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.6227e-05 - val_loss: 1.5572e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9793e-05 - val_loss: 2.7702e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9791e-05 - val_loss: 1.6723e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7270e-05 - val_loss: 1.5551e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7397e-05 - val_loss: 1.9969e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1136e-05 - val_loss: 1.9094e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8477e-05 - val_loss: 2.3138e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.8816e-05 - val_loss: 2.0318e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7798e-05 - val_loss: 1.7999e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9446e-05 - val_loss: 1.9524e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7799e-05 - val_loss: 1.8910e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9090e-05 - val_loss: 2.5303e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9128e-05 - val_loss: 1.9897e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9019e-05 - val_loss: 2.4169e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7835e-05 - val_loss: 2.8844e-04\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8238e-05 - val_loss: 1.5585e-04\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8632e-05 - val_loss: 2.3232e-04\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8900e-05 - val_loss: 1.9958e-04\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8612e-05 - val_loss: 2.7549e-04\n",
            "build model: lstm_coins_cv  features: 2\n",
            "training:  lstm_coins_cv\n",
            "lstm_coins_cv  should train on everything\n",
            "training dfs: 55\n",
            "training:  lstm_coins_cv  df:  0\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 13ms/step - loss: 0.0048 - val_loss: 0.2924\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 6.4526e-04 - val_loss: 0.2603\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.8880e-04 - val_loss: 0.1583\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.7814e-04 - val_loss: 0.0464\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.3255e-04 - val_loss: 0.0155\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.1811e-04 - val_loss: 0.0131\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.8478e-04 - val_loss: 0.0111\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.6876e-04 - val_loss: 0.0046\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.6850e-04 - val_loss: 0.0049\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.5865e-04 - val_loss: 0.0144\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.2677e-04 - val_loss: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.6624e-04 - val_loss: 0.0149\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.7319e-04 - val_loss: 0.0090\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.0929e-04 - val_loss: 0.0060\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.1421e-04 - val_loss: 0.0091\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.7270e-04 - val_loss: 0.0086\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.3665e-04 - val_loss: 0.0157\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.3880e-04 - val_loss: 0.0089\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.6741e-04 - val_loss: 0.0065\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.2303e-04 - val_loss: 0.0110\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.9204e-04 - val_loss: 0.0185\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.7993e-04 - val_loss: 0.0253\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.8967e-04 - val_loss: 0.0256\n",
            "training:  lstm_coins_cv  df:  1\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/80 [==>...........................] - ETA: 0s - loss: 2.1897e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 8ms/step - loss: 1.1833e-04 - val_loss: 0.0089\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 6.9841e-05 - val_loss: 0.0119\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.4605e-05 - val_loss: 0.0247\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.1200e-04 - val_loss: 0.0248\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 6.4071e-05 - val_loss: 0.0371\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.6951e-05 - val_loss: 0.0597\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.9779e-05 - val_loss: 0.0518\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.5667e-05 - val_loss: 0.0670\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.2741e-05 - val_loss: 0.0825\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.9436e-05 - val_loss: 0.0697\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.0354e-05 - val_loss: 0.0699\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.4241e-05 - val_loss: 0.0881\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.2286e-05 - val_loss: 0.0558\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.5104e-05 - val_loss: 0.0725\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 8.7829e-05 - val_loss: 0.0597\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.7311e-05 - val_loss: 0.1176\n",
            "training:  lstm_coins_cv  df:  2\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 1.9696e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 8ms/step - loss: 2.2063e-05 - val_loss: 0.1018\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2943e-05 - val_loss: 0.1209\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2156e-05 - val_loss: 0.1144\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.3150e-05 - val_loss: 0.1332\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.4423e-05 - val_loss: 0.1357\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2560e-05 - val_loss: 0.1109\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.3188e-05 - val_loss: 0.1233\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.3672e-05 - val_loss: 0.1140\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.3330e-05 - val_loss: 0.1126\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2477e-05 - val_loss: 0.1113\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2370e-05 - val_loss: 0.1192\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.1423e-05 - val_loss: 0.1118\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.2856e-05 - val_loss: 0.1092\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 9.7513e-06 - val_loss: 0.1168\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0439e-05 - val_loss: 0.1168\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.3869e-05 - val_loss: 0.1239\n",
            "training:  lstm_coins_cv  df:  3\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1818e-04 - val_loss: 0.0209\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.6041e-04 - val_loss: 0.0246\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8916e-04 - val_loss: 0.0184\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8026e-04 - val_loss: 0.0195\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5665e-04 - val_loss: 0.0217\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5473e-04 - val_loss: 0.0201\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5116e-04 - val_loss: 0.0185\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3482e-04 - val_loss: 0.0148\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3313e-04 - val_loss: 0.0170\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2104e-04 - val_loss: 0.0241\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3370e-04 - val_loss: 0.0200\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2800e-04 - val_loss: 0.0173\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0276e-04 - val_loss: 0.0144\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1608e-04 - val_loss: 0.0163\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0975e-04 - val_loss: 0.0145\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0954e-04 - val_loss: 0.0160\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0000e-04 - val_loss: 0.0173\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.7419e-05 - val_loss: 0.0139\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0788e-04 - val_loss: 0.0155\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0407e-04 - val_loss: 0.0187\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5459e-05 - val_loss: 0.0156\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3851e-05 - val_loss: 0.0136\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.5313e-05 - val_loss: 0.0145\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2342e-05 - val_loss: 0.0136\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9290e-05 - val_loss: 0.0143\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0483e-04 - val_loss: 0.0152\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4731e-05 - val_loss: 0.0150\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0987e-05 - val_loss: 0.0137\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1906e-05 - val_loss: 0.0160\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4882e-05 - val_loss: 0.0132\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2048e-05 - val_loss: 0.0103\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5468e-05 - val_loss: 0.0147\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4237e-05 - val_loss: 0.0224\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9474e-05 - val_loss: 0.0154\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.1480e-05 - val_loss: 0.0153\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6931e-05 - val_loss: 0.0195\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2761e-05 - val_loss: 0.0164\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.3389e-05 - val_loss: 0.0157\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6700e-05 - val_loss: 0.0149\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3820e-05 - val_loss: 0.0174\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2733e-05 - val_loss: 0.0154\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.7685e-05 - val_loss: 0.0137\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.7426e-05 - val_loss: 0.0124\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.0697e-05 - val_loss: 0.0124\n",
            "Epoch 45/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.9013e-05 - val_loss: 0.0112\n",
            "Epoch 46/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9995e-05 - val_loss: 0.0120\n",
            "training:  lstm_coins_cv  df:  4\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.6663e-04 - val_loss: 1.2725e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.7800e-04 - val_loss: 1.5432e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.8654e-04 - val_loss: 6.9639e-05\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.6059e-04 - val_loss: 7.8145e-05\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5404e-04 - val_loss: 2.5625e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4428e-04 - val_loss: 8.5731e-05\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4958e-04 - val_loss: 8.4505e-05\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4302e-04 - val_loss: 6.5742e-05\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4888e-04 - val_loss: 8.5025e-05\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4017e-04 - val_loss: 7.5090e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3261e-04 - val_loss: 7.3683e-05\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3906e-04 - val_loss: 1.3492e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4158e-04 - val_loss: 2.1426e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4069e-04 - val_loss: 1.2205e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3886e-04 - val_loss: 7.7189e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3635e-04 - val_loss: 6.9641e-05\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2953e-04 - val_loss: 9.5481e-05\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3601e-04 - val_loss: 5.9792e-05\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4346e-04 - val_loss: 8.9650e-05\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3609e-04 - val_loss: 2.4221e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4294e-04 - val_loss: 8.2186e-05\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3556e-04 - val_loss: 5.5793e-05\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3224e-04 - val_loss: 6.9436e-05\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3376e-04 - val_loss: 1.0712e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2546e-04 - val_loss: 1.1774e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3588e-04 - val_loss: 9.2372e-05\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3349e-04 - val_loss: 7.4063e-05\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2624e-04 - val_loss: 2.2858e-04\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2441e-04 - val_loss: 9.7114e-05\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2859e-04 - val_loss: 7.5021e-05\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2867e-04 - val_loss: 1.1179e-04\n",
            "Epoch 32/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3169e-04 - val_loss: 6.2739e-05\n",
            "Epoch 33/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2806e-04 - val_loss: 9.0128e-05\n",
            "Epoch 34/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2554e-04 - val_loss: 1.1259e-04\n",
            "Epoch 35/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1938e-04 - val_loss: 1.0434e-04\n",
            "Epoch 36/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2148e-04 - val_loss: 1.1341e-04\n",
            "Epoch 37/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.1558e-04 - val_loss: 7.8383e-05\n",
            "training:  lstm_coins_cv  df:  5\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3190e-05 - val_loss: 0.0031\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.7268e-05 - val_loss: 0.0034\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5400e-05 - val_loss: 0.0031\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2502e-05 - val_loss: 0.0026\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1597e-05 - val_loss: 0.0025\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1409e-05 - val_loss: 0.0026\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0305e-05 - val_loss: 0.0025\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9672e-05 - val_loss: 0.0024\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1616e-05 - val_loss: 0.0030\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0795e-05 - val_loss: 0.0032\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2010e-05 - val_loss: 0.0026\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9800e-05 - val_loss: 0.0031\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1460e-05 - val_loss: 0.0033\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9091e-05 - val_loss: 0.0036\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8368e-05 - val_loss: 0.0036\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8604e-05 - val_loss: 0.0047\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8179e-05 - val_loss: 0.0043\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8066e-05 - val_loss: 0.0045\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7059e-05 - val_loss: 0.0051\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8214e-05 - val_loss: 0.0060\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7971e-05 - val_loss: 0.0068\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6386e-05 - val_loss: 0.0075\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7214e-05 - val_loss: 0.0082\n",
            "training:  lstm_coins_cv  df:  6\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 7ms/step - loss: 5.0682e-04 - val_loss: 1.5659e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.8554e-04 - val_loss: 1.4102e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.7962e-04 - val_loss: 1.3085e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.7338e-04 - val_loss: 1.2501e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.6556e-04 - val_loss: 1.1694e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.6072e-04 - val_loss: 1.1093e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.6065e-04 - val_loss: 1.3917e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4760e-04 - val_loss: 1.1042e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4964e-04 - val_loss: 1.0506e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5641e-04 - val_loss: 1.5190e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5568e-04 - val_loss: 1.9322e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4418e-04 - val_loss: 1.3083e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4339e-04 - val_loss: 1.1877e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5602e-04 - val_loss: 1.9238e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4138e-04 - val_loss: 1.4790e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5803e-04 - val_loss: 1.0156e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4880e-04 - val_loss: 1.1336e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3913e-04 - val_loss: 1.4206e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4606e-04 - val_loss: 1.5255e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4510e-04 - val_loss: 1.1336e-04\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4486e-04 - val_loss: 1.3576e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3760e-04 - val_loss: 1.3104e-04\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3547e-04 - val_loss: 1.4432e-04\n",
            "Epoch 24/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4046e-04 - val_loss: 1.2628e-04\n",
            "Epoch 25/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4333e-04 - val_loss: 1.2939e-04\n",
            "Epoch 26/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3957e-04 - val_loss: 1.1877e-04\n",
            "Epoch 27/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4302e-04 - val_loss: 1.1565e-04\n",
            "Epoch 28/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4076e-04 - val_loss: 1.2517e-04\n",
            "Epoch 29/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3759e-04 - val_loss: 1.4836e-04\n",
            "Epoch 30/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3808e-04 - val_loss: 9.6774e-05\n",
            "Epoch 31/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5249e-04 - val_loss: 1.1085e-04\n",
            "Epoch 32/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3981e-04 - val_loss: 1.1359e-04\n",
            "Epoch 33/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3931e-04 - val_loss: 1.9382e-04\n",
            "Epoch 34/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3146e-04 - val_loss: 1.2760e-04\n",
            "Epoch 35/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3530e-04 - val_loss: 2.1165e-04\n",
            "Epoch 36/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3442e-04 - val_loss: 1.1699e-04\n",
            "Epoch 37/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3672e-04 - val_loss: 1.3604e-04\n",
            "Epoch 38/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3195e-04 - val_loss: 1.5675e-04\n",
            "Epoch 39/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3566e-04 - val_loss: 1.1388e-04\n",
            "Epoch 40/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3840e-04 - val_loss: 1.1213e-04\n",
            "Epoch 41/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3878e-04 - val_loss: 1.3743e-04\n",
            "Epoch 42/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3628e-04 - val_loss: 1.2860e-04\n",
            "Epoch 43/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3373e-04 - val_loss: 1.1945e-04\n",
            "Epoch 44/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3448e-04 - val_loss: 1.5377e-04\n",
            "Epoch 45/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3655e-04 - val_loss: 1.3027e-04\n",
            "training:  lstm_coins_cv  df:  7\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 1.5619e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 6.8815e-05 - val_loss: 3.8656e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.8622e-05 - val_loss: 5.6787e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.5742e-05 - val_loss: 4.6355e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.8555e-05 - val_loss: 5.5171e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.5292e-05 - val_loss: 6.0468e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.1361e-05 - val_loss: 6.0042e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.0336e-05 - val_loss: 4.3350e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.4989e-05 - val_loss: 8.8585e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.9555e-05 - val_loss: 7.8255e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.1456e-05 - val_loss: 6.5958e-04\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.7273e-05 - val_loss: 5.9354e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.8074e-05 - val_loss: 9.0103e-04\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.8923e-05 - val_loss: 9.9861e-04\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.0941e-05 - val_loss: 8.7683e-04\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.7359e-05 - val_loss: 0.0010\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.8155e-05 - val_loss: 9.9282e-04\n",
            "training:  lstm_coins_cv  df:  8\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/68 [==>...........................] - ETA: 0s - loss: 1.3895e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 2.2255e-04 - val_loss: 0.0028\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.8989e-04 - val_loss: 0.0063\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.8656e-04 - val_loss: 0.0059\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4424e-04 - val_loss: 0.0047\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2088e-04 - val_loss: 0.0047\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3298e-04 - val_loss: 0.0041\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3294e-04 - val_loss: 0.0053\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2611e-04 - val_loss: 0.0053\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1420e-04 - val_loss: 0.0044\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1817e-04 - val_loss: 0.0032\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2396e-04 - val_loss: 0.0042\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1483e-04 - val_loss: 0.0046\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1239e-04 - val_loss: 0.0048\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1336e-04 - val_loss: 0.0049\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0818e-04 - val_loss: 0.0047\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1655e-04 - val_loss: 0.0045\n",
            "training:  lstm_coins_cv  df:  9\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/162 [..............................] - ETA: 1s - loss: 3.5631e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 5.7583e-05 - val_loss: 0.0024\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.7033e-05 - val_loss: 0.0025\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.2815e-05 - val_loss: 0.0028\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.0191e-05 - val_loss: 0.0029\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8308e-05 - val_loss: 0.0032\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.0337e-05 - val_loss: 0.0035\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.7007e-05 - val_loss: 0.0037\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6451e-05 - val_loss: 0.0040\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6551e-05 - val_loss: 0.0042\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6266e-05 - val_loss: 0.0043\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.7693e-05 - val_loss: 0.0045\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8676e-05 - val_loss: 0.0050\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.5845e-05 - val_loss: 0.0050\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.5552e-05 - val_loss: 0.0050\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.4591e-05 - val_loss: 0.0052\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.5116e-05 - val_loss: 0.0057\n",
            "training:  lstm_coins_cv  df:  10\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.3418e-05 - val_loss: 0.0010\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5114e-05 - val_loss: 9.5005e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3721e-05 - val_loss: 8.0996e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2030e-05 - val_loss: 7.5360e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5432e-05 - val_loss: 8.9347e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7159e-05 - val_loss: 8.8739e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6698e-05 - val_loss: 7.3761e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6397e-05 - val_loss: 9.0351e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0390e-05 - val_loss: 7.7270e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.2075e-05 - val_loss: 8.8429e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6317e-05 - val_loss: 7.4451e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2773e-05 - val_loss: 7.6687e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4791e-05 - val_loss: 8.0687e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1620e-05 - val_loss: 6.5243e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7509e-05 - val_loss: 7.8952e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.4308e-05 - val_loss: 9.8601e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5108e-05 - val_loss: 8.7174e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3248e-05 - val_loss: 7.5181e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5131e-05 - val_loss: 0.0010\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3690e-05 - val_loss: 8.8258e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5985e-05 - val_loss: 9.2090e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.9780e-05 - val_loss: 5.6474e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7481e-05 - val_loss: 0.0013\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7426e-05 - val_loss: 7.6742e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.2091e-05 - val_loss: 5.5604e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.0068e-05 - val_loss: 7.4347e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3558e-05 - val_loss: 0.0014\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.0800e-05 - val_loss: 6.8093e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5454e-05 - val_loss: 5.4722e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.1584e-05 - val_loss: 7.7346e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7228e-05 - val_loss: 9.8230e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.9799e-05 - val_loss: 6.1305e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.8890e-05 - val_loss: 7.4571e-04\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6323e-05 - val_loss: 8.9421e-04\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9643e-05 - val_loss: 9.8496e-04\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8946e-05 - val_loss: 8.1090e-04\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.8980e-05 - val_loss: 5.9629e-04\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.2383e-05 - val_loss: 5.5934e-04\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.2877e-05 - val_loss: 7.6818e-04\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.9285e-05 - val_loss: 7.8104e-04\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.1077e-05 - val_loss: 5.6312e-04\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9852e-05 - val_loss: 7.3081e-04\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3525e-05 - val_loss: 0.0010\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.2072e-05 - val_loss: 9.9235e-04\n",
            "training:  lstm_coins_cv  df:  11\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2891e-04 - val_loss: 1.1198e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9010e-05 - val_loss: 2.6724e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9131e-05 - val_loss: 1.2221e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.4994e-05 - val_loss: 7.1185e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5431e-05 - val_loss: 1.9824e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1698e-05 - val_loss: 3.1312e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0495e-04 - val_loss: 7.2905e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0597e-05 - val_loss: 8.3340e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2411e-05 - val_loss: 7.6741e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0528e-05 - val_loss: 9.0305e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7818e-05 - val_loss: 1.1456e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0801e-05 - val_loss: 1.0939e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9160e-05 - val_loss: 8.6193e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5261e-05 - val_loss: 9.6487e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.5876e-05 - val_loss: 7.6067e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0641e-05 - val_loss: 7.7649e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9808e-05 - val_loss: 1.5325e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2271e-05 - val_loss: 1.1275e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3833e-05 - val_loss: 7.5633e-05\n",
            "training:  lstm_coins_cv  df:  12\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0027\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7783e-04 - val_loss: 0.0018\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9400e-04 - val_loss: 0.0018\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.2786e-04 - val_loss: 0.0020\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9236e-04 - val_loss: 0.0018\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.4316e-04 - val_loss: 0.0017\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.4397e-04 - val_loss: 0.0017\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.4340e-04 - val_loss: 0.0017\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6910e-04 - val_loss: 0.0018\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "training:  lstm_coins_cv  df:  13\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/132 [=>............................] - ETA: 0s - loss: 2.1120e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 8ms/step - loss: 6.0082e-05 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.8543e-05 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.8629e-05 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.3913e-05 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.2525e-05 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.2399e-05 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.1096e-05 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.1667e-05 - val_loss: 0.0017\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9460e-05 - val_loss: 0.0017\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.0385e-05 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8990e-05 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7739e-05 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7653e-05 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8502e-05 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8050e-05 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7258e-05 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8241e-05 - val_loss: 0.0016\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7618e-05 - val_loss: 0.0016\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8094e-05 - val_loss: 0.0016\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6043e-05 - val_loss: 0.0016\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6172e-05 - val_loss: 0.0016\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6842e-05 - val_loss: 0.0016\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6203e-05 - val_loss: 0.0016\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6226e-05 - val_loss: 0.0016\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5818e-05 - val_loss: 0.0016\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5726e-05 - val_loss: 0.0016\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5378e-05 - val_loss: 0.0016\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.6096e-05 - val_loss: 0.0016\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5928e-05 - val_loss: 0.0015\n",
            "Epoch 30/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5725e-05 - val_loss: 0.0016\n",
            "Epoch 31/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5143e-05 - val_loss: 0.0015\n",
            "Epoch 32/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5937e-05 - val_loss: 0.0015\n",
            "Epoch 33/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5244e-05 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.4628e-05 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4464e-05 - val_loss: 0.0014\n",
            "Epoch 36/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4191e-05 - val_loss: 0.0014\n",
            "Epoch 37/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4560e-05 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4327e-05 - val_loss: 0.0015\n",
            "Epoch 39/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5545e-05 - val_loss: 0.0014\n",
            "Epoch 40/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5865e-05 - val_loss: 0.0014\n",
            "Epoch 41/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3055e-05 - val_loss: 0.0014\n",
            "Epoch 42/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3167e-05 - val_loss: 0.0014\n",
            "Epoch 43/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.3545e-05 - val_loss: 0.0014\n",
            "Epoch 44/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4990e-05 - val_loss: 0.0014\n",
            "Epoch 45/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4418e-05 - val_loss: 0.0014\n",
            "Epoch 46/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4283e-05 - val_loss: 0.0014\n",
            "Epoch 47/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3380e-05 - val_loss: 0.0014\n",
            "Epoch 48/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.3983e-05 - val_loss: 0.0014\n",
            "Epoch 49/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2748e-05 - val_loss: 0.0014\n",
            "Epoch 50/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.4290e-05 - val_loss: 0.0013\n",
            "Epoch 51/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.4326e-05 - val_loss: 0.0015\n",
            "Epoch 52/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3652e-05 - val_loss: 0.0014\n",
            "Epoch 53/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2765e-05 - val_loss: 0.0015\n",
            "Epoch 54/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.3723e-05 - val_loss: 0.0014\n",
            "Epoch 55/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3280e-05 - val_loss: 0.0015\n",
            "Epoch 56/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2106e-05 - val_loss: 0.0017\n",
            "Epoch 57/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3545e-05 - val_loss: 0.0015\n",
            "Epoch 58/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1699e-05 - val_loss: 0.0015\n",
            "Epoch 59/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1472e-05 - val_loss: 0.0014\n",
            "Epoch 60/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2091e-05 - val_loss: 0.0016\n",
            "Epoch 61/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.3636e-05 - val_loss: 0.0015\n",
            "Epoch 62/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2161e-05 - val_loss: 0.0015\n",
            "Epoch 63/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1901e-05 - val_loss: 0.0019\n",
            "Epoch 64/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1500e-05 - val_loss: 0.0013\n",
            "Epoch 65/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1408e-05 - val_loss: 0.0013\n",
            "Epoch 66/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1496e-05 - val_loss: 0.0015\n",
            "Epoch 67/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1581e-05 - val_loss: 0.0013\n",
            "Epoch 68/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2663e-05 - val_loss: 0.0014\n",
            "Epoch 69/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1542e-05 - val_loss: 0.0016\n",
            "Epoch 70/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2654e-05 - val_loss: 0.0014\n",
            "Epoch 71/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2211e-05 - val_loss: 0.0016\n",
            "Epoch 72/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1008e-05 - val_loss: 0.0013\n",
            "Epoch 73/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1519e-05 - val_loss: 0.0014\n",
            "Epoch 74/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1116e-05 - val_loss: 0.0015\n",
            "Epoch 75/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1349e-05 - val_loss: 0.0014\n",
            "Epoch 76/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1521e-05 - val_loss: 0.0014\n",
            "Epoch 77/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.0477e-05 - val_loss: 0.0033\n",
            "Epoch 78/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1287e-05 - val_loss: 0.0036\n",
            "Epoch 79/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1767e-05 - val_loss: 0.0029\n",
            "training:  lstm_coins_cv  df:  14\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/26 [=========>....................] - ETA: 0s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 9ms/step - loss: 9.1843e-04 - val_loss: 8.6431e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6293e-04 - val_loss: 2.3435e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.4606e-04 - val_loss: 3.9799e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.4343e-04 - val_loss: 2.7339e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6919e-04 - val_loss: 2.0825e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6825e-04 - val_loss: 2.1290e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3592e-04 - val_loss: 2.1273e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6804e-04 - val_loss: 2.9010e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 5.1892e-04 - val_loss: 2.6988e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1200e-04 - val_loss: 2.5914e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.4512e-04 - val_loss: 2.0465e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0334e-04 - val_loss: 2.2887e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6629e-04 - val_loss: 2.2438e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6175e-04 - val_loss: 2.2822e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9096e-04 - val_loss: 3.2076e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.4902e-04 - val_loss: 3.1725e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.5495e-04 - val_loss: 4.3708e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.9985e-04 - val_loss: 5.2818e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.2414e-04 - val_loss: 2.2999e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7355e-04 - val_loss: 3.0039e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9522e-04 - val_loss: 2.3053e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7179e-04 - val_loss: 2.2955e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6110e-04 - val_loss: 2.2769e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6401e-04 - val_loss: 2.2105e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.4673e-04 - val_loss: 2.3530e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9696e-04 - val_loss: 2.8108e-04\n",
            "training:  lstm_coins_cv  df:  15\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5931e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1719e-05 - val_loss: 0.0012\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1098e-05 - val_loss: 0.0011\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0586e-05 - val_loss: 0.0011\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0193e-05 - val_loss: 0.0010\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9123e-06 - val_loss: 9.8735e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.6958e-06 - val_loss: 0.0010\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5313e-06 - val_loss: 9.2807e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.8855e-06 - val_loss: 0.0010\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9596e-06 - val_loss: 8.5397e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6764e-06 - val_loss: 0.0011\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8538e-06 - val_loss: 8.7888e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.4165e-06 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2274e-06 - val_loss: 0.0012\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4783e-06 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.5656e-06 - val_loss: 0.0015\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.2689e-06 - val_loss: 0.0017\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.0695e-06 - val_loss: 0.0021\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.3489e-06 - val_loss: 0.0017\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4437e-06 - val_loss: 0.0019\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.9377e-06 - val_loss: 0.0022\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.0821e-06 - val_loss: 0.0019\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.1464e-06 - val_loss: 0.0020\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9053e-06 - val_loss: 0.0022\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0945e-06 - val_loss: 0.0027\n",
            "training:  lstm_coins_cv  df:  16\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.3599e-05 - val_loss: 0.0157\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2823e-05 - val_loss: 0.0181\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1335e-05 - val_loss: 0.0155\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0191e-05 - val_loss: 0.0154\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9539e-05 - val_loss: 0.0166\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8428e-05 - val_loss: 0.0130\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8208e-05 - val_loss: 0.0156\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9257e-05 - val_loss: 0.0155\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7326e-05 - val_loss: 0.0170\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7510e-05 - val_loss: 0.0153\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7165e-05 - val_loss: 0.0175\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7824e-05 - val_loss: 0.0192\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8300e-05 - val_loss: 0.0189\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7180e-05 - val_loss: 0.0203\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7656e-05 - val_loss: 0.0212\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6914e-05 - val_loss: 0.0206\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6928e-05 - val_loss: 0.0202\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5813e-05 - val_loss: 0.0222\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8087e-05 - val_loss: 0.0249\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6952e-05 - val_loss: 0.0216\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7057e-05 - val_loss: 0.0246\n",
            "training:  lstm_coins_cv  df:  17\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 1.0672e-05 - val_loss: 0.0219\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 9.2629e-06 - val_loss: 0.0243\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 9.2550e-06 - val_loss: 0.0222\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.2854e-06 - val_loss: 0.0235\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.3953e-06 - val_loss: 0.0239\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.6063e-06 - val_loss: 0.0261\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.7862e-06 - val_loss: 0.0297\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.4059e-06 - val_loss: 0.0337\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.9995e-06 - val_loss: 0.0360\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.2641e-06 - val_loss: 0.0347\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.0525e-06 - val_loss: 0.0382\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.7905e-06 - val_loss: 0.0430\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.4569e-06 - val_loss: 0.0434\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.7631e-06 - val_loss: 0.0346\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.3672e-06 - val_loss: 0.0507\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.3781e-06 - val_loss: 0.0520\n",
            "training:  lstm_coins_cv  df:  18\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/174 [..............................] - ETA: 1s - loss: 0.0280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 2.6608e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.6432e-04 - val_loss: 2.0228e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.4833e-04 - val_loss: 1.8906e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.4459e-04 - val_loss: 2.2423e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2707e-04 - val_loss: 2.0631e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2906e-04 - val_loss: 1.8849e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2295e-04 - val_loss: 1.9997e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2395e-04 - val_loss: 1.7931e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2393e-04 - val_loss: 1.8875e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1794e-04 - val_loss: 2.0674e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1688e-04 - val_loss: 1.8410e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2223e-04 - val_loss: 1.9151e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2695e-04 - val_loss: 1.8516e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2096e-04 - val_loss: 1.8350e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1624e-04 - val_loss: 1.8344e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1606e-04 - val_loss: 2.0339e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1107e-04 - val_loss: 1.7969e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1031e-04 - val_loss: 2.0167e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1898e-04 - val_loss: 1.9743e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1822e-04 - val_loss: 1.8406e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2338e-04 - val_loss: 1.9328e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1748e-04 - val_loss: 1.8424e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0680e-04 - val_loss: 1.8249e-04\n",
            "training:  lstm_coins_cv  df:  19\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/47 [====>.........................] - ETA: 0s - loss: 2.3801e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9892e-04 - val_loss: 1.7773e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8044e-04 - val_loss: 1.7401e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0219e-04 - val_loss: 1.7538e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8911e-04 - val_loss: 1.8354e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8863e-04 - val_loss: 1.8712e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8353e-04 - val_loss: 1.7478e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9326e-04 - val_loss: 1.7008e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9345e-04 - val_loss: 1.7129e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8174e-04 - val_loss: 1.9582e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8704e-04 - val_loss: 1.7484e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7951e-04 - val_loss: 2.0296e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8378e-04 - val_loss: 1.7058e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8743e-04 - val_loss: 1.7876e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9435e-04 - val_loss: 1.8432e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9343e-04 - val_loss: 2.1454e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9168e-04 - val_loss: 1.7938e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9175e-04 - val_loss: 1.9211e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.2902e-04 - val_loss: 1.7452e-04\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9086e-04 - val_loss: 2.3571e-04\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9180e-04 - val_loss: 2.2388e-04\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8245e-04 - val_loss: 1.8247e-04\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8993e-04 - val_loss: 1.7239e-04\n",
            "training:  lstm_coins_cv  df:  20\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/151 [>.............................] - ETA: 0s - loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 9.4965e-05 - val_loss: 0.0013\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.6150e-05 - val_loss: 0.0013\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.2012e-05 - val_loss: 0.0012\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.0739e-05 - val_loss: 0.0012\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.0172e-05 - val_loss: 0.0012\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.8868e-06 - val_loss: 0.0012\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.6235e-06 - val_loss: 0.0012\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 8.0038e-06 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 8.4627e-06 - val_loss: 0.0012\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 8.4654e-06 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.1536e-06 - val_loss: 0.0012\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.4195e-06 - val_loss: 0.0012\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.8693e-06 - val_loss: 0.0013\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.0586e-06 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.9522e-06 - val_loss: 0.0013\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.8992e-06 - val_loss: 0.0014\n",
            "Epoch 17/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.8128e-06 - val_loss: 0.0014\n",
            "Epoch 18/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.8174e-06 - val_loss: 0.0014\n",
            "Epoch 19/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.7018e-06 - val_loss: 0.0014\n",
            "training:  lstm_coins_cv  df:  21\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.1614e-05 - val_loss: 1.8832e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.6582e-05 - val_loss: 3.3407e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.4454e-05 - val_loss: 3.4243e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.3247e-05 - val_loss: 1.6877e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.1499e-05 - val_loss: 1.3363e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.8873e-05 - val_loss: 3.7426e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.7055e-05 - val_loss: 1.7145e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.1556e-05 - val_loss: 2.3162e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9916e-05 - val_loss: 1.3002e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8780e-05 - val_loss: 1.6131e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.9155e-05 - val_loss: 1.4525e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.1880e-05 - val_loss: 2.9372e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.0068e-05 - val_loss: 1.6857e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8539e-05 - val_loss: 1.8657e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.6261e-05 - val_loss: 2.1116e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8811e-05 - val_loss: 1.9877e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8690e-05 - val_loss: 3.1876e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.8843e-05 - val_loss: 2.6308e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8871e-05 - val_loss: 2.9076e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8406e-05 - val_loss: 3.5670e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.6631e-05 - val_loss: 4.6640e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.6929e-05 - val_loss: 2.4941e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.6521e-05 - val_loss: 1.8204e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.6615e-05 - val_loss: 3.2137e-04\n",
            "training:  lstm_coins_cv  df:  22\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 2s 8ms/step - loss: 2.9829e-05 - val_loss: 0.0015\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.8737e-05 - val_loss: 0.0015\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5655e-05 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.8026e-05 - val_loss: 0.0024\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5337e-05 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5220e-05 - val_loss: 0.0021\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5118e-05 - val_loss: 0.0025\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4227e-05 - val_loss: 0.0030\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5853e-05 - val_loss: 0.0029\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4898e-05 - val_loss: 0.0032\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5076e-05 - val_loss: 0.0040\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4715e-05 - val_loss: 0.0048\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.3496e-05 - val_loss: 0.0053\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.2712e-05 - val_loss: 0.0067\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.2892e-05 - val_loss: 0.0078\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.3170e-05 - val_loss: 0.0066\n",
            "training:  lstm_coins_cv  df:  23\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 8.8301e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 7ms/step - loss: 2.3497e-04 - val_loss: 1.0257e-05\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.8172e-04 - val_loss: 6.1690e-06\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6789e-04 - val_loss: 8.0149e-06\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6126e-04 - val_loss: 6.9924e-06\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4670e-04 - val_loss: 6.4433e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5694e-04 - val_loss: 9.8912e-06\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5482e-04 - val_loss: 1.7641e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5816e-04 - val_loss: 2.2373e-05\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5132e-04 - val_loss: 5.4801e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5803e-04 - val_loss: 9.9965e-06\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4693e-04 - val_loss: 1.2185e-05\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5075e-04 - val_loss: 8.8202e-06\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5713e-04 - val_loss: 5.6871e-06\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4825e-04 - val_loss: 5.8368e-06\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5474e-04 - val_loss: 1.0902e-05\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5854e-04 - val_loss: 6.6949e-06\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5141e-04 - val_loss: 1.0306e-05\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5112e-04 - val_loss: 7.4806e-06\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4274e-04 - val_loss: 6.4202e-06\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4657e-04 - val_loss: 1.0741e-05\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5063e-04 - val_loss: 1.3910e-05\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4694e-04 - val_loss: 1.8650e-05\n",
            "Epoch 23/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4983e-04 - val_loss: 1.0382e-05\n",
            "Epoch 24/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5359e-04 - val_loss: 7.1225e-06\n",
            "training:  lstm_coins_cv  df:  24\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 3.1630e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 7ms/step - loss: 1.7538e-04 - val_loss: 8.2829e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4777e-04 - val_loss: 8.3025e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4527e-04 - val_loss: 8.2238e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3757e-04 - val_loss: 7.9668e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4006e-04 - val_loss: 1.2928e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4046e-04 - val_loss: 7.8030e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3640e-04 - val_loss: 9.0117e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3814e-04 - val_loss: 7.6561e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3904e-04 - val_loss: 9.1679e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3163e-04 - val_loss: 7.4440e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3689e-04 - val_loss: 1.1260e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3960e-04 - val_loss: 9.8540e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3377e-04 - val_loss: 8.7884e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3679e-04 - val_loss: 9.0608e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3598e-04 - val_loss: 7.3737e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3299e-04 - val_loss: 1.0686e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3955e-04 - val_loss: 1.0541e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3602e-04 - val_loss: 7.3061e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2982e-04 - val_loss: 8.5743e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4302e-04 - val_loss: 7.8042e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3061e-04 - val_loss: 7.4315e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3664e-04 - val_loss: 8.4407e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3499e-04 - val_loss: 9.1983e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2884e-04 - val_loss: 7.6126e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2963e-04 - val_loss: 8.7189e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3762e-04 - val_loss: 7.7162e-05\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3090e-04 - val_loss: 7.7363e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3565e-04 - val_loss: 8.3847e-05\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3924e-04 - val_loss: 1.2520e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3564e-04 - val_loss: 7.6879e-05\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2965e-04 - val_loss: 1.2048e-04\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3737e-04 - val_loss: 7.6226e-05\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3652e-04 - val_loss: 9.8130e-05\n",
            "training:  lstm_coins_cv  df:  25\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/53 [====>.........................] - ETA: 0s - loss: 2.6936e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6004e-04 - val_loss: 3.1616e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6773e-04 - val_loss: 3.1112e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5511e-04 - val_loss: 3.2165e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.4584e-04 - val_loss: 3.3523e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5502e-04 - val_loss: 3.0964e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.6004e-04 - val_loss: 3.3447e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6512e-04 - val_loss: 3.3115e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6011e-04 - val_loss: 3.0749e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.7710e-04 - val_loss: 3.1728e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.5402e-04 - val_loss: 3.1818e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.4341e-04 - val_loss: 3.3249e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.5744e-04 - val_loss: 3.1006e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.4940e-04 - val_loss: 3.0734e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.4951e-04 - val_loss: 3.0539e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3909e-04 - val_loss: 3.2504e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4664e-04 - val_loss: 3.3417e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4769e-04 - val_loss: 3.1413e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.5041e-04 - val_loss: 3.2575e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4510e-04 - val_loss: 3.0888e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5053e-04 - val_loss: 3.1755e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4985e-04 - val_loss: 3.3689e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4418e-04 - val_loss: 3.1960e-04\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.4552e-04 - val_loss: 3.1049e-04\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4074e-04 - val_loss: 3.3345e-04\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4845e-04 - val_loss: 3.0526e-04\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4090e-04 - val_loss: 3.3200e-04\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4064e-04 - val_loss: 2.9997e-04\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3994e-04 - val_loss: 3.2814e-04\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.5583e-04 - val_loss: 3.0418e-04\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5545e-04 - val_loss: 3.1020e-04\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.4510e-04 - val_loss: 3.0922e-04\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6042e-04 - val_loss: 3.0278e-04\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3813e-04 - val_loss: 3.3046e-04\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4648e-04 - val_loss: 3.0843e-04\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4919e-04 - val_loss: 3.1050e-04\n",
            "Epoch 36/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4930e-04 - val_loss: 3.0251e-04\n",
            "Epoch 37/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4104e-04 - val_loss: 3.1960e-04\n",
            "Epoch 38/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4417e-04 - val_loss: 3.0845e-04\n",
            "Epoch 39/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.5293e-04 - val_loss: 3.2151e-04\n",
            "Epoch 40/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3803e-04 - val_loss: 3.5479e-04\n",
            "Epoch 41/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3671e-04 - val_loss: 2.9818e-04\n",
            "Epoch 42/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3575e-04 - val_loss: 3.2021e-04\n",
            "Epoch 43/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4799e-04 - val_loss: 3.1238e-04\n",
            "Epoch 44/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3153e-04 - val_loss: 3.0765e-04\n",
            "Epoch 45/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3872e-04 - val_loss: 3.0256e-04\n",
            "Epoch 46/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3691e-04 - val_loss: 3.4628e-04\n",
            "Epoch 47/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4634e-04 - val_loss: 3.1990e-04\n",
            "Epoch 48/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3942e-04 - val_loss: 3.3911e-04\n",
            "Epoch 49/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4187e-04 - val_loss: 3.0641e-04\n",
            "Epoch 50/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5086e-04 - val_loss: 3.1158e-04\n",
            "Epoch 51/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3804e-04 - val_loss: 3.1527e-04\n",
            "Epoch 52/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4220e-04 - val_loss: 3.1691e-04\n",
            "Epoch 53/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3717e-04 - val_loss: 3.1091e-04\n",
            "Epoch 54/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3450e-04 - val_loss: 3.3789e-04\n",
            "Epoch 55/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3353e-04 - val_loss: 3.0773e-04\n",
            "Epoch 56/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3771e-04 - val_loss: 3.1469e-04\n",
            "training:  lstm_coins_cv  df:  26\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/58 [===>..........................] - ETA: 0s - loss: 1.7365e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7303e-04 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6273e-04 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5704e-04 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4388e-04 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4885e-04 - val_loss: 0.0016\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4758e-04 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4610e-04 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4346e-04 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3953e-04 - val_loss: 0.0016\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4496e-04 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3964e-04 - val_loss: 0.0016\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3260e-04 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3868e-04 - val_loss: 0.0016\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2857e-04 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3108e-04 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3277e-04 - val_loss: 0.0016\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3003e-04 - val_loss: 0.0015\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3413e-04 - val_loss: 0.0016\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3084e-04 - val_loss: 0.0016\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2611e-04 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3003e-04 - val_loss: 0.0015\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2886e-04 - val_loss: 0.0016\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2738e-04 - val_loss: 0.0016\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2076e-04 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2249e-04 - val_loss: 0.0016\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3782e-04 - val_loss: 0.0015\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2496e-04 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2793e-04 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2813e-04 - val_loss: 0.0016\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2846e-04 - val_loss: 0.0015\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3176e-04 - val_loss: 0.0016\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1945e-04 - val_loss: 0.0015\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2859e-04 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2800e-04 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2101e-04 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2772e-04 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2297e-04 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2834e-04 - val_loss: 0.0015\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2961e-04 - val_loss: 0.0016\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2445e-04 - val_loss: 0.0016\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2261e-04 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2079e-04 - val_loss: 0.0015\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1943e-04 - val_loss: 0.0015\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2532e-04 - val_loss: 0.0015\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1820e-04 - val_loss: 0.0015\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1999e-04 - val_loss: 0.0015\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2051e-04 - val_loss: 0.0015\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1768e-04 - val_loss: 0.0015\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2309e-04 - val_loss: 0.0015\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2722e-04 - val_loss: 0.0015\n",
            "Epoch 51/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3693e-04 - val_loss: 0.0015\n",
            "Epoch 52/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2094e-04 - val_loss: 0.0015\n",
            "Epoch 53/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1983e-04 - val_loss: 0.0015\n",
            "Epoch 54/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3110e-04 - val_loss: 0.0015\n",
            "Epoch 55/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2267e-04 - val_loss: 0.0015\n",
            "Epoch 56/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1988e-04 - val_loss: 0.0015\n",
            "Epoch 57/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2246e-04 - val_loss: 0.0015\n",
            "Epoch 58/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2214e-04 - val_loss: 0.0015\n",
            "Epoch 59/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2591e-04 - val_loss: 0.0015\n",
            "Epoch 60/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2283e-04 - val_loss: 0.0015\n",
            "Epoch 61/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2498e-04 - val_loss: 0.0015\n",
            "Epoch 62/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2531e-04 - val_loss: 0.0015\n",
            "Epoch 63/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1972e-04 - val_loss: 0.0016\n",
            "Epoch 64/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1716e-04 - val_loss: 0.0015\n",
            "Epoch 65/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1591e-04 - val_loss: 0.0015\n",
            "Epoch 66/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1245e-04 - val_loss: 0.0015\n",
            "Epoch 67/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2651e-04 - val_loss: 0.0015\n",
            "Epoch 68/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1396e-04 - val_loss: 0.0015\n",
            "Epoch 69/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2428e-04 - val_loss: 0.0015\n",
            "Epoch 70/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2179e-04 - val_loss: 0.0016\n",
            "Epoch 71/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2188e-04 - val_loss: 0.0016\n",
            "Epoch 72/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2222e-04 - val_loss: 0.0016\n",
            "Epoch 73/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2369e-04 - val_loss: 0.0015\n",
            "Epoch 74/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1803e-04 - val_loss: 0.0016\n",
            "training:  lstm_coins_cv  df:  27\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 8/46 [====>.........................] - ETA: 0s - loss: 6.2379e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 9ms/step - loss: 4.1615e-04 - val_loss: 9.4637e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8708e-04 - val_loss: 0.0011\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 4.6045e-04 - val_loss: 5.8509e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.9902e-04 - val_loss: 5.1532e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7754e-04 - val_loss: 5.1411e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8263e-04 - val_loss: 5.8212e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5255e-04 - val_loss: 4.4221e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2377e-04 - val_loss: 4.4585e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2081e-04 - val_loss: 4.4021e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.2792e-04 - val_loss: 4.4948e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.1690e-04 - val_loss: 4.7733e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3425e-04 - val_loss: 4.2585e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3404e-04 - val_loss: 4.3181e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3357e-04 - val_loss: 4.3118e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5968e-04 - val_loss: 5.1470e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 5.3435e-04 - val_loss: 4.5136e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3802e-04 - val_loss: 4.5079e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.3521e-04 - val_loss: 4.3142e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.2259e-04 - val_loss: 4.3783e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1514e-04 - val_loss: 4.9403e-04\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5607e-04 - val_loss: 4.8070e-04\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0485e-04 - val_loss: 4.5421e-04\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1653e-04 - val_loss: 5.4702e-04\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.1344e-04 - val_loss: 4.4499e-04\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1069e-04 - val_loss: 4.7800e-04\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2166e-04 - val_loss: 4.4563e-04\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 2.4378e-04 - val_loss: 4.5749e-04\n",
            "training:  lstm_coins_cv  df:  28\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 8.7755e-05 - val_loss: 4.1769e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.9089e-05 - val_loss: 5.2757e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.5515e-05 - val_loss: 5.2232e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.3543e-05 - val_loss: 4.4145e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.4093e-05 - val_loss: 4.5972e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.3214e-05 - val_loss: 4.4619e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.1342e-05 - val_loss: 4.1384e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.9927e-05 - val_loss: 4.4306e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.4750e-05 - val_loss: 4.5964e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.1033e-05 - val_loss: 4.5188e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.9958e-05 - val_loss: 5.0496e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.8735e-05 - val_loss: 4.3690e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.9199e-05 - val_loss: 4.2045e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.2315e-05 - val_loss: 4.8547e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.7606e-05 - val_loss: 4.4290e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.0642e-05 - val_loss: 5.6851e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.0475e-05 - val_loss: 6.4459e-04\n",
            "Epoch 18/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.6758e-05 - val_loss: 5.3309e-04\n",
            "Epoch 19/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.8945e-05 - val_loss: 4.6513e-04\n",
            "Epoch 20/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.1763e-05 - val_loss: 6.0288e-04\n",
            "Epoch 21/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.6871e-05 - val_loss: 5.0232e-04\n",
            "Epoch 22/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.6033e-05 - val_loss: 6.0397e-04\n",
            "training:  lstm_coins_cv  df:  29\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 6.0684e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 7ms/step - loss: 4.1107e-05 - val_loss: 9.3915e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 3.5368e-05 - val_loss: 0.0010\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 3.2232e-05 - val_loss: 9.7631e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.8478e-05 - val_loss: 0.0010\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.8138e-05 - val_loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.7614e-05 - val_loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.7899e-05 - val_loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.7087e-05 - val_loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6658e-05 - val_loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.6412e-05 - val_loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.6971e-05 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.5945e-05 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3974e-05 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4048e-05 - val_loss: 0.0019\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4044e-05 - val_loss: 0.0022\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.6183e-05 - val_loss: 0.0021\n",
            "training:  lstm_coins_cv  df:  30\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 2.8111e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3768e-05 - val_loss: 0.0021\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4931e-05 - val_loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2340e-05 - val_loss: 0.0025\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2685e-05 - val_loss: 0.0023\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2490e-05 - val_loss: 0.0025\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.5048e-05 - val_loss: 0.0024\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3676e-05 - val_loss: 0.0029\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4406e-05 - val_loss: 0.0030\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3340e-05 - val_loss: 0.0025\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2133e-05 - val_loss: 0.0030\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3630e-05 - val_loss: 0.0031\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3990e-05 - val_loss: 0.0031\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3091e-05 - val_loss: 0.0033\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3825e-05 - val_loss: 0.0034\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3264e-05 - val_loss: 0.0033\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3118e-05 - val_loss: 0.0029\n",
            "training:  lstm_coins_cv  df:  31\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1499e-05 - val_loss: 3.1962e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.9063e-05 - val_loss: 5.2582e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.8715e-05 - val_loss: 3.8459e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.7082e-05 - val_loss: 3.7907e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5065e-05 - val_loss: 2.9641e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.4355e-05 - val_loss: 3.9043e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2501e-05 - val_loss: 3.9836e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0287e-05 - val_loss: 2.9928e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.4820e-05 - val_loss: 4.4548e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2780e-05 - val_loss: 4.1467e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3759e-05 - val_loss: 3.7334e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3439e-05 - val_loss: 3.0533e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9672e-05 - val_loss: 4.0378e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2011e-05 - val_loss: 3.9065e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1518e-05 - val_loss: 5.0184e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0348e-05 - val_loss: 7.3788e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1166e-05 - val_loss: 4.0421e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9207e-05 - val_loss: 4.3622e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8788e-05 - val_loss: 3.1060e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9860e-05 - val_loss: 6.5316e-05\n",
            "training:  lstm_coins_cv  df:  32\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 3.1549e-05 - val_loss: 2.6309e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.8587e-05 - val_loss: 2.2615e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.8744e-05 - val_loss: 2.2790e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5628e-05 - val_loss: 2.0907e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5759e-05 - val_loss: 1.7421e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4743e-05 - val_loss: 1.6182e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4916e-05 - val_loss: 1.8486e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4970e-05 - val_loss: 2.5583e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4497e-05 - val_loss: 1.8245e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4348e-05 - val_loss: 2.0785e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4976e-05 - val_loss: 2.2375e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3829e-05 - val_loss: 2.8296e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3146e-05 - val_loss: 2.4097e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3606e-05 - val_loss: 2.6490e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4222e-05 - val_loss: 2.6733e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4395e-05 - val_loss: 2.8202e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4512e-05 - val_loss: 2.9997e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3140e-05 - val_loss: 3.9850e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3269e-05 - val_loss: 7.0199e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3208e-05 - val_loss: 6.1190e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3905e-05 - val_loss: 0.0022\n",
            "training:  lstm_coins_cv  df:  33\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 7.7968e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 7ms/step - loss: 1.4060e-04 - val_loss: 1.7422e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 1.1370e-04 - val_loss: 2.6330e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.6817e-05 - val_loss: 1.5659e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2680e-05 - val_loss: 1.9588e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.6982e-05 - val_loss: 2.8295e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3971e-05 - val_loss: 2.6181e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.1241e-05 - val_loss: 2.9839e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2375e-05 - val_loss: 2.0185e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.6330e-05 - val_loss: 1.5496e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 1.0148e-04 - val_loss: 3.2157e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.5662e-05 - val_loss: 2.1764e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4045e-05 - val_loss: 2.1239e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.5878e-05 - val_loss: 1.7271e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3150e-05 - val_loss: 3.8606e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9649e-05 - val_loss: 3.6302e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0389e-05 - val_loss: 3.6455e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.8166e-05 - val_loss: 1.4270e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9397e-05 - val_loss: 7.1929e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3188e-05 - val_loss: 1.7119e-04\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0070e-05 - val_loss: 1.4052e-04\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9145e-05 - val_loss: 1.7458e-04\n",
            "Epoch 22/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.7813e-05 - val_loss: 2.7647e-04\n",
            "Epoch 23/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9585e-05 - val_loss: 1.4338e-04\n",
            "Epoch 24/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.1162e-05 - val_loss: 2.5999e-04\n",
            "Epoch 25/200\n",
            "208/208 [==============================] - 1s 7ms/step - loss: 8.8587e-05 - val_loss: 1.7124e-04\n",
            "Epoch 26/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2710e-05 - val_loss: 1.4132e-04\n",
            "Epoch 27/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.6812e-05 - val_loss: 1.3941e-04\n",
            "Epoch 28/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0921e-05 - val_loss: 3.9886e-04\n",
            "Epoch 29/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9113e-05 - val_loss: 6.9647e-04\n",
            "Epoch 30/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9239e-05 - val_loss: 2.6786e-04\n",
            "Epoch 31/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0439e-05 - val_loss: 1.7764e-04\n",
            "Epoch 32/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1453e-05 - val_loss: 2.9432e-04\n",
            "Epoch 33/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3594e-05 - val_loss: 1.8802e-04\n",
            "Epoch 34/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0715e-05 - val_loss: 3.3310e-04\n",
            "Epoch 35/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0552e-05 - val_loss: 4.7045e-04\n",
            "Epoch 36/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3722e-05 - val_loss: 4.3002e-04\n",
            "Epoch 37/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.7116e-05 - val_loss: 6.8966e-04\n",
            "Epoch 38/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2194e-05 - val_loss: 2.2645e-04\n",
            "Epoch 39/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.1024e-05 - val_loss: 1.8477e-04\n",
            "Epoch 40/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0901e-05 - val_loss: 2.6321e-04\n",
            "Epoch 41/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2243e-05 - val_loss: 1.5796e-04\n",
            "Epoch 42/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.4126e-05 - val_loss: 1.4138e-04\n",
            "training:  lstm_coins_cv  df:  34\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 1.3354e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 7ms/step - loss: 2.9785e-05 - val_loss: 2.7102e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4905e-05 - val_loss: 3.2870e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4009e-05 - val_loss: 3.8053e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2959e-05 - val_loss: 3.7233e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2495e-05 - val_loss: 3.8555e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.3738e-05 - val_loss: 5.0852e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1828e-05 - val_loss: 5.2472e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2007e-05 - val_loss: 4.9060e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1520e-05 - val_loss: 6.2870e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1990e-05 - val_loss: 4.1649e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1338e-05 - val_loss: 4.5395e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2156e-05 - val_loss: 6.5718e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9904e-05 - val_loss: 7.2822e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1829e-05 - val_loss: 7.6282e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9845e-05 - val_loss: 6.4803e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0869e-05 - val_loss: 0.0013\n",
            "training:  lstm_coins_cv  df:  35\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 4.0641e-05 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.4374e-05 - val_loss: 0.0015\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.0295e-05 - val_loss: 0.0024\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9073e-05 - val_loss: 0.0024\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8573e-05 - val_loss: 0.0027\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.8701e-05 - val_loss: 0.0027\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8023e-05 - val_loss: 0.0034\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8356e-05 - val_loss: 0.0048\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6400e-05 - val_loss: 0.0033\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6226e-05 - val_loss: 0.0031\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7171e-05 - val_loss: 0.0033\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.5570e-05 - val_loss: 0.0050\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8709e-05 - val_loss: 0.0035\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6681e-05 - val_loss: 0.0039\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6840e-05 - val_loss: 0.0051\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.5573e-05 - val_loss: 0.0048\n",
            "Epoch 17/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6888e-05 - val_loss: 0.0063\n",
            "training:  lstm_coins_cv  df:  36\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/118 [=>............................] - ETA: 0s - loss: 6.8304e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 5.9323e-05 - val_loss: 0.0058\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.8778e-05 - val_loss: 0.0063\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.6054e-05 - val_loss: 0.0070\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.5576e-05 - val_loss: 0.0069\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5958e-05 - val_loss: 0.0061\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3593e-05 - val_loss: 0.0062\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.5931e-05 - val_loss: 0.0072\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.4239e-05 - val_loss: 0.0084\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.2904e-05 - val_loss: 0.0092\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.1156e-05 - val_loss: 0.0102\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.6965e-05 - val_loss: 0.0117\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.3681e-05 - val_loss: 0.0120\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.2010e-05 - val_loss: 0.0116\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.2396e-05 - val_loss: 0.0127\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.4106e-05 - val_loss: 0.0135\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.3273e-05 - val_loss: 0.0134\n",
            "training:  lstm_coins_cv  df:  37\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 1s - loss: 6.4125e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 1s 7ms/step - loss: 3.5472e-05 - val_loss: 0.0115\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.2735e-05 - val_loss: 0.0093\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.3036e-05 - val_loss: 0.0091\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.3129e-05 - val_loss: 0.0085\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1788e-05 - val_loss: 0.0084\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.4110e-05 - val_loss: 0.0102\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1406e-05 - val_loss: 0.0087\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1290e-05 - val_loss: 0.0089\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1693e-05 - val_loss: 0.0098\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1093e-05 - val_loss: 0.0126\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0538e-05 - val_loss: 0.0112\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1616e-05 - val_loss: 0.0108\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.2494e-05 - val_loss: 0.0116\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0137e-05 - val_loss: 0.0130\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0138e-05 - val_loss: 0.0119\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.2193e-05 - val_loss: 0.0127\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0913e-05 - val_loss: 0.0121\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0456e-05 - val_loss: 0.0140\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9424e-05 - val_loss: 0.0138\n",
            "Epoch 20/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9782e-05 - val_loss: 0.0152\n",
            "training:  lstm_coins_cv  df:  38\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/99 [=>............................] - ETA: 0s - loss: 0.0020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 5.3045e-04 - val_loss: 5.2171e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.9046e-04 - val_loss: 4.4341e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7865e-04 - val_loss: 4.6682e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.9001e-04 - val_loss: 5.1085e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.9139e-04 - val_loss: 4.6216e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7488e-04 - val_loss: 4.4198e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7326e-04 - val_loss: 4.9227e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.8079e-04 - val_loss: 5.5459e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7110e-04 - val_loss: 4.7181e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.8488e-04 - val_loss: 4.3767e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7120e-04 - val_loss: 4.2837e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7040e-04 - val_loss: 4.8908e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7030e-04 - val_loss: 4.5902e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7597e-04 - val_loss: 4.5630e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6849e-04 - val_loss: 4.8847e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7044e-04 - val_loss: 4.9402e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6488e-04 - val_loss: 4.4732e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7111e-04 - val_loss: 4.6306e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6207e-04 - val_loss: 5.1761e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5701e-04 - val_loss: 4.6221e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7599e-04 - val_loss: 4.8101e-04\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.8422e-04 - val_loss: 4.4868e-04\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6140e-04 - val_loss: 4.7651e-04\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6895e-04 - val_loss: 4.3955e-04\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.5955e-04 - val_loss: 4.6597e-04\n",
            "Epoch 26/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6119e-04 - val_loss: 4.7095e-04\n",
            "training:  lstm_coins_cv  df:  39\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 1.4329e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 7ms/step - loss: 5.0149e-05 - val_loss: 2.2811e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 4.3215e-05 - val_loss: 1.8973e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 5.0208e-05 - val_loss: 1.8723e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.3887e-05 - val_loss: 2.2238e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.9682e-05 - val_loss: 2.1523e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9337e-05 - val_loss: 1.8820e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 4.1582e-05 - val_loss: 2.0675e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.2148e-05 - val_loss: 2.0331e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.7488e-05 - val_loss: 2.2090e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8632e-05 - val_loss: 2.3800e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8145e-05 - val_loss: 2.1436e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8479e-05 - val_loss: 2.3710e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9521e-05 - val_loss: 3.0716e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6809e-05 - val_loss: 3.6283e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9589e-05 - val_loss: 2.9860e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.7345e-05 - val_loss: 4.9171e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6984e-05 - val_loss: 3.1954e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.7880e-05 - val_loss: 3.6694e-04\n",
            "training:  lstm_coins_cv  df:  40\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 0s - loss: 5.2746e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 4.3276e-05 - val_loss: 2.9154e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.9418e-05 - val_loss: 2.5193e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.8141e-05 - val_loss: 2.6828e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.7673e-05 - val_loss: 2.4878e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5872e-05 - val_loss: 2.3991e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4992e-05 - val_loss: 2.4730e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.7226e-05 - val_loss: 3.0200e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.6166e-05 - val_loss: 2.5297e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4924e-05 - val_loss: 2.7885e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.6043e-05 - val_loss: 2.8712e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.7783e-05 - val_loss: 3.9097e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4859e-05 - val_loss: 3.3135e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3686e-05 - val_loss: 4.2565e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5092e-05 - val_loss: 4.2999e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4048e-05 - val_loss: 6.2128e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3302e-05 - val_loss: 4.7194e-04\n",
            "Epoch 17/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3042e-05 - val_loss: 6.2736e-04\n",
            "Epoch 18/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4745e-05 - val_loss: 5.3703e-04\n",
            "Epoch 19/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3601e-05 - val_loss: 5.2019e-04\n",
            "Epoch 20/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3011e-05 - val_loss: 5.7705e-04\n",
            "training:  lstm_coins_cv  df:  41\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 0s - loss: 4.4892e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2583e-05 - val_loss: 5.0810e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4583e-05 - val_loss: 7.1874e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4687e-05 - val_loss: 7.4566e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4708e-05 - val_loss: 7.6222e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4900e-05 - val_loss: 7.3990e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3849e-05 - val_loss: 8.0986e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5012e-05 - val_loss: 8.4605e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4247e-05 - val_loss: 0.0010\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4492e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.2711e-05 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4569e-05 - val_loss: 0.0013\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3720e-05 - val_loss: 0.0013\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3906e-05 - val_loss: 0.0016\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3436e-05 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3921e-05 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4904e-05 - val_loss: 0.0014\n",
            "training:  lstm_coins_cv  df:  42\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 5.2102e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 7ms/step - loss: 4.1697e-05 - val_loss: 0.0013\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.7365e-05 - val_loss: 0.0012\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5385e-05 - val_loss: 0.0022\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5425e-05 - val_loss: 0.0024\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5374e-05 - val_loss: 0.0032\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4122e-05 - val_loss: 0.0027\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3108e-05 - val_loss: 0.0028\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4327e-05 - val_loss: 0.0029\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3766e-05 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5325e-05 - val_loss: 0.0039\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3499e-05 - val_loss: 0.0028\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3948e-05 - val_loss: 0.0027\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3947e-05 - val_loss: 0.0035\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4005e-05 - val_loss: 0.0025\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.3306e-05 - val_loss: 0.0045\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.2651e-05 - val_loss: 0.0040\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3734e-05 - val_loss: 0.0053\n",
            "training:  lstm_coins_cv  df:  43\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/64 [===>..........................] - ETA: 0s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 8ms/step - loss: 7.2708e-04 - val_loss: 7.1259e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.5925e-04 - val_loss: 5.7039e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.5245e-04 - val_loss: 7.6681e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.4893e-04 - val_loss: 7.7960e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.3648e-04 - val_loss: 8.3629e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.1273e-04 - val_loss: 8.6436e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.3780e-04 - val_loss: 8.9414e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.0490e-04 - val_loss: 8.5382e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1850e-04 - val_loss: 8.9521e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.2760e-04 - val_loss: 8.6625e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.3124e-04 - val_loss: 8.5056e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.0779e-04 - val_loss: 7.8171e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1862e-04 - val_loss: 8.5986e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1319e-04 - val_loss: 8.5619e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1960e-04 - val_loss: 8.6511e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1094e-04 - val_loss: 8.7038e-04\n",
            "Epoch 17/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1917e-04 - val_loss: 8.2427e-04\n",
            "training:  lstm_coins_cv  df:  44\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 2.6748e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 7ms/step - loss: 1.5227e-04 - val_loss: 1.5801e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4586e-04 - val_loss: 1.5929e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4373e-04 - val_loss: 1.8573e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4547e-04 - val_loss: 2.3548e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4186e-04 - val_loss: 1.8966e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4449e-04 - val_loss: 1.6408e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3789e-04 - val_loss: 1.6851e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4304e-04 - val_loss: 1.6170e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4127e-04 - val_loss: 1.7068e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4391e-04 - val_loss: 1.8819e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3749e-04 - val_loss: 1.6528e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3849e-04 - val_loss: 1.7237e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4692e-04 - val_loss: 1.7904e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4483e-04 - val_loss: 1.8359e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3809e-04 - val_loss: 2.0726e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3916e-04 - val_loss: 1.9788e-04\n",
            "training:  lstm_coins_cv  df:  45\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/174 [..............................] - ETA: 1s - loss: 2.0066e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2379e-04 - val_loss: 2.0928e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0306e-04 - val_loss: 1.9400e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9364e-04 - val_loss: 1.7909e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9443e-04 - val_loss: 1.9915e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0028e-04 - val_loss: 1.8636e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9195e-04 - val_loss: 1.8583e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9745e-04 - val_loss: 1.8209e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9521e-04 - val_loss: 1.9490e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9273e-04 - val_loss: 1.8538e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9510e-04 - val_loss: 1.8002e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9947e-04 - val_loss: 1.9796e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8403e-04 - val_loss: 1.8714e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9380e-04 - val_loss: 1.8187e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9516e-04 - val_loss: 1.9377e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8485e-04 - val_loss: 1.8106e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9846e-04 - val_loss: 1.9191e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9776e-04 - val_loss: 1.8166e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9073e-04 - val_loss: 1.7867e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9423e-04 - val_loss: 2.1775e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9064e-04 - val_loss: 2.0228e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9036e-04 - val_loss: 1.9612e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0470e-04 - val_loss: 1.8860e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8844e-04 - val_loss: 1.8490e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9126e-04 - val_loss: 1.9634e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8850e-04 - val_loss: 1.7821e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8759e-04 - val_loss: 1.7809e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8687e-04 - val_loss: 1.8465e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9494e-04 - val_loss: 1.7963e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8821e-04 - val_loss: 1.9278e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9060e-04 - val_loss: 1.9409e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9638e-04 - val_loss: 2.0108e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9606e-04 - val_loss: 1.9653e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8563e-04 - val_loss: 1.8409e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8808e-04 - val_loss: 1.8751e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9247e-04 - val_loss: 1.8367e-04\n",
            "Epoch 36/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9847e-04 - val_loss: 1.9477e-04\n",
            "Epoch 37/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8634e-04 - val_loss: 1.7807e-04\n",
            "Epoch 38/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9143e-04 - val_loss: 1.9104e-04\n",
            "Epoch 39/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9623e-04 - val_loss: 1.7590e-04\n",
            "Epoch 40/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8824e-04 - val_loss: 2.0066e-04\n",
            "Epoch 41/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8878e-04 - val_loss: 2.2546e-04\n",
            "Epoch 42/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8501e-04 - val_loss: 1.7902e-04\n",
            "Epoch 43/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9224e-04 - val_loss: 1.9734e-04\n",
            "Epoch 44/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8690e-04 - val_loss: 2.2261e-04\n",
            "Epoch 45/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9341e-04 - val_loss: 1.8496e-04\n",
            "Epoch 46/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9212e-04 - val_loss: 2.0080e-04\n",
            "Epoch 47/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8305e-04 - val_loss: 1.8837e-04\n",
            "Epoch 48/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9064e-04 - val_loss: 1.8460e-04\n",
            "Epoch 49/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9526e-04 - val_loss: 2.0224e-04\n",
            "Epoch 50/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8810e-04 - val_loss: 2.0237e-04\n",
            "Epoch 51/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9118e-04 - val_loss: 1.7757e-04\n",
            "Epoch 52/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8297e-04 - val_loss: 1.7996e-04\n",
            "Epoch 53/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8294e-04 - val_loss: 1.8699e-04\n",
            "Epoch 54/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8257e-04 - val_loss: 1.7803e-04\n",
            "training:  lstm_coins_cv  df:  46\n",
            "Training model: lstm_coins_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5252e-05 - val_loss: 1.1972e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0727e-05 - val_loss: 1.0392e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9707e-05 - val_loss: 1.0173e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8528e-05 - val_loss: 1.0010e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9097e-05 - val_loss: 1.1158e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0020e-05 - val_loss: 1.0297e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9892e-05 - val_loss: 1.1069e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7885e-05 - val_loss: 1.1486e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2551e-05 - val_loss: 1.1324e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9395e-05 - val_loss: 1.0063e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0025e-05 - val_loss: 1.0037e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1468e-05 - val_loss: 1.1844e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1714e-05 - val_loss: 1.0301e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1165e-05 - val_loss: 1.1296e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8310e-05 - val_loss: 1.0240e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9620e-05 - val_loss: 1.0084e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0582e-05 - val_loss: 1.0785e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9695e-05 - val_loss: 1.0435e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0030e-05 - val_loss: 1.2101e-04\n",
            "training:  lstm_coins_cv  df:  47\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 2.2233e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 7ms/step - loss: 1.5498e-04 - val_loss: 1.8774e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4150e-04 - val_loss: 2.5556e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3524e-04 - val_loss: 2.8013e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3376e-04 - val_loss: 2.0983e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3445e-04 - val_loss: 1.9204e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2974e-04 - val_loss: 1.6969e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3470e-04 - val_loss: 1.8662e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3280e-04 - val_loss: 2.1861e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3155e-04 - val_loss: 2.0216e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3266e-04 - val_loss: 1.7977e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3438e-04 - val_loss: 1.8600e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3409e-04 - val_loss: 2.1762e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3534e-04 - val_loss: 1.7870e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3246e-04 - val_loss: 1.8730e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3077e-04 - val_loss: 3.0160e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3077e-04 - val_loss: 2.6011e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3141e-04 - val_loss: 1.6642e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3124e-04 - val_loss: 2.0744e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3018e-04 - val_loss: 2.2688e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3081e-04 - val_loss: 2.6886e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3045e-04 - val_loss: 1.6889e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2876e-04 - val_loss: 2.9091e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2912e-04 - val_loss: 2.3162e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2862e-04 - val_loss: 2.0830e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2851e-04 - val_loss: 2.0997e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3144e-04 - val_loss: 2.4030e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3060e-04 - val_loss: 1.8951e-04\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2876e-04 - val_loss: 2.2437e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2949e-04 - val_loss: 2.7796e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2821e-04 - val_loss: 2.2685e-04\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2749e-04 - val_loss: 1.6627e-04\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3201e-04 - val_loss: 1.6244e-04\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3060e-04 - val_loss: 2.1975e-04\n",
            "Epoch 34/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2640e-04 - val_loss: 1.6488e-04\n",
            "Epoch 35/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2849e-04 - val_loss: 1.8035e-04\n",
            "Epoch 36/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3198e-04 - val_loss: 1.9248e-04\n",
            "Epoch 37/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2604e-04 - val_loss: 1.9311e-04\n",
            "Epoch 38/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2728e-04 - val_loss: 1.8290e-04\n",
            "Epoch 39/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2821e-04 - val_loss: 2.0202e-04\n",
            "Epoch 40/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2791e-04 - val_loss: 1.6935e-04\n",
            "Epoch 41/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2810e-04 - val_loss: 1.5648e-04\n",
            "Epoch 42/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2979e-04 - val_loss: 2.1113e-04\n",
            "Epoch 43/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2833e-04 - val_loss: 1.5246e-04\n",
            "Epoch 44/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2989e-04 - val_loss: 2.0327e-04\n",
            "Epoch 45/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2950e-04 - val_loss: 2.1732e-04\n",
            "Epoch 46/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2761e-04 - val_loss: 2.0961e-04\n",
            "Epoch 47/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2669e-04 - val_loss: 1.3677e-04\n",
            "Epoch 48/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3027e-04 - val_loss: 2.1299e-04\n",
            "Epoch 49/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2998e-04 - val_loss: 2.2462e-04\n",
            "Epoch 50/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2878e-04 - val_loss: 2.0931e-04\n",
            "Epoch 51/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3212e-04 - val_loss: 2.5704e-04\n",
            "Epoch 52/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3074e-04 - val_loss: 1.8264e-04\n",
            "Epoch 53/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2856e-04 - val_loss: 1.8592e-04\n",
            "Epoch 54/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2894e-04 - val_loss: 2.2156e-04\n",
            "Epoch 55/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2962e-04 - val_loss: 2.5240e-04\n",
            "Epoch 56/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2710e-04 - val_loss: 2.3177e-04\n",
            "Epoch 57/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2817e-04 - val_loss: 1.7503e-04\n",
            "Epoch 58/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2521e-04 - val_loss: 1.5071e-04\n",
            "Epoch 59/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2804e-04 - val_loss: 2.4493e-04\n",
            "Epoch 60/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2957e-04 - val_loss: 2.0162e-04\n",
            "Epoch 61/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2601e-04 - val_loss: 1.9589e-04\n",
            "Epoch 62/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2604e-04 - val_loss: 2.4939e-04\n",
            "training:  lstm_coins_cv  df:  48\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 9.7707e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2674e-04 - val_loss: 9.2958e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2356e-04 - val_loss: 8.4463e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2231e-04 - val_loss: 8.3470e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1788e-04 - val_loss: 8.5085e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1723e-04 - val_loss: 7.8222e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2003e-04 - val_loss: 1.1322e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2315e-04 - val_loss: 1.1985e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2245e-04 - val_loss: 9.3041e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2382e-04 - val_loss: 9.3738e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1586e-04 - val_loss: 8.7375e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1943e-04 - val_loss: 8.8000e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2123e-04 - val_loss: 7.5292e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2185e-04 - val_loss: 8.0431e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2077e-04 - val_loss: 8.4922e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2232e-04 - val_loss: 7.6641e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1780e-04 - val_loss: 7.5478e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1823e-04 - val_loss: 8.1317e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1842e-04 - val_loss: 9.3067e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1650e-04 - val_loss: 8.7503e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2058e-04 - val_loss: 1.3134e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2382e-04 - val_loss: 8.7849e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1878e-04 - val_loss: 7.8691e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2253e-04 - val_loss: 7.9114e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1714e-04 - val_loss: 7.9762e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1654e-04 - val_loss: 7.6549e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1728e-04 - val_loss: 7.7845e-05\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1881e-04 - val_loss: 8.7897e-05\n",
            "training:  lstm_coins_cv  df:  49\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 3.6853e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 7ms/step - loss: 1.0153e-04 - val_loss: 9.8851e-05\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.6399e-05 - val_loss: 9.9302e-05\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3820e-05 - val_loss: 1.0943e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1213e-05 - val_loss: 9.7630e-05\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0869e-05 - val_loss: 9.4616e-05\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0972e-05 - val_loss: 9.5917e-05\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1555e-05 - val_loss: 1.0355e-04\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.4641e-05 - val_loss: 9.9248e-05\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3982e-05 - val_loss: 9.5137e-05\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9617e-05 - val_loss: 1.0158e-04\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3690e-05 - val_loss: 1.0809e-04\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9305e-05 - val_loss: 9.9036e-05\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0863e-05 - val_loss: 9.7467e-05\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 1.0007e-04 - val_loss: 9.9242e-05\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1590e-05 - val_loss: 9.3337e-05\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.7331e-05 - val_loss: 1.0903e-04\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0374e-05 - val_loss: 1.1141e-04\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0536e-05 - val_loss: 9.6997e-05\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0791e-05 - val_loss: 1.2114e-04\n",
            "Epoch 20/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2830e-05 - val_loss: 1.0307e-04\n",
            "Epoch 21/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2244e-05 - val_loss: 9.5664e-05\n",
            "Epoch 22/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2239e-05 - val_loss: 1.0892e-04\n",
            "Epoch 23/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9979e-05 - val_loss: 9.2047e-05\n",
            "Epoch 24/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1485e-05 - val_loss: 9.6716e-05\n",
            "Epoch 25/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9684e-05 - val_loss: 9.5812e-05\n",
            "Epoch 26/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9845e-05 - val_loss: 9.6682e-05\n",
            "Epoch 27/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.7929e-05 - val_loss: 9.8477e-05\n",
            "Epoch 28/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.8761e-05 - val_loss: 9.6690e-05\n",
            "Epoch 29/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9529e-05 - val_loss: 1.4466e-04\n",
            "Epoch 30/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9397e-05 - val_loss: 1.0004e-04\n",
            "Epoch 31/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3633e-05 - val_loss: 1.0867e-04\n",
            "Epoch 32/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1470e-05 - val_loss: 1.0006e-04\n",
            "Epoch 33/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9920e-05 - val_loss: 1.0568e-04\n",
            "Epoch 34/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1226e-05 - val_loss: 1.0141e-04\n",
            "Epoch 35/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0332e-05 - val_loss: 9.1521e-05\n",
            "Epoch 36/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0185e-05 - val_loss: 9.5616e-05\n",
            "Epoch 37/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0917e-05 - val_loss: 1.1226e-04\n",
            "Epoch 38/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9093e-05 - val_loss: 9.6794e-05\n",
            "Epoch 39/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1711e-05 - val_loss: 9.5610e-05\n",
            "Epoch 40/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.9979e-05 - val_loss: 9.8967e-05\n",
            "Epoch 41/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.8596e-05 - val_loss: 1.0242e-04\n",
            "Epoch 42/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.8636e-05 - val_loss: 1.2105e-04\n",
            "Epoch 43/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.7943e-05 - val_loss: 9.2630e-05\n",
            "Epoch 44/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0996e-05 - val_loss: 1.0518e-04\n",
            "Epoch 45/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0823e-05 - val_loss: 1.0629e-04\n",
            "Epoch 46/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0357e-05 - val_loss: 9.9615e-05\n",
            "Epoch 47/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0386e-05 - val_loss: 1.2268e-04\n",
            "Epoch 48/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.7314e-05 - val_loss: 9.7931e-05\n",
            "Epoch 49/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2077e-05 - val_loss: 1.0154e-04\n",
            "Epoch 50/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.6918e-05 - val_loss: 9.5305e-05\n",
            "training:  lstm_coins_cv  df:  50\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7062e-04 - val_loss: 0.0019\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6247e-04 - val_loss: 0.0018\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.5428e-04 - val_loss: 0.0019\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8045e-04 - val_loss: 0.0019\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7839e-04 - val_loss: 0.0018\n",
            "training:  lstm_coins_cv  df:  51\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/106 [=>............................] - ETA: 0s - loss: 2.7781e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.6430e-04 - val_loss: 6.7118e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.4379e-04 - val_loss: 6.7668e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2853e-04 - val_loss: 6.5851e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3491e-04 - val_loss: 6.9404e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3681e-04 - val_loss: 6.7218e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3231e-04 - val_loss: 6.6986e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3323e-04 - val_loss: 6.8285e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2903e-04 - val_loss: 6.8492e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2603e-04 - val_loss: 6.6387e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2591e-04 - val_loss: 6.8056e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3430e-04 - val_loss: 6.7088e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2297e-04 - val_loss: 6.8112e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2180e-04 - val_loss: 7.3634e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2484e-04 - val_loss: 6.6083e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3283e-04 - val_loss: 6.9451e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2021e-04 - val_loss: 7.6932e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2707e-04 - val_loss: 6.7849e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2559e-04 - val_loss: 6.8497e-04\n",
            "training:  lstm_coins_cv  df:  52\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 4.9578e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 7ms/step - loss: 4.4192e-05 - val_loss: 2.1214e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.8864e-05 - val_loss: 2.1873e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.3565e-05 - val_loss: 1.9887e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.3955e-05 - val_loss: 2.1453e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2021e-05 - val_loss: 2.0266e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2084e-05 - val_loss: 2.1348e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2280e-05 - val_loss: 2.0524e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0623e-05 - val_loss: 2.0721e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1140e-05 - val_loss: 2.1873e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0780e-05 - val_loss: 2.3515e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0595e-05 - val_loss: 2.2641e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0942e-05 - val_loss: 2.4791e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0076e-05 - val_loss: 2.5558e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9792e-05 - val_loss: 2.3428e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0103e-05 - val_loss: 2.5943e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9507e-05 - val_loss: 3.0305e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9266e-05 - val_loss: 2.9592e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9338e-05 - val_loss: 3.2574e-04\n",
            "training:  lstm_coins_cv  df:  53\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/79 [==>...........................] - ETA: 0s - loss: 1.2603e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 1.1703e-04 - val_loss: 9.5760e-04\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.9837e-05 - val_loss: 6.4543e-04\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.5888e-05 - val_loss: 6.8993e-04\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.5872e-05 - val_loss: 7.2824e-04\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.9159e-05 - val_loss: 7.9297e-04\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.5786e-05 - val_loss: 7.0470e-04\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.0841e-05 - val_loss: 6.7418e-04\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.0631e-05 - val_loss: 7.9283e-04\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.9844e-05 - val_loss: 7.2406e-04\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.7780e-05 - val_loss: 7.7836e-04\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.5379e-05 - val_loss: 8.7206e-04\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2673e-05 - val_loss: 8.0535e-04\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.8685e-05 - val_loss: 8.3327e-04\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3653e-05 - val_loss: 8.7514e-04\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.6647e-05 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.4643e-05 - val_loss: 0.0011\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.4841e-05 - val_loss: 0.0011\n",
            "training:  lstm_coins_cv  df:  54\n",
            "Training model: lstm_coins_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 3.4850e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 5.8266e-05 - val_loss: 1.8728e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.3647e-05 - val_loss: 1.9378e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1498e-05 - val_loss: 1.3842e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1679e-05 - val_loss: 1.2780e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0362e-05 - val_loss: 1.9797e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8544e-05 - val_loss: 1.1269e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0202e-05 - val_loss: 1.1307e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0229e-05 - val_loss: 1.4168e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8476e-05 - val_loss: 1.5046e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1313e-05 - val_loss: 1.7621e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8867e-05 - val_loss: 2.0286e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8982e-05 - val_loss: 1.9756e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9599e-05 - val_loss: 2.4876e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8784e-05 - val_loss: 1.6198e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9926e-05 - val_loss: 1.3107e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9231e-05 - val_loss: 2.4360e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9035e-05 - val_loss: 2.4449e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7721e-05 - val_loss: 1.3575e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9520e-05 - val_loss: 1.2547e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0190e-05 - val_loss: 1.6086e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8850e-05 - val_loss: 1.8541e-04\n",
            "build model: lstm_att_cv  features: 2\n",
            "training:  lstm_att_cv\n",
            "lstm_att_cv  should train on stocks\n",
            "training dfs: 55\n",
            "training:  lstm_att_cv  df:  0\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 6s 12ms/step - loss: 0.0035 - val_loss: 0.2809\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 6.4215e-04 - val_loss: 0.2623\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 4.4718e-04 - val_loss: 0.1641\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.4189e-04 - val_loss: 0.0280\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.4996e-04 - val_loss: 0.0380\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.2449e-04 - val_loss: 0.0028\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.3531e-04 - val_loss: 0.0119\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.1221e-04 - val_loss: 0.0212\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.8180e-04 - val_loss: 0.0129\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.3988e-04 - val_loss: 0.0274\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.8380e-04 - val_loss: 0.0133\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.7045e-04 - val_loss: 0.0182\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.6961e-04 - val_loss: 0.0251\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.8292e-04 - val_loss: 0.0250\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.5813e-04 - val_loss: 0.0297\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.4877e-04 - val_loss: 0.0163\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.9904e-04 - val_loss: 0.0163\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.2255e-04 - val_loss: 0.0202\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.8857e-04 - val_loss: 0.0169\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.7901e-04 - val_loss: 0.0207\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.9750e-04 - val_loss: 0.0265\n",
            "training:  lstm_att_cv  df:  1\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/80 [==>...........................] - ETA: 0s - loss: 2.9819e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 8ms/step - loss: 1.3360e-04 - val_loss: 0.0050\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 8.6036e-05 - val_loss: 0.0089\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 1.3044e-04 - val_loss: 0.0074\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 5.6733e-05 - val_loss: 0.0228\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 6.1409e-05 - val_loss: 0.0281\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.3492e-05 - val_loss: 0.0216\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 1.3112e-04 - val_loss: 0.0451\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 3.8744e-05 - val_loss: 0.0543\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 4.2617e-05 - val_loss: 0.0428\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.0623e-04 - val_loss: 0.0425\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 7.0083e-05 - val_loss: 0.0523\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.3619e-05 - val_loss: 0.0397\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.2352e-05 - val_loss: 0.0393\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 3.4721e-05 - val_loss: 0.0595\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.1371e-05 - val_loss: 0.0561\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 3.4804e-05 - val_loss: 0.0550\n",
            "training:  lstm_att_cv  df:  2\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 3.5682e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 7ms/step - loss: 1.7664e-05 - val_loss: 0.0714\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2123e-05 - val_loss: 0.0885\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2522e-05 - val_loss: 0.1018\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2470e-05 - val_loss: 0.1086\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2617e-05 - val_loss: 0.1079\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2835e-05 - val_loss: 0.1199\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.0882e-05 - val_loss: 0.1250\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2714e-05 - val_loss: 0.1180\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2043e-05 - val_loss: 0.1106\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.2056e-05 - val_loss: 0.1020\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.0475e-05 - val_loss: 0.0914\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.1122e-05 - val_loss: 0.0961\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.1855e-05 - val_loss: 0.0873\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.1140e-05 - val_loss: 0.0862\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.3791e-05 - val_loss: 0.0958\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.1308e-05 - val_loss: 0.1066\n",
            "training:  lstm_att_cv  df:  3\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3087e-04 - val_loss: 0.0189\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5671e-04 - val_loss: 0.0184\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9502e-04 - val_loss: 0.0239\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6466e-04 - val_loss: 0.0170\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4952e-04 - val_loss: 0.0215\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6077e-04 - val_loss: 0.0179\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2592e-04 - val_loss: 0.0150\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2542e-04 - val_loss: 0.0165\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3299e-04 - val_loss: 0.0188\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2413e-04 - val_loss: 0.0141\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2117e-04 - val_loss: 0.0182\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1300e-04 - val_loss: 0.0165\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0994e-04 - val_loss: 0.0129\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1022e-04 - val_loss: 0.0151\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1718e-04 - val_loss: 0.0166\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0018e-04 - val_loss: 0.0148\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1244e-04 - val_loss: 0.0209\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.6531e-05 - val_loss: 0.0196\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0701e-04 - val_loss: 0.0142\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.6739e-05 - val_loss: 0.0171\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9849e-05 - val_loss: 0.0146\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2701e-05 - val_loss: 0.0107\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1562e-05 - val_loss: 0.0099\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1717e-05 - val_loss: 0.0143\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1064e-05 - val_loss: 0.0129\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0379e-05 - val_loss: 0.0100\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.4233e-05 - val_loss: 0.0106\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.3404e-05 - val_loss: 0.0098\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0292e-04 - val_loss: 0.0105\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0442e-05 - val_loss: 0.0128\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.1391e-05 - val_loss: 0.0130\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4448e-05 - val_loss: 0.0132\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.1808e-05 - val_loss: 0.0117\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.5939e-05 - val_loss: 0.0123\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.3088e-05 - val_loss: 0.0138\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7934e-05 - val_loss: 0.0187\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6680e-05 - val_loss: 0.0142\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.8901e-05 - val_loss: 0.0158\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0767e-05 - val_loss: 0.0138\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.7318e-05 - val_loss: 0.0094\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.2872e-05 - val_loss: 0.0116\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.6156e-05 - val_loss: 0.0115\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.5504e-05 - val_loss: 0.0153\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.7247e-05 - val_loss: 0.0163\n",
            "Epoch 45/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.1721e-05 - val_loss: 0.0159\n",
            "Epoch 46/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.5555e-05 - val_loss: 0.0146\n",
            "Epoch 47/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.9460e-05 - val_loss: 0.0165\n",
            "Epoch 48/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.4429e-05 - val_loss: 0.0147\n",
            "Epoch 49/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3717e-05 - val_loss: 0.0137\n",
            "Epoch 50/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3764e-05 - val_loss: 0.0137\n",
            "Epoch 51/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.1100e-05 - val_loss: 0.0163\n",
            "Epoch 52/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.2795e-05 - val_loss: 0.0158\n",
            "Epoch 53/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5643e-05 - val_loss: 0.0154\n",
            "Epoch 54/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3832e-05 - val_loss: 0.0147\n",
            "Epoch 55/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3401e-05 - val_loss: 0.0176\n",
            "training:  lstm_att_cv  df:  4\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 7ms/step - loss: 2.8694e-04 - val_loss: 1.0120e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.7396e-04 - val_loss: 7.9583e-05\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.6462e-04 - val_loss: 1.7133e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5345e-04 - val_loss: 1.2205e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4548e-04 - val_loss: 6.7535e-05\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5356e-04 - val_loss: 7.8668e-05\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3876e-04 - val_loss: 7.9369e-05\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4004e-04 - val_loss: 9.3180e-05\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3582e-04 - val_loss: 8.3092e-05\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4788e-04 - val_loss: 8.4300e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3219e-04 - val_loss: 8.3663e-05\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3443e-04 - val_loss: 1.5769e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3845e-04 - val_loss: 8.8623e-05\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3240e-04 - val_loss: 1.3774e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2766e-04 - val_loss: 7.9357e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2704e-04 - val_loss: 8.5732e-05\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2501e-04 - val_loss: 8.2740e-05\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2755e-04 - val_loss: 7.2136e-05\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3008e-04 - val_loss: 7.1179e-05\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2696e-04 - val_loss: 1.6418e-04\n",
            "training:  lstm_att_cv  df:  5\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.2056e-05 - val_loss: 6.5575e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.8863e-05 - val_loss: 7.9416e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5819e-05 - val_loss: 9.4458e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5670e-05 - val_loss: 0.0010\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.5080e-05 - val_loss: 0.0011\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4565e-05 - val_loss: 0.0013\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0882e-05 - val_loss: 0.0014\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1109e-05 - val_loss: 0.0015\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2588e-05 - val_loss: 0.0016\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0215e-05 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1080e-05 - val_loss: 0.0025\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9321e-05 - val_loss: 0.0029\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8969e-05 - val_loss: 0.0025\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0985e-05 - val_loss: 0.0019\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8944e-05 - val_loss: 0.0030\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9322e-05 - val_loss: 0.0020\n",
            "training:  lstm_att_cv  df:  6\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 0.0203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 3.6427e-04 - val_loss: 1.4828e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 2.1055e-04 - val_loss: 2.4037e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.7786e-04 - val_loss: 1.3838e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.7368e-04 - val_loss: 1.1345e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.7110e-04 - val_loss: 1.1124e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.6485e-04 - val_loss: 1.5949e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.6380e-04 - val_loss: 1.8766e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5404e-04 - val_loss: 1.7309e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5673e-04 - val_loss: 1.3389e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.6599e-04 - val_loss: 1.6105e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4876e-04 - val_loss: 1.1953e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5178e-04 - val_loss: 1.6115e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5188e-04 - val_loss: 1.1818e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5111e-04 - val_loss: 1.0550e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5159e-04 - val_loss: 1.3588e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5181e-04 - val_loss: 1.2905e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4474e-04 - val_loss: 1.3258e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4632e-04 - val_loss: 1.2341e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4427e-04 - val_loss: 1.0003e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4437e-04 - val_loss: 1.2019e-04\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5256e-04 - val_loss: 1.2291e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4288e-04 - val_loss: 9.5634e-05\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4463e-04 - val_loss: 1.0874e-04\n",
            "Epoch 24/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4052e-04 - val_loss: 1.0912e-04\n",
            "Epoch 25/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4497e-04 - val_loss: 1.2340e-04\n",
            "Epoch 26/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4210e-04 - val_loss: 1.0634e-04\n",
            "Epoch 27/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4510e-04 - val_loss: 1.3223e-04\n",
            "Epoch 28/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3691e-04 - val_loss: 1.1365e-04\n",
            "Epoch 29/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3608e-04 - val_loss: 1.2087e-04\n",
            "Epoch 30/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3613e-04 - val_loss: 9.5002e-05\n",
            "Epoch 31/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3887e-04 - val_loss: 1.0761e-04\n",
            "Epoch 32/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4384e-04 - val_loss: 2.2140e-04\n",
            "Epoch 33/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5558e-04 - val_loss: 2.0034e-04\n",
            "Epoch 34/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4583e-04 - val_loss: 1.0620e-04\n",
            "Epoch 35/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3318e-04 - val_loss: 1.0400e-04\n",
            "Epoch 36/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3938e-04 - val_loss: 1.1924e-04\n",
            "Epoch 37/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3939e-04 - val_loss: 2.1211e-04\n",
            "Epoch 38/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3987e-04 - val_loss: 2.3442e-04\n",
            "Epoch 39/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3133e-04 - val_loss: 1.1156e-04\n",
            "Epoch 40/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3130e-04 - val_loss: 1.6287e-04\n",
            "Epoch 41/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3677e-04 - val_loss: 1.0382e-04\n",
            "Epoch 42/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3405e-04 - val_loss: 2.9053e-04\n",
            "Epoch 43/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3163e-04 - val_loss: 9.5769e-05\n",
            "Epoch 44/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3436e-04 - val_loss: 1.9699e-04\n",
            "Epoch 45/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3553e-04 - val_loss: 9.7245e-05\n",
            "training:  lstm_att_cv  df:  7\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 9.2856e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 7ms/step - loss: 7.8121e-05 - val_loss: 2.8855e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 6.1602e-05 - val_loss: 3.0376e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 6.0053e-05 - val_loss: 2.9474e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.6295e-05 - val_loss: 3.5018e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.3774e-05 - val_loss: 3.4257e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.3898e-05 - val_loss: 3.0996e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.2753e-05 - val_loss: 3.3531e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.1988e-05 - val_loss: 3.4718e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.3179e-05 - val_loss: 3.8921e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.4767e-05 - val_loss: 5.0322e-04\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.1778e-05 - val_loss: 6.2355e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.0108e-05 - val_loss: 9.0375e-04\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.7891e-05 - val_loss: 7.2443e-04\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.0067e-05 - val_loss: 8.0760e-04\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.8832e-05 - val_loss: 8.2940e-04\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.6755e-05 - val_loss: 9.0806e-04\n",
            "training:  lstm_att_cv  df:  8\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/68 [==>...........................] - ETA: 0s - loss: 1.9724e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 1.9802e-04 - val_loss: 0.0043\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.6441e-04 - val_loss: 0.0038\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.6085e-04 - val_loss: 0.0044\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4272e-04 - val_loss: 0.0043\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3410e-04 - val_loss: 0.0051\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2915e-04 - val_loss: 0.0042\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2787e-04 - val_loss: 0.0045\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3960e-04 - val_loss: 0.0037\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1636e-04 - val_loss: 0.0043\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.4099e-04 - val_loss: 0.0042\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.5026e-04 - val_loss: 0.0043\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2137e-04 - val_loss: 0.0045\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2890e-04 - val_loss: 0.0056\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.1628e-04 - val_loss: 0.0062\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.1380e-04 - val_loss: 0.0057\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3511e-04 - val_loss: 0.0039\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2959e-04 - val_loss: 0.0051\n",
            "Epoch 18/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.3836e-04 - val_loss: 0.0053\n",
            "Epoch 19/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1863e-04 - val_loss: 0.0048\n",
            "Epoch 20/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3683e-04 - val_loss: 0.0053\n",
            "Epoch 21/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.1584e-04 - val_loss: 0.0049\n",
            "Epoch 22/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.2152e-04 - val_loss: 0.0044\n",
            "Epoch 23/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.3475e-04 - val_loss: 0.0045\n",
            "training:  lstm_att_cv  df:  9\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/162 [>.............................] - ETA: 1s - loss: 1.8508e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 5.6180e-05 - val_loss: 0.0034\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.6773e-05 - val_loss: 0.0037\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.2477e-05 - val_loss: 0.0041\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.2262e-05 - val_loss: 0.0044\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.2816e-05 - val_loss: 0.0046\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.2404e-05 - val_loss: 0.0050\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.9401e-05 - val_loss: 0.0055\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.0490e-05 - val_loss: 0.0056\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.7227e-05 - val_loss: 0.0059\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.7950e-05 - val_loss: 0.0060\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.6581e-05 - val_loss: 0.0061\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.7549e-05 - val_loss: 0.0063\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.6673e-05 - val_loss: 0.0060\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.8389e-05 - val_loss: 0.0063\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.5634e-05 - val_loss: 0.0068\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.6901e-05 - val_loss: 0.0067\n",
            "training:  lstm_att_cv  df:  10\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.5666e-05 - val_loss: 0.0014\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.7597e-05 - val_loss: 7.5794e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1266e-05 - val_loss: 6.8075e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3471e-05 - val_loss: 9.4719e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3220e-05 - val_loss: 0.0010\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3674e-05 - val_loss: 7.3524e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0273e-05 - val_loss: 6.2057e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5021e-05 - val_loss: 8.5415e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.4934e-05 - val_loss: 5.8826e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4876e-05 - val_loss: 7.7785e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8212e-05 - val_loss: 0.0011\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3670e-05 - val_loss: 8.6375e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8506e-05 - val_loss: 6.4078e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9781e-05 - val_loss: 6.6217e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8110e-05 - val_loss: 6.2540e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6500e-05 - val_loss: 6.5441e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.4313e-05 - val_loss: 6.4605e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5051e-05 - val_loss: 8.7681e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7091e-05 - val_loss: 6.7215e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6598e-05 - val_loss: 6.4254e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5297e-05 - val_loss: 7.8425e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3630e-05 - val_loss: 6.2094e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5841e-05 - val_loss: 6.4175e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.2459e-05 - val_loss: 6.7195e-04\n",
            "training:  lstm_att_cv  df:  11\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3450e-04 - val_loss: 9.5417e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0328e-04 - val_loss: 7.6207e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.4939e-05 - val_loss: 9.1626e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5224e-05 - val_loss: 8.9820e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5450e-05 - val_loss: 2.3868e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0584e-04 - val_loss: 1.2427e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8299e-05 - val_loss: 7.6159e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8764e-05 - val_loss: 7.3211e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0564e-05 - val_loss: 7.4682e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9419e-05 - val_loss: 6.4893e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1762e-05 - val_loss: 1.1988e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.6441e-05 - val_loss: 9.4948e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.3401e-05 - val_loss: 3.1593e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9843e-05 - val_loss: 1.4724e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0413e-04 - val_loss: 9.6513e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7289e-05 - val_loss: 9.2620e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1548e-05 - val_loss: 1.7252e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4998e-05 - val_loss: 2.1156e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3413e-05 - val_loss: 9.5625e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8814e-05 - val_loss: 1.0611e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7061e-05 - val_loss: 8.6464e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8425e-05 - val_loss: 8.8708e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6970e-05 - val_loss: 1.8165e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.3832e-05 - val_loss: 6.9502e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.6147e-05 - val_loss: 9.4666e-05\n",
            "training:  lstm_att_cv  df:  12\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0045\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0024\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7325e-04 - val_loss: 0.0020\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "training:  lstm_att_cv  df:  13\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/132 [=>............................] - ETA: 0s - loss: 2.8946e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 8ms/step - loss: 6.7516e-05 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.9813e-05 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.8082e-05 - val_loss: 0.0015\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.4530e-05 - val_loss: 0.0015\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.2523e-05 - val_loss: 0.0015\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.2285e-05 - val_loss: 0.0015\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.0912e-05 - val_loss: 0.0014\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.1351e-05 - val_loss: 0.0014\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.9909e-05 - val_loss: 0.0014\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 2.0217e-05 - val_loss: 0.0014\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.9965e-05 - val_loss: 0.0014\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.9162e-05 - val_loss: 0.0014\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7669e-05 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.7902e-05 - val_loss: 0.0014\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.7629e-05 - val_loss: 0.0014\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.8089e-05 - val_loss: 0.0014\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.7179e-05 - val_loss: 0.0014\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.6511e-05 - val_loss: 0.0014\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.9014e-05 - val_loss: 0.0014\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.6289e-05 - val_loss: 0.0014\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.7136e-05 - val_loss: 0.0014\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.6353e-05 - val_loss: 0.0014\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5566e-05 - val_loss: 0.0014\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5975e-05 - val_loss: 0.0014\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.6267e-05 - val_loss: 0.0014\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.4926e-05 - val_loss: 0.0014\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5153e-05 - val_loss: 0.0014\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.7738e-05 - val_loss: 0.0014\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.4799e-05 - val_loss: 0.0014\n",
            "training:  lstm_att_cv  df:  14\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/26 [=========>....................] - ETA: 0s - loss: 0.0010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 9ms/step - loss: 8.2373e-04 - val_loss: 3.0705e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6690e-04 - val_loss: 5.9577e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3377e-04 - val_loss: 2.3118e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.5599e-04 - val_loss: 2.4959e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.5523e-04 - val_loss: 4.7358e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3875e-04 - val_loss: 2.5044e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9313e-04 - val_loss: 3.4233e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.2061e-04 - val_loss: 2.0957e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1525e-04 - val_loss: 3.2393e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1852e-04 - val_loss: 2.3046e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0241e-04 - val_loss: 2.1776e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8850e-04 - val_loss: 6.8733e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0134e-04 - val_loss: 6.4792e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9829e-04 - val_loss: 3.9825e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7259e-04 - val_loss: 2.1028e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8520e-04 - val_loss: 2.2404e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1459e-04 - val_loss: 2.7379e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6958e-04 - val_loss: 2.0143e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9361e-04 - val_loss: 2.3148e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6730e-04 - val_loss: 4.5780e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0993e-04 - val_loss: 2.2634e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8583e-04 - val_loss: 2.5287e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6555e-04 - val_loss: 2.2564e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7863e-04 - val_loss: 2.1918e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1475e-04 - val_loss: 2.9245e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7738e-04 - val_loss: 2.0691e-04\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8672e-04 - val_loss: 2.2454e-04\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6748e-04 - val_loss: 3.1763e-04\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8286e-04 - val_loss: 2.0782e-04\n",
            "Epoch 30/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8087e-04 - val_loss: 2.0670e-04\n",
            "Epoch 31/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.5603e-04 - val_loss: 2.1921e-04\n",
            "Epoch 32/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6445e-04 - val_loss: 2.5224e-04\n",
            "Epoch 33/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6873e-04 - val_loss: 2.6598e-04\n",
            "training:  lstm_att_cv  df:  15\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0902e-05 - val_loss: 7.7428e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6088e-05 - val_loss: 7.6844e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3905e-05 - val_loss: 7.4194e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4279e-05 - val_loss: 8.0812e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4422e-05 - val_loss: 6.4080e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3743e-05 - val_loss: 7.3379e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3600e-05 - val_loss: 8.2645e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2720e-05 - val_loss: 6.9079e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3037e-05 - val_loss: 7.4016e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2906e-05 - val_loss: 6.4552e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1796e-05 - val_loss: 5.4942e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2123e-05 - val_loss: 6.3380e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1713e-05 - val_loss: 5.7542e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1244e-05 - val_loss: 7.4267e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1100e-05 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1403e-05 - val_loss: 0.0010\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0377e-05 - val_loss: 0.0011\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0252e-05 - val_loss: 0.0014\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0501e-05 - val_loss: 0.0013\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9480e-06 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0283e-05 - val_loss: 0.0017\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0764e-06 - val_loss: 0.0018\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2587e-06 - val_loss: 0.0024\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1184e-06 - val_loss: 0.0029\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0415e-06 - val_loss: 0.0038\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1498e-06 - val_loss: 0.0044\n",
            "training:  lstm_att_cv  df:  16\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 3.5251e-05 - val_loss: 0.0177\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4311e-05 - val_loss: 0.0216\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2942e-05 - val_loss: 0.0209\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0560e-05 - val_loss: 0.0251\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9511e-05 - val_loss: 0.0274\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1911e-05 - val_loss: 0.0290\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0207e-05 - val_loss: 0.0290\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9778e-05 - val_loss: 0.0298\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9205e-05 - val_loss: 0.0333\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8801e-05 - val_loss: 0.0306\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0492e-05 - val_loss: 0.0325\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9254e-05 - val_loss: 0.0290\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9674e-05 - val_loss: 0.0335\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8770e-05 - val_loss: 0.0271\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9413e-05 - val_loss: 0.0258\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9520e-05 - val_loss: 0.0268\n",
            "training:  lstm_att_cv  df:  17\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 4.1427e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3404e-05 - val_loss: 0.0363\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.1308e-05 - val_loss: 0.0379\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 9.9558e-06 - val_loss: 0.0382\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 9.2408e-06 - val_loss: 0.0389\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.3531e-06 - val_loss: 0.0371\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.2732e-06 - val_loss: 0.0412\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.2023e-06 - val_loss: 0.0437\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.3583e-06 - val_loss: 0.0487\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.6450e-06 - val_loss: 0.0479\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.6512e-06 - val_loss: 0.0475\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.2621e-06 - val_loss: 0.0518\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.4987e-06 - val_loss: 0.0542\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.1690e-06 - val_loss: 0.0597\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.1688e-06 - val_loss: 0.0611\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.1731e-06 - val_loss: 0.0610\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.1452e-06 - val_loss: 0.0591\n",
            "training:  lstm_att_cv  df:  18\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/174 [..............................] - ETA: 1s - loss: 0.0274"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 7ms/step - loss: 7.7386e-04 - val_loss: 1.8952e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.6335e-04 - val_loss: 1.8983e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.4803e-04 - val_loss: 2.0314e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.3656e-04 - val_loss: 1.9895e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2998e-04 - val_loss: 2.1224e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.3772e-04 - val_loss: 1.9245e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.3159e-04 - val_loss: 1.8827e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1608e-04 - val_loss: 1.8466e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1987e-04 - val_loss: 1.9312e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1708e-04 - val_loss: 1.8845e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1676e-04 - val_loss: 1.9240e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2363e-04 - val_loss: 1.8696e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1580e-04 - val_loss: 1.8223e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1311e-04 - val_loss: 1.8996e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1729e-04 - val_loss: 1.8938e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2677e-04 - val_loss: 2.1899e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2206e-04 - val_loss: 1.9040e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0723e-04 - val_loss: 2.1787e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1596e-04 - val_loss: 2.3223e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1482e-04 - val_loss: 1.8440e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0620e-04 - val_loss: 1.7724e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1210e-04 - val_loss: 1.8080e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1736e-04 - val_loss: 1.7917e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1797e-04 - val_loss: 1.8211e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0846e-04 - val_loss: 2.1964e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0948e-04 - val_loss: 1.9402e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1604e-04 - val_loss: 1.9652e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1213e-04 - val_loss: 2.2641e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0743e-04 - val_loss: 2.0251e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2150e-04 - val_loss: 1.9852e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1104e-04 - val_loss: 1.9535e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1809e-04 - val_loss: 2.0633e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0845e-04 - val_loss: 1.9303e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0955e-04 - val_loss: 1.8691e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0795e-04 - val_loss: 1.7855e-04\n",
            "Epoch 36/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1340e-04 - val_loss: 2.0783e-04\n",
            "training:  lstm_att_cv  df:  19\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/47 [====>.........................] - ETA: 0s - loss: 2.3550e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0777e-04 - val_loss: 2.0427e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9346e-04 - val_loss: 1.9450e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9651e-04 - val_loss: 1.7093e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9687e-04 - val_loss: 1.8221e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1372e-04 - val_loss: 1.7191e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9504e-04 - val_loss: 1.8448e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9949e-04 - val_loss: 2.4803e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8740e-04 - val_loss: 1.7696e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8688e-04 - val_loss: 2.2158e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8578e-04 - val_loss: 1.8014e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9733e-04 - val_loss: 1.9130e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8981e-04 - val_loss: 1.9497e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8964e-04 - val_loss: 2.6706e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7912e-04 - val_loss: 2.7950e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9422e-04 - val_loss: 1.9227e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9999e-04 - val_loss: 2.0036e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9188e-04 - val_loss: 2.3344e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9691e-04 - val_loss: 1.7869e-04\n",
            "training:  lstm_att_cv  df:  20\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/151 [>.............................] - ETA: 0s - loss: 3.9292e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 4.7966e-05 - val_loss: 0.0022\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.4105e-05 - val_loss: 0.0023\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.1556e-05 - val_loss: 0.0022\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 1.0371e-05 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.1208e-06 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 8.0661e-06 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 8.3678e-06 - val_loss: 0.0021\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.7086e-06 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.4833e-06 - val_loss: 0.0022\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.4425e-06 - val_loss: 0.0022\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.6152e-06 - val_loss: 0.0023\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.7138e-06 - val_loss: 0.0021\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.4365e-06 - val_loss: 0.0022\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.7184e-06 - val_loss: 0.0022\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.4485e-06 - val_loss: 0.0022\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.6823e-06 - val_loss: 0.0022\n",
            "Epoch 17/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.4061e-06 - val_loss: 0.0023\n",
            "Epoch 18/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.2396e-06 - val_loss: 0.0025\n",
            "Epoch 19/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.3081e-06 - val_loss: 0.0025\n",
            "Epoch 20/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.8245e-06 - val_loss: 0.0024\n",
            "training:  lstm_att_cv  df:  21\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 9.7111e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 7ms/step - loss: 1.0606e-04 - val_loss: 3.4567e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.6664e-05 - val_loss: 3.5723e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.4169e-05 - val_loss: 3.0557e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.2172e-05 - val_loss: 1.9860e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.1776e-05 - val_loss: 1.7697e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.2240e-05 - val_loss: 2.3384e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.2196e-05 - val_loss: 5.9840e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8470e-05 - val_loss: 4.8709e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.8771e-05 - val_loss: 4.3425e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.9872e-05 - val_loss: 4.5722e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.7304e-05 - val_loss: 4.1516e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.9678e-05 - val_loss: 3.1410e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8814e-05 - val_loss: 6.0242e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8129e-05 - val_loss: 7.9967e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.7885e-05 - val_loss: 5.9926e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.9653e-05 - val_loss: 5.6017e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.5888e-05 - val_loss: 5.5895e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.9152e-05 - val_loss: 7.8960e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.7913e-05 - val_loss: 5.6335e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.7291e-05 - val_loss: 6.8680e-04\n",
            "training:  lstm_att_cv  df:  22\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 2s 7ms/step - loss: 3.0939e-05 - val_loss: 0.0032\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.6879e-05 - val_loss: 0.0037\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.8103e-05 - val_loss: 0.0045\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.9625e-05 - val_loss: 0.0046\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.7888e-05 - val_loss: 0.0053\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.7147e-05 - val_loss: 0.0057\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5912e-05 - val_loss: 0.0064\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4816e-05 - val_loss: 0.0079\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4884e-05 - val_loss: 0.0073\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5574e-05 - val_loss: 0.0089\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4925e-05 - val_loss: 0.0097\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5612e-05 - val_loss: 0.0124\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4236e-05 - val_loss: 0.0133\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4456e-05 - val_loss: 0.0151\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.6242e-05 - val_loss: 0.0159\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4949e-05 - val_loss: 0.0149\n",
            "training:  lstm_att_cv  df:  23\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 2.2826e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.2695e-04 - val_loss: 1.4182e-05\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6700e-04 - val_loss: 6.7709e-06\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5767e-04 - val_loss: 1.0712e-05\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6407e-04 - val_loss: 8.1030e-06\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6946e-04 - val_loss: 6.1929e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5653e-04 - val_loss: 2.6395e-05\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5484e-04 - val_loss: 3.6094e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5955e-04 - val_loss: 1.4966e-05\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4962e-04 - val_loss: 1.0112e-05\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5720e-04 - val_loss: 2.5465e-05\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5119e-04 - val_loss: 8.0937e-06\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5440e-04 - val_loss: 5.3298e-06\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4991e-04 - val_loss: 6.0419e-06\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5247e-04 - val_loss: 8.9130e-06\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5106e-04 - val_loss: 7.1292e-06\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6021e-04 - val_loss: 1.2752e-05\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4917e-04 - val_loss: 1.0317e-05\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5678e-04 - val_loss: 1.7088e-05\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5709e-04 - val_loss: 1.2169e-05\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4864e-04 - val_loss: 9.8764e-06\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5212e-04 - val_loss: 9.9462e-06\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5438e-04 - val_loss: 7.6679e-06\n",
            "Epoch 23/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4829e-04 - val_loss: 7.8849e-06\n",
            "Epoch 24/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.3990e-04 - val_loss: 8.5236e-06\n",
            "Epoch 25/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4512e-04 - val_loss: 6.3608e-06\n",
            "Epoch 26/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5316e-04 - val_loss: 7.4374e-06\n",
            "Epoch 27/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5298e-04 - val_loss: 1.1695e-05\n",
            "training:  lstm_att_cv  df:  24\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 2.0267e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.6711e-04 - val_loss: 9.3053e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.5715e-04 - val_loss: 9.1171e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4284e-04 - val_loss: 8.6941e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4177e-04 - val_loss: 7.7042e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3631e-04 - val_loss: 9.4596e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4620e-04 - val_loss: 1.0392e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3674e-04 - val_loss: 1.0749e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4626e-04 - val_loss: 7.8863e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3622e-04 - val_loss: 7.6577e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3636e-04 - val_loss: 7.7337e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3484e-04 - val_loss: 1.0310e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3575e-04 - val_loss: 7.8826e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3022e-04 - val_loss: 8.2871e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3802e-04 - val_loss: 9.4412e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3051e-04 - val_loss: 8.0831e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3558e-04 - val_loss: 1.0222e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3291e-04 - val_loss: 9.6566e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2992e-04 - val_loss: 8.0994e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3502e-04 - val_loss: 8.0749e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3314e-04 - val_loss: 7.5743e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3261e-04 - val_loss: 7.7654e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4378e-04 - val_loss: 9.6318e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3403e-04 - val_loss: 7.5732e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3150e-04 - val_loss: 7.3441e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3179e-04 - val_loss: 1.2721e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4184e-04 - val_loss: 8.1335e-05\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3270e-04 - val_loss: 7.6825e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3980e-04 - val_loss: 1.3891e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3074e-04 - val_loss: 7.6603e-05\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3848e-04 - val_loss: 7.6682e-05\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2912e-04 - val_loss: 7.6760e-05\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3503e-04 - val_loss: 8.4053e-05\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3293e-04 - val_loss: 1.3282e-04\n",
            "Epoch 34/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3038e-04 - val_loss: 1.1079e-04\n",
            "Epoch 35/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2935e-04 - val_loss: 7.8225e-05\n",
            "Epoch 36/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2781e-04 - val_loss: 8.7058e-05\n",
            "Epoch 37/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3242e-04 - val_loss: 1.0141e-04\n",
            "Epoch 38/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3016e-04 - val_loss: 7.7202e-05\n",
            "Epoch 39/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3548e-04 - val_loss: 7.8352e-05\n",
            "training:  lstm_att_cv  df:  25\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/53 [====>.........................] - ETA: 0s - loss: 3.0275e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6559e-04 - val_loss: 3.1537e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5958e-04 - val_loss: 3.1520e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5691e-04 - val_loss: 3.1381e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5760e-04 - val_loss: 4.2170e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.7245e-04 - val_loss: 3.2008e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4998e-04 - val_loss: 3.1882e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4973e-04 - val_loss: 3.3642e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4417e-04 - val_loss: 3.2126e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5555e-04 - val_loss: 3.8578e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4927e-04 - val_loss: 3.1650e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.5861e-04 - val_loss: 3.4612e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5482e-04 - val_loss: 3.2912e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.7135e-04 - val_loss: 3.5651e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4615e-04 - val_loss: 2.9341e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4573e-04 - val_loss: 3.0861e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.4909e-04 - val_loss: 3.2929e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4499e-04 - val_loss: 3.1240e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4872e-04 - val_loss: 3.4195e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5237e-04 - val_loss: 3.0058e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3759e-04 - val_loss: 2.9714e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3119e-04 - val_loss: 3.1026e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3943e-04 - val_loss: 3.2667e-04\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 2.5081e-04 - val_loss: 3.2012e-04\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5515e-04 - val_loss: 3.0931e-04\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4892e-04 - val_loss: 3.2699e-04\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5091e-04 - val_loss: 3.0645e-04\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4389e-04 - val_loss: 2.9881e-04\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5834e-04 - val_loss: 3.1914e-04\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.7693e-04 - val_loss: 3.2848e-04\n",
            "training:  lstm_att_cv  df:  26\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/58 [===>..........................] - ETA: 0s - loss: 1.8107e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7628e-04 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5289e-04 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4615e-04 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5211e-04 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5247e-04 - val_loss: 0.0016\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5010e-04 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4382e-04 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3734e-04 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4998e-04 - val_loss: 0.0016\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3294e-04 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4361e-04 - val_loss: 0.0016\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2909e-04 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3648e-04 - val_loss: 0.0016\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3721e-04 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4346e-04 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2641e-04 - val_loss: 0.0016\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2917e-04 - val_loss: 0.0016\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3525e-04 - val_loss: 0.0016\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2475e-04 - val_loss: 0.0016\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3103e-04 - val_loss: 0.0016\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3226e-04 - val_loss: 0.0016\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4798e-04 - val_loss: 0.0015\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2151e-04 - val_loss: 0.0015\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2713e-04 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2887e-04 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3173e-04 - val_loss: 0.0016\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2504e-04 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2354e-04 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3823e-04 - val_loss: 0.0015\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2877e-04 - val_loss: 0.0015\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2983e-04 - val_loss: 0.0015\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2917e-04 - val_loss: 0.0015\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3256e-04 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2162e-04 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2785e-04 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2234e-04 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2492e-04 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2750e-04 - val_loss: 0.0015\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3804e-04 - val_loss: 0.0015\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2380e-04 - val_loss: 0.0015\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2616e-04 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1795e-04 - val_loss: 0.0015\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2429e-04 - val_loss: 0.0014\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1908e-04 - val_loss: 0.0015\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2213e-04 - val_loss: 0.0014\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1034e-04 - val_loss: 0.0015\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2244e-04 - val_loss: 0.0015\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2711e-04 - val_loss: 0.0015\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2836e-04 - val_loss: 0.0015\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4567e-04 - val_loss: 0.0015\n",
            "Epoch 51/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2490e-04 - val_loss: 0.0015\n",
            "Epoch 52/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2913e-04 - val_loss: 0.0015\n",
            "Epoch 53/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2328e-04 - val_loss: 0.0015\n",
            "Epoch 54/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1598e-04 - val_loss: 0.0015\n",
            "Epoch 55/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2344e-04 - val_loss: 0.0015\n",
            "Epoch 56/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2911e-04 - val_loss: 0.0015\n",
            "Epoch 57/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1787e-04 - val_loss: 0.0014\n",
            "Epoch 58/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3485e-04 - val_loss: 0.0015\n",
            "Epoch 59/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2241e-04 - val_loss: 0.0014\n",
            "Epoch 60/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2522e-04 - val_loss: 0.0015\n",
            "Epoch 61/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4348e-04 - val_loss: 0.0015\n",
            "Epoch 62/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1903e-04 - val_loss: 0.0015\n",
            "Epoch 63/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1908e-04 - val_loss: 0.0015\n",
            "Epoch 64/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2109e-04 - val_loss: 0.0015\n",
            "Epoch 65/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2631e-04 - val_loss: 0.0015\n",
            "Epoch 66/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2495e-04 - val_loss: 0.0015\n",
            "Epoch 67/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.2495e-04 - val_loss: 0.0015\n",
            "Epoch 68/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1660e-04 - val_loss: 0.0015\n",
            "Epoch 69/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2391e-04 - val_loss: 0.0014\n",
            "Epoch 70/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1267e-04 - val_loss: 0.0015\n",
            "Epoch 71/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2215e-04 - val_loss: 0.0015\n",
            "Epoch 72/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4162e-04 - val_loss: 0.0015\n",
            "training:  lstm_att_cv  df:  27\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/46 [====>.........................] - ETA: 0s - loss: 4.7945e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 8ms/step - loss: 3.6723e-04 - val_loss: 6.4274e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6623e-04 - val_loss: 6.3447e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7288e-04 - val_loss: 6.2428e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7685e-04 - val_loss: 4.8879e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.2619e-04 - val_loss: 3.9889e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3520e-04 - val_loss: 5.0643e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2941e-04 - val_loss: 4.7097e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3934e-04 - val_loss: 4.2790e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4012e-04 - val_loss: 4.8696e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2517e-04 - val_loss: 4.1866e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4133e-04 - val_loss: 5.8861e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8912e-04 - val_loss: 4.9509e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3255e-04 - val_loss: 4.3857e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2800e-04 - val_loss: 6.1084e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3912e-04 - val_loss: 5.2722e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2091e-04 - val_loss: 4.4456e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2717e-04 - val_loss: 4.7152e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3592e-04 - val_loss: 4.1966e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1436e-04 - val_loss: 4.8878e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2867e-04 - val_loss: 4.6753e-04\n",
            "training:  lstm_att_cv  df:  28\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/171 [..............................] - ETA: 1s - loss: 2.2656e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 7ms/step - loss: 8.8755e-05 - val_loss: 4.8873e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.8041e-05 - val_loss: 5.7464e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.9756e-05 - val_loss: 5.2540e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.5361e-05 - val_loss: 5.0967e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.4587e-05 - val_loss: 4.6131e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.1006e-05 - val_loss: 4.8595e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.1780e-05 - val_loss: 4.4601e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.2495e-05 - val_loss: 4.5228e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.0368e-05 - val_loss: 4.5375e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.1869e-05 - val_loss: 4.6052e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.0406e-05 - val_loss: 4.4693e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8674e-05 - val_loss: 4.8910e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.9053e-05 - val_loss: 4.5888e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.9264e-05 - val_loss: 6.1835e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.0092e-05 - val_loss: 5.7504e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0360e-05 - val_loss: 5.1228e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.4068e-05 - val_loss: 5.4639e-04\n",
            "Epoch 18/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8775e-05 - val_loss: 6.7284e-04\n",
            "Epoch 19/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.7646e-05 - val_loss: 6.2562e-04\n",
            "Epoch 20/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.6808e-05 - val_loss: 6.1378e-04\n",
            "Epoch 21/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.1761e-05 - val_loss: 6.2333e-04\n",
            "Epoch 22/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.2874e-05 - val_loss: 8.7235e-04\n",
            "training:  lstm_att_cv  df:  29\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 6.0878e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 4.2181e-05 - val_loss: 0.0024\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 3.2663e-05 - val_loss: 0.0029\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 3.2993e-05 - val_loss: 0.0033\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 3.0221e-05 - val_loss: 0.0034\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.7826e-05 - val_loss: 0.0032\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.6900e-05 - val_loss: 0.0034\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.7312e-05 - val_loss: 0.0038\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.8195e-05 - val_loss: 0.0039\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6862e-05 - val_loss: 0.0038\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.6128e-05 - val_loss: 0.0041\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6883e-05 - val_loss: 0.0043\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4383e-05 - val_loss: 0.0042\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4578e-05 - val_loss: 0.0048\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.7119e-05 - val_loss: 0.0047\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5849e-05 - val_loss: 0.0051\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4685e-05 - val_loss: 0.0053\n",
            "training:  lstm_att_cv  df:  30\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 2.1905e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3880e-05 - val_loss: 0.0062\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3817e-05 - val_loss: 0.0061\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4939e-05 - val_loss: 0.0064\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3901e-05 - val_loss: 0.0063\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2136e-05 - val_loss: 0.0064\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2321e-05 - val_loss: 0.0064\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2773e-05 - val_loss: 0.0067\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3968e-05 - val_loss: 0.0070\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1466e-05 - val_loss: 0.0075\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4685e-05 - val_loss: 0.0082\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4048e-05 - val_loss: 0.0081\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2837e-05 - val_loss: 0.0082\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3390e-05 - val_loss: 0.0076\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2345e-05 - val_loss: 0.0085\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.1913e-05 - val_loss: 0.0085\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2195e-05 - val_loss: 0.0083\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2019e-05 - val_loss: 0.0094\n",
            "training:  lstm_att_cv  df:  31\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.5483e-05 - val_loss: 7.2691e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3711e-05 - val_loss: 6.6111e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.7313e-05 - val_loss: 6.9763e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1787e-05 - val_loss: 4.3277e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1939e-05 - val_loss: 3.0078e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2730e-05 - val_loss: 4.5496e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2459e-05 - val_loss: 3.9613e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2828e-05 - val_loss: 3.0920e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5516e-05 - val_loss: 5.2474e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1481e-05 - val_loss: 4.5900e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1542e-05 - val_loss: 3.7397e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1372e-05 - val_loss: 3.3418e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8196e-05 - val_loss: 5.9347e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0216e-05 - val_loss: 3.5782e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5135e-05 - val_loss: 3.4199e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0312e-05 - val_loss: 3.6671e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0274e-05 - val_loss: 2.9057e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8882e-05 - val_loss: 5.8710e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0015e-05 - val_loss: 3.6225e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0748e-05 - val_loss: 4.6793e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0622e-05 - val_loss: 3.3993e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9225e-05 - val_loss: 4.0237e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2345e-05 - val_loss: 3.5807e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9432e-05 - val_loss: 4.7368e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1943e-05 - val_loss: 3.3255e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1094e-05 - val_loss: 4.1086e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0509e-05 - val_loss: 3.1536e-05\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8703e-05 - val_loss: 5.2319e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1519e-05 - val_loss: 4.5083e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1197e-05 - val_loss: 6.0636e-05\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8386e-05 - val_loss: 3.4418e-05\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7653e-05 - val_loss: 4.8103e-05\n",
            "training:  lstm_att_cv  df:  32\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.9910e-05 - val_loss: 2.7909e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.9108e-05 - val_loss: 2.6275e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.8689e-05 - val_loss: 2.5157e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.6374e-05 - val_loss: 3.2451e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.7189e-05 - val_loss: 2.3484e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.6465e-05 - val_loss: 2.4941e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3632e-05 - val_loss: 2.5720e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4661e-05 - val_loss: 2.5513e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4710e-05 - val_loss: 2.5581e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4076e-05 - val_loss: 4.5544e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4293e-05 - val_loss: 5.8355e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3790e-05 - val_loss: 3.5811e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3986e-05 - val_loss: 4.1945e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4198e-05 - val_loss: 5.3696e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2714e-05 - val_loss: 4.3656e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4182e-05 - val_loss: 5.1862e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2675e-05 - val_loss: 6.8101e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4027e-05 - val_loss: 6.8490e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2839e-05 - val_loss: 0.0010\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1827e-05 - val_loss: 0.0011\n",
            "training:  lstm_att_cv  df:  33\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 6.0264e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 7ms/step - loss: 1.1664e-04 - val_loss: 4.0677e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 1.0905e-04 - val_loss: 2.9791e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 1.0339e-04 - val_loss: 1.9113e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.6359e-05 - val_loss: 3.3536e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4140e-05 - val_loss: 1.3805e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2080e-05 - val_loss: 8.3885e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4452e-05 - val_loss: 1.7743e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4875e-05 - val_loss: 2.1266e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3900e-05 - val_loss: 2.0373e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9611e-05 - val_loss: 2.5101e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.8745e-05 - val_loss: 3.0012e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3034e-05 - val_loss: 2.0142e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3175e-05 - val_loss: 1.5118e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.3443e-05 - val_loss: 2.1140e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2094e-05 - val_loss: 2.5043e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.8182e-05 - val_loss: 5.4881e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9609e-05 - val_loss: 2.7161e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.8554e-05 - val_loss: 2.0477e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0515e-05 - val_loss: 2.9856e-04\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 1s 7ms/step - loss: 9.2364e-05 - val_loss: 7.7889e-04\n",
            "training:  lstm_att_cv  df:  34\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 7.2215e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 7ms/step - loss: 3.1408e-05 - val_loss: 3.6794e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.5672e-05 - val_loss: 3.4976e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4234e-05 - val_loss: 3.5050e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.3789e-05 - val_loss: 3.7359e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2479e-05 - val_loss: 4.6316e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1312e-05 - val_loss: 4.3390e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2945e-05 - val_loss: 5.9802e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1836e-05 - val_loss: 5.8610e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1552e-05 - val_loss: 6.8660e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1084e-05 - val_loss: 7.2501e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1677e-05 - val_loss: 7.3542e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1717e-05 - val_loss: 6.8712e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0162e-05 - val_loss: 7.1364e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0320e-05 - val_loss: 6.9683e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0141e-05 - val_loss: 7.2627e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9407e-05 - val_loss: 7.5458e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9474e-05 - val_loss: 8.5636e-04\n",
            "training:  lstm_att_cv  df:  35\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/314 [..............................] - ETA: 3s - loss: 1.1023e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 2s 7ms/step - loss: 4.2036e-05 - val_loss: 0.0029\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.2378e-05 - val_loss: 0.0026\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.2203e-05 - val_loss: 0.0030\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9305e-05 - val_loss: 0.0030\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.0130e-05 - val_loss: 0.0033\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7406e-05 - val_loss: 0.0032\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8735e-05 - val_loss: 0.0038\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8423e-05 - val_loss: 0.0037\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8749e-05 - val_loss: 0.0049\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8155e-05 - val_loss: 0.0051\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7658e-05 - val_loss: 0.0067\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7509e-05 - val_loss: 0.0067\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7454e-05 - val_loss: 0.0074\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8743e-05 - val_loss: 0.0071\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6986e-05 - val_loss: 0.0084\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7215e-05 - val_loss: 0.0062\n",
            "Epoch 17/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7819e-05 - val_loss: 0.0071\n",
            "training:  lstm_att_cv  df:  36\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/118 [=>............................] - ETA: 0s - loss: 6.8348e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 5.6472e-05 - val_loss: 0.0046\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 5.1952e-05 - val_loss: 0.0041\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.7339e-05 - val_loss: 0.0043\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.4975e-05 - val_loss: 0.0051\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.6027e-05 - val_loss: 0.0052\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.5507e-05 - val_loss: 0.0049\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.6498e-05 - val_loss: 0.0052\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.4957e-05 - val_loss: 0.0054\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.5742e-05 - val_loss: 0.0050\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.3058e-05 - val_loss: 0.0063\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.3511e-05 - val_loss: 0.0060\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5118e-05 - val_loss: 0.0064\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4206e-05 - val_loss: 0.0068\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.3372e-05 - val_loss: 0.0069\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.3772e-05 - val_loss: 0.0075\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.5056e-05 - val_loss: 0.0082\n",
            "Epoch 17/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.2091e-05 - val_loss: 0.0074\n",
            "training:  lstm_att_cv  df:  37\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 1s - loss: 6.6852e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 1s 7ms/step - loss: 3.3812e-05 - val_loss: 0.0064\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1377e-05 - val_loss: 0.0054\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1145e-05 - val_loss: 0.0055\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.3438e-05 - val_loss: 0.0070\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1035e-05 - val_loss: 0.0067\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1160e-05 - val_loss: 0.0053\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1157e-05 - val_loss: 0.0044\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.3423e-05 - val_loss: 0.0068\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1597e-05 - val_loss: 0.0057\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1682e-05 - val_loss: 0.0063\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0723e-05 - val_loss: 0.0066\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9126e-05 - val_loss: 0.0069\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9459e-05 - val_loss: 0.0083\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0189e-05 - val_loss: 0.0077\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9879e-05 - val_loss: 0.0086\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.4878e-05 - val_loss: 0.0077\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1146e-05 - val_loss: 0.0091\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9885e-05 - val_loss: 0.0078\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1708e-05 - val_loss: 0.0066\n",
            "Epoch 20/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9923e-05 - val_loss: 0.0084\n",
            "Epoch 21/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9724e-05 - val_loss: 0.0081\n",
            "Epoch 22/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0484e-05 - val_loss: 0.0084\n",
            "training:  lstm_att_cv  df:  38\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/99 [=>............................] - ETA: 0s - loss: 0.0046"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 8.1350e-04 - val_loss: 4.8468e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 2.0137e-04 - val_loss: 4.7234e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.8432e-04 - val_loss: 4.3338e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7444e-04 - val_loss: 4.9118e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.8011e-04 - val_loss: 4.9084e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.8424e-04 - val_loss: 4.3624e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6818e-04 - val_loss: 4.4331e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7815e-04 - val_loss: 4.7881e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.7461e-04 - val_loss: 4.5987e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.5974e-04 - val_loss: 4.4725e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6386e-04 - val_loss: 4.3819e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6833e-04 - val_loss: 4.4200e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6248e-04 - val_loss: 4.3907e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6317e-04 - val_loss: 4.5148e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6269e-04 - val_loss: 4.4994e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6732e-04 - val_loss: 4.3969e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6464e-04 - val_loss: 4.3379e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 1.6013e-04 - val_loss: 4.5591e-04\n",
            "training:  lstm_att_cv  df:  39\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 1.5908e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 7ms/step - loss: 5.1640e-05 - val_loss: 2.7219e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.5156e-05 - val_loss: 1.9914e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.1216e-05 - val_loss: 2.8451e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.7579e-05 - val_loss: 2.2395e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.0352e-05 - val_loss: 3.3891e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.7771e-05 - val_loss: 2.5436e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.8750e-05 - val_loss: 3.1386e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9257e-05 - val_loss: 4.0989e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8742e-05 - val_loss: 5.3680e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8306e-05 - val_loss: 3.2570e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.5220e-05 - val_loss: 2.8032e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.5879e-05 - val_loss: 0.0019\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 6.8086e-05 - val_loss: 9.3222e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.5941e-05 - val_loss: 0.0010\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.5660e-05 - val_loss: 7.1154e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6307e-05 - val_loss: 7.4282e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6347e-05 - val_loss: 5.4613e-04\n",
            "training:  lstm_att_cv  df:  40\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 0s - loss: 4.2522e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 4.6442e-05 - val_loss: 2.3737e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.9650e-05 - val_loss: 2.3450e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 4.0072e-05 - val_loss: 2.3794e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.7944e-05 - val_loss: 2.4836e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.7813e-05 - val_loss: 3.1169e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.6103e-05 - val_loss: 2.5748e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5365e-05 - val_loss: 2.5692e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.8227e-05 - val_loss: 3.2517e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6554e-05 - val_loss: 3.1753e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.6762e-05 - val_loss: 3.5824e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5432e-05 - val_loss: 4.1550e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5775e-05 - val_loss: 4.4708e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4907e-05 - val_loss: 4.2815e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4323e-05 - val_loss: 4.9634e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5930e-05 - val_loss: 5.1738e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4789e-05 - val_loss: 3.8471e-04\n",
            "Epoch 17/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4569e-05 - val_loss: 4.1985e-04\n",
            "training:  lstm_att_cv  df:  41\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 0s - loss: 3.9021e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5642e-05 - val_loss: 5.0510e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3843e-05 - val_loss: 4.5523e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4446e-05 - val_loss: 4.8554e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4493e-05 - val_loss: 5.8525e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4470e-05 - val_loss: 5.6519e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3072e-05 - val_loss: 4.4349e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3145e-05 - val_loss: 4.4322e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3124e-05 - val_loss: 4.7524e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4589e-05 - val_loss: 5.3839e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.7456e-05 - val_loss: 5.9823e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5444e-05 - val_loss: 7.2435e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4185e-05 - val_loss: 5.3704e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4701e-05 - val_loss: 7.7523e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.6572e-05 - val_loss: 5.6591e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3046e-05 - val_loss: 6.8944e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5800e-05 - val_loss: 5.9179e-04\n",
            "Epoch 17/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.2222e-05 - val_loss: 5.7562e-04\n",
            "Epoch 18/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.5227e-05 - val_loss: 4.7816e-04\n",
            "Epoch 19/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.3395e-05 - val_loss: 6.3055e-04\n",
            "Epoch 20/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4108e-05 - val_loss: 5.7375e-04\n",
            "Epoch 21/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4832e-05 - val_loss: 7.6426e-04\n",
            "Epoch 22/200\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 3.4815e-05 - val_loss: 5.2035e-04\n",
            "training:  lstm_att_cv  df:  42\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 5.1859e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 7ms/step - loss: 4.4092e-05 - val_loss: 0.0014\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.9407e-05 - val_loss: 8.9244e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5620e-05 - val_loss: 0.0026\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5327e-05 - val_loss: 0.0015\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5745e-05 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3738e-05 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3707e-05 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4134e-05 - val_loss: 0.0027\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4481e-05 - val_loss: 0.0040\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4528e-05 - val_loss: 0.0030\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5146e-05 - val_loss: 0.0047\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.2340e-05 - val_loss: 0.0049\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.2880e-05 - val_loss: 0.0064\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3858e-05 - val_loss: 0.0068\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.2273e-05 - val_loss: 0.0068\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4251e-05 - val_loss: 0.0082\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.2515e-05 - val_loss: 0.0056\n",
            "training:  lstm_att_cv  df:  43\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/64 [===>..........................] - ETA: 0s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 8ms/step - loss: 6.1908e-04 - val_loss: 5.5963e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 4.1734e-04 - val_loss: 9.1103e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.6827e-04 - val_loss: 7.1868e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.4030e-04 - val_loss: 7.5546e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.4823e-04 - val_loss: 7.4970e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.2242e-04 - val_loss: 8.2855e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.4230e-04 - val_loss: 8.2261e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.2892e-04 - val_loss: 7.4539e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.3491e-04 - val_loss: 8.1446e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.2637e-04 - val_loss: 7.0012e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.2147e-04 - val_loss: 7.3259e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1562e-04 - val_loss: 7.9522e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.2360e-04 - val_loss: 7.3255e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.2804e-04 - val_loss: 7.0649e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 3.2793e-04 - val_loss: 8.3950e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.2584e-04 - val_loss: 9.5166e-04\n",
            "training:  lstm_att_cv  df:  44\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 2.3275e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 7ms/step - loss: 1.5201e-04 - val_loss: 1.6257e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4383e-04 - val_loss: 1.5987e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3889e-04 - val_loss: 1.7898e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4151e-04 - val_loss: 1.9004e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4344e-04 - val_loss: 1.8110e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4072e-04 - val_loss: 1.6913e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4036e-04 - val_loss: 2.4057e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4020e-04 - val_loss: 2.1618e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4424e-04 - val_loss: 1.6780e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4262e-04 - val_loss: 1.8578e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4100e-04 - val_loss: 1.6791e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4174e-04 - val_loss: 1.7059e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3873e-04 - val_loss: 1.7222e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4170e-04 - val_loss: 1.8105e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3747e-04 - val_loss: 1.7452e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3925e-04 - val_loss: 1.7516e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4433e-04 - val_loss: 1.7869e-04\n",
            "training:  lstm_att_cv  df:  45\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/174 [>.............................] - ETA: 1s - loss: 2.4957e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2625e-04 - val_loss: 1.9727e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0801e-04 - val_loss: 1.8605e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0514e-04 - val_loss: 1.8797e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9847e-04 - val_loss: 1.8373e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9648e-04 - val_loss: 1.8799e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9482e-04 - val_loss: 1.8821e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9205e-04 - val_loss: 1.9280e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9298e-04 - val_loss: 2.0846e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9167e-04 - val_loss: 1.7827e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9131e-04 - val_loss: 1.7798e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9759e-04 - val_loss: 2.0356e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8874e-04 - val_loss: 1.7758e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8600e-04 - val_loss: 1.7801e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9320e-04 - val_loss: 1.7811e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9044e-04 - val_loss: 1.9492e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0112e-04 - val_loss: 2.0269e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8889e-04 - val_loss: 1.8638e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8495e-04 - val_loss: 1.8787e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8996e-04 - val_loss: 1.9418e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8853e-04 - val_loss: 1.8161e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9154e-04 - val_loss: 1.8029e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9225e-04 - val_loss: 1.8144e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.8858e-04 - val_loss: 1.8437e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9022e-04 - val_loss: 1.8439e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9063e-04 - val_loss: 2.1512e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9477e-04 - val_loss: 1.9455e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9096e-04 - val_loss: 1.8388e-04\n",
            "training:  lstm_att_cv  df:  46\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7922e-05 - val_loss: 1.4251e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1364e-05 - val_loss: 1.0719e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1359e-05 - val_loss: 9.8783e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6337e-05 - val_loss: 1.2095e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0364e-05 - val_loss: 9.9830e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1427e-05 - val_loss: 1.0292e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0731e-05 - val_loss: 1.0097e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6130e-05 - val_loss: 1.0471e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6821e-05 - val_loss: 1.0246e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1802e-05 - val_loss: 1.4473e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8799e-05 - val_loss: 1.0089e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6559e-05 - val_loss: 1.1591e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7927e-05 - val_loss: 1.0489e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8447e-05 - val_loss: 1.5001e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2692e-05 - val_loss: 1.3059e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0672e-05 - val_loss: 1.1653e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0711e-05 - val_loss: 1.0647e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9277e-05 - val_loss: 1.0108e-04\n",
            "training:  lstm_att_cv  df:  47\n",
            "Training model: lstm_att_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.5421e-04 - val_loss: 2.3824e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3705e-04 - val_loss: 3.2070e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4135e-04 - val_loss: 2.2446e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3259e-04 - val_loss: 1.6488e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3751e-04 - val_loss: 1.9649e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3336e-04 - val_loss: 1.7512e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3598e-04 - val_loss: 2.3280e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3625e-04 - val_loss: 2.3997e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3168e-04 - val_loss: 1.9994e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2963e-04 - val_loss: 2.1858e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3269e-04 - val_loss: 1.9955e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3141e-04 - val_loss: 2.2303e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3531e-04 - val_loss: 2.2662e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3090e-04 - val_loss: 2.0554e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2919e-04 - val_loss: 1.8654e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3042e-04 - val_loss: 1.5484e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2570e-04 - val_loss: 1.4335e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2978e-04 - val_loss: 2.2931e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3654e-04 - val_loss: 1.8224e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2932e-04 - val_loss: 1.8984e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3199e-04 - val_loss: 1.5217e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3290e-04 - val_loss: 2.8101e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2889e-04 - val_loss: 1.8586e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2792e-04 - val_loss: 2.1619e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3018e-04 - val_loss: 1.4813e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3148e-04 - val_loss: 1.6998e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2683e-04 - val_loss: 1.7983e-04\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3204e-04 - val_loss: 1.6751e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3011e-04 - val_loss: 1.7402e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3360e-04 - val_loss: 1.6622e-04\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3031e-04 - val_loss: 2.7804e-04\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3456e-04 - val_loss: 2.4784e-04\n",
            "training:  lstm_att_cv  df:  48\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.9804e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2853e-04 - val_loss: 7.3950e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2452e-04 - val_loss: 8.2760e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2675e-04 - val_loss: 8.1842e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2231e-04 - val_loss: 8.0023e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2424e-04 - val_loss: 9.3720e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2377e-04 - val_loss: 8.8177e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2027e-04 - val_loss: 7.6783e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1920e-04 - val_loss: 7.8475e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2130e-04 - val_loss: 8.3410e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2489e-04 - val_loss: 7.7660e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1977e-04 - val_loss: 7.2675e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2126e-04 - val_loss: 8.2132e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2203e-04 - val_loss: 7.4795e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2448e-04 - val_loss: 7.2225e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1940e-04 - val_loss: 7.6447e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1729e-04 - val_loss: 8.0955e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2156e-04 - val_loss: 8.1770e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2010e-04 - val_loss: 7.8055e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1986e-04 - val_loss: 9.0200e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2300e-04 - val_loss: 8.9242e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2036e-04 - val_loss: 8.9954e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1861e-04 - val_loss: 8.4361e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1734e-04 - val_loss: 7.7088e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2032e-04 - val_loss: 9.7408e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2140e-04 - val_loss: 7.5591e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2017e-04 - val_loss: 8.3285e-05\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1711e-04 - val_loss: 8.2338e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1885e-04 - val_loss: 7.8765e-05\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2204e-04 - val_loss: 8.7706e-05\n",
            "training:  lstm_att_cv  df:  49\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 2.5640e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 9.7758e-05 - val_loss: 9.0156e-05\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.4472e-05 - val_loss: 9.5259e-05\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3528e-05 - val_loss: 9.6260e-05\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2985e-05 - val_loss: 1.0346e-04\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3703e-05 - val_loss: 1.0498e-04\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1598e-05 - val_loss: 1.0400e-04\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.4743e-05 - val_loss: 9.9503e-05\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0075e-05 - val_loss: 9.4155e-05\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.6393e-05 - val_loss: 1.2938e-04\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1331e-05 - val_loss: 9.5259e-05\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0333e-05 - val_loss: 9.3861e-05\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1473e-05 - val_loss: 9.3781e-05\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.2434e-05 - val_loss: 1.0587e-04\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3690e-05 - val_loss: 9.3918e-05\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.5660e-05 - val_loss: 1.0113e-04\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.5547e-05 - val_loss: 9.6276e-05\n",
            "training:  lstm_att_cv  df:  50\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6781e-04 - val_loss: 0.0018\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.4884e-04 - val_loss: 0.0018\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8079e-04 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9337e-04 - val_loss: 0.0019\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5252e-04 - val_loss: 0.0017\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8692e-04 - val_loss: 0.0018\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9019e-04 - val_loss: 0.0018\n",
            "training:  lstm_att_cv  df:  51\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/106 [=>............................] - ETA: 0s - loss: 4.3086e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.8033e-04 - val_loss: 6.5770e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.4631e-04 - val_loss: 6.7001e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2989e-04 - val_loss: 6.6565e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3352e-04 - val_loss: 6.6907e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3699e-04 - val_loss: 6.7075e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3711e-04 - val_loss: 6.7514e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3007e-04 - val_loss: 6.8808e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3151e-04 - val_loss: 6.6783e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.3522e-04 - val_loss: 6.6592e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.1842e-04 - val_loss: 7.9611e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3068e-04 - val_loss: 7.2598e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2857e-04 - val_loss: 6.6283e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2471e-04 - val_loss: 6.6008e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2866e-04 - val_loss: 6.5928e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2623e-04 - val_loss: 6.7275e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2409e-04 - val_loss: 6.7945e-04\n",
            "training:  lstm_att_cv  df:  52\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 2.8507e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 7ms/step - loss: 4.1823e-05 - val_loss: 2.8819e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.6288e-05 - val_loss: 3.1946e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4241e-05 - val_loss: 3.2403e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4013e-05 - val_loss: 3.4592e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.3277e-05 - val_loss: 3.8592e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1599e-05 - val_loss: 3.6841e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1968e-05 - val_loss: 3.7331e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1661e-05 - val_loss: 4.0886e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0998e-05 - val_loss: 4.3211e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0809e-05 - val_loss: 4.2381e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0852e-05 - val_loss: 4.5529e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0287e-05 - val_loss: 4.3133e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0054e-05 - val_loss: 4.3230e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0588e-05 - val_loss: 4.2086e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0296e-05 - val_loss: 4.4039e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0061e-05 - val_loss: 4.8290e-04\n",
            "training:  lstm_att_cv  df:  53\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/79 [==>...........................] - ETA: 0s - loss: 1.4756e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 1.1208e-04 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.0097e-04 - val_loss: 0.0011\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.9235e-05 - val_loss: 0.0013\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.0458e-05 - val_loss: 0.0013\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.0003e-05 - val_loss: 0.0011\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.9516e-05 - val_loss: 0.0011\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 9.3584e-05 - val_loss: 0.0013\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.6303e-05 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.5791e-05 - val_loss: 0.0013\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.8161e-05 - val_loss: 0.0014\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.5487e-05 - val_loss: 0.0013\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.7900e-05 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.8444e-05 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0877e-05 - val_loss: 0.0015\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.7368e-05 - val_loss: 0.0013\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.5427e-05 - val_loss: 0.0016\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.8482e-05 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.5246e-05 - val_loss: 0.0016\n",
            "Epoch 19/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.1559e-05 - val_loss: 0.0017\n",
            "Epoch 20/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.6645e-05 - val_loss: 0.0016\n",
            "Epoch 21/200\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 8.3964e-05 - val_loss: 0.0019\n",
            "training:  lstm_att_cv  df:  54\n",
            "Training model: lstm_att_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 8.6943e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 7ms/step - loss: 5.9535e-05 - val_loss: 5.4787e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1765e-05 - val_loss: 4.3800e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0822e-05 - val_loss: 4.0136e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.2029e-05 - val_loss: 4.4354e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0271e-05 - val_loss: 3.5160e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0043e-05 - val_loss: 4.7645e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1530e-05 - val_loss: 2.5889e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9240e-05 - val_loss: 5.9612e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9795e-05 - val_loss: 2.5632e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9564e-05 - val_loss: 3.4570e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1060e-05 - val_loss: 4.6660e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8499e-05 - val_loss: 3.4349e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9632e-05 - val_loss: 3.2762e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8753e-05 - val_loss: 2.8245e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1230e-05 - val_loss: 2.7840e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9486e-05 - val_loss: 3.4078e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0497e-05 - val_loss: 2.8132e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8889e-05 - val_loss: 2.7392e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8894e-05 - val_loss: 3.4098e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.1550e-05 - val_loss: 2.1144e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8934e-05 - val_loss: 3.1644e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9857e-05 - val_loss: 2.3600e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7559e-05 - val_loss: 2.3971e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8549e-05 - val_loss: 2.9384e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8940e-05 - val_loss: 3.7062e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7345e-05 - val_loss: 2.9910e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7328e-05 - val_loss: 3.1335e-04\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7452e-05 - val_loss: 3.0146e-04\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8727e-05 - val_loss: 2.6724e-04\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0096e-05 - val_loss: 2.6346e-04\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0572e-05 - val_loss: 3.3131e-04\n",
            "Epoch 32/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7959e-05 - val_loss: 3.3751e-04\n",
            "Epoch 33/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9145e-05 - val_loss: 4.3534e-04\n",
            "Epoch 34/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.8863e-05 - val_loss: 3.0268e-04\n",
            "Epoch 35/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0115e-05 - val_loss: 3.2561e-04\n",
            "build model: lstm_att_ohlcv  features: 5\n",
            "training:  lstm_att_ohlcv\n",
            "lstm_att_ohlcv  should train on stocks\n",
            "training dfs: 55\n",
            "training:  lstm_att_ohlcv  df:  0\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 6s 12ms/step - loss: 0.0184 - val_loss: 0.3323\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.2252\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0801\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0886\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.6379e-04 - val_loss: 0.0844\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.9332e-04 - val_loss: 0.0786\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 7.3820e-04 - val_loss: 0.0871\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.6030e-04 - val_loss: 0.0912\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.3573e-04 - val_loss: 0.0753\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.9705e-04 - val_loss: 0.0926\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.5360e-04 - val_loss: 0.0847\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.8742e-04 - val_loss: 0.0837\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.7052e-04 - val_loss: 0.0877\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.5703e-04 - val_loss: 0.0872\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.2503e-04 - val_loss: 0.0860\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.7109e-04 - val_loss: 0.0855\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.0088e-04 - val_loss: 0.0843\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.0382e-04 - val_loss: 0.0889\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.7325e-04 - val_loss: 0.0832\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.4467e-04 - val_loss: 0.0834\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.1773e-04 - val_loss: 0.0750\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.2151e-04 - val_loss: 0.0810\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0693e-04 - val_loss: 0.0806\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.1822e-04 - val_loss: 0.0765\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 1.0098e-04 - val_loss: 0.0769\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 1.2539e-04 - val_loss: 0.0849\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.2239e-04 - val_loss: 0.0786\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0613e-04 - val_loss: 0.0771\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.6764e-05 - val_loss: 0.0752\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.8588e-05 - val_loss: 0.0720\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.7333e-05 - val_loss: 0.0774\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.0265e-05 - val_loss: 0.0773\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.6282e-05 - val_loss: 0.0793\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.5386e-05 - val_loss: 0.0757\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.4154e-05 - val_loss: 0.0715\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.0470e-05 - val_loss: 0.0726\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.3079e-05 - val_loss: 0.0729\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.7204e-05 - val_loss: 0.0763\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.6420e-05 - val_loss: 0.0793\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 6.2099e-05 - val_loss: 0.0689\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.1095e-05 - val_loss: 0.0751\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.9501e-05 - val_loss: 0.0711\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.2388e-05 - val_loss: 0.0566\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.8111e-05 - val_loss: 0.0740\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.4476e-05 - val_loss: 0.0729\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.7188e-05 - val_loss: 0.0645\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.4968e-05 - val_loss: 0.0754\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.9500e-05 - val_loss: 0.0817\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.0143e-05 - val_loss: 0.0758\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.5010e-05 - val_loss: 0.0616\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.3140e-05 - val_loss: 0.0696\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.3104e-05 - val_loss: 0.0709\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.8716e-05 - val_loss: 0.0665\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.8638e-05 - val_loss: 0.0618\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.7122e-05 - val_loss: 0.0698\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.3449e-05 - val_loss: 0.0497\n",
            "Epoch 57/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.2238e-05 - val_loss: 0.0284\n",
            "Epoch 58/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.4780e-05 - val_loss: 0.0415\n",
            "Epoch 59/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6210e-05 - val_loss: 0.0542\n",
            "Epoch 60/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.9171e-05 - val_loss: 0.0509\n",
            "Epoch 61/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 5.9548e-05 - val_loss: 0.0978\n",
            "Epoch 62/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.0704e-05 - val_loss: 0.0728\n",
            "Epoch 63/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.4488e-05 - val_loss: 0.0673\n",
            "Epoch 64/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.9025e-05 - val_loss: 0.0782\n",
            "Epoch 65/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.0780e-05 - val_loss: 0.0644\n",
            "Epoch 66/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 5.3227e-05 - val_loss: 0.0955\n",
            "Epoch 67/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.7523e-05 - val_loss: 0.1026\n",
            "Epoch 68/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.1028e-05 - val_loss: 0.0905\n",
            "Epoch 69/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.3202e-05 - val_loss: 0.1028\n",
            "Epoch 70/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6598e-05 - val_loss: 0.0990\n",
            "Epoch 71/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.1956e-05 - val_loss: 0.0765\n",
            "Epoch 72/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6106e-05 - val_loss: 0.0937\n",
            "training:  lstm_att_ohlcv  df:  1\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 9/80 [==>...........................] - ETA: 0s - loss: 0.0010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 9ms/step - loss: 3.7277e-04 - val_loss: 0.2009\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.3492e-04 - val_loss: 0.1857\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 7.4596e-05 - val_loss: 0.1525\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.3462e-05 - val_loss: 0.1380\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.2308e-05 - val_loss: 0.1349\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.4643e-05 - val_loss: 0.1278\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.2295e-05 - val_loss: 0.1281\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.9458e-05 - val_loss: 0.1268\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.2780e-05 - val_loss: 0.1306\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.1771e-05 - val_loss: 0.1264\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.0495e-05 - val_loss: 0.1246\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.9423e-05 - val_loss: 0.1342\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.3015e-05 - val_loss: 0.1252\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.0025e-05 - val_loss: 0.1290\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.1592e-05 - val_loss: 0.1454\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.4192e-05 - val_loss: 0.1374\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.7606e-05 - val_loss: 0.1378\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.4891e-05 - val_loss: 0.1493\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.9354e-05 - val_loss: 0.1432\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.7014e-05 - val_loss: 0.1404\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.8405e-05 - val_loss: 0.1459\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.8227e-05 - val_loss: 0.1394\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.0773e-05 - val_loss: 0.1534\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3306e-05 - val_loss: 0.1465\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.2488e-05 - val_loss: 0.1497\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.4158e-05 - val_loss: 0.1363\n",
            "training:  lstm_att_ohlcv  df:  2\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 1.9118e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 8ms/step - loss: 2.0576e-05 - val_loss: 0.1055\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 7.2067e-06 - val_loss: 0.1081\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 7.1311e-06 - val_loss: 0.1111\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 6.5056e-06 - val_loss: 0.1146\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 6.0139e-06 - val_loss: 0.1125\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.7822e-06 - val_loss: 0.1156\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.2968e-06 - val_loss: 0.1161\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.6334e-06 - val_loss: 0.1151\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.2686e-06 - val_loss: 0.1203\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.9719e-06 - val_loss: 0.1182\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.3218e-06 - val_loss: 0.1221\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.5352e-06 - val_loss: 0.1234\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.1022e-06 - val_loss: 0.1186\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.8131e-06 - val_loss: 0.1224\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.6680e-06 - val_loss: 0.1170\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.0004e-06 - val_loss: 0.1204\n",
            "training:  lstm_att_ohlcv  df:  3\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4083e-04 - val_loss: 0.0263\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5737e-04 - val_loss: 0.0232\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3195e-04 - val_loss: 0.0249\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0579e-04 - val_loss: 0.0231\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0291e-04 - val_loss: 0.0220\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0893e-04 - val_loss: 0.0234\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0015e-04 - val_loss: 0.0212\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0675e-04 - val_loss: 0.0255\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.9479e-05 - val_loss: 0.0208\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4081e-05 - val_loss: 0.0186\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4216e-05 - val_loss: 0.0203\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5567e-05 - val_loss: 0.0174\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1534e-05 - val_loss: 0.0145\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2702e-05 - val_loss: 0.0139\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3545e-05 - val_loss: 0.0152\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2294e-05 - val_loss: 0.0125\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0194e-05 - val_loss: 0.0130\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5559e-05 - val_loss: 0.0180\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7652e-05 - val_loss: 0.0181\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6364e-05 - val_loss: 0.0201\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4883e-05 - val_loss: 0.0155\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4250e-05 - val_loss: 0.0140\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2940e-05 - val_loss: 0.0161\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9511e-05 - val_loss: 0.0132\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.6489e-05 - val_loss: 0.0154\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8328e-05 - val_loss: 0.0148\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4195e-05 - val_loss: 0.0132\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2232e-05 - val_loss: 0.0154\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2321e-05 - val_loss: 0.0104\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.6369e-05 - val_loss: 0.0200\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2576e-05 - val_loss: 0.0193\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8362e-05 - val_loss: 0.0289\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1950e-05 - val_loss: 0.0220\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1096e-05 - val_loss: 0.0169\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.6874e-05 - val_loss: 0.0047\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1427e-05 - val_loss: 0.0212\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3569e-05 - val_loss: 0.0220\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9443e-05 - val_loss: 0.0214\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8756e-05 - val_loss: 0.0202\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1698e-05 - val_loss: 0.0235\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1206e-05 - val_loss: 0.0398\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2242e-05 - val_loss: 0.0293\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9562e-05 - val_loss: 0.0269\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1623e-05 - val_loss: 0.0108\n",
            "Epoch 45/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5645e-05 - val_loss: 0.0289\n",
            "Epoch 46/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8438e-05 - val_loss: 0.0222\n",
            "Epoch 47/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4823e-05 - val_loss: 0.0562\n",
            "Epoch 48/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2076e-05 - val_loss: 0.0360\n",
            "Epoch 49/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4928e-05 - val_loss: 0.0371\n",
            "Epoch 50/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7959e-05 - val_loss: 0.0533\n",
            "training:  lstm_att_ohlcv  df:  4\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.4155e-04 - val_loss: 1.0852e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4931e-04 - val_loss: 9.1611e-05\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2897e-04 - val_loss: 8.2709e-05\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2306e-04 - val_loss: 9.6757e-05\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2773e-04 - val_loss: 1.4699e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1969e-04 - val_loss: 1.2880e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3577e-04 - val_loss: 1.0365e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2683e-04 - val_loss: 1.3509e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2210e-04 - val_loss: 1.5603e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2842e-04 - val_loss: 8.9506e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1955e-04 - val_loss: 1.1672e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1936e-04 - val_loss: 1.6945e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2852e-04 - val_loss: 1.0441e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2343e-04 - val_loss: 1.2297e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2225e-04 - val_loss: 7.9755e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1457e-04 - val_loss: 1.7769e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1576e-04 - val_loss: 1.6430e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1557e-04 - val_loss: 8.6337e-05\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1357e-04 - val_loss: 8.2616e-05\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1501e-04 - val_loss: 9.6894e-05\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2009e-04 - val_loss: 1.0679e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1617e-04 - val_loss: 1.2153e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1239e-04 - val_loss: 1.0192e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1953e-04 - val_loss: 9.7118e-05\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1899e-04 - val_loss: 1.0835e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0851e-04 - val_loss: 1.7544e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1049e-04 - val_loss: 7.6697e-05\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1383e-04 - val_loss: 8.2484e-05\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0435e-04 - val_loss: 8.1580e-05\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1734e-04 - val_loss: 1.0410e-04\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0640e-04 - val_loss: 7.9340e-05\n",
            "Epoch 32/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0852e-04 - val_loss: 1.1029e-04\n",
            "Epoch 33/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1522e-04 - val_loss: 8.5432e-05\n",
            "Epoch 34/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0607e-04 - val_loss: 7.7444e-05\n",
            "Epoch 35/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0535e-04 - val_loss: 1.5685e-04\n",
            "Epoch 36/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1307e-04 - val_loss: 1.0942e-04\n",
            "Epoch 37/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0213e-04 - val_loss: 7.6353e-05\n",
            "Epoch 38/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0947e-04 - val_loss: 1.4705e-04\n",
            "Epoch 39/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0899e-04 - val_loss: 8.5874e-05\n",
            "Epoch 40/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0534e-04 - val_loss: 8.9709e-05\n",
            "Epoch 41/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0762e-04 - val_loss: 7.6925e-05\n",
            "Epoch 42/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0445e-04 - val_loss: 1.2435e-04\n",
            "Epoch 43/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2060e-04 - val_loss: 1.2456e-04\n",
            "Epoch 44/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0597e-04 - val_loss: 9.2385e-05\n",
            "Epoch 45/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0285e-04 - val_loss: 8.0607e-05\n",
            "Epoch 46/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0810e-04 - val_loss: 1.1257e-04\n",
            "Epoch 47/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0369e-04 - val_loss: 7.6355e-05\n",
            "Epoch 48/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0164e-04 - val_loss: 1.0615e-04\n",
            "Epoch 49/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0307e-04 - val_loss: 7.4628e-05\n",
            "Epoch 50/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 9.4339e-05 - val_loss: 8.7760e-05\n",
            "Epoch 51/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0999e-04 - val_loss: 9.9647e-05\n",
            "Epoch 52/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0339e-04 - val_loss: 7.3442e-05\n",
            "Epoch 53/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0468e-04 - val_loss: 7.7561e-05\n",
            "Epoch 54/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0023e-04 - val_loss: 7.9181e-05\n",
            "Epoch 55/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0215e-04 - val_loss: 8.3793e-05\n",
            "Epoch 56/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0086e-04 - val_loss: 2.2163e-04\n",
            "Epoch 57/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0060e-04 - val_loss: 8.6319e-05\n",
            "Epoch 58/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.5418e-05 - val_loss: 1.1704e-04\n",
            "Epoch 59/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0398e-04 - val_loss: 8.6044e-05\n",
            "Epoch 60/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 9.8348e-05 - val_loss: 1.1431e-04\n",
            "Epoch 61/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 9.8194e-05 - val_loss: 9.6301e-05\n",
            "Epoch 62/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0562e-04 - val_loss: 1.1173e-04\n",
            "Epoch 63/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.6383e-05 - val_loss: 7.8698e-05\n",
            "Epoch 64/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.9091e-05 - val_loss: 8.6288e-05\n",
            "Epoch 65/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.7136e-05 - val_loss: 7.2496e-05\n",
            "Epoch 66/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0102e-04 - val_loss: 1.2915e-04\n",
            "Epoch 67/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.9542e-05 - val_loss: 7.8831e-05\n",
            "Epoch 68/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0442e-04 - val_loss: 1.3632e-04\n",
            "Epoch 69/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 9.5967e-05 - val_loss: 7.7288e-05\n",
            "Epoch 70/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.9680e-05 - val_loss: 1.0570e-04\n",
            "Epoch 71/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0014e-04 - val_loss: 7.5861e-05\n",
            "Epoch 72/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 9.9063e-05 - val_loss: 9.5113e-05\n",
            "Epoch 73/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.3592e-05 - val_loss: 8.8310e-05\n",
            "Epoch 74/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.4873e-05 - val_loss: 7.9524e-05\n",
            "Epoch 75/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.7025e-05 - val_loss: 7.5004e-05\n",
            "Epoch 76/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.6315e-05 - val_loss: 1.0488e-04\n",
            "Epoch 77/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.6274e-05 - val_loss: 8.4720e-05\n",
            "Epoch 78/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.3652e-05 - val_loss: 8.5618e-05\n",
            "Epoch 79/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.3647e-05 - val_loss: 7.6415e-05\n",
            "Epoch 80/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 9.8702e-05 - val_loss: 8.4774e-05\n",
            "training:  lstm_att_ohlcv  df:  5\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3232e-05 - val_loss: 2.1926e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8268e-05 - val_loss: 2.4217e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6557e-05 - val_loss: 2.7365e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6602e-05 - val_loss: 2.4314e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4773e-05 - val_loss: 3.6437e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5687e-05 - val_loss: 4.0938e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4188e-05 - val_loss: 4.7762e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3593e-05 - val_loss: 4.4118e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2886e-05 - val_loss: 5.3538e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4421e-05 - val_loss: 7.5193e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2761e-05 - val_loss: 0.0010\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3483e-05 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2768e-05 - val_loss: 0.0023\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3483e-05 - val_loss: 0.0028\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3895e-05 - val_loss: 0.0037\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3412e-05 - val_loss: 0.0060\n",
            "training:  lstm_att_ohlcv  df:  6\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 2.4310e-04 - val_loss: 3.1392e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5186e-04 - val_loss: 1.4921e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4296e-04 - val_loss: 1.4665e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4091e-04 - val_loss: 1.2519e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3849e-04 - val_loss: 1.7447e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2409e-04 - val_loss: 1.5421e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2944e-04 - val_loss: 1.1063e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2504e-04 - val_loss: 1.0311e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1688e-04 - val_loss: 1.0783e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2375e-04 - val_loss: 1.8161e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2082e-04 - val_loss: 1.0745e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2620e-04 - val_loss: 1.1338e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2922e-04 - val_loss: 1.2627e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2016e-04 - val_loss: 1.3080e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2845e-04 - val_loss: 1.0923e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1926e-04 - val_loss: 3.1690e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2216e-04 - val_loss: 1.0945e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2365e-04 - val_loss: 1.1044e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2127e-04 - val_loss: 1.5898e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1430e-04 - val_loss: 1.8598e-04\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1789e-04 - val_loss: 1.5360e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2655e-04 - val_loss: 1.0770e-04\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1633e-04 - val_loss: 1.2175e-04\n",
            "training:  lstm_att_ohlcv  df:  7\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 1.0795e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 5.4287e-05 - val_loss: 4.9237e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9262e-05 - val_loss: 8.8341e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.2531e-05 - val_loss: 9.8624e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.2241e-05 - val_loss: 0.0013\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.1633e-05 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.0576e-05 - val_loss: 0.0026\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.2022e-05 - val_loss: 0.0023\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.1521e-05 - val_loss: 0.0024\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.0412e-05 - val_loss: 0.0035\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.9908e-05 - val_loss: 0.0046\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.1657e-05 - val_loss: 0.0050\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.7334e-05 - val_loss: 0.0041\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.0444e-05 - val_loss: 0.0047\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.1397e-05 - val_loss: 0.0041\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.9357e-05 - val_loss: 0.0076\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.7494e-05 - val_loss: 0.0088\n",
            "training:  lstm_att_ohlcv  df:  8\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 9/68 [==>...........................] - ETA: 0s - loss: 2.0918e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 1.7157e-04 - val_loss: 0.0023\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3743e-04 - val_loss: 0.0026\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2256e-04 - val_loss: 0.0034\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1264e-04 - val_loss: 0.0041\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.5386e-04 - val_loss: 0.0046\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1870e-04 - val_loss: 0.0037\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1279e-04 - val_loss: 0.0043\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0391e-04 - val_loss: 0.0043\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0898e-04 - val_loss: 0.0040\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2162e-04 - val_loss: 0.0054\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0763e-04 - val_loss: 0.0051\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0079e-04 - val_loss: 0.0049\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0427e-04 - val_loss: 0.0041\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0125e-04 - val_loss: 0.0048\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0169e-04 - val_loss: 0.0067\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1652e-04 - val_loss: 0.0054\n",
            "training:  lstm_att_ohlcv  df:  9\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  9/162 [>.............................] - ETA: 1s - loss: 2.6653e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 3.9885e-05 - val_loss: 0.0247\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.5167e-05 - val_loss: 0.0515\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.3879e-05 - val_loss: 0.0654\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1808e-05 - val_loss: 0.0652\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1868e-05 - val_loss: 0.0690\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1726e-05 - val_loss: 0.0692\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.8081e-06 - val_loss: 0.0707\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.5014e-06 - val_loss: 0.0631\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.6673e-06 - val_loss: 0.0660\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.7506e-06 - val_loss: 0.0614\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0295e-05 - val_loss: 0.0619\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1057e-05 - val_loss: 0.0591\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.3352e-06 - val_loss: 0.0508\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 8.6703e-06 - val_loss: 0.0503\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 8.9446e-06 - val_loss: 0.0576\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 8.9255e-06 - val_loss: 0.0496\n",
            "training:  lstm_att_ohlcv  df:  10\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2539e-05 - val_loss: 4.6057e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.7973e-05 - val_loss: 5.5457e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9251e-05 - val_loss: 6.2771e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.7013e-05 - val_loss: 8.7712e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5861e-05 - val_loss: 8.0730e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5447e-05 - val_loss: 8.3027e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4510e-05 - val_loss: 6.5758e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6099e-05 - val_loss: 8.7471e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8104e-05 - val_loss: 7.5584e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5514e-05 - val_loss: 6.3691e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4771e-05 - val_loss: 9.8294e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6119e-05 - val_loss: 8.0189e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.7788e-05 - val_loss: 5.9589e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5113e-05 - val_loss: 9.2247e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3659e-05 - val_loss: 9.7033e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5833e-05 - val_loss: 7.3255e-04\n",
            "training:  lstm_att_ohlcv  df:  11\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0666e-04 - val_loss: 7.9571e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4972e-05 - val_loss: 7.3162e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5559e-05 - val_loss: 1.9646e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3332e-05 - val_loss: 8.3933e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3064e-05 - val_loss: 1.6079e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4588e-05 - val_loss: 8.0991e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2618e-05 - val_loss: 2.3759e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6612e-05 - val_loss: 8.0679e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2837e-05 - val_loss: 2.5974e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7397e-05 - val_loss: 8.6436e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8150e-05 - val_loss: 7.7182e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0014e-05 - val_loss: 1.3265e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6943e-05 - val_loss: 7.9757e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5960e-05 - val_loss: 2.1190e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0388e-05 - val_loss: 2.6719e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8773e-05 - val_loss: 1.0128e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5182e-05 - val_loss: 7.0307e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0198e-05 - val_loss: 8.1468e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3909e-05 - val_loss: 7.4818e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4016e-05 - val_loss: 8.8953e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0812e-05 - val_loss: 1.3362e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1598e-04 - val_loss: 8.8569e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7911e-05 - val_loss: 8.9720e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8761e-05 - val_loss: 1.2463e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8460e-05 - val_loss: 7.0204e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6707e-05 - val_loss: 1.1708e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0286e-05 - val_loss: 7.7444e-05\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5082e-05 - val_loss: 7.3942e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6399e-05 - val_loss: 6.9662e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8675e-05 - val_loss: 7.1609e-05\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6244e-05 - val_loss: 1.4897e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6375e-05 - val_loss: 1.0165e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3140e-05 - val_loss: 8.9158e-05\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4194e-05 - val_loss: 1.0376e-04\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7480e-05 - val_loss: 7.8490e-05\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9466e-05 - val_loss: 3.0181e-04\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8897e-05 - val_loss: 1.2376e-04\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6850e-05 - val_loss: 1.3479e-04\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5657e-05 - val_loss: 2.1217e-04\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0904e-05 - val_loss: 7.5386e-05\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2512e-05 - val_loss: 9.1491e-05\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4190e-05 - val_loss: 7.1746e-05\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8469e-05 - val_loss: 7.8862e-05\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6415e-05 - val_loss: 1.7275e-04\n",
            "training:  lstm_att_ohlcv  df:  12\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0014    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0032\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0027\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0025\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0021\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0032\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0023\n",
            "training:  lstm_att_ohlcv  df:  13\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  9/132 [=>............................] - ETA: 0s - loss: 1.2151e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 8ms/step - loss: 4.2956e-05 - val_loss: 0.0023\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.3733e-05 - val_loss: 0.0039\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.1044e-05 - val_loss: 0.0048\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7596e-05 - val_loss: 0.0049\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7501e-05 - val_loss: 0.0053\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6547e-05 - val_loss: 0.0052\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5262e-05 - val_loss: 0.0051\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5647e-05 - val_loss: 0.0048\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6575e-05 - val_loss: 0.0047\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5535e-05 - val_loss: 0.0047\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5368e-05 - val_loss: 0.0047\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4551e-05 - val_loss: 0.0048\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3507e-05 - val_loss: 0.0048\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4185e-05 - val_loss: 0.0047\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3991e-05 - val_loss: 0.0046\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4314e-05 - val_loss: 0.0047\n",
            "training:  lstm_att_ohlcv  df:  14\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "15/26 [================>.............] - ETA: 0s - loss: 8.3496e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 9ms/step - loss: 8.5483e-04 - val_loss: 2.6446e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 5.6708e-04 - val_loss: 5.6553e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.9404e-04 - val_loss: 3.3444e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.5844e-04 - val_loss: 2.6322e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.6934e-04 - val_loss: 5.6328e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3587e-04 - val_loss: 2.5743e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3404e-04 - val_loss: 3.1742e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8555e-04 - val_loss: 2.7585e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.0664e-04 - val_loss: 2.4531e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6755e-04 - val_loss: 2.6400e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9558e-04 - val_loss: 2.4236e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9432e-04 - val_loss: 2.8302e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1620e-04 - val_loss: 3.5502e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3245e-04 - val_loss: 2.4076e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8102e-04 - val_loss: 2.8600e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8726e-04 - val_loss: 2.3561e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.4527e-04 - val_loss: 2.7595e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7926e-04 - val_loss: 2.6115e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6433e-04 - val_loss: 2.3395e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6409e-04 - val_loss: 2.2709e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8446e-04 - val_loss: 3.4466e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9093e-04 - val_loss: 4.0720e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7897e-04 - val_loss: 2.7284e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7806e-04 - val_loss: 2.7100e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7432e-04 - val_loss: 3.1233e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.4591e-04 - val_loss: 2.7575e-04\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6511e-04 - val_loss: 2.6749e-04\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8651e-04 - val_loss: 2.5755e-04\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6837e-04 - val_loss: 2.6860e-04\n",
            "Epoch 30/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7986e-04 - val_loss: 2.6703e-04\n",
            "Epoch 31/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.5308e-04 - val_loss: 2.4280e-04\n",
            "Epoch 32/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1924e-04 - val_loss: 4.7223e-04\n",
            "Epoch 33/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6012e-04 - val_loss: 2.9602e-04\n",
            "Epoch 34/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6725e-04 - val_loss: 3.9148e-04\n",
            "Epoch 35/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6343e-04 - val_loss: 2.4535e-04\n",
            "training:  lstm_att_ohlcv  df:  15\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2160e-05 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.9021e-06 - val_loss: 0.0021\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3581e-06 - val_loss: 0.0021\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9466e-06 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2490e-06 - val_loss: 0.0023\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8833e-06 - val_loss: 0.0024\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4631e-06 - val_loss: 0.0023\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5991e-06 - val_loss: 0.0025\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3836e-06 - val_loss: 0.0024\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4663e-06 - val_loss: 0.0025\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2105e-06 - val_loss: 0.0028\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0520e-06 - val_loss: 0.0030\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1297e-06 - val_loss: 0.0030\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6967e-06 - val_loss: 0.0031\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8036e-06 - val_loss: 0.0034\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9512e-06 - val_loss: 0.0036\n",
            "training:  lstm_att_ohlcv  df:  16\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.7855e-05 - val_loss: 0.0228\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9166e-05 - val_loss: 0.0270\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9224e-05 - val_loss: 0.0250\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7670e-05 - val_loss: 0.0336\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7695e-05 - val_loss: 0.0385\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9654e-05 - val_loss: 0.0388\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6517e-05 - val_loss: 0.0484\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5175e-05 - val_loss: 0.0455\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5785e-05 - val_loss: 0.0494\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5462e-05 - val_loss: 0.0511\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4771e-05 - val_loss: 0.0592\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5266e-05 - val_loss: 0.0610\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5543e-05 - val_loss: 0.0604\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5071e-05 - val_loss: 0.0606\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3691e-05 - val_loss: 0.0719\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4127e-05 - val_loss: 0.0702\n",
            "training:  lstm_att_ohlcv  df:  17\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 3s 8ms/step - loss: 8.7163e-06 - val_loss: 0.0840\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.7755e-06 - val_loss: 0.0880\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.1680e-06 - val_loss: 0.0957\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.7029e-06 - val_loss: 0.0930\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.2803e-06 - val_loss: 0.1003\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.1018e-06 - val_loss: 0.1104\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.5853e-06 - val_loss: 0.1095\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.0683e-06 - val_loss: 0.1144\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.3498e-06 - val_loss: 0.1073\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.8800e-06 - val_loss: 0.1050\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.9930e-06 - val_loss: 0.1110\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.0741e-06 - val_loss: 0.1040\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.5151e-06 - val_loss: 0.1171\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.6046e-06 - val_loss: 0.1250\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.1874e-06 - val_loss: 0.1284\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.9113e-06 - val_loss: 0.1233\n",
            "training:  lstm_att_ohlcv  df:  18\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 8.5530e-04 - val_loss: 2.6869e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.6122e-04 - val_loss: 2.2566e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.4193e-04 - val_loss: 2.2166e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.4078e-04 - val_loss: 2.0542e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2731e-04 - val_loss: 2.5052e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3440e-04 - val_loss: 2.2775e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2286e-04 - val_loss: 2.0308e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2691e-04 - val_loss: 2.1506e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1990e-04 - val_loss: 2.2196e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1917e-04 - val_loss: 2.2175e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2648e-04 - val_loss: 2.9745e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2143e-04 - val_loss: 2.7310e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2709e-04 - val_loss: 2.2266e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2350e-04 - val_loss: 2.0252e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0768e-04 - val_loss: 2.0507e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0731e-04 - val_loss: 2.0752e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1428e-04 - val_loss: 2.5260e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0932e-04 - val_loss: 2.5350e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0759e-04 - val_loss: 2.0938e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1342e-04 - val_loss: 2.4744e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2266e-04 - val_loss: 2.3963e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1490e-04 - val_loss: 2.5492e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0855e-04 - val_loss: 2.1975e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1902e-04 - val_loss: 2.8221e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1211e-04 - val_loss: 2.1384e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1137e-04 - val_loss: 2.0691e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0394e-04 - val_loss: 1.9210e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1045e-04 - val_loss: 2.2148e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0632e-04 - val_loss: 1.9531e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0783e-04 - val_loss: 2.2340e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0373e-04 - val_loss: 2.0440e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1163e-04 - val_loss: 1.9194e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2145e-04 - val_loss: 2.1900e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1441e-04 - val_loss: 2.1007e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0994e-04 - val_loss: 2.1593e-04\n",
            "Epoch 36/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0658e-04 - val_loss: 2.1065e-04\n",
            "Epoch 37/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0723e-04 - val_loss: 2.2389e-04\n",
            "Epoch 38/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0478e-04 - val_loss: 1.9724e-04\n",
            "Epoch 39/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0745e-04 - val_loss: 2.0536e-04\n",
            "Epoch 40/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1203e-04 - val_loss: 2.2303e-04\n",
            "Epoch 41/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0119e-04 - val_loss: 2.0242e-04\n",
            "Epoch 42/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0256e-04 - val_loss: 2.1668e-04\n",
            "Epoch 43/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0377e-04 - val_loss: 2.3703e-04\n",
            "Epoch 44/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1102e-04 - val_loss: 2.4556e-04\n",
            "Epoch 45/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0616e-04 - val_loss: 2.0156e-04\n",
            "Epoch 46/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9736e-04 - val_loss: 2.1061e-04\n",
            "Epoch 47/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9456e-04 - val_loss: 2.2900e-04\n",
            "training:  lstm_att_ohlcv  df:  19\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 8/47 [====>.........................] - ETA: 0s - loss: 2.3016e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 9ms/step - loss: 2.3114e-04 - val_loss: 2.2569e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0145e-04 - val_loss: 2.3533e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0428e-04 - val_loss: 2.1556e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0399e-04 - val_loss: 1.8392e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0113e-04 - val_loss: 2.0370e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.2597e-04 - val_loss: 1.9610e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1185e-04 - val_loss: 1.8236e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9286e-04 - val_loss: 2.6113e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8511e-04 - val_loss: 1.7997e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9483e-04 - val_loss: 2.4716e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7818e-04 - val_loss: 1.9145e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8282e-04 - val_loss: 2.1352e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0013e-04 - val_loss: 1.8532e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9033e-04 - val_loss: 2.0407e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8108e-04 - val_loss: 2.0319e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9186e-04 - val_loss: 2.8004e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8180e-04 - val_loss: 2.0506e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8225e-04 - val_loss: 1.8638e-04\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9269e-04 - val_loss: 1.8102e-04\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9394e-04 - val_loss: 1.9321e-04\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9034e-04 - val_loss: 1.9041e-04\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7463e-04 - val_loss: 2.3983e-04\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9387e-04 - val_loss: 1.9140e-04\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8021e-04 - val_loss: 1.9681e-04\n",
            "training:  lstm_att_ohlcv  df:  20\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  9/151 [>.............................] - ETA: 0s - loss: 3.5614e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 3.5821e-05 - val_loss: 5.6666e-04\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.2027e-06 - val_loss: 8.0894e-04\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.6685e-06 - val_loss: 0.0010\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.6916e-06 - val_loss: 0.0011\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.7961e-06 - val_loss: 0.0011\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.9714e-06 - val_loss: 0.0012\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.0198e-06 - val_loss: 0.0012\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.6768e-06 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.4647e-06 - val_loss: 0.0013\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.0533e-06 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.9158e-06 - val_loss: 0.0013\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.6478e-06 - val_loss: 0.0012\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.2943e-06 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.5742e-06 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.6886e-06 - val_loss: 0.0013\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.3315e-06 - val_loss: 0.0013\n",
            "training:  lstm_att_ohlcv  df:  21\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 1.6440e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 6.8769e-05 - val_loss: 1.4767e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.0195e-05 - val_loss: 1.4377e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.1468e-05 - val_loss: 1.2310e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.4682e-05 - val_loss: 2.8467e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.4872e-05 - val_loss: 1.3976e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.4703e-05 - val_loss: 1.7855e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.6205e-05 - val_loss: 1.1640e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3095e-05 - val_loss: 1.3349e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.7350e-05 - val_loss: 1.4562e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.4380e-05 - val_loss: 1.4577e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2367e-05 - val_loss: 3.4338e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.4302e-05 - val_loss: 2.3158e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.1924e-05 - val_loss: 1.6788e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.2719e-05 - val_loss: 1.7246e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0915e-05 - val_loss: 2.9180e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3614e-05 - val_loss: 2.4554e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1016e-05 - val_loss: 2.1003e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2379e-05 - val_loss: 1.7224e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2246e-05 - val_loss: 1.8847e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3940e-05 - val_loss: 2.1982e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3514e-05 - val_loss: 3.4653e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2718e-05 - val_loss: 2.1471e-04\n",
            "training:  lstm_att_ohlcv  df:  22\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/317 [..............................] - ETA: 3s - loss: 1.9245e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6312e-05 - val_loss: 0.0040\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.3567e-05 - val_loss: 0.0065\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.3195e-05 - val_loss: 0.0083\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2750e-05 - val_loss: 0.0108\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2432e-05 - val_loss: 0.0137\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2184e-05 - val_loss: 0.0164\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2391e-05 - val_loss: 0.0165\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.1022e-05 - val_loss: 0.0195\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1940e-05 - val_loss: 0.0234\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0724e-05 - val_loss: 0.0231\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2064e-05 - val_loss: 0.0244\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0557e-05 - val_loss: 0.0251\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1086e-05 - val_loss: 0.0286\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2406e-05 - val_loss: 0.0310\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0901e-05 - val_loss: 0.0280\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0661e-05 - val_loss: 0.0340\n",
            "training:  lstm_att_ohlcv  df:  23\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 4.3090e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.1343e-04 - val_loss: 7.0294e-06\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6313e-04 - val_loss: 7.9073e-06\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6640e-04 - val_loss: 9.0332e-06\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5857e-04 - val_loss: 2.6026e-05\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5708e-04 - val_loss: 8.6876e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4543e-04 - val_loss: 6.2319e-06\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5171e-04 - val_loss: 1.9887e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4683e-04 - val_loss: 2.5294e-05\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4625e-04 - val_loss: 6.9366e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4845e-04 - val_loss: 1.0724e-05\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4899e-04 - val_loss: 1.2968e-05\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5024e-04 - val_loss: 5.6466e-05\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4591e-04 - val_loss: 9.5068e-06\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4994e-04 - val_loss: 1.3556e-05\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4534e-04 - val_loss: 1.0396e-05\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4794e-04 - val_loss: 2.7746e-05\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4805e-04 - val_loss: 1.4592e-05\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4492e-04 - val_loss: 2.3869e-05\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4339e-04 - val_loss: 8.0377e-06\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4286e-04 - val_loss: 1.1897e-05\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4821e-04 - val_loss: 2.2125e-05\n",
            "training:  lstm_att_ohlcv  df:  24\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.9330e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3602e-04 - val_loss: 1.0158e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3820e-04 - val_loss: 7.8348e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3422e-04 - val_loss: 1.0696e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3041e-04 - val_loss: 9.2804e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3089e-04 - val_loss: 1.0702e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2775e-04 - val_loss: 9.2777e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2809e-04 - val_loss: 8.7697e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2935e-04 - val_loss: 9.5068e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2781e-04 - val_loss: 8.0807e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2598e-04 - val_loss: 1.2619e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2856e-04 - val_loss: 9.3987e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3180e-04 - val_loss: 1.1490e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2418e-04 - val_loss: 1.0742e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2255e-04 - val_loss: 1.4682e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2299e-04 - val_loss: 1.0767e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2779e-04 - val_loss: 8.5107e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3146e-04 - val_loss: 9.9287e-05\n",
            "training:  lstm_att_ohlcv  df:  25\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 8/53 [===>..........................] - ETA: 0s - loss: 2.3952e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 9ms/step - loss: 2.8553e-04 - val_loss: 3.6129e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5762e-04 - val_loss: 3.5832e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4604e-04 - val_loss: 4.1576e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6439e-04 - val_loss: 3.4207e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6172e-04 - val_loss: 3.6670e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5155e-04 - val_loss: 3.4528e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4891e-04 - val_loss: 3.7534e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6990e-04 - val_loss: 3.4081e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4597e-04 - val_loss: 3.8644e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6039e-04 - val_loss: 3.5430e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5334e-04 - val_loss: 4.0915e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4468e-04 - val_loss: 3.4536e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4131e-04 - val_loss: 4.0093e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4306e-04 - val_loss: 3.3395e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3520e-04 - val_loss: 3.6818e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4393e-04 - val_loss: 3.4223e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3614e-04 - val_loss: 3.5220e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5679e-04 - val_loss: 3.5121e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4617e-04 - val_loss: 3.5952e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4555e-04 - val_loss: 3.5833e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3259e-04 - val_loss: 4.1047e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5273e-04 - val_loss: 3.5370e-04\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4570e-04 - val_loss: 3.7351e-04\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3265e-04 - val_loss: 3.5326e-04\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4943e-04 - val_loss: 3.6163e-04\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3275e-04 - val_loss: 3.3676e-04\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3880e-04 - val_loss: 3.3230e-04\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3458e-04 - val_loss: 3.2938e-04\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5113e-04 - val_loss: 3.5460e-04\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5938e-04 - val_loss: 3.6438e-04\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3429e-04 - val_loss: 3.4029e-04\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3644e-04 - val_loss: 3.2626e-04\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3796e-04 - val_loss: 3.2551e-04\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4558e-04 - val_loss: 4.0722e-04\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3462e-04 - val_loss: 4.0279e-04\n",
            "Epoch 36/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3741e-04 - val_loss: 4.6997e-04\n",
            "Epoch 37/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4698e-04 - val_loss: 3.8435e-04\n",
            "Epoch 38/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4375e-04 - val_loss: 3.9003e-04\n",
            "Epoch 39/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4637e-04 - val_loss: 3.5988e-04\n",
            "Epoch 40/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4405e-04 - val_loss: 4.5148e-04\n",
            "Epoch 41/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3777e-04 - val_loss: 3.3426e-04\n",
            "Epoch 42/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4091e-04 - val_loss: 3.6040e-04\n",
            "Epoch 43/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4188e-04 - val_loss: 3.5783e-04\n",
            "Epoch 44/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5498e-04 - val_loss: 3.9980e-04\n",
            "Epoch 45/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4400e-04 - val_loss: 3.4190e-04\n",
            "Epoch 46/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2325e-04 - val_loss: 3.6125e-04\n",
            "Epoch 47/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4377e-04 - val_loss: 3.6367e-04\n",
            "Epoch 48/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3226e-04 - val_loss: 3.5696e-04\n",
            "training:  lstm_att_ohlcv  df:  26\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 8/58 [===>..........................] - ETA: 0s - loss: 4.3886e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 9ms/step - loss: 1.7574e-04 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6257e-04 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4910e-04 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5874e-04 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4477e-04 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5022e-04 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4627e-04 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3567e-04 - val_loss: 0.0017\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3809e-04 - val_loss: 0.0018\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3487e-04 - val_loss: 0.0018\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5943e-04 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4317e-04 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4078e-04 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4009e-04 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3644e-04 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2804e-04 - val_loss: 0.0018\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3769e-04 - val_loss: 0.0017\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3443e-04 - val_loss: 0.0017\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3320e-04 - val_loss: 0.0017\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3653e-04 - val_loss: 0.0017\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4192e-04 - val_loss: 0.0017\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3528e-04 - val_loss: 0.0017\n",
            "training:  lstm_att_ohlcv  df:  27\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 8/46 [====>.........................] - ETA: 0s - loss: 2.7174e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 9ms/step - loss: 2.4505e-04 - val_loss: 4.8689e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3253e-04 - val_loss: 4.7458e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4102e-04 - val_loss: 5.9450e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1301e-04 - val_loss: 5.1135e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2003e-04 - val_loss: 4.8771e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1447e-04 - val_loss: 6.3939e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1466e-04 - val_loss: 5.1477e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2350e-04 - val_loss: 5.6754e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1792e-04 - val_loss: 5.6841e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0516e-04 - val_loss: 8.0520e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2838e-04 - val_loss: 6.2847e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2493e-04 - val_loss: 8.6635e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2538e-04 - val_loss: 5.1863e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.2139e-04 - val_loss: 4.8815e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2892e-04 - val_loss: 5.6658e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1954e-04 - val_loss: 6.6456e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0507e-04 - val_loss: 4.9260e-04\n",
            "training:  lstm_att_ohlcv  df:  28\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  8/171 [>.............................] - ETA: 1s - loss: 8.5689e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 8ms/step - loss: 7.5121e-05 - val_loss: 4.1924e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8098e-05 - val_loss: 4.4517e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0911e-05 - val_loss: 4.5125e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.1684e-05 - val_loss: 4.8444e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0052e-05 - val_loss: 3.7264e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8048e-05 - val_loss: 4.0499e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7648e-05 - val_loss: 3.2540e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7468e-05 - val_loss: 3.1772e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5420e-05 - val_loss: 2.9945e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7912e-05 - val_loss: 2.9354e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.6408e-05 - val_loss: 2.7217e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8629e-05 - val_loss: 4.8787e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9901e-05 - val_loss: 2.7388e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7660e-05 - val_loss: 2.7820e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3707e-05 - val_loss: 3.2156e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7726e-05 - val_loss: 2.9511e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7996e-05 - val_loss: 3.1954e-04\n",
            "Epoch 18/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8411e-05 - val_loss: 3.3661e-04\n",
            "Epoch 19/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.6680e-05 - val_loss: 3.2900e-04\n",
            "Epoch 20/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7763e-05 - val_loss: 3.3879e-04\n",
            "Epoch 21/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.2235e-05 - val_loss: 3.0957e-04\n",
            "Epoch 22/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5416e-05 - val_loss: 3.3298e-04\n",
            "Epoch 23/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.6371e-05 - val_loss: 3.0455e-04\n",
            "Epoch 24/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8311e-05 - val_loss: 3.1344e-04\n",
            "Epoch 25/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.4641e-05 - val_loss: 3.4552e-04\n",
            "Epoch 26/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.6740e-05 - val_loss: 3.2116e-04\n",
            "training:  lstm_att_ohlcv  df:  29\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 3.1653e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5369e-05 - val_loss: 0.0011\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3084e-05 - val_loss: 0.0015\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3300e-05 - val_loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1905e-05 - val_loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9787e-05 - val_loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9949e-05 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9757e-05 - val_loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8868e-05 - val_loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9593e-05 - val_loss: 0.0015\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8019e-05 - val_loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8977e-05 - val_loss: 0.0013\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8036e-05 - val_loss: 0.0013\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8907e-05 - val_loss: 0.0013\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9674e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0317e-05 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8397e-05 - val_loss: 0.0013\n",
            "training:  lstm_att_ohlcv  df:  30\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 1.4343e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8029e-05 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7914e-05 - val_loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7867e-05 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8059e-05 - val_loss: 0.0019\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8659e-05 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7333e-05 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7828e-05 - val_loss: 0.0021\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7728e-05 - val_loss: 0.0030\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6761e-05 - val_loss: 0.0025\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9018e-05 - val_loss: 0.0024\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7621e-05 - val_loss: 0.0027\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7232e-05 - val_loss: 0.0024\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8096e-05 - val_loss: 0.0021\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6059e-05 - val_loss: 0.0025\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6356e-05 - val_loss: 0.0028\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7461e-05 - val_loss: 0.0023\n",
            "training:  lstm_att_ohlcv  df:  31\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1979e-05 - val_loss: 5.0530e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0472e-05 - val_loss: 4.5996e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1675e-05 - val_loss: 1.1460e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6765e-05 - val_loss: 4.1758e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1392e-05 - val_loss: 3.1199e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3902e-05 - val_loss: 5.8559e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6685e-05 - val_loss: 4.4562e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5939e-05 - val_loss: 6.4797e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6394e-05 - val_loss: 6.3447e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4502e-05 - val_loss: 5.9786e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6606e-05 - val_loss: 6.6645e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5796e-05 - val_loss: 6.5263e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5804e-05 - val_loss: 4.0898e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5755e-05 - val_loss: 6.2113e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4847e-05 - val_loss: 7.5940e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1698e-05 - val_loss: 5.0022e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5724e-05 - val_loss: 3.8527e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3748e-05 - val_loss: 5.3757e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1183e-05 - val_loss: 3.9329e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3543e-05 - val_loss: 9.9008e-05\n",
            "training:  lstm_att_ohlcv  df:  32\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2311e-05 - val_loss: 1.4506e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1760e-05 - val_loss: 1.5612e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0354e-05 - val_loss: 1.3999e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9908e-05 - val_loss: 1.5632e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0020e-05 - val_loss: 1.6241e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9736e-05 - val_loss: 1.7459e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0137e-05 - val_loss: 2.1372e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9183e-05 - val_loss: 2.3142e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9496e-05 - val_loss: 2.0360e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9651e-05 - val_loss: 2.8030e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9949e-05 - val_loss: 4.4845e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8518e-05 - val_loss: 4.9430e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0251e-05 - val_loss: 6.7462e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8715e-05 - val_loss: 7.1820e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9666e-05 - val_loss: 9.4335e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8212e-05 - val_loss: 0.0011\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8820e-05 - val_loss: 6.4160e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8187e-05 - val_loss: 8.3862e-04\n",
            "training:  lstm_att_ohlcv  df:  33\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 1.0465e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 8ms/step - loss: 1.2249e-04 - val_loss: 1.4496e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0714e-04 - val_loss: 1.5730e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.9171e-05 - val_loss: 2.0584e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1041e-05 - val_loss: 3.9663e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3542e-05 - val_loss: 2.5422e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2952e-05 - val_loss: 1.1907e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0639e-05 - val_loss: 1.5166e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1135e-05 - val_loss: 3.7969e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.6850e-05 - val_loss: 2.0597e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9932e-05 - val_loss: 1.9675e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5638e-05 - val_loss: 1.9832e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.6457e-05 - val_loss: 1.5155e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.6210e-05 - val_loss: 2.6398e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9794e-05 - val_loss: 2.1121e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.7438e-05 - val_loss: 1.6320e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5001e-05 - val_loss: 3.4909e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0375e-05 - val_loss: 1.5169e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5657e-05 - val_loss: 1.5997e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.4706e-05 - val_loss: 1.7280e-04\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.6516e-05 - val_loss: 2.0054e-04\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.4267e-05 - val_loss: 2.2797e-04\n",
            "training:  lstm_att_ohlcv  df:  34\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 2.7559e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0190e-05 - val_loss: 2.4371e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9014e-05 - val_loss: 2.5989e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7500e-05 - val_loss: 2.4876e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8550e-05 - val_loss: 2.5929e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7061e-05 - val_loss: 2.3381e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7659e-05 - val_loss: 2.3476e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6873e-05 - val_loss: 2.6628e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7047e-05 - val_loss: 2.4703e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7420e-05 - val_loss: 2.6818e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7284e-05 - val_loss: 2.6312e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6939e-05 - val_loss: 2.5606e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7338e-05 - val_loss: 2.9550e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6816e-05 - val_loss: 3.6757e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7371e-05 - val_loss: 3.1588e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7203e-05 - val_loss: 4.2032e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8068e-05 - val_loss: 4.6570e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7422e-05 - val_loss: 5.0105e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6874e-05 - val_loss: 5.7678e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6504e-05 - val_loss: 4.9211e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7300e-05 - val_loss: 5.4942e-04\n",
            "training:  lstm_att_ohlcv  df:  35\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/314 [..............................] - ETA: 3s - loss: 4.7850e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 2s 8ms/step - loss: 3.0524e-05 - val_loss: 7.6523e-04\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4623e-05 - val_loss: 0.0011\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3941e-05 - val_loss: 0.0015\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4119e-05 - val_loss: 0.0011\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4300e-05 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2674e-05 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3330e-05 - val_loss: 0.0027\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4553e-05 - val_loss: 0.0032\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2644e-05 - val_loss: 0.0052\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2488e-05 - val_loss: 0.0055\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3398e-05 - val_loss: 0.0074\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2490e-05 - val_loss: 0.0065\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2413e-05 - val_loss: 0.0061\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1894e-05 - val_loss: 0.0060\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2943e-05 - val_loss: 0.0083\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2155e-05 - val_loss: 0.0066\n",
            "training:  lstm_att_ohlcv  df:  36\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  9/118 [=>............................] - ETA: 0s - loss: 5.0102e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 4.7084e-05 - val_loss: 0.0027\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3667e-05 - val_loss: 0.0034\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3405e-05 - val_loss: 0.0042\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2525e-05 - val_loss: 0.0041\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1187e-05 - val_loss: 0.0043\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2417e-05 - val_loss: 0.0040\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1457e-05 - val_loss: 0.0039\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2749e-05 - val_loss: 0.0044\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2012e-05 - val_loss: 0.0041\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0465e-05 - val_loss: 0.0054\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2685e-05 - val_loss: 0.0051\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0036e-05 - val_loss: 0.0051\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1886e-05 - val_loss: 0.0061\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8912e-05 - val_loss: 0.0063\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9877e-05 - val_loss: 0.0053\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8918e-05 - val_loss: 0.0058\n",
            "training:  lstm_att_ohlcv  df:  37\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 1s - loss: 3.0117e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8928e-05 - val_loss: 0.0067\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7622e-05 - val_loss: 0.0085\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6386e-05 - val_loss: 0.0082\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7179e-05 - val_loss: 0.0094\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.6310e-05 - val_loss: 0.0092\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7189e-05 - val_loss: 0.0095\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6510e-05 - val_loss: 0.0086\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6980e-05 - val_loss: 0.0075\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.5856e-05 - val_loss: 0.0086\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6601e-05 - val_loss: 0.0106\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6341e-05 - val_loss: 0.0106\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6304e-05 - val_loss: 0.0081\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9740e-05 - val_loss: 0.0077\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5959e-05 - val_loss: 0.0087\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6902e-05 - val_loss: 0.0085\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6695e-05 - val_loss: 0.0075\n",
            "training:  lstm_att_ohlcv  df:  38\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 8/99 [=>............................] - ETA: 0s - loss: 0.0045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 7.0822e-04 - val_loss: 6.1522e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 2.1665e-04 - val_loss: 5.0890e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8432e-04 - val_loss: 5.1410e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8710e-04 - val_loss: 5.0013e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7579e-04 - val_loss: 5.0424e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7739e-04 - val_loss: 4.9269e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7431e-04 - val_loss: 4.7696e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7604e-04 - val_loss: 5.2439e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8552e-04 - val_loss: 4.8555e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7028e-04 - val_loss: 4.7250e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7396e-04 - val_loss: 4.7263e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6932e-04 - val_loss: 4.8366e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8021e-04 - val_loss: 4.9215e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7355e-04 - val_loss: 4.8171e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6809e-04 - val_loss: 5.1115e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8035e-04 - val_loss: 4.6936e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7961e-04 - val_loss: 4.8219e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6670e-04 - val_loss: 5.0640e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7070e-04 - val_loss: 4.8423e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6628e-04 - val_loss: 4.8336e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6740e-04 - val_loss: 4.7710e-04\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6344e-04 - val_loss: 4.8130e-04\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5789e-04 - val_loss: 4.6844e-04\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6816e-04 - val_loss: 5.0293e-04\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7091e-04 - val_loss: 4.6450e-04\n",
            "Epoch 26/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6366e-04 - val_loss: 4.6779e-04\n",
            "Epoch 27/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7253e-04 - val_loss: 5.0902e-04\n",
            "Epoch 28/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6634e-04 - val_loss: 4.9955e-04\n",
            "Epoch 29/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6432e-04 - val_loss: 4.9275e-04\n",
            "Epoch 30/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7326e-04 - val_loss: 4.9481e-04\n",
            "Epoch 31/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6450e-04 - val_loss: 4.8371e-04\n",
            "Epoch 32/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5898e-04 - val_loss: 4.8627e-04\n",
            "Epoch 33/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6529e-04 - val_loss: 5.2456e-04\n",
            "Epoch 34/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6391e-04 - val_loss: 4.6993e-04\n",
            "Epoch 35/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6145e-04 - val_loss: 4.6929e-04\n",
            "Epoch 36/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6289e-04 - val_loss: 5.0817e-04\n",
            "Epoch 37/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6495e-04 - val_loss: 4.7888e-04\n",
            "Epoch 38/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6833e-04 - val_loss: 6.7223e-04\n",
            "Epoch 39/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6587e-04 - val_loss: 4.8402e-04\n",
            "Epoch 40/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6365e-04 - val_loss: 4.6922e-04\n",
            "training:  lstm_att_ohlcv  df:  39\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.7619e-05 - val_loss: 2.1660e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2042e-05 - val_loss: 1.7748e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2190e-05 - val_loss: 1.7766e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2219e-05 - val_loss: 2.7582e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.6900e-05 - val_loss: 2.1390e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2183e-05 - val_loss: 1.8159e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.4883e-05 - val_loss: 2.9347e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1127e-05 - val_loss: 1.9066e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 4.3779e-05 - val_loss: 2.7905e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1277e-05 - val_loss: 2.1748e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0779e-05 - val_loss: 9.1335e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 5.5368e-05 - val_loss: 0.0032\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.4044e-05 - val_loss: 0.0030\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.6366e-05 - val_loss: 0.0025\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.4169e-05 - val_loss: 0.0025\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.3373e-05 - val_loss: 0.0024\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.4372e-05 - val_loss: 0.0020\n",
            "training:  lstm_att_ohlcv  df:  40\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 9.3625e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 4.2412e-05 - val_loss: 6.8968e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5691e-05 - val_loss: 6.9639e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4822e-05 - val_loss: 7.4465e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4652e-05 - val_loss: 7.4404e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2020e-05 - val_loss: 7.4817e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3018e-05 - val_loss: 8.1770e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3379e-05 - val_loss: 7.8995e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2944e-05 - val_loss: 8.8415e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2078e-05 - val_loss: 9.1950e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1641e-05 - val_loss: 9.2328e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2601e-05 - val_loss: 9.9284e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2210e-05 - val_loss: 0.0010\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1809e-05 - val_loss: 9.9561e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2022e-05 - val_loss: 0.0010\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2636e-05 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3380e-05 - val_loss: 0.0011\n",
            "training:  lstm_att_ohlcv  df:  41\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 2.7559e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1584e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2852e-05 - val_loss: 0.0013\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2131e-05 - val_loss: 0.0013\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1372e-05 - val_loss: 0.0014\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1809e-05 - val_loss: 0.0014\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2525e-05 - val_loss: 0.0014\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1406e-05 - val_loss: 0.0014\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1156e-05 - val_loss: 0.0013\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1516e-05 - val_loss: 0.0013\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2845e-05 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2516e-05 - val_loss: 0.0015\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2333e-05 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2104e-05 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0747e-05 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1083e-05 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0544e-05 - val_loss: 0.0016\n",
            "training:  lstm_att_ohlcv  df:  42\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 4.7647e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 3.6281e-05 - val_loss: 0.0015\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.1896e-05 - val_loss: 0.0019\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.1502e-05 - val_loss: 0.0021\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.2266e-05 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.2546e-05 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0915e-05 - val_loss: 0.0033\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.1936e-05 - val_loss: 0.0023\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0255e-05 - val_loss: 0.0021\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.1814e-05 - val_loss: 0.0030\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9923e-05 - val_loss: 0.0035\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0399e-05 - val_loss: 0.0030\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9887e-05 - val_loss: 0.0030\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.1601e-05 - val_loss: 0.0036\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9734e-05 - val_loss: 0.0041\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9892e-05 - val_loss: 0.0029\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0944e-05 - val_loss: 0.0039\n",
            "training:  lstm_att_ohlcv  df:  43\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 9/64 [===>..........................] - ETA: 0s - loss: 6.4156e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 8ms/step - loss: 5.7840e-04 - val_loss: 6.4345e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.9323e-04 - val_loss: 7.4417e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.4271e-04 - val_loss: 7.1296e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.8613e-04 - val_loss: 7.7750e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.6478e-04 - val_loss: 6.5976e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3109e-04 - val_loss: 7.8539e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.4213e-04 - val_loss: 9.0516e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3626e-04 - val_loss: 8.0284e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.3722e-04 - val_loss: 7.8255e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1759e-04 - val_loss: 7.6901e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.2139e-04 - val_loss: 7.8410e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1890e-04 - val_loss: 8.0109e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.0889e-04 - val_loss: 7.8117e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1391e-04 - val_loss: 7.2860e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1647e-04 - val_loss: 6.5422e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2478e-04 - val_loss: 9.6089e-04\n",
            "training:  lstm_att_ohlcv  df:  44\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 3.9923e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 1.5027e-04 - val_loss: 1.9575e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4785e-04 - val_loss: 2.0983e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4538e-04 - val_loss: 1.7507e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4332e-04 - val_loss: 2.4615e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4293e-04 - val_loss: 2.4151e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4048e-04 - val_loss: 1.9585e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3973e-04 - val_loss: 2.3790e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4543e-04 - val_loss: 2.0770e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4500e-04 - val_loss: 2.0278e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4606e-04 - val_loss: 2.1737e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4378e-04 - val_loss: 1.9088e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4494e-04 - val_loss: 1.9481e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4301e-04 - val_loss: 2.5494e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4447e-04 - val_loss: 2.2142e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4547e-04 - val_loss: 2.0330e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4650e-04 - val_loss: 1.9675e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4634e-04 - val_loss: 1.9924e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4079e-04 - val_loss: 1.9886e-04\n",
            "training:  lstm_att_ohlcv  df:  45\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  9/174 [>.............................] - ETA: 1s - loss: 1.8976e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1911e-04 - val_loss: 2.0837e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0374e-04 - val_loss: 1.8295e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0247e-04 - val_loss: 1.8946e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9969e-04 - val_loss: 1.9497e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8831e-04 - val_loss: 2.2171e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8878e-04 - val_loss: 1.8873e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9908e-04 - val_loss: 2.5032e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9045e-04 - val_loss: 1.9846e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8829e-04 - val_loss: 1.9185e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8795e-04 - val_loss: 2.0706e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8668e-04 - val_loss: 1.8938e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9055e-04 - val_loss: 1.9743e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8522e-04 - val_loss: 2.0288e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9218e-04 - val_loss: 1.9209e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9160e-04 - val_loss: 1.8906e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8679e-04 - val_loss: 2.0028e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9567e-04 - val_loss: 2.1146e-04\n",
            "training:  lstm_att_ohlcv  df:  46\n",
            "Training model: lstm_att_ohlcv  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3554e-05 - val_loss: 1.0164e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7178e-05 - val_loss: 1.0907e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0370e-05 - val_loss: 1.1091e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9157e-05 - val_loss: 1.1092e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5687e-05 - val_loss: 1.1074e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9263e-05 - val_loss: 1.0913e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0708e-05 - val_loss: 1.2102e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6533e-05 - val_loss: 1.0817e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7612e-05 - val_loss: 1.0939e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8145e-05 - val_loss: 1.0506e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.8988e-05 - val_loss: 1.1516e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 9.0398e-05 - val_loss: 1.0836e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.7614e-05 - val_loss: 1.9852e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1309e-05 - val_loss: 1.2851e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9150e-05 - val_loss: 1.0453e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8915e-05 - val_loss: 1.0363e-04\n",
            "training:  lstm_att_ohlcv  df:  47\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 2.5949e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3843e-04 - val_loss: 3.9938e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3299e-04 - val_loss: 2.7392e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3182e-04 - val_loss: 1.6294e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2554e-04 - val_loss: 2.1061e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2460e-04 - val_loss: 2.2498e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3051e-04 - val_loss: 2.0601e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2569e-04 - val_loss: 1.6113e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2345e-04 - val_loss: 1.9421e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2354e-04 - val_loss: 2.4734e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2369e-04 - val_loss: 2.3223e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2368e-04 - val_loss: 2.0479e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2889e-04 - val_loss: 2.0500e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2228e-04 - val_loss: 2.3410e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2399e-04 - val_loss: 2.1683e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2698e-04 - val_loss: 2.0409e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2492e-04 - val_loss: 2.2215e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2148e-04 - val_loss: 1.9399e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2718e-04 - val_loss: 2.0663e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2164e-04 - val_loss: 1.9511e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2548e-04 - val_loss: 2.0567e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2422e-04 - val_loss: 1.6183e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2302e-04 - val_loss: 1.9722e-04\n",
            "training:  lstm_att_ohlcv  df:  48\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 3s - loss: 2.2429e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1863e-04 - val_loss: 7.8638e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1714e-04 - val_loss: 7.8177e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1546e-04 - val_loss: 7.8075e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1635e-04 - val_loss: 8.0506e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1600e-04 - val_loss: 7.4451e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1709e-04 - val_loss: 7.5687e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1543e-04 - val_loss: 9.0249e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1757e-04 - val_loss: 8.2807e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1672e-04 - val_loss: 8.0163e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1493e-04 - val_loss: 8.7631e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1460e-04 - val_loss: 9.9635e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1628e-04 - val_loss: 8.7818e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1931e-04 - val_loss: 8.7115e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1812e-04 - val_loss: 7.6740e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1632e-04 - val_loss: 7.5924e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1759e-04 - val_loss: 1.3976e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1563e-04 - val_loss: 7.9761e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1318e-04 - val_loss: 7.6726e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1841e-04 - val_loss: 9.7691e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1312e-04 - val_loss: 9.6631e-05\n",
            "training:  lstm_att_ohlcv  df:  49\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 1.0605e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 9.2448e-05 - val_loss: 1.0507e-04\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9828e-05 - val_loss: 1.0469e-04\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.1628e-05 - val_loss: 1.2002e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8213e-05 - val_loss: 1.1264e-04\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5072e-05 - val_loss: 1.0232e-04\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9005e-05 - val_loss: 1.0405e-04\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8304e-05 - val_loss: 1.1083e-04\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8638e-05 - val_loss: 1.0398e-04\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6318e-05 - val_loss: 1.0598e-04\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7680e-05 - val_loss: 1.0090e-04\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4642e-05 - val_loss: 1.0245e-04\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8066e-05 - val_loss: 1.0641e-04\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.0642e-05 - val_loss: 1.0583e-04\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7634e-05 - val_loss: 1.1166e-04\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9807e-05 - val_loss: 1.1479e-04\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5958e-05 - val_loss: 1.0514e-04\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.1173e-05 - val_loss: 1.0103e-04\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4321e-05 - val_loss: 1.1081e-04\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5361e-05 - val_loss: 1.0771e-04\n",
            "Epoch 20/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4785e-05 - val_loss: 1.1314e-04\n",
            "Epoch 21/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5962e-05 - val_loss: 1.0747e-04\n",
            "Epoch 22/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7358e-05 - val_loss: 1.0432e-04\n",
            "Epoch 23/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7383e-05 - val_loss: 1.2600e-04\n",
            "Epoch 24/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8232e-05 - val_loss: 1.0329e-04\n",
            "Epoch 25/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1992e-05 - val_loss: 1.2205e-04\n",
            "training:  lstm_att_ohlcv  df:  50\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0011    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5468e-04 - val_loss: 0.0022\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7574e-04 - val_loss: 0.0021\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6783e-04 - val_loss: 0.0024\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.4152e-04 - val_loss: 0.0022\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.0775e-04 - val_loss: 0.0025\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6074e-04 - val_loss: 0.0021\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.2923e-04 - val_loss: 0.0025\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0037\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0021\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6095e-04 - val_loss: 0.0023\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0026\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.2637e-04 - val_loss: 0.0025\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.2463e-04 - val_loss: 0.0023\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 8.8792e-04 - val_loss: 0.0027\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 8.4879e-04 - val_loss: 0.0022\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 8.7306e-04 - val_loss: 0.0022\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 8.5866e-04 - val_loss: 0.0024\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 7.9765e-04 - val_loss: 0.0024\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 8.2487e-04 - val_loss: 0.0027\n",
            "training:  lstm_att_ohlcv  df:  51\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  9/106 [=>............................] - ETA: 0s - loss: 4.8078e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.7160e-04 - val_loss: 7.4818e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.5071e-04 - val_loss: 8.1559e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3738e-04 - val_loss: 7.3560e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.4077e-04 - val_loss: 7.5473e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3835e-04 - val_loss: 7.6345e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.4464e-04 - val_loss: 7.2471e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2684e-04 - val_loss: 7.4686e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2827e-04 - val_loss: 7.4799e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3228e-04 - val_loss: 8.0330e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 3.0115e-04 - val_loss: 8.7922e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.5872e-04 - val_loss: 8.3303e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3562e-04 - val_loss: 8.2466e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3492e-04 - val_loss: 8.4292e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3135e-04 - val_loss: 7.9632e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3008e-04 - val_loss: 8.0201e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3293e-04 - val_loss: 7.9659e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2576e-04 - val_loss: 8.0800e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3055e-04 - val_loss: 7.8537e-04\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2353e-04 - val_loss: 8.0093e-04\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3178e-04 - val_loss: 7.7690e-04\n",
            "Epoch 21/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2778e-04 - val_loss: 8.1216e-04\n",
            "training:  lstm_att_ohlcv  df:  52\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 6.0636e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 8.7014e-05 - val_loss: 8.6074e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.3277e-05 - val_loss: 9.5458e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1024e-05 - val_loss: 0.0010\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1357e-05 - val_loss: 0.0011\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9593e-05 - val_loss: 0.0011\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9898e-05 - val_loss: 0.0012\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9689e-05 - val_loss: 0.0012\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8968e-05 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8826e-05 - val_loss: 0.0012\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8594e-05 - val_loss: 0.0013\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8691e-05 - val_loss: 0.0013\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8509e-05 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8848e-05 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7848e-05 - val_loss: 0.0015\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6454e-05 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7028e-05 - val_loss: 0.0014\n",
            "training:  lstm_att_ohlcv  df:  53\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            " 9/79 [==>...........................] - ETA: 0s - loss: 9.7987e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 9.9115e-05 - val_loss: 0.0048\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0593e-05 - val_loss: 0.0041\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.7012e-05 - val_loss: 0.0040\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.9651e-05 - val_loss: 0.0036\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.9004e-05 - val_loss: 0.0045\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.5282e-05 - val_loss: 0.0044\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2188e-05 - val_loss: 0.0036\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3616e-05 - val_loss: 0.0041\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.2019e-05 - val_loss: 0.0041\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7368e-05 - val_loss: 0.0040\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1590e-05 - val_loss: 0.0041\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2152e-05 - val_loss: 0.0041\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8408e-05 - val_loss: 0.0041\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2653e-05 - val_loss: 0.0031\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7483e-05 - val_loss: 0.0030\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.1241e-05 - val_loss: 0.0039\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0742e-05 - val_loss: 0.0041\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7359e-05 - val_loss: 0.0031\n",
            "Epoch 19/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3405e-05 - val_loss: 0.0035\n",
            "Epoch 20/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1752e-05 - val_loss: 0.0031\n",
            "Epoch 21/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8688e-05 - val_loss: 0.0035\n",
            "Epoch 22/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.5898e-05 - val_loss: 0.0035\n",
            "Epoch 23/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2384e-05 - val_loss: 0.0032\n",
            "Epoch 24/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8679e-05 - val_loss: 0.0036\n",
            "Epoch 25/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1744e-05 - val_loss: 0.0037\n",
            "Epoch 26/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3508e-05 - val_loss: 0.0041\n",
            "Epoch 27/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8337e-05 - val_loss: 0.0040\n",
            "Epoch 28/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9538e-05 - val_loss: 0.0036\n",
            "Epoch 29/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8827e-05 - val_loss: 0.0032\n",
            "Epoch 30/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3259e-05 - val_loss: 0.0033\n",
            "training:  lstm_att_ohlcv  df:  54\n",
            "Training model: lstm_att_ohlcv  features: 5\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 5.2958e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2584e-05 - val_loss: 7.3400e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6484e-05 - val_loss: 3.6572e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7218e-05 - val_loss: 4.7690e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3787e-05 - val_loss: 2.5528e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5882e-05 - val_loss: 2.9420e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5458e-05 - val_loss: 3.2124e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4677e-05 - val_loss: 3.3852e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4965e-05 - val_loss: 3.0560e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4324e-05 - val_loss: 3.6950e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3849e-05 - val_loss: 1.9319e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4780e-05 - val_loss: 2.5132e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3705e-05 - val_loss: 2.9644e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5578e-05 - val_loss: 1.5624e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5664e-05 - val_loss: 2.3481e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6169e-05 - val_loss: 1.5786e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5298e-05 - val_loss: 2.6282e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4305e-05 - val_loss: 4.8848e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4985e-05 - val_loss: 7.5716e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3737e-05 - val_loss: 2.8799e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6212e-05 - val_loss: 2.8348e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5041e-05 - val_loss: 2.7809e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4389e-05 - val_loss: 2.6218e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4755e-05 - val_loss: 1.9560e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2476e-05 - val_loss: 2.9617e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5936e-05 - val_loss: 4.1364e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3844e-05 - val_loss: 2.0844e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4671e-05 - val_loss: 2.0996e-04\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2080e-05 - val_loss: 1.6883e-04\n",
            "build model: lstm_cv_rvi  features: 3\n",
            "training:  lstm_cv_rvi\n",
            "lstm_cv_rvi  should train on stocks\n",
            "training dfs: 55\n",
            "training:  lstm_cv_rvi  df:  0\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 6s 12ms/step - loss: 0.0079 - val_loss: 0.2819\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.2240\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.1129\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 8.9675e-04 - val_loss: 0.0744\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.2464e-04 - val_loss: 0.0917\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.7954e-04 - val_loss: 0.0817\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.4206e-04 - val_loss: 0.0557\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 4.1694e-04 - val_loss: 0.0457\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.5443e-04 - val_loss: 0.0581\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.9841e-04 - val_loss: 0.0361\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.4700e-04 - val_loss: 0.0450\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.2674e-04 - val_loss: 0.0396\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.0916e-04 - val_loss: 0.0577\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.2083e-04 - val_loss: 0.0576\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.7132e-04 - val_loss: 0.0594\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.8383e-04 - val_loss: 0.0737\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.7325e-04 - val_loss: 0.0775\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.5651e-04 - val_loss: 0.0670\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.4488e-04 - val_loss: 0.0578\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.4523e-04 - val_loss: 0.0871\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.6731e-04 - val_loss: 0.0775\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.2381e-04 - val_loss: 0.0788\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.0779e-04 - val_loss: 0.0703\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.2498e-04 - val_loss: 0.0644\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.4077e-04 - val_loss: 0.0727\n",
            "training:  lstm_cv_rvi  df:  1\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 9/80 [==>...........................] - ETA: 0s - loss: 7.4216e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 8ms/step - loss: 2.0017e-04 - val_loss: 0.0910\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 7.9681e-05 - val_loss: 0.1189\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.4378e-05 - val_loss: 0.1167\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.9999e-05 - val_loss: 0.1232\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 6.6659e-05 - val_loss: 0.1160\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.0069e-05 - val_loss: 0.1207\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 6.4405e-05 - val_loss: 0.1324\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.8223e-05 - val_loss: 0.1283\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.0859e-05 - val_loss: 0.1387\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 3.4699e-05 - val_loss: 0.1350\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 2.5970e-05 - val_loss: 0.1269\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 2.6664e-05 - val_loss: 0.1291\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 4.2429e-05 - val_loss: 0.1209\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.8156e-05 - val_loss: 0.1348\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.8325e-05 - val_loss: 0.1209\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3713e-05 - val_loss: 0.1182\n",
            "training:  lstm_cv_rvi  df:  2\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 5.2178e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 7ms/step - loss: 1.4737e-05 - val_loss: 0.1106\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 9.8167e-06 - val_loss: 0.1172\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.5803e-06 - val_loss: 0.1204\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.0927e-06 - val_loss: 0.1227\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.4782e-06 - val_loss: 0.1273\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 7.6133e-06 - val_loss: 0.1269\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 7.8110e-06 - val_loss: 0.1245\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 7.7687e-06 - val_loss: 0.1239\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 7.7090e-06 - val_loss: 0.1229\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 7.0362e-06 - val_loss: 0.1223\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 8.2899e-06 - val_loss: 0.1194\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 7.4805e-06 - val_loss: 0.1276\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.0264e-05 - val_loss: 0.1337\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 8.2185e-06 - val_loss: 0.1258\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 7.8042e-06 - val_loss: 0.1244\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.9068e-06 - val_loss: 0.1334\n",
            "training:  lstm_cv_rvi  df:  3\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3125e-04 - val_loss: 0.0172\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0954e-04 - val_loss: 0.0209\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5917e-04 - val_loss: 0.0225\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4558e-04 - val_loss: 0.0190\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3738e-04 - val_loss: 0.0171\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3461e-04 - val_loss: 0.0192\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3034e-04 - val_loss: 0.0168\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1809e-04 - val_loss: 0.0183\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1668e-04 - val_loss: 0.0182\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0464e-04 - val_loss: 0.0186\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2726e-04 - val_loss: 0.0163\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0830e-04 - val_loss: 0.0184\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1398e-04 - val_loss: 0.0187\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0547e-04 - val_loss: 0.0197\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1075e-04 - val_loss: 0.0254\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0249e-04 - val_loss: 0.0181\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0650e-04 - val_loss: 0.0221\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7932e-05 - val_loss: 0.0163\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2610e-05 - val_loss: 0.0185\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.7796e-05 - val_loss: 0.0157\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2032e-05 - val_loss: 0.0166\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8759e-05 - val_loss: 0.0175\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6465e-05 - val_loss: 0.0172\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.5756e-05 - val_loss: 0.0182\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6462e-05 - val_loss: 0.0194\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.4045e-05 - val_loss: 0.0151\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2153e-05 - val_loss: 0.0177\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1240e-05 - val_loss: 0.0198\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0728e-05 - val_loss: 0.0168\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0828e-05 - val_loss: 0.0183\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.9680e-05 - val_loss: 0.0160\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7787e-05 - val_loss: 0.0155\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.1746e-05 - val_loss: 0.0160\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.1246e-05 - val_loss: 0.0176\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3100e-05 - val_loss: 0.0197\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5947e-05 - val_loss: 0.0157\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.4824e-05 - val_loss: 0.0156\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.6464e-05 - val_loss: 0.0175\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9731e-05 - val_loss: 0.0182\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.6530e-05 - val_loss: 0.0163\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3069e-05 - val_loss: 0.0130\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.7905e-05 - val_loss: 0.0139\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.5027e-05 - val_loss: 0.0118\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.8670e-05 - val_loss: 0.0166\n",
            "Epoch 45/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5188e-05 - val_loss: 0.0157\n",
            "Epoch 46/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.9267e-05 - val_loss: 0.0166\n",
            "Epoch 47/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.9980e-05 - val_loss: 0.0181\n",
            "Epoch 48/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.9341e-05 - val_loss: 0.0190\n",
            "Epoch 49/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3622e-05 - val_loss: 0.0166\n",
            "Epoch 50/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5276e-05 - val_loss: 0.0115\n",
            "Epoch 51/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.4322e-05 - val_loss: 0.0152\n",
            "Epoch 52/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3240e-05 - val_loss: 0.0145\n",
            "Epoch 53/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.7944e-05 - val_loss: 0.0190\n",
            "Epoch 54/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8626e-05 - val_loss: 0.0157\n",
            "Epoch 55/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6725e-05 - val_loss: 0.0178\n",
            "Epoch 56/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.6855e-05 - val_loss: 0.0136\n",
            "Epoch 57/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3352e-04 - val_loss: 0.0049\n",
            "Epoch 58/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.3457e-05 - val_loss: 0.0054\n",
            "Epoch 59/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3423e-05 - val_loss: 0.0050\n",
            "Epoch 60/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3063e-05 - val_loss: 0.0052\n",
            "Epoch 61/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0294e-05 - val_loss: 0.0068\n",
            "Epoch 62/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1276e-05 - val_loss: 0.0073\n",
            "Epoch 63/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8465e-05 - val_loss: 0.0107\n",
            "Epoch 64/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6387e-05 - val_loss: 0.0093\n",
            "Epoch 65/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2306e-05 - val_loss: 0.0116\n",
            "Epoch 66/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8304e-05 - val_loss: 0.0105\n",
            "Epoch 67/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8206e-05 - val_loss: 0.0133\n",
            "Epoch 68/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9622e-05 - val_loss: 0.0108\n",
            "Epoch 69/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0818e-05 - val_loss: 0.0152\n",
            "Epoch 70/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9216e-05 - val_loss: 0.0153\n",
            "Epoch 71/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5967e-05 - val_loss: 0.0165\n",
            "Epoch 72/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6546e-05 - val_loss: 0.0156\n",
            "training:  lstm_cv_rvi  df:  4\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 0.0062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 2.2367e-04 - val_loss: 7.1438e-05\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3694e-04 - val_loss: 2.8561e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2788e-04 - val_loss: 1.3712e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.5331e-04 - val_loss: 1.7850e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2281e-04 - val_loss: 7.7918e-05\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2022e-04 - val_loss: 9.5184e-05\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2516e-04 - val_loss: 7.7166e-05\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2042e-04 - val_loss: 9.0915e-05\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.1439e-04 - val_loss: 1.0483e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.0394e-04 - val_loss: 7.5673e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0687e-04 - val_loss: 6.5210e-05\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2965e-04 - val_loss: 9.5957e-05\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.1516e-04 - val_loss: 6.9635e-05\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.1276e-04 - val_loss: 6.8339e-05\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.0747e-04 - val_loss: 3.2608e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.1204e-04 - val_loss: 7.3194e-05\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0786e-04 - val_loss: 1.1737e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.0645e-04 - val_loss: 6.7386e-05\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.0730e-04 - val_loss: 1.1444e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0786e-04 - val_loss: 8.0252e-05\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0283e-04 - val_loss: 8.9988e-05\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1021e-04 - val_loss: 8.4939e-05\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0835e-04 - val_loss: 1.5959e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0407e-04 - val_loss: 7.6617e-05\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.0631e-04 - val_loss: 9.0576e-05\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1323e-04 - val_loss: 7.2651e-05\n",
            "training:  lstm_cv_rvi  df:  5\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.4860e-05 - val_loss: 1.8754e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9244e-05 - val_loss: 1.4883e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8441e-05 - val_loss: 1.7223e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8030e-05 - val_loss: 1.7822e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8277e-05 - val_loss: 2.3064e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5987e-05 - val_loss: 3.4278e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5871e-05 - val_loss: 3.6176e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5312e-05 - val_loss: 4.4466e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5946e-05 - val_loss: 4.7554e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4714e-05 - val_loss: 5.8159e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4865e-05 - val_loss: 6.6401e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4058e-05 - val_loss: 7.1800e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4088e-05 - val_loss: 8.4718e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4627e-05 - val_loss: 8.2626e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3979e-05 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3757e-05 - val_loss: 0.0013\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3897e-05 - val_loss: 0.0016\n",
            "training:  lstm_cv_rvi  df:  6\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 7ms/step - loss: 2.7860e-04 - val_loss: 1.3865e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5087e-04 - val_loss: 1.3709e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4574e-04 - val_loss: 1.0726e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3593e-04 - val_loss: 1.2378e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3256e-04 - val_loss: 1.4001e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3013e-04 - val_loss: 1.1482e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2401e-04 - val_loss: 9.2544e-05\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3457e-04 - val_loss: 1.0031e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2631e-04 - val_loss: 1.0421e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2516e-04 - val_loss: 1.1160e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3440e-04 - val_loss: 1.2500e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2116e-04 - val_loss: 9.1866e-05\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2499e-04 - val_loss: 1.8814e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2181e-04 - val_loss: 1.0066e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2392e-04 - val_loss: 9.6589e-05\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1601e-04 - val_loss: 1.0602e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2465e-04 - val_loss: 1.1968e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2584e-04 - val_loss: 1.4208e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.1998e-04 - val_loss: 1.3752e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.1768e-04 - val_loss: 9.4863e-05\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.1850e-04 - val_loss: 2.1686e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.1730e-04 - val_loss: 1.2213e-04\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2049e-04 - val_loss: 1.0816e-04\n",
            "Epoch 24/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2359e-04 - val_loss: 9.5689e-05\n",
            "Epoch 25/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.2138e-04 - val_loss: 1.4897e-04\n",
            "Epoch 26/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.1978e-04 - val_loss: 2.2718e-04\n",
            "Epoch 27/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1413e-04 - val_loss: 1.4694e-04\n",
            "training:  lstm_cv_rvi  df:  7\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 1.0678e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 5.0875e-05 - val_loss: 2.7945e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.7052e-05 - val_loss: 3.4185e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.3115e-05 - val_loss: 4.0327e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.3759e-05 - val_loss: 4.1708e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.2649e-05 - val_loss: 4.1409e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.2739e-05 - val_loss: 3.6927e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.1544e-05 - val_loss: 3.9543e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 3.9783e-05 - val_loss: 4.6802e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.1317e-05 - val_loss: 5.0223e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 3.8968e-05 - val_loss: 5.9974e-04\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 3.8380e-05 - val_loss: 4.8031e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.0696e-05 - val_loss: 5.6472e-04\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.1609e-05 - val_loss: 5.6534e-04\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 3.9446e-05 - val_loss: 8.7920e-04\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 3.9264e-05 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 3.9458e-05 - val_loss: 7.1791e-04\n",
            "training:  lstm_cv_rvi  df:  8\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 9/68 [==>...........................] - ETA: 0s - loss: 2.0112e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 1.7604e-04 - val_loss: 0.0048\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4842e-04 - val_loss: 0.0027\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1603e-04 - val_loss: 0.0032\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0995e-04 - val_loss: 0.0026\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1533e-04 - val_loss: 0.0032\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1906e-04 - val_loss: 0.0028\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2267e-04 - val_loss: 0.0030\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1405e-04 - val_loss: 0.0048\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0211e-04 - val_loss: 0.0030\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 9.7567e-05 - val_loss: 0.0032\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2666e-04 - val_loss: 0.0075\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0486e-04 - val_loss: 0.0055\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1089e-04 - val_loss: 0.0057\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0929e-04 - val_loss: 0.0050\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0082e-04 - val_loss: 0.0046\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0516e-04 - val_loss: 0.0058\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1825e-04 - val_loss: 0.0052\n",
            "Epoch 18/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0649e-04 - val_loss: 0.0037\n",
            "Epoch 19/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0191e-04 - val_loss: 0.0055\n",
            "training:  lstm_cv_rvi  df:  9\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  9/162 [>.............................] - ETA: 1s - loss: 4.8777e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 6.0448e-05 - val_loss: 0.0160\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.0956e-05 - val_loss: 0.0222\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8148e-05 - val_loss: 0.0234\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.7242e-05 - val_loss: 0.0214\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.5682e-05 - val_loss: 0.0207\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.4630e-05 - val_loss: 0.0209\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.3332e-05 - val_loss: 0.0181\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.4824e-05 - val_loss: 0.0183\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.3720e-05 - val_loss: 0.0189\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.2612e-05 - val_loss: 0.0177\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.2328e-05 - val_loss: 0.0191\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.2686e-05 - val_loss: 0.0179\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1979e-05 - val_loss: 0.0172\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.1227e-05 - val_loss: 0.0177\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.1874e-05 - val_loss: 0.0181\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.2502e-05 - val_loss: 0.0180\n",
            "training:  lstm_cv_rvi  df:  10\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.7143e-05 - val_loss: 9.9442e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9391e-05 - val_loss: 9.7208e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.8878e-05 - val_loss: 5.2404e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.7130e-05 - val_loss: 8.4227e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.7672e-05 - val_loss: 9.2962e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.7175e-05 - val_loss: 8.0063e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.8569e-05 - val_loss: 6.1297e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.7704e-05 - val_loss: 7.5901e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.5073e-05 - val_loss: 7.3809e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.2139e-05 - val_loss: 6.9354e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0608e-05 - val_loss: 8.0710e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0287e-05 - val_loss: 8.7360e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.4599e-05 - val_loss: 0.0011\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.5062e-05 - val_loss: 8.6123e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5947e-05 - val_loss: 7.3508e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.3681e-05 - val_loss: 8.6954e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 4.7236e-05 - val_loss: 5.4664e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9102e-05 - val_loss: 8.9909e-04\n",
            "training:  lstm_cv_rvi  df:  11\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0252e-04 - val_loss: 9.6186e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6137e-05 - val_loss: 1.5679e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6476e-05 - val_loss: 4.7410e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3822e-05 - val_loss: 1.9934e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9462e-05 - val_loss: 7.1467e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.2584e-05 - val_loss: 8.3548e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.9780e-05 - val_loss: 7.1167e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.8812e-05 - val_loss: 7.1426e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.2975e-05 - val_loss: 7.8673e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.5626e-05 - val_loss: 7.8087e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.8239e-05 - val_loss: 9.5843e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.8545e-05 - val_loss: 6.9011e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.9399e-05 - val_loss: 7.2546e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7634e-05 - val_loss: 8.1454e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0114e-05 - val_loss: 1.8948e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6296e-05 - val_loss: 1.0485e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6594e-05 - val_loss: 7.0789e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.2956e-05 - val_loss: 2.2587e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7080e-05 - val_loss: 9.3295e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.4579e-05 - val_loss: 7.6046e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3969e-05 - val_loss: 6.7183e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5724e-05 - val_loss: 1.0839e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.0604e-05 - val_loss: 1.8783e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.6814e-05 - val_loss: 6.9278e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8561e-05 - val_loss: 1.2248e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.7987e-05 - val_loss: 8.6426e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3264e-05 - val_loss: 1.3559e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2332e-05 - val_loss: 4.5142e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6947e-05 - val_loss: 1.0391e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.5682e-05 - val_loss: 1.4096e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5327e-05 - val_loss: 8.2405e-05\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3598e-05 - val_loss: 9.5413e-05\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3827e-05 - val_loss: 7.3452e-05\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.4783e-05 - val_loss: 9.8623e-05\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.1539e-05 - val_loss: 7.5308e-05\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.5375e-05 - val_loss: 1.5998e-04\n",
            "training:  lstm_cv_rvi  df:  12\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 8/13 [=================>............] - ETA: 0s - loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8396e-04 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "training:  lstm_cv_rvi  df:  13\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 3.9110e-05 - val_loss: 0.0039\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.8387e-05 - val_loss: 0.0036\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7890e-05 - val_loss: 0.0036\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5576e-05 - val_loss: 0.0036\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5330e-05 - val_loss: 0.0036\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3715e-05 - val_loss: 0.0037\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5043e-05 - val_loss: 0.0037\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3682e-05 - val_loss: 0.0037\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3436e-05 - val_loss: 0.0037\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4983e-05 - val_loss: 0.0036\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.3755e-05 - val_loss: 0.0038\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.4647e-05 - val_loss: 0.0039\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.3586e-05 - val_loss: 0.0038\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.5878e-05 - val_loss: 0.0037\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.3594e-05 - val_loss: 0.0039\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2493e-05 - val_loss: 0.0040\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3955e-05 - val_loss: 0.0040\n",
            "training:  lstm_cv_rvi  df:  14\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 9/26 [=========>....................] - ETA: 0s - loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 10ms/step - loss: 7.4260e-04 - val_loss: 4.9044e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.5978e-04 - val_loss: 3.9298e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1344e-04 - val_loss: 2.4927e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1741e-04 - val_loss: 6.1975e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9080e-04 - val_loss: 3.2527e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1547e-04 - val_loss: 2.1529e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9442e-04 - val_loss: 2.5914e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.4117e-04 - val_loss: 2.3536e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9169e-04 - val_loss: 2.4809e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9573e-04 - val_loss: 2.1360e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.2096e-04 - val_loss: 3.8913e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0004e-04 - val_loss: 2.9191e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.4855e-04 - val_loss: 2.1714e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6390e-04 - val_loss: 2.1102e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6228e-04 - val_loss: 2.0299e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.4114e-04 - val_loss: 2.1782e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.5712e-04 - val_loss: 2.8791e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.4725e-04 - val_loss: 2.2976e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.3427e-04 - val_loss: 2.0830e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6005e-04 - val_loss: 3.2558e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6912e-04 - val_loss: 2.4131e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6564e-04 - val_loss: 2.2773e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7281e-04 - val_loss: 2.2973e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.3408e-04 - val_loss: 2.6580e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.5084e-04 - val_loss: 2.1267e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7668e-04 - val_loss: 2.5475e-04\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6526e-04 - val_loss: 2.3241e-04\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8552e-04 - val_loss: 2.1583e-04\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.2285e-04 - val_loss: 2.2341e-04\n",
            "Epoch 30/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6444e-04 - val_loss: 3.0801e-04\n",
            "training:  lstm_cv_rvi  df:  15\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5308e-05 - val_loss: 2.9240e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1372e-05 - val_loss: 2.7598e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0274e-05 - val_loss: 3.0244e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0362e-05 - val_loss: 2.9616e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0262e-05 - val_loss: 3.0638e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.9348e-06 - val_loss: 3.5692e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0311e-05 - val_loss: 3.7204e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1425e-06 - val_loss: 4.3009e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.6868e-06 - val_loss: 4.3375e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.4218e-06 - val_loss: 5.0333e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.5430e-06 - val_loss: 5.3610e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6445e-06 - val_loss: 6.4061e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0662e-06 - val_loss: 7.7437e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6669e-06 - val_loss: 8.8161e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4439e-06 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4230e-06 - val_loss: 0.0012\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4776e-06 - val_loss: 0.0015\n",
            "training:  lstm_cv_rvi  df:  16\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.9161e-05 - val_loss: 0.0056\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0423e-05 - val_loss: 0.0061\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8513e-05 - val_loss: 0.0065\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7205e-05 - val_loss: 0.0073\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7167e-05 - val_loss: 0.0079\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6309e-05 - val_loss: 0.0084\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5988e-05 - val_loss: 0.0093\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5714e-05 - val_loss: 0.0117\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6000e-05 - val_loss: 0.0129\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6954e-05 - val_loss: 0.0119\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5733e-05 - val_loss: 0.0149\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5715e-05 - val_loss: 0.0147\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6431e-05 - val_loss: 0.0179\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.5728e-05 - val_loss: 0.0217\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5665e-05 - val_loss: 0.0206\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5417e-05 - val_loss: 0.0205\n",
            "training:  lstm_cv_rvi  df:  17\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 1.0048e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 9.3354e-06 - val_loss: 0.0235\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 8.0625e-06 - val_loss: 0.0262\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.8735e-06 - val_loss: 0.0266\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.7708e-06 - val_loss: 0.0274\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.6661e-06 - val_loss: 0.0298\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.3479e-06 - val_loss: 0.0323\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.4771e-06 - val_loss: 0.0340\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.3832e-06 - val_loss: 0.0344\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.5724e-06 - val_loss: 0.0340\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 5.7201e-06 - val_loss: 0.0345\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.1243e-06 - val_loss: 0.0353\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.3090e-06 - val_loss: 0.0362\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.2972e-06 - val_loss: 0.0387\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.6902e-06 - val_loss: 0.0420\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.6739e-06 - val_loss: 0.0435\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.4987e-06 - val_loss: 0.0456\n",
            "training:  lstm_cv_rvi  df:  18\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  9/174 [>.............................] - ETA: 1s - loss: 0.0071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 6.9714e-04 - val_loss: 2.0218e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1761e-04 - val_loss: 1.8868e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0981e-04 - val_loss: 1.8418e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1543e-04 - val_loss: 1.7638e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0607e-04 - val_loss: 1.9173e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1124e-04 - val_loss: 1.9901e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1371e-04 - val_loss: 1.8044e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0152e-04 - val_loss: 1.9236e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0229e-04 - val_loss: 1.7938e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9924e-04 - val_loss: 2.3474e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1483e-04 - val_loss: 1.7982e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9906e-04 - val_loss: 1.8498e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9536e-04 - val_loss: 2.1559e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0529e-04 - val_loss: 1.9677e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8973e-04 - val_loss: 1.8158e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9204e-04 - val_loss: 1.8978e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0178e-04 - val_loss: 2.0922e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0558e-04 - val_loss: 2.1099e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8885e-04 - val_loss: 1.9361e-04\n",
            "training:  lstm_cv_rvi  df:  19\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 8/47 [====>.........................] - ETA: 0s - loss: 2.5436e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0328e-04 - val_loss: 1.8818e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0537e-04 - val_loss: 2.0770e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8664e-04 - val_loss: 1.8696e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8006e-04 - val_loss: 1.6473e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.7843e-04 - val_loss: 1.7461e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.7546e-04 - val_loss: 1.7997e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6713e-04 - val_loss: 1.9825e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.7491e-04 - val_loss: 1.6490e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7868e-04 - val_loss: 2.4157e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7633e-04 - val_loss: 1.7310e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7258e-04 - val_loss: 1.9479e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7881e-04 - val_loss: 1.8638e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.7101e-04 - val_loss: 1.7572e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7641e-04 - val_loss: 1.6486e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.7821e-04 - val_loss: 1.9985e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8149e-04 - val_loss: 1.6824e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7601e-04 - val_loss: 1.8377e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8371e-04 - val_loss: 2.0290e-04\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8593e-04 - val_loss: 1.6462e-04\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8045e-04 - val_loss: 2.3628e-04\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8133e-04 - val_loss: 1.8945e-04\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.6413e-04 - val_loss: 1.7445e-04\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.8733e-04 - val_loss: 1.7789e-04\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7230e-04 - val_loss: 1.7019e-04\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7858e-04 - val_loss: 1.7364e-04\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8813e-04 - val_loss: 1.9945e-04\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8748e-04 - val_loss: 1.8159e-04\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7482e-04 - val_loss: 2.3174e-04\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7483e-04 - val_loss: 1.7015e-04\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8147e-04 - val_loss: 1.9849e-04\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9390e-04 - val_loss: 2.6126e-04\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1144e-04 - val_loss: 1.9844e-04\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7707e-04 - val_loss: 1.6728e-04\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7329e-04 - val_loss: 2.2672e-04\n",
            "training:  lstm_cv_rvi  df:  20\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  9/151 [>.............................] - ETA: 0s - loss: 5.2228e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 5.3291e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.1535e-05 - val_loss: 0.0069\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.7146e-06 - val_loss: 0.0056\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.0020e-06 - val_loss: 0.0036\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.2354e-06 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.2034e-06 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.7742e-06 - val_loss: 0.0014\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.7508e-06 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.5787e-06 - val_loss: 0.0012\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 5.2172e-06 - val_loss: 9.4591e-04\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.6835e-06 - val_loss: 9.6158e-04\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 10ms/step - loss: 5.1253e-06 - val_loss: 8.6561e-04\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 5.0221e-06 - val_loss: 8.2448e-04\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.7738e-06 - val_loss: 7.8133e-04\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.1081e-06 - val_loss: 7.4077e-04\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.9068e-06 - val_loss: 8.3366e-04\n",
            "Epoch 17/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.1007e-06 - val_loss: 8.0266e-04\n",
            "Epoch 18/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.7289e-06 - val_loss: 7.5518e-04\n",
            "Epoch 19/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.8057e-06 - val_loss: 7.3392e-04\n",
            "Epoch 20/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.0881e-06 - val_loss: 7.8183e-04\n",
            "Epoch 21/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.6232e-06 - val_loss: 8.1216e-04\n",
            "Epoch 22/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.3431e-06 - val_loss: 9.0947e-04\n",
            "Epoch 23/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.2731e-06 - val_loss: 9.4826e-04\n",
            "Epoch 24/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.4876e-06 - val_loss: 9.9577e-04\n",
            "Epoch 25/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.0100e-06 - val_loss: 9.8818e-04\n",
            "Epoch 26/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.6302e-06 - val_loss: 0.0010\n",
            "Epoch 27/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.9658e-06 - val_loss: 0.0011\n",
            "Epoch 28/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.1142e-06 - val_loss: 0.0011\n",
            "Epoch 29/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.0139e-06 - val_loss: 0.0012\n",
            "Epoch 30/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.6458e-06 - val_loss: 0.0012\n",
            "Epoch 31/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.2692e-06 - val_loss: 0.0014\n",
            "Epoch 32/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 3.8963e-06 - val_loss: 0.0014\n",
            "Epoch 33/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.0100e-06 - val_loss: 0.0013\n",
            "Epoch 34/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.5429e-06 - val_loss: 0.0014\n",
            "training:  lstm_cv_rvi  df:  21\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 8.6350e-05 - val_loss: 8.8492e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.8216e-05 - val_loss: 4.2570e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.4544e-05 - val_loss: 4.8568e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6802e-05 - val_loss: 3.7520e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.4233e-05 - val_loss: 2.9391e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.1645e-05 - val_loss: 2.3076e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3262e-05 - val_loss: 7.4242e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.5695e-05 - val_loss: 4.1648e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1379e-05 - val_loss: 3.2783e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9029e-05 - val_loss: 4.8506e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2478e-05 - val_loss: 4.0322e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.6473e-05 - val_loss: 6.4020e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.0285e-05 - val_loss: 3.8860e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2731e-05 - val_loss: 5.7861e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3614e-05 - val_loss: 6.2353e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1718e-05 - val_loss: 4.9545e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1949e-05 - val_loss: 9.4165e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0718e-05 - val_loss: 4.7555e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9862e-05 - val_loss: 8.4600e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9436e-05 - val_loss: 9.3569e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7757e-05 - val_loss: 7.1267e-04\n",
            "training:  lstm_cv_rvi  df:  22\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 3s 8ms/step - loss: 2.4646e-05 - val_loss: 0.0036\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2650e-05 - val_loss: 0.0043\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2599e-05 - val_loss: 0.0052\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.2034e-05 - val_loss: 0.0065\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.0661e-05 - val_loss: 0.0067\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1274e-05 - val_loss: 0.0069\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1478e-05 - val_loss: 0.0082\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.1118e-05 - val_loss: 0.0091\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0221e-05 - val_loss: 0.0104\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2068e-05 - val_loss: 0.0109\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0180e-05 - val_loss: 0.0100\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0840e-05 - val_loss: 0.0099\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0623e-05 - val_loss: 0.0099\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0819e-05 - val_loss: 0.0092\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 1.9853e-05 - val_loss: 0.0116\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0772e-05 - val_loss: 0.0128\n",
            "training:  lstm_cv_rvi  df:  23\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 0.0019"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.1383e-04 - val_loss: 1.0714e-05\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6126e-04 - val_loss: 6.7947e-06\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6156e-04 - val_loss: 4.3952e-05\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4885e-04 - val_loss: 1.8280e-05\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6348e-04 - val_loss: 5.2211e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4909e-04 - val_loss: 1.0903e-05\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4621e-04 - val_loss: 4.7536e-06\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4511e-04 - val_loss: 8.6905e-06\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5624e-04 - val_loss: 8.3630e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5070e-04 - val_loss: 5.4068e-06\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3641e-04 - val_loss: 5.2621e-06\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5092e-04 - val_loss: 1.2894e-05\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4482e-04 - val_loss: 5.3342e-06\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4523e-04 - val_loss: 5.3703e-06\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3712e-04 - val_loss: 7.8950e-06\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4394e-04 - val_loss: 5.2051e-06\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4929e-04 - val_loss: 1.5432e-05\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4582e-04 - val_loss: 7.5721e-06\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4485e-04 - val_loss: 1.7061e-05\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3650e-04 - val_loss: 5.4183e-06\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4206e-04 - val_loss: 2.6780e-05\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3868e-04 - val_loss: 1.1812e-05\n",
            "training:  lstm_cv_rvi  df:  24\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 2.4879e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.5028e-04 - val_loss: 7.4316e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3033e-04 - val_loss: 7.5666e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3118e-04 - val_loss: 8.2517e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2907e-04 - val_loss: 9.4540e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2874e-04 - val_loss: 7.8524e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2810e-04 - val_loss: 9.4908e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2706e-04 - val_loss: 8.2732e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2355e-04 - val_loss: 8.0951e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2346e-04 - val_loss: 1.2947e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2802e-04 - val_loss: 8.0548e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2598e-04 - val_loss: 7.4152e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1894e-04 - val_loss: 7.5512e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2187e-04 - val_loss: 7.1616e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3321e-04 - val_loss: 7.7053e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2072e-04 - val_loss: 7.6420e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2083e-04 - val_loss: 7.4081e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2019e-04 - val_loss: 8.1736e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2551e-04 - val_loss: 8.9827e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2442e-04 - val_loss: 8.1005e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2378e-04 - val_loss: 8.5841e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2595e-04 - val_loss: 9.1346e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2570e-04 - val_loss: 8.8976e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1680e-04 - val_loss: 1.0042e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2463e-04 - val_loss: 8.7098e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2672e-04 - val_loss: 7.4538e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2384e-04 - val_loss: 1.0873e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2396e-04 - val_loss: 7.4399e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1832e-04 - val_loss: 1.1949e-04\n",
            "training:  lstm_cv_rvi  df:  25\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 9/53 [====>.........................] - ETA: 0s - loss: 2.3684e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4831e-04 - val_loss: 3.5452e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5672e-04 - val_loss: 3.0969e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4995e-04 - val_loss: 3.4572e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4893e-04 - val_loss: 3.7108e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4875e-04 - val_loss: 3.1242e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4930e-04 - val_loss: 3.3417e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3853e-04 - val_loss: 3.2575e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4110e-04 - val_loss: 3.3322e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4439e-04 - val_loss: 3.4473e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3751e-04 - val_loss: 3.2784e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3543e-04 - val_loss: 3.3137e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2520e-04 - val_loss: 3.9446e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3225e-04 - val_loss: 3.3453e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3724e-04 - val_loss: 3.5232e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3750e-04 - val_loss: 3.2302e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4701e-04 - val_loss: 3.3483e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3179e-04 - val_loss: 3.3980e-04\n",
            "training:  lstm_cv_rvi  df:  26\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 8/58 [===>..........................] - ETA: 0s - loss: 2.9874e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7265e-04 - val_loss: 0.0015\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4855e-04 - val_loss: 0.0015\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4231e-04 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3793e-04 - val_loss: 0.0015\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2873e-04 - val_loss: 0.0016\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2864e-04 - val_loss: 0.0015\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2237e-04 - val_loss: 0.0015\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1923e-04 - val_loss: 0.0015\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2184e-04 - val_loss: 0.0015\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2576e-04 - val_loss: 0.0015\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1705e-04 - val_loss: 0.0015\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1454e-04 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2526e-04 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2119e-04 - val_loss: 0.0015\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2079e-04 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2055e-04 - val_loss: 0.0015\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1986e-04 - val_loss: 0.0015\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2339e-04 - val_loss: 0.0015\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1894e-04 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1139e-04 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1711e-04 - val_loss: 0.0015\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2228e-04 - val_loss: 0.0015\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1570e-04 - val_loss: 0.0015\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2944e-04 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.1847e-04 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2346e-04 - val_loss: 0.0015\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2206e-04 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1799e-04 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2454e-04 - val_loss: 0.0015\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1476e-04 - val_loss: 0.0015\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0738e-04 - val_loss: 0.0015\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1517e-04 - val_loss: 0.0015\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1593e-04 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1924e-04 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0533e-04 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2236e-04 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1743e-04 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0685e-04 - val_loss: 0.0015\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1053e-04 - val_loss: 0.0015\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0756e-04 - val_loss: 0.0015\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1158e-04 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3118e-04 - val_loss: 0.0015\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1257e-04 - val_loss: 0.0015\n",
            "training:  lstm_cv_rvi  df:  27\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 8/46 [====>.........................] - ETA: 0s - loss: 4.3647e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 9ms/step - loss: 3.0082e-04 - val_loss: 6.5065e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.8406e-04 - val_loss: 4.5938e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3601e-04 - val_loss: 4.1186e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1907e-04 - val_loss: 6.9020e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.4021e-04 - val_loss: 6.9664e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2987e-04 - val_loss: 5.5587e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3922e-04 - val_loss: 4.8561e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1812e-04 - val_loss: 5.4736e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1609e-04 - val_loss: 5.3173e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.9504e-04 - val_loss: 4.8256e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9189e-04 - val_loss: 4.3134e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1102e-04 - val_loss: 4.4165e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1729e-04 - val_loss: 5.7628e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1719e-04 - val_loss: 4.3438e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.8965e-04 - val_loss: 4.7516e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0055e-04 - val_loss: 4.2719e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0668e-04 - val_loss: 5.1886e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1946e-04 - val_loss: 4.5545e-04\n",
            "training:  lstm_cv_rvi  df:  28\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/171 [..............................] - ETA: 1s - loss: 6.2688e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 8ms/step - loss: 7.4574e-05 - val_loss: 2.8081e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5722e-05 - val_loss: 2.8262e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.6727e-05 - val_loss: 2.6572e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.4557e-05 - val_loss: 2.6926e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5237e-05 - val_loss: 2.5523e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3700e-05 - val_loss: 2.5424e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7082e-05 - val_loss: 2.9653e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7851e-05 - val_loss: 2.9903e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.6017e-05 - val_loss: 2.6358e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5484e-05 - val_loss: 2.7795e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3729e-05 - val_loss: 2.6288e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3358e-05 - val_loss: 2.5025e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1802e-05 - val_loss: 2.5474e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3335e-05 - val_loss: 2.6608e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3984e-05 - val_loss: 2.7167e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0643e-05 - val_loss: 2.9086e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3337e-05 - val_loss: 3.1648e-04\n",
            "Epoch 18/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.6378e-05 - val_loss: 2.9302e-04\n",
            "Epoch 19/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0620e-05 - val_loss: 3.4859e-04\n",
            "Epoch 20/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3822e-05 - val_loss: 3.0631e-04\n",
            "Epoch 21/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3594e-05 - val_loss: 3.5609e-04\n",
            "Epoch 22/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1419e-05 - val_loss: 4.5767e-04\n",
            "Epoch 23/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7407e-05 - val_loss: 3.5525e-04\n",
            "Epoch 24/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5117e-05 - val_loss: 3.6980e-04\n",
            "Epoch 25/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5067e-05 - val_loss: 4.1051e-04\n",
            "Epoch 26/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5345e-05 - val_loss: 4.2558e-04\n",
            "Epoch 27/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.2863e-05 - val_loss: 4.6819e-04\n",
            "training:  lstm_cv_rvi  df:  29\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 3.8895e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 3.1170e-05 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5894e-05 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3035e-05 - val_loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3600e-05 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2929e-05 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2863e-05 - val_loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1389e-05 - val_loss: 0.0021\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1133e-05 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9721e-05 - val_loss: 0.0025\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0848e-05 - val_loss: 0.0027\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0102e-05 - val_loss: 0.0030\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1427e-05 - val_loss: 0.0030\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9910e-05 - val_loss: 0.0033\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1198e-05 - val_loss: 0.0033\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0224e-05 - val_loss: 0.0034\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0007e-05 - val_loss: 0.0036\n",
            "training:  lstm_cv_rvi  df:  30\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 1.9187e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9624e-05 - val_loss: 0.0039\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9620e-05 - val_loss: 0.0041\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8513e-05 - val_loss: 0.0040\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9266e-05 - val_loss: 0.0041\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7900e-05 - val_loss: 0.0051\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8601e-05 - val_loss: 0.0046\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8176e-05 - val_loss: 0.0049\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7958e-05 - val_loss: 0.0053\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2298e-05 - val_loss: 0.0056\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0473e-05 - val_loss: 0.0065\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8533e-05 - val_loss: 0.0058\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8181e-05 - val_loss: 0.0060\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8804e-05 - val_loss: 0.0061\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7584e-05 - val_loss: 0.0066\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8165e-05 - val_loss: 0.0063\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8364e-05 - val_loss: 0.0064\n",
            "training:  lstm_cv_rvi  df:  31\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0186e-05 - val_loss: 3.6207e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6843e-05 - val_loss: 3.8635e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7954e-05 - val_loss: 3.4903e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8012e-05 - val_loss: 3.4774e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7605e-05 - val_loss: 3.2766e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3471e-05 - val_loss: 4.4934e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5795e-05 - val_loss: 3.7159e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6011e-05 - val_loss: 6.0857e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5425e-05 - val_loss: 2.7505e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5262e-05 - val_loss: 3.0900e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2972e-05 - val_loss: 3.5118e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6204e-05 - val_loss: 5.1285e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4112e-05 - val_loss: 5.3877e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4042e-05 - val_loss: 3.6949e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5917e-05 - val_loss: 4.9141e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3972e-05 - val_loss: 4.0835e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3665e-05 - val_loss: 3.0885e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2852e-05 - val_loss: 3.0978e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5297e-05 - val_loss: 4.0686e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9893e-05 - val_loss: 3.9485e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2420e-05 - val_loss: 4.3867e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4888e-05 - val_loss: 3.3747e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6730e-05 - val_loss: 6.6649e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4247e-05 - val_loss: 3.8345e-05\n",
            "training:  lstm_cv_rvi  df:  32\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.6034e-05 - val_loss: 1.3265e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4566e-05 - val_loss: 1.3108e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.3335e-05 - val_loss: 1.3443e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1398e-05 - val_loss: 1.3538e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0644e-05 - val_loss: 1.6255e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1100e-05 - val_loss: 3.1344e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0576e-05 - val_loss: 1.4701e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1596e-05 - val_loss: 1.6829e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0080e-05 - val_loss: 2.5114e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9918e-05 - val_loss: 3.1662e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9645e-05 - val_loss: 3.2632e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9059e-05 - val_loss: 3.3720e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9380e-05 - val_loss: 5.7086e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9327e-05 - val_loss: 5.8738e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8986e-05 - val_loss: 8.0126e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8745e-05 - val_loss: 6.0096e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8915e-05 - val_loss: 8.4888e-04\n",
            "training:  lstm_cv_rvi  df:  33\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 7.0943e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 8ms/step - loss: 1.1517e-04 - val_loss: 2.2828e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.5368e-05 - val_loss: 1.9510e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3249e-05 - val_loss: 1.9980e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2572e-05 - val_loss: 2.3873e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.7675e-05 - val_loss: 2.5794e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9124e-05 - val_loss: 1.6713e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0962e-05 - val_loss: 2.2840e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.3857e-05 - val_loss: 2.1918e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1432e-05 - val_loss: 6.3581e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.6719e-05 - val_loss: 1.7754e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5897e-05 - val_loss: 2.0336e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.7530e-05 - val_loss: 2.5500e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.4808e-05 - val_loss: 3.0505e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.8255e-05 - val_loss: 2.5691e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.2599e-05 - val_loss: 2.1471e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9606e-05 - val_loss: 5.4828e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9157e-05 - val_loss: 2.1888e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5081e-05 - val_loss: 2.1958e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5449e-05 - val_loss: 3.9591e-04\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.4364e-05 - val_loss: 1.7943e-04\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.2967e-05 - val_loss: 6.2730e-04\n",
            "training:  lstm_cv_rvi  df:  34\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.3689e-05 - val_loss: 5.6303e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9749e-05 - val_loss: 3.6165e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9499e-05 - val_loss: 3.1950e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8303e-05 - val_loss: 2.8494e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7557e-05 - val_loss: 3.1854e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7704e-05 - val_loss: 2.6067e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6722e-05 - val_loss: 3.6403e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6748e-05 - val_loss: 3.4871e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7090e-05 - val_loss: 3.6572e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6470e-05 - val_loss: 3.3907e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7087e-05 - val_loss: 3.5481e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7333e-05 - val_loss: 3.5191e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6307e-05 - val_loss: 3.7173e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7330e-05 - val_loss: 3.7715e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6978e-05 - val_loss: 4.2232e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6669e-05 - val_loss: 4.0413e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7803e-05 - val_loss: 4.8188e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6633e-05 - val_loss: 5.0234e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6563e-05 - val_loss: 4.9563e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6926e-05 - val_loss: 6.1190e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6826e-05 - val_loss: 6.3951e-04\n",
            "training:  lstm_cv_rvi  df:  35\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/314 [..............................] - ETA: 3s - loss: 4.5092e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 3s 8ms/step - loss: 3.0039e-05 - val_loss: 0.0072\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.6761e-05 - val_loss: 0.0069\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.5207e-05 - val_loss: 0.0081\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4319e-05 - val_loss: 0.0081\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4982e-05 - val_loss: 0.0077\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3143e-05 - val_loss: 0.0090\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2610e-05 - val_loss: 0.0132\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4077e-05 - val_loss: 0.0104\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4487e-05 - val_loss: 0.0118\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2224e-05 - val_loss: 0.0132\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2074e-05 - val_loss: 0.0095\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2763e-05 - val_loss: 0.0121\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1496e-05 - val_loss: 0.0149\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2015e-05 - val_loss: 0.0150\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2879e-05 - val_loss: 0.0114\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1940e-05 - val_loss: 0.0110\n",
            "Epoch 17/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2679e-05 - val_loss: 0.0154\n",
            "training:  lstm_cv_rvi  df:  36\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  8/118 [=>............................] - ETA: 0s - loss: 5.1584e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 5.0299e-05 - val_loss: 0.0098\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3550e-05 - val_loss: 0.0112\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2364e-05 - val_loss: 0.0119\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9482e-05 - val_loss: 0.0123\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9197e-05 - val_loss: 0.0123\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9499e-05 - val_loss: 0.0129\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4082e-05 - val_loss: 0.0127\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9273e-05 - val_loss: 0.0131\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8495e-05 - val_loss: 0.0132\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6910e-05 - val_loss: 0.0143\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6379e-05 - val_loss: 0.0143\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7855e-05 - val_loss: 0.0149\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9358e-05 - val_loss: 0.0159\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1282e-05 - val_loss: 0.0156\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8855e-05 - val_loss: 0.0152\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7566e-05 - val_loss: 0.0161\n",
            "training:  lstm_cv_rvi  df:  37\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 2s - loss: 5.1716e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 2s 8ms/step - loss: 2.9992e-05 - val_loss: 0.0109\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8409e-05 - val_loss: 0.0078\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8234e-05 - val_loss: 0.0096\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6805e-05 - val_loss: 0.0102\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6240e-05 - val_loss: 0.0117\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6621e-05 - val_loss: 0.0125\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.9280e-05 - val_loss: 0.0121\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5879e-05 - val_loss: 0.0116\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6874e-05 - val_loss: 0.0112\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6853e-05 - val_loss: 0.0097\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6731e-05 - val_loss: 0.0102\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6597e-05 - val_loss: 0.0117\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5919e-05 - val_loss: 0.0125\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5466e-05 - val_loss: 0.0127\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5490e-05 - val_loss: 0.0122\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7715e-05 - val_loss: 0.0121\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7098e-05 - val_loss: 0.0132\n",
            "training:  lstm_cv_rvi  df:  38\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 9/99 [=>............................] - ETA: 0s - loss: 0.0054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 7.7941e-04 - val_loss: 5.2829e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7924e-04 - val_loss: 4.4813e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5974e-04 - val_loss: 4.5850e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7386e-04 - val_loss: 4.5060e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7013e-04 - val_loss: 4.4452e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6945e-04 - val_loss: 4.3125e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5264e-04 - val_loss: 4.4851e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7035e-04 - val_loss: 4.5186e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5873e-04 - val_loss: 4.7071e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6671e-04 - val_loss: 4.6143e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5316e-04 - val_loss: 4.4475e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5641e-04 - val_loss: 4.5352e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5790e-04 - val_loss: 4.5316e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5785e-04 - val_loss: 4.4239e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4741e-04 - val_loss: 4.5747e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5595e-04 - val_loss: 4.3482e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5615e-04 - val_loss: 4.9165e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5982e-04 - val_loss: 4.4191e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5490e-04 - val_loss: 4.5961e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4615e-04 - val_loss: 4.3530e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5167e-04 - val_loss: 4.3809e-04\n",
            "training:  lstm_cv_rvi  df:  39\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 3s - loss: 7.5701e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 4.0710e-05 - val_loss: 1.6205e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.6468e-05 - val_loss: 1.7071e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.7380e-05 - val_loss: 1.6830e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2397e-05 - val_loss: 1.6907e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0753e-05 - val_loss: 1.6773e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2960e-05 - val_loss: 1.8968e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0586e-05 - val_loss: 2.3821e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1540e-05 - val_loss: 1.7702e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2207e-05 - val_loss: 2.2185e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.7962e-05 - val_loss: 2.5044e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1046e-05 - val_loss: 9.0128e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 4.1569e-05 - val_loss: 5.4275e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2190e-05 - val_loss: 5.4707e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1659e-05 - val_loss: 4.6726e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0777e-05 - val_loss: 4.9620e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9957e-05 - val_loss: 2.9057e-04\n",
            "training:  lstm_cv_rvi  df:  40\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 3.5516e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4578e-05 - val_loss: 2.8183e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2712e-05 - val_loss: 4.6338e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2275e-05 - val_loss: 4.7231e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0386e-05 - val_loss: 4.6296e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2985e-05 - val_loss: 4.6368e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1198e-05 - val_loss: 5.6075e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0263e-05 - val_loss: 5.6274e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1077e-05 - val_loss: 4.7737e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2251e-05 - val_loss: 5.5936e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1490e-05 - val_loss: 5.7815e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1560e-05 - val_loss: 8.6615e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1218e-05 - val_loss: 6.2686e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1176e-05 - val_loss: 6.2321e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9933e-05 - val_loss: 7.5056e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1046e-05 - val_loss: 5.3880e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1180e-05 - val_loss: 7.6517e-04\n",
            "training:  lstm_cv_rvi  df:  41\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 2.4491e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1539e-05 - val_loss: 6.1745e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0093e-05 - val_loss: 7.8365e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9698e-05 - val_loss: 7.7604e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9955e-05 - val_loss: 9.2652e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0866e-05 - val_loss: 6.8349e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3717e-05 - val_loss: 8.2712e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1561e-05 - val_loss: 9.0961e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0800e-05 - val_loss: 7.4102e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0338e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4773e-05 - val_loss: 0.0011\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1216e-05 - val_loss: 9.5801e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0133e-05 - val_loss: 0.0011\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9606e-05 - val_loss: 0.0010\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0583e-05 - val_loss: 8.9445e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0297e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9317e-05 - val_loss: 0.0011\n",
            "training:  lstm_cv_rvi  df:  42\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 6.0883e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 3.6959e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.1018e-05 - val_loss: 8.8284e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0737e-05 - val_loss: 9.1877e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0247e-05 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9270e-05 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0893e-05 - val_loss: 0.0023\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0399e-05 - val_loss: 0.0028\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9179e-05 - val_loss: 0.0034\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9253e-05 - val_loss: 0.0031\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9272e-05 - val_loss: 0.0035\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9453e-05 - val_loss: 0.0041\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0166e-05 - val_loss: 0.0038\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.8405e-05 - val_loss: 0.0032\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.8282e-05 - val_loss: 0.0043\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.8701e-05 - val_loss: 0.0047\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9533e-05 - val_loss: 0.0050\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.8788e-05 - val_loss: 0.0044\n",
            "training:  lstm_cv_rvi  df:  43\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 8/64 [==>...........................] - ETA: 0s - loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 9ms/step - loss: 5.0028e-04 - val_loss: 6.8247e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3636e-04 - val_loss: 7.9533e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3203e-04 - val_loss: 8.8372e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.2068e-04 - val_loss: 8.8219e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0513e-04 - val_loss: 8.5114e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1854e-04 - val_loss: 8.9280e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.5227e-04 - val_loss: 9.3267e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0923e-04 - val_loss: 8.9423e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0229e-04 - val_loss: 9.0461e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0681e-04 - val_loss: 8.4082e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1097e-04 - val_loss: 9.1467e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9295e-04 - val_loss: 8.0242e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0665e-04 - val_loss: 8.7986e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1538e-04 - val_loss: 9.0167e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0564e-04 - val_loss: 9.1557e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0908e-04 - val_loss: 0.0010\n",
            "training:  lstm_cv_rvi  df:  44\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 6.2677e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4967e-04 - val_loss: 1.8369e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3399e-04 - val_loss: 1.7124e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3705e-04 - val_loss: 1.6366e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3572e-04 - val_loss: 1.6006e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3394e-04 - val_loss: 1.6118e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3352e-04 - val_loss: 1.5960e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3343e-04 - val_loss: 1.7938e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3606e-04 - val_loss: 2.2453e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3506e-04 - val_loss: 1.7667e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3783e-04 - val_loss: 1.7483e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3812e-04 - val_loss: 2.2314e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3805e-04 - val_loss: 2.1065e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3887e-04 - val_loss: 1.9841e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3545e-04 - val_loss: 2.1640e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3601e-04 - val_loss: 2.0723e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3558e-04 - val_loss: 2.1490e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3380e-04 - val_loss: 2.2696e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3669e-04 - val_loss: 2.0957e-04\n",
            "Epoch 19/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3477e-04 - val_loss: 1.9934e-04\n",
            "Epoch 20/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3337e-04 - val_loss: 2.7245e-04\n",
            "Epoch 21/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3533e-04 - val_loss: 2.7605e-04\n",
            "training:  lstm_cv_rvi  df:  45\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/174 [..............................] - ETA: 1s - loss: 3.1258e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1256e-04 - val_loss: 2.0036e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8911e-04 - val_loss: 1.7748e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8885e-04 - val_loss: 1.8515e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8779e-04 - val_loss: 1.8419e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8636e-04 - val_loss: 1.8768e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9021e-04 - val_loss: 1.8320e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8675e-04 - val_loss: 1.8750e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8364e-04 - val_loss: 1.7895e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8522e-04 - val_loss: 1.7959e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8175e-04 - val_loss: 1.9014e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7456e-04 - val_loss: 1.9801e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7961e-04 - val_loss: 1.9632e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8269e-04 - val_loss: 1.8038e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8683e-04 - val_loss: 2.0006e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8751e-04 - val_loss: 1.8165e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7858e-04 - val_loss: 1.8992e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8006e-04 - val_loss: 1.7609e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9224e-04 - val_loss: 1.9351e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8496e-04 - val_loss: 2.0580e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7471e-04 - val_loss: 1.7757e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8451e-04 - val_loss: 1.8821e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8187e-04 - val_loss: 2.1379e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8466e-04 - val_loss: 1.7955e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7733e-04 - val_loss: 1.9550e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7750e-04 - val_loss: 1.8186e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8100e-04 - val_loss: 1.9000e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8512e-04 - val_loss: 1.9153e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8145e-04 - val_loss: 1.8899e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8552e-04 - val_loss: 1.9304e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8924e-04 - val_loss: 2.1116e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7913e-04 - val_loss: 1.7803e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8465e-04 - val_loss: 1.9365e-04\n",
            "training:  lstm_cv_rvi  df:  46\n",
            "Training model: lstm_cv_rvi  features: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6705e-05 - val_loss: 1.0509e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5637e-05 - val_loss: 1.0151e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5066e-05 - val_loss: 1.1003e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4109e-05 - val_loss: 1.0264e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3237e-05 - val_loss: 1.0193e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7065e-05 - val_loss: 1.0929e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5637e-05 - val_loss: 1.0075e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7669e-05 - val_loss: 1.0359e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1294e-05 - val_loss: 1.0958e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5169e-05 - val_loss: 1.0651e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3930e-05 - val_loss: 1.0038e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7676e-05 - val_loss: 1.2356e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3167e-05 - val_loss: 1.0276e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3533e-05 - val_loss: 1.1882e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4130e-05 - val_loss: 1.0134e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5264e-05 - val_loss: 1.0708e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3337e-05 - val_loss: 9.9427e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5085e-05 - val_loss: 1.0102e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4212e-05 - val_loss: 1.0025e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5438e-05 - val_loss: 1.3951e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4951e-05 - val_loss: 1.0574e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7141e-05 - val_loss: 9.8376e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3868e-05 - val_loss: 1.1103e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3157e-05 - val_loss: 1.2640e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3107e-05 - val_loss: 1.0682e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0007e-05 - val_loss: 1.2042e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1404e-05 - val_loss: 1.2696e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4289e-05 - val_loss: 1.4697e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2404e-05 - val_loss: 1.2019e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3380e-05 - val_loss: 1.0528e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5281e-05 - val_loss: 1.0094e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1986e-05 - val_loss: 1.0712e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5681e-05 - val_loss: 1.0256e-04\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2974e-05 - val_loss: 1.0936e-04\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4545e-05 - val_loss: 1.0600e-04\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3861e-05 - val_loss: 9.9019e-05\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4356e-05 - val_loss: 1.1248e-04\n",
            "training:  lstm_cv_rvi  df:  47\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.8657e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3884e-04 - val_loss: 2.2635e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3830e-04 - val_loss: 2.3906e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2566e-04 - val_loss: 1.8504e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2534e-04 - val_loss: 2.5114e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2520e-04 - val_loss: 1.9137e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2411e-04 - val_loss: 2.4823e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2969e-04 - val_loss: 2.0447e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2359e-04 - val_loss: 2.7752e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2478e-04 - val_loss: 1.7957e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2939e-04 - val_loss: 2.0606e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2578e-04 - val_loss: 1.8372e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2493e-04 - val_loss: 2.2104e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1899e-04 - val_loss: 3.1854e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2121e-04 - val_loss: 1.8906e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2402e-04 - val_loss: 1.9939e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2369e-04 - val_loss: 1.6095e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2086e-04 - val_loss: 2.1693e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2222e-04 - val_loss: 1.8374e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1829e-04 - val_loss: 2.1105e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2944e-04 - val_loss: 1.7683e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2170e-04 - val_loss: 1.7682e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1815e-04 - val_loss: 2.2856e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2460e-04 - val_loss: 2.5128e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2385e-04 - val_loss: 1.8278e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1929e-04 - val_loss: 1.7404e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2244e-04 - val_loss: 1.8548e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2800e-04 - val_loss: 1.7109e-04\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2273e-04 - val_loss: 1.9151e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2575e-04 - val_loss: 2.6239e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1967e-04 - val_loss: 2.4926e-04\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2273e-04 - val_loss: 1.6774e-04\n",
            "training:  lstm_cv_rvi  df:  48\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 9.9047e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1963e-04 - val_loss: 8.6585e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1709e-04 - val_loss: 7.5924e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1154e-04 - val_loss: 8.1134e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1175e-04 - val_loss: 7.3092e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1490e-04 - val_loss: 1.1622e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1344e-04 - val_loss: 7.8587e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1503e-04 - val_loss: 7.6889e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1644e-04 - val_loss: 7.8251e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1227e-04 - val_loss: 8.6653e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1335e-04 - val_loss: 8.3087e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1556e-04 - val_loss: 9.9070e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1144e-04 - val_loss: 7.5997e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1071e-04 - val_loss: 7.7169e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1158e-04 - val_loss: 7.8626e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0958e-04 - val_loss: 8.6067e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1186e-04 - val_loss: 7.5121e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1321e-04 - val_loss: 1.4099e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1484e-04 - val_loss: 8.1702e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1198e-04 - val_loss: 8.2146e-05\n",
            "training:  lstm_cv_rvi  df:  49\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 7.5421e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8218e-05 - val_loss: 9.3784e-05\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7817e-05 - val_loss: 9.8408e-05\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7883e-05 - val_loss: 1.0110e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4500e-05 - val_loss: 9.9343e-05\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6467e-05 - val_loss: 9.6873e-05\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4152e-05 - val_loss: 9.7999e-05\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7799e-05 - val_loss: 1.0489e-04\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8706e-05 - val_loss: 1.0024e-04\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9475e-05 - val_loss: 9.3868e-05\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4498e-05 - val_loss: 9.2666e-05\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6477e-05 - val_loss: 1.0729e-04\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5183e-05 - val_loss: 9.9061e-05\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6849e-05 - val_loss: 9.5835e-05\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5521e-05 - val_loss: 9.8464e-05\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5909e-05 - val_loss: 9.4282e-05\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8179e-05 - val_loss: 9.8409e-05\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4862e-05 - val_loss: 9.5168e-05\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6184e-05 - val_loss: 1.0057e-04\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5611e-05 - val_loss: 1.0676e-04\n",
            "Epoch 20/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9873e-05 - val_loss: 9.7480e-05\n",
            "Epoch 21/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6096e-05 - val_loss: 1.0895e-04\n",
            "Epoch 22/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6344e-05 - val_loss: 1.0512e-04\n",
            "Epoch 23/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6154e-05 - val_loss: 1.0381e-04\n",
            "Epoch 24/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8450e-05 - val_loss: 9.5675e-05\n",
            "Epoch 25/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6364e-05 - val_loss: 9.6719e-05\n",
            "training:  lstm_cv_rvi  df:  50\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0026\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5885e-04 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9804e-04 - val_loss: 0.0020\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.4352e-04 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5258e-04 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6644e-04 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6887e-04 - val_loss: 0.0018\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7477e-04 - val_loss: 0.0018\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8636e-04 - val_loss: 0.0019\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6543e-04 - val_loss: 0.0018\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8955e-04 - val_loss: 0.0019\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.3800e-04 - val_loss: 0.0018\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.4000e-04 - val_loss: 0.0021\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9890e-04 - val_loss: 0.0018\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8149e-04 - val_loss: 0.0019\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8837e-04 - val_loss: 0.0019\n",
            "training:  lstm_cv_rvi  df:  51\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  8/106 [=>............................] - ETA: 0s - loss: 3.2027e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.6518e-04 - val_loss: 6.5668e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3944e-04 - val_loss: 6.4883e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3161e-04 - val_loss: 6.5596e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2413e-04 - val_loss: 6.6470e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2439e-04 - val_loss: 6.4500e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2277e-04 - val_loss: 6.4667e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2666e-04 - val_loss: 6.7243e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1919e-04 - val_loss: 7.5868e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2624e-04 - val_loss: 6.6088e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2597e-04 - val_loss: 6.5709e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3058e-04 - val_loss: 6.5666e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2371e-04 - val_loss: 6.6804e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2105e-04 - val_loss: 6.7530e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2236e-04 - val_loss: 6.6886e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1695e-04 - val_loss: 6.7431e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2411e-04 - val_loss: 6.9509e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2846e-04 - val_loss: 6.8863e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1794e-04 - val_loss: 6.9961e-04\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2730e-04 - val_loss: 6.8020e-04\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2060e-04 - val_loss: 6.7654e-04\n",
            "training:  lstm_cv_rvi  df:  52\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 3s - loss: 8.5222e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 3.0247e-05 - val_loss: 2.4519e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9373e-05 - val_loss: 2.2559e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8603e-05 - val_loss: 2.1506e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8165e-05 - val_loss: 2.2526e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7894e-05 - val_loss: 2.2366e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7507e-05 - val_loss: 2.4425e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7592e-05 - val_loss: 2.4801e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7000e-05 - val_loss: 2.5301e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7575e-05 - val_loss: 2.5867e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7694e-05 - val_loss: 2.4433e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7065e-05 - val_loss: 2.8663e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6856e-05 - val_loss: 2.6062e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7345e-05 - val_loss: 2.7582e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7315e-05 - val_loss: 2.6542e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7416e-05 - val_loss: 2.8948e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7097e-05 - val_loss: 3.2443e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6649e-05 - val_loss: 3.3649e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6841e-05 - val_loss: 3.4738e-04\n",
            "training:  lstm_cv_rvi  df:  53\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n",
            " 9/79 [==>...........................] - ETA: 0s - loss: 1.5528e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 1.0276e-04 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 1.0143e-04 - val_loss: 0.0021\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0014e-05 - val_loss: 0.0026\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0579e-05 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4052e-05 - val_loss: 0.0024\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0753e-05 - val_loss: 0.0023\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2509e-05 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.6640e-05 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3058e-05 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9524e-05 - val_loss: 0.0025\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8916e-05 - val_loss: 0.0023\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.6465e-05 - val_loss: 0.0023\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3825e-05 - val_loss: 0.0025\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9512e-05 - val_loss: 0.0022\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8650e-05 - val_loss: 0.0025\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7540e-05 - val_loss: 0.0019\n",
            "training:  lstm_cv_rvi  df:  54\n",
            "Training model: lstm_cv_rvi  features: 3\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 5.2005e-05 - val_loss: 3.4019e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7380e-05 - val_loss: 2.9161e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7124e-05 - val_loss: 2.4435e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5812e-05 - val_loss: 3.3929e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.6013e-05 - val_loss: 3.2696e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7907e-05 - val_loss: 3.8324e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5590e-05 - val_loss: 5.5522e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5993e-05 - val_loss: 4.8418e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5739e-05 - val_loss: 3.6791e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6996e-05 - val_loss: 2.9305e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6868e-05 - val_loss: 4.4495e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7043e-05 - val_loss: 5.9511e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4103e-05 - val_loss: 5.7189e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7029e-05 - val_loss: 4.4287e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3971e-05 - val_loss: 5.4033e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3245e-05 - val_loss: 5.4269e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.7082e-05 - val_loss: 5.5111e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5176e-05 - val_loss: 4.9789e-04\n",
            "build model: lstm_cv_vwap  features: 4\n",
            "training:  lstm_cv_vwap\n",
            "lstm_cv_vwap  should train on stocks\n",
            "training dfs: 55\n",
            "training:  lstm_cv_vwap  df:  0\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 13ms/step - loss: 0.0102 - val_loss: 0.3296\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 0.0025 - val_loss: 0.2161\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.1052\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.1083\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.4178e-04 - val_loss: 0.1297\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.8223e-04 - val_loss: 0.1312\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6899e-04 - val_loss: 0.1208\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 5.3517e-04 - val_loss: 0.1263\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.9465e-04 - val_loss: 0.1175\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.9368e-04 - val_loss: 0.1215\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.8278e-04 - val_loss: 0.1179\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.6075e-04 - val_loss: 0.1096\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 2.0805e-04 - val_loss: 0.1179\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.8293e-04 - val_loss: 0.1027\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.0906e-04 - val_loss: 0.1076\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.5776e-04 - val_loss: 0.0955\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.4645e-04 - val_loss: 0.0996\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 1.3039e-04 - val_loss: 0.1044\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.1895e-04 - val_loss: 0.1036\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.1319e-04 - val_loss: 0.0934\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.4614e-04 - val_loss: 0.0995\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.1655e-04 - val_loss: 0.0915\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0995e-04 - val_loss: 0.0934\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0702e-04 - val_loss: 0.0937\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.8472e-05 - val_loss: 0.0915\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.3133e-05 - val_loss: 0.0953\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.3196e-05 - val_loss: 0.0916\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.9575e-05 - val_loss: 0.0959\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.0273e-05 - val_loss: 0.0933\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.0493e-05 - val_loss: 0.0949\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.4242e-05 - val_loss: 0.0876\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 7.5658e-05 - val_loss: 0.0858\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.5112e-05 - val_loss: 0.0871\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.9505e-05 - val_loss: 0.0903\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 6.6621e-05 - val_loss: 0.0923\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.7324e-05 - val_loss: 0.0923\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.5044e-05 - val_loss: 0.0902\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.4766e-05 - val_loss: 0.0912\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.6057e-05 - val_loss: 0.0851\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.3543e-05 - val_loss: 0.0900\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.0155e-05 - val_loss: 0.0850\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 6.4569e-05 - val_loss: 0.0863\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 7.2368e-05 - val_loss: 0.0899\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 6.6193e-05 - val_loss: 0.0792\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.9667e-05 - val_loss: 0.0879\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.8125e-05 - val_loss: 0.0867\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.0734e-05 - val_loss: 0.0872\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 6.1320e-05 - val_loss: 0.0816\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.5592e-05 - val_loss: 0.0839\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.1158e-05 - val_loss: 0.0795\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.8565e-05 - val_loss: 0.0910\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.1226e-05 - val_loss: 0.0840\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.8643e-05 - val_loss: 0.0794\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.5942e-05 - val_loss: 0.0797\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 5.0041e-05 - val_loss: 0.0779\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.2914e-05 - val_loss: 0.0782\n",
            "Epoch 57/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.2472e-05 - val_loss: 0.0893\n",
            "Epoch 58/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 6.2968e-05 - val_loss: 0.0861\n",
            "Epoch 59/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.8099e-05 - val_loss: 0.0825\n",
            "Epoch 60/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.5900e-05 - val_loss: 0.0800\n",
            "Epoch 61/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.8955e-05 - val_loss: 0.0756\n",
            "Epoch 62/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.1398e-05 - val_loss: 0.0884\n",
            "Epoch 63/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.3056e-05 - val_loss: 0.0823\n",
            "Epoch 64/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.0491e-05 - val_loss: 0.0840\n",
            "Epoch 65/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.3510e-05 - val_loss: 0.0826\n",
            "Epoch 66/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.9371e-05 - val_loss: 0.0817\n",
            "Epoch 67/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.3280e-05 - val_loss: 0.0839\n",
            "Epoch 68/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 4.0963e-05 - val_loss: 0.0881\n",
            "Epoch 69/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.4622e-05 - val_loss: 0.0843\n",
            "Epoch 70/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6476e-05 - val_loss: 0.0782\n",
            "Epoch 71/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.0328e-05 - val_loss: 0.0836\n",
            "Epoch 72/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.4907e-05 - val_loss: 0.0831\n",
            "Epoch 73/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.4706e-05 - val_loss: 0.0835\n",
            "Epoch 74/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6070e-05 - val_loss: 0.0821\n",
            "Epoch 75/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.3351e-05 - val_loss: 0.0846\n",
            "Epoch 76/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.5746e-05 - val_loss: 0.0846\n",
            "training:  lstm_cv_vwap  df:  1\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/80 [==>...........................] - ETA: 0s - loss: 8.0888e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 8ms/step - loss: 1.8678e-04 - val_loss: 0.1750\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.5408e-05 - val_loss: 0.1696\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.7806e-05 - val_loss: 0.1799\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.2520e-05 - val_loss: 0.1765\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.8776e-05 - val_loss: 0.1755\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3015e-05 - val_loss: 0.1748\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5495e-05 - val_loss: 0.1645\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.0692e-05 - val_loss: 0.1735\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.2571e-05 - val_loss: 0.1691\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.4637e-05 - val_loss: 0.1674\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5882e-05 - val_loss: 0.1669\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5646e-05 - val_loss: 0.1731\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.4832e-05 - val_loss: 0.1705\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.7792e-05 - val_loss: 0.1699\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.2362e-05 - val_loss: 0.1743\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.2369e-05 - val_loss: 0.1732\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.2471e-05 - val_loss: 0.1672\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.8517e-05 - val_loss: 0.1681\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.4094e-05 - val_loss: 0.1482\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.1388e-05 - val_loss: 0.1668\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.9643e-05 - val_loss: 0.1629\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.0428e-05 - val_loss: 0.1574\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6658e-05 - val_loss: 0.1582\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6990e-05 - val_loss: 0.1531\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.3505e-05 - val_loss: 0.1565\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.7262e-05 - val_loss: 0.1437\n",
            "Epoch 27/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6499e-05 - val_loss: 0.1522\n",
            "Epoch 28/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.8468e-05 - val_loss: 0.1755\n",
            "Epoch 29/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.2493e-05 - val_loss: 0.1659\n",
            "Epoch 30/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.1879e-05 - val_loss: 0.1841\n",
            "Epoch 31/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.2391e-05 - val_loss: 0.1765\n",
            "Epoch 32/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.0727e-05 - val_loss: 0.1896\n",
            "Epoch 33/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5535e-05 - val_loss: 0.1749\n",
            "Epoch 34/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5712e-05 - val_loss: 0.1725\n",
            "Epoch 35/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5477e-05 - val_loss: 0.1704\n",
            "Epoch 36/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.3028e-05 - val_loss: 0.1766\n",
            "Epoch 37/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.2272e-05 - val_loss: 0.1499\n",
            "Epoch 38/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.2513e-05 - val_loss: 0.1528\n",
            "Epoch 39/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.3905e-05 - val_loss: 0.1598\n",
            "Epoch 40/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.9195e-05 - val_loss: 0.1681\n",
            "Epoch 41/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.7543e-05 - val_loss: 0.1543\n",
            "training:  lstm_cv_vwap  df:  2\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 7.4500e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 8ms/step - loss: 1.0222e-05 - val_loss: 0.1122\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.4748e-06 - val_loss: 0.1100\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.9270e-06 - val_loss: 0.1136\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.4215e-06 - val_loss: 0.1179\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.1504e-06 - val_loss: 0.1187\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.9241e-06 - val_loss: 0.1229\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.0788e-06 - val_loss: 0.1249\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.9969e-06 - val_loss: 0.1253\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.8473e-06 - val_loss: 0.1271\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.6421e-06 - val_loss: 0.1252\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.8163e-06 - val_loss: 0.1290\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.7389e-06 - val_loss: 0.1315\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.6463e-06 - val_loss: 0.1275\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.4879e-06 - val_loss: 0.1327\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.8221e-06 - val_loss: 0.1353\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.4084e-06 - val_loss: 0.1363\n",
            "Epoch 17/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.6946e-06 - val_loss: 0.1329\n",
            "training:  lstm_cv_vwap  df:  3\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.7602e-04 - val_loss: 0.0245\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0875e-04 - val_loss: 0.0211\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3129e-05 - val_loss: 0.0162\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8308e-05 - val_loss: 0.0181\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7108e-05 - val_loss: 0.0179\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1114e-05 - val_loss: 0.0174\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9749e-05 - val_loss: 0.0161\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5023e-05 - val_loss: 0.0162\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8059e-05 - val_loss: 0.0173\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3788e-05 - val_loss: 0.0148\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3359e-05 - val_loss: 0.0178\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.7969e-05 - val_loss: 0.0157\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5291e-05 - val_loss: 0.0181\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.6203e-05 - val_loss: 0.0172\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8896e-05 - val_loss: 0.0151\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8648e-05 - val_loss: 0.0184\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5898e-05 - val_loss: 0.0195\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1882e-05 - val_loss: 0.0199\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.4403e-05 - val_loss: 0.0188\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2502e-05 - val_loss: 0.0165\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8697e-05 - val_loss: 0.0206\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9589e-05 - val_loss: 0.0178\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0766e-05 - val_loss: 0.0168\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3052e-05 - val_loss: 0.0174\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5554e-05 - val_loss: 0.0177\n",
            "training:  lstm_cv_vwap  df:  4\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6663e-04 - val_loss: 9.2743e-05\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.6854e-04 - val_loss: 6.3790e-05\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3325e-04 - val_loss: 7.6744e-05\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3635e-04 - val_loss: 1.0101e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.3050e-04 - val_loss: 6.7632e-05\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.3053e-04 - val_loss: 9.0889e-05\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2985e-04 - val_loss: 7.0004e-05\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1992e-04 - val_loss: 6.3808e-05\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1884e-04 - val_loss: 5.7813e-05\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1542e-04 - val_loss: 6.6965e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1779e-04 - val_loss: 1.1457e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0968e-04 - val_loss: 6.4568e-05\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1102e-04 - val_loss: 1.2514e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1598e-04 - val_loss: 6.5208e-05\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1595e-04 - val_loss: 7.6573e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1859e-04 - val_loss: 1.0060e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1293e-04 - val_loss: 9.1682e-05\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1037e-04 - val_loss: 1.2809e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1317e-04 - val_loss: 1.6047e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2144e-04 - val_loss: 7.1533e-05\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1183e-04 - val_loss: 6.2684e-05\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1015e-04 - val_loss: 6.8815e-05\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0781e-04 - val_loss: 9.6715e-05\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0935e-04 - val_loss: 8.1370e-05\n",
            "training:  lstm_cv_vwap  df:  5\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.0564e-05 - val_loss: 3.4177e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.3755e-05 - val_loss: 4.1401e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1324e-05 - val_loss: 4.8254e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9529e-05 - val_loss: 5.9154e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8798e-05 - val_loss: 8.5553e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7149e-05 - val_loss: 7.6335e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8577e-05 - val_loss: 7.8038e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6872e-05 - val_loss: 7.1805e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6578e-05 - val_loss: 9.3910e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6505e-05 - val_loss: 7.0396e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6266e-05 - val_loss: 7.2216e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7408e-05 - val_loss: 8.4352e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7424e-05 - val_loss: 0.0011\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5601e-05 - val_loss: 8.7196e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4714e-05 - val_loss: 9.6059e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5458e-05 - val_loss: 0.0010\n",
            "training:  lstm_cv_vwap  df:  6\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 4.5991e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 3.1770e-04 - val_loss: 2.0183e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.5152e-04 - val_loss: 9.8495e-05\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4332e-04 - val_loss: 9.5907e-05\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3755e-04 - val_loss: 1.0916e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4250e-04 - val_loss: 1.0705e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.3837e-04 - val_loss: 1.6995e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2945e-04 - val_loss: 1.1911e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3868e-04 - val_loss: 9.8851e-05\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3788e-04 - val_loss: 1.1014e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3820e-04 - val_loss: 1.2841e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.3376e-04 - val_loss: 9.4450e-05\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3327e-04 - val_loss: 9.9594e-05\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3146e-04 - val_loss: 9.8081e-05\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2694e-04 - val_loss: 1.2906e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3294e-04 - val_loss: 9.3579e-05\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2995e-04 - val_loss: 9.3262e-05\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3555e-04 - val_loss: 1.3523e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2298e-04 - val_loss: 1.1567e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2017e-04 - val_loss: 1.1281e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2456e-04 - val_loss: 1.0120e-04\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1792e-04 - val_loss: 1.0986e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1829e-04 - val_loss: 9.5783e-05\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1875e-04 - val_loss: 1.4211e-04\n",
            "Epoch 24/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1910e-04 - val_loss: 1.0140e-04\n",
            "Epoch 25/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1727e-04 - val_loss: 1.4188e-04\n",
            "Epoch 26/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2393e-04 - val_loss: 1.0871e-04\n",
            "Epoch 27/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1176e-04 - val_loss: 1.0358e-04\n",
            "Epoch 28/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1912e-04 - val_loss: 1.0734e-04\n",
            "Epoch 29/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2001e-04 - val_loss: 1.0654e-04\n",
            "Epoch 30/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2475e-04 - val_loss: 2.2075e-04\n",
            "Epoch 31/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1787e-04 - val_loss: 1.0753e-04\n",
            "training:  lstm_cv_vwap  df:  7\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 1.3050e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 6.1784e-05 - val_loss: 3.7710e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.0351e-05 - val_loss: 3.2210e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.8993e-05 - val_loss: 3.2104e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.2638e-05 - val_loss: 3.2953e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.2677e-05 - val_loss: 3.3949e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.0532e-05 - val_loss: 3.5502e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.1644e-05 - val_loss: 3.7635e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.3242e-05 - val_loss: 3.7170e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.8573e-05 - val_loss: 4.2817e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.0115e-05 - val_loss: 4.0431e-04\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.8837e-05 - val_loss: 5.6562e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.0885e-05 - val_loss: 5.0089e-04\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.7851e-05 - val_loss: 6.6836e-04\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.8403e-05 - val_loss: 7.5506e-04\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.7615e-05 - val_loss: 7.4355e-04\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.6677e-05 - val_loss: 0.0012\n",
            "Epoch 17/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.9234e-05 - val_loss: 0.0011\n",
            "Epoch 18/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.0052e-05 - val_loss: 0.0014\n",
            "training:  lstm_cv_vwap  df:  8\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/68 [==>...........................] - ETA: 0s - loss: 1.7802e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 1.5747e-04 - val_loss: 9.5628e-04\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.6403e-04 - val_loss: 9.2774e-04\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4967e-04 - val_loss: 0.0024\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3398e-04 - val_loss: 0.0027\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2280e-04 - val_loss: 0.0015\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2087e-04 - val_loss: 0.0021\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0437e-04 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1677e-04 - val_loss: 0.0024\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1398e-04 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0913e-04 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1296e-04 - val_loss: 0.0022\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.5968e-04 - val_loss: 0.0021\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2133e-04 - val_loss: 0.0026\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2310e-04 - val_loss: 0.0039\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0732e-04 - val_loss: 0.0036\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1532e-04 - val_loss: 0.0035\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0405e-04 - val_loss: 0.0036\n",
            "training:  lstm_cv_vwap  df:  9\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/162 [..............................] - ETA: 1s - loss: 3.1299e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 3.4220e-05 - val_loss: 0.0042\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8789e-05 - val_loss: 0.0050\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.5315e-05 - val_loss: 0.0055\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6061e-05 - val_loss: 0.0059\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.3255e-05 - val_loss: 0.0062\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.4457e-05 - val_loss: 0.0065\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.3822e-05 - val_loss: 0.0070\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.2910e-05 - val_loss: 0.0074\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.2747e-05 - val_loss: 0.0077\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1279e-05 - val_loss: 0.0083\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0641e-05 - val_loss: 0.0087\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0688e-05 - val_loss: 0.0091\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0508e-05 - val_loss: 0.0096\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0828e-05 - val_loss: 0.0098\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0734e-05 - val_loss: 0.0102\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1296e-05 - val_loss: 0.0103\n",
            "training:  lstm_cv_vwap  df:  10\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7939e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8555e-05 - val_loss: 6.9113e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1206e-05 - val_loss: 5.2676e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8678e-05 - val_loss: 5.6642e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9787e-05 - val_loss: 6.2374e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6707e-05 - val_loss: 7.0302e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5818e-05 - val_loss: 0.0010\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6684e-05 - val_loss: 0.0011\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6112e-05 - val_loss: 7.6600e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1443e-05 - val_loss: 7.6378e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4224e-05 - val_loss: 4.8304e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5537e-05 - val_loss: 6.8786e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6294e-05 - val_loss: 7.9905e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6597e-05 - val_loss: 0.0010\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6347e-05 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5091e-05 - val_loss: 0.0011\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8340e-05 - val_loss: 4.5982e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5361e-05 - val_loss: 6.1107e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4375e-05 - val_loss: 0.0011\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3056e-05 - val_loss: 0.0012\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4577e-05 - val_loss: 6.4209e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3974e-05 - val_loss: 6.8669e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.0955e-05 - val_loss: 0.0011\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6716e-05 - val_loss: 7.7854e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2209e-05 - val_loss: 5.8771e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5822e-05 - val_loss: 7.6242e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8922e-05 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3519e-05 - val_loss: 6.7273e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3208e-05 - val_loss: 4.9591e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4191e-05 - val_loss: 6.4695e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3834e-05 - val_loss: 7.1955e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2627e-05 - val_loss: 8.8097e-04\n",
            "training:  lstm_cv_vwap  df:  11\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0707e-04 - val_loss: 3.5075e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3216e-05 - val_loss: 7.5282e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1326e-05 - val_loss: 6.8004e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2005e-05 - val_loss: 9.4300e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8258e-05 - val_loss: 1.3957e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1831e-05 - val_loss: 1.0080e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0891e-05 - val_loss: 1.2804e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5737e-05 - val_loss: 7.4329e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5528e-05 - val_loss: 1.1248e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8030e-05 - val_loss: 8.2220e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6445e-05 - val_loss: 7.2944e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6374e-05 - val_loss: 2.9295e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9897e-05 - val_loss: 8.8946e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4000e-05 - val_loss: 7.6560e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8950e-05 - val_loss: 7.1496e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7607e-05 - val_loss: 9.0285e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4398e-05 - val_loss: 8.0788e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5292e-05 - val_loss: 1.6265e-04\n",
            "training:  lstm_cv_vwap  df:  12\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7510e-04 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.9395e-04 - val_loss: 0.0018\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "training:  lstm_cv_vwap  df:  13\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 5.9975e-05 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.8263e-05 - val_loss: 0.0014\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.2638e-05 - val_loss: 0.0014\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.0070e-05 - val_loss: 0.0014\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7609e-05 - val_loss: 0.0013\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7427e-05 - val_loss: 0.0013\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6779e-05 - val_loss: 0.0014\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6079e-05 - val_loss: 0.0014\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4698e-05 - val_loss: 0.0014\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5527e-05 - val_loss: 0.0014\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4955e-05 - val_loss: 0.0014\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4795e-05 - val_loss: 0.0014\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3907e-05 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3042e-05 - val_loss: 0.0014\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5329e-05 - val_loss: 0.0014\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3232e-05 - val_loss: 0.0014\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3902e-05 - val_loss: 0.0014\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3160e-05 - val_loss: 0.0014\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2468e-05 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5512e-05 - val_loss: 0.0014\n",
            "training:  lstm_cv_vwap  df:  14\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/26 [========>.....................] - ETA: 0s - loss: 6.5513e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 10ms/step - loss: 6.0456e-04 - val_loss: 9.4545e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.3539e-04 - val_loss: 2.6739e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.5715e-04 - val_loss: 2.2252e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.5634e-04 - val_loss: 3.2321e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2573e-04 - val_loss: 2.2366e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1019e-04 - val_loss: 2.2133e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1897e-04 - val_loss: 2.4803e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3792e-04 - val_loss: 2.8065e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.4749e-04 - val_loss: 6.7136e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 5.2337e-04 - val_loss: 2.8496e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.0141e-04 - val_loss: 2.1606e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6406e-04 - val_loss: 2.3749e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.4267e-04 - val_loss: 2.3204e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6943e-04 - val_loss: 2.1955e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.5044e-04 - val_loss: 2.0786e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7553e-04 - val_loss: 2.0245e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8682e-04 - val_loss: 2.6163e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7228e-04 - val_loss: 2.0663e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9461e-04 - val_loss: 2.9117e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8724e-04 - val_loss: 2.3926e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7041e-04 - val_loss: 2.2988e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.3501e-04 - val_loss: 2.8580e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7344e-04 - val_loss: 2.9090e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7329e-04 - val_loss: 2.1055e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.5598e-04 - val_loss: 1.9721e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.5883e-04 - val_loss: 2.1590e-04\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.5207e-04 - val_loss: 2.1723e-04\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.5086e-04 - val_loss: 2.1051e-04\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.3127e-04 - val_loss: 2.4944e-04\n",
            "Epoch 30/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.5444e-04 - val_loss: 2.0766e-04\n",
            "Epoch 31/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6954e-04 - val_loss: 2.3679e-04\n",
            "Epoch 32/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.5572e-04 - val_loss: 2.3810e-04\n",
            "Epoch 33/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8025e-04 - val_loss: 3.7395e-04\n",
            "Epoch 34/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.4946e-04 - val_loss: 2.1414e-04\n",
            "Epoch 35/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6508e-04 - val_loss: 2.2299e-04\n",
            "Epoch 36/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8681e-04 - val_loss: 2.0812e-04\n",
            "Epoch 37/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8384e-04 - val_loss: 2.2523e-04\n",
            "Epoch 38/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.0900e-04 - val_loss: 2.6153e-04\n",
            "Epoch 39/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.5510e-04 - val_loss: 2.4883e-04\n",
            "Epoch 40/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6592e-04 - val_loss: 2.1318e-04\n",
            "training:  lstm_cv_vwap  df:  15\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5512e-05 - val_loss: 6.3300e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1619e-05 - val_loss: 6.7139e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1256e-05 - val_loss: 6.5267e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0217e-05 - val_loss: 6.5147e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0031e-05 - val_loss: 6.7295e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.9513e-06 - val_loss: 6.8680e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0001e-05 - val_loss: 6.8195e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4453e-06 - val_loss: 8.3020e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7109e-06 - val_loss: 7.9095e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6742e-06 - val_loss: 8.7764e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9257e-06 - val_loss: 9.2276e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7141e-06 - val_loss: 9.1454e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2492e-06 - val_loss: 0.0010\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7926e-06 - val_loss: 0.0011\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5581e-06 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2580e-06 - val_loss: 0.0012\n",
            "training:  lstm_cv_vwap  df:  16\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.8327e-05 - val_loss: 0.0036\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1658e-05 - val_loss: 0.0033\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8020e-05 - val_loss: 0.0039\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7640e-05 - val_loss: 0.0042\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6657e-05 - val_loss: 0.0047\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7419e-05 - val_loss: 0.0056\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6551e-05 - val_loss: 0.0064\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6187e-05 - val_loss: 0.0072\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6345e-05 - val_loss: 0.0080\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6464e-05 - val_loss: 0.0087\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5025e-05 - val_loss: 0.0104\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5058e-05 - val_loss: 0.0112\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6104e-05 - val_loss: 0.0128\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5713e-05 - val_loss: 0.0161\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5284e-05 - val_loss: 0.0145\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4712e-05 - val_loss: 0.0158\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5292e-05 - val_loss: 0.0195\n",
            "training:  lstm_cv_vwap  df:  17\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 1.4118e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3276e-05 - val_loss: 0.0193\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 8.9329e-06 - val_loss: 0.0222\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 8.4794e-06 - val_loss: 0.0232\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.7482e-06 - val_loss: 0.0280\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.9683e-06 - val_loss: 0.0309\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.2515e-06 - val_loss: 0.0328\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.3553e-06 - val_loss: 0.0342\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.0729e-06 - val_loss: 0.0380\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 5.9419e-06 - val_loss: 0.0442\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.0403e-06 - val_loss: 0.0462\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.0077e-06 - val_loss: 0.0453\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.6498e-06 - val_loss: 0.0458\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.5710e-06 - val_loss: 0.0500\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.1181e-06 - val_loss: 0.0560\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.4382e-06 - val_loss: 0.0569\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.6797e-06 - val_loss: 0.0612\n",
            "training:  lstm_cv_vwap  df:  18\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/174 [>.............................] - ETA: 1s - loss: 0.0132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 2.2845e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.5441e-04 - val_loss: 2.4485e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1809e-04 - val_loss: 1.9934e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2132e-04 - val_loss: 1.8404e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0252e-04 - val_loss: 2.2052e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0875e-04 - val_loss: 1.7680e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0058e-04 - val_loss: 1.8336e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0795e-04 - val_loss: 1.7663e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9922e-04 - val_loss: 1.7735e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1179e-04 - val_loss: 1.9345e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0012e-04 - val_loss: 1.9213e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9479e-04 - val_loss: 1.8397e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0823e-04 - val_loss: 1.9011e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9500e-04 - val_loss: 1.9145e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9279e-04 - val_loss: 1.9085e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9756e-04 - val_loss: 1.7558e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9222e-04 - val_loss: 1.9138e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0207e-04 - val_loss: 2.3735e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9703e-04 - val_loss: 1.9114e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0416e-04 - val_loss: 1.9965e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9957e-04 - val_loss: 1.8782e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0590e-04 - val_loss: 1.8304e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9427e-04 - val_loss: 2.0896e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9595e-04 - val_loss: 1.9162e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9599e-04 - val_loss: 1.9084e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9884e-04 - val_loss: 1.8439e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8674e-04 - val_loss: 2.5594e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0110e-04 - val_loss: 1.9369e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9837e-04 - val_loss: 1.7895e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9848e-04 - val_loss: 1.8385e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9052e-04 - val_loss: 1.7881e-04\n",
            "training:  lstm_cv_vwap  df:  19\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/47 [====>.........................] - ETA: 0s - loss: 1.9747e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0215e-04 - val_loss: 1.9942e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9241e-04 - val_loss: 1.9418e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0975e-04 - val_loss: 2.0321e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8654e-04 - val_loss: 2.1509e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9684e-04 - val_loss: 2.5105e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.6930e-04 - val_loss: 1.9910e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8931e-04 - val_loss: 2.0831e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7607e-04 - val_loss: 1.9720e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7415e-04 - val_loss: 1.8967e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0511e-04 - val_loss: 1.9142e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.8301e-04 - val_loss: 2.1251e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.7377e-04 - val_loss: 2.0643e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8253e-04 - val_loss: 1.8517e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8074e-04 - val_loss: 1.9914e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7686e-04 - val_loss: 1.9056e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7272e-04 - val_loss: 1.9549e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7535e-04 - val_loss: 1.9661e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7211e-04 - val_loss: 1.8537e-04\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.6737e-04 - val_loss: 2.4492e-04\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9184e-04 - val_loss: 2.0889e-04\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7397e-04 - val_loss: 1.9598e-04\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7194e-04 - val_loss: 1.9038e-04\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8020e-04 - val_loss: 1.9368e-04\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7313e-04 - val_loss: 1.8620e-04\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8223e-04 - val_loss: 2.5029e-04\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9602e-04 - val_loss: 2.2112e-04\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8951e-04 - val_loss: 2.0992e-04\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7781e-04 - val_loss: 2.3987e-04\n",
            "training:  lstm_cv_vwap  df:  20\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  9/151 [>.............................] - ETA: 0s - loss: 6.2753e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 6.0987e-05 - val_loss: 5.5454e-04\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.7312e-06 - val_loss: 5.6464e-04\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.1182e-06 - val_loss: 6.1375e-04\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.1532e-06 - val_loss: 6.3498e-04\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.4236e-06 - val_loss: 6.3192e-04\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.1679e-06 - val_loss: 7.0461e-04\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.8953e-06 - val_loss: 7.0431e-04\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.3909e-06 - val_loss: 7.3015e-04\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.6121e-06 - val_loss: 7.4336e-04\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.6460e-06 - val_loss: 7.6811e-04\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.9037e-06 - val_loss: 7.7898e-04\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.6628e-06 - val_loss: 7.7955e-04\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.1138e-06 - val_loss: 7.7307e-04\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.3699e-06 - val_loss: 7.6977e-04\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.8402e-06 - val_loss: 8.2400e-04\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.7880e-06 - val_loss: 8.0987e-04\n",
            "training:  lstm_cv_vwap  df:  21\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 7.5797e-05 - val_loss: 2.5389e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6946e-05 - val_loss: 4.3946e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.8041e-05 - val_loss: 3.3417e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.5419e-05 - val_loss: 2.4187e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3291e-05 - val_loss: 2.7153e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3672e-05 - val_loss: 1.6592e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2729e-05 - val_loss: 1.5050e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1091e-05 - val_loss: 1.6495e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3075e-05 - val_loss: 4.4242e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2463e-05 - val_loss: 1.9669e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0704e-05 - val_loss: 1.5452e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0033e-05 - val_loss: 1.2255e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9149e-05 - val_loss: 1.9037e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1429e-05 - val_loss: 1.6071e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2243e-05 - val_loss: 3.2755e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.8649e-05 - val_loss: 1.6989e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9191e-05 - val_loss: 1.6840e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0634e-05 - val_loss: 1.9959e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.0418e-05 - val_loss: 1.9998e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9125e-05 - val_loss: 1.7933e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1407e-05 - val_loss: 2.0330e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1293e-05 - val_loss: 2.4149e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0980e-05 - val_loss: 2.3941e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0993e-05 - val_loss: 2.3603e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9935e-05 - val_loss: 1.3034e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9206e-05 - val_loss: 1.7058e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9132e-05 - val_loss: 4.1221e-04\n",
            "training:  lstm_cv_vwap  df:  22\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/317 [..............................] - ETA: 3s - loss: 1.9374e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 2s 8ms/step - loss: 2.3733e-05 - val_loss: 0.0011\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1789e-05 - val_loss: 0.0011\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1415e-05 - val_loss: 0.0012\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1632e-05 - val_loss: 0.0012\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1017e-05 - val_loss: 0.0013\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0142e-05 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0551e-05 - val_loss: 0.0024\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0318e-05 - val_loss: 0.0024\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.1156e-05 - val_loss: 0.0028\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.9404e-05 - val_loss: 0.0025\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0499e-05 - val_loss: 0.0033\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.0130e-05 - val_loss: 0.0038\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0735e-05 - val_loss: 0.0031\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 1.9413e-05 - val_loss: 0.0048\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 1.9703e-05 - val_loss: 0.0062\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0460e-05 - val_loss: 0.0063\n",
            "training:  lstm_cv_vwap  df:  23\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 9.0255e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.0589e-04 - val_loss: 6.9454e-05\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6323e-04 - val_loss: 1.7029e-05\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.7315e-04 - val_loss: 7.3277e-06\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5965e-04 - val_loss: 5.9390e-06\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4073e-04 - val_loss: 5.7351e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5495e-04 - val_loss: 6.7673e-06\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3809e-04 - val_loss: 7.9229e-06\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4399e-04 - val_loss: 5.2646e-06\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4959e-04 - val_loss: 5.7533e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3708e-04 - val_loss: 8.5405e-06\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4146e-04 - val_loss: 8.8676e-06\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3175e-04 - val_loss: 6.3740e-06\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3547e-04 - val_loss: 2.5177e-05\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4904e-04 - val_loss: 1.9506e-05\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3236e-04 - val_loss: 5.6590e-06\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4046e-04 - val_loss: 1.1251e-05\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4344e-04 - val_loss: 9.0466e-06\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3884e-04 - val_loss: 6.2128e-06\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3544e-04 - val_loss: 2.3826e-05\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4255e-04 - val_loss: 5.1790e-06\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3727e-04 - val_loss: 5.0740e-06\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3755e-04 - val_loss: 1.0660e-05\n",
            "Epoch 23/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3610e-04 - val_loss: 1.0976e-05\n",
            "Epoch 24/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4070e-04 - val_loss: 5.2101e-06\n",
            "Epoch 25/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3848e-04 - val_loss: 6.4406e-06\n",
            "Epoch 26/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3566e-04 - val_loss: 6.2924e-06\n",
            "Epoch 27/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3863e-04 - val_loss: 5.1167e-06\n",
            "Epoch 28/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4542e-04 - val_loss: 4.8826e-06\n",
            "Epoch 29/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3207e-04 - val_loss: 8.6269e-06\n",
            "Epoch 30/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4306e-04 - val_loss: 5.2965e-06\n",
            "Epoch 31/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3948e-04 - val_loss: 5.3858e-06\n",
            "Epoch 32/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3487e-04 - val_loss: 5.1972e-05\n",
            "Epoch 33/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3914e-04 - val_loss: 2.2722e-05\n",
            "Epoch 34/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3147e-04 - val_loss: 2.7026e-05\n",
            "Epoch 35/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3062e-04 - val_loss: 1.0081e-05\n",
            "Epoch 36/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.2850e-04 - val_loss: 9.1407e-06\n",
            "Epoch 37/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4038e-04 - val_loss: 6.3598e-06\n",
            "Epoch 38/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3920e-04 - val_loss: 1.4752e-05\n",
            "Epoch 39/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4112e-04 - val_loss: 7.7439e-06\n",
            "Epoch 40/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3551e-04 - val_loss: 1.0703e-05\n",
            "Epoch 41/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4575e-04 - val_loss: 8.8455e-05\n",
            "Epoch 42/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4412e-04 - val_loss: 7.5260e-06\n",
            "Epoch 43/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3303e-04 - val_loss: 5.6600e-06\n",
            "training:  lstm_cv_vwap  df:  24\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.0506e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3902e-04 - val_loss: 8.6485e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3041e-04 - val_loss: 8.7467e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3512e-04 - val_loss: 8.1207e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2554e-04 - val_loss: 7.5849e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2204e-04 - val_loss: 7.3235e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2344e-04 - val_loss: 7.4623e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2042e-04 - val_loss: 8.4554e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2313e-04 - val_loss: 1.1551e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2163e-04 - val_loss: 7.5884e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2453e-04 - val_loss: 7.5213e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1940e-04 - val_loss: 1.0064e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1796e-04 - val_loss: 9.7406e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1772e-04 - val_loss: 7.7776e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1906e-04 - val_loss: 7.5391e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2079e-04 - val_loss: 8.9227e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1794e-04 - val_loss: 8.8336e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2085e-04 - val_loss: 8.1046e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1927e-04 - val_loss: 1.0503e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2308e-04 - val_loss: 8.1155e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1942e-04 - val_loss: 8.3634e-05\n",
            "training:  lstm_cv_vwap  df:  25\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/53 [===>..........................] - ETA: 0s - loss: 2.6173e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4311e-04 - val_loss: 3.1636e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4208e-04 - val_loss: 3.1599e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2962e-04 - val_loss: 3.0823e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.3349e-04 - val_loss: 3.2213e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.5680e-04 - val_loss: 3.1708e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3062e-04 - val_loss: 3.2864e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4267e-04 - val_loss: 3.1586e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.3220e-04 - val_loss: 3.2341e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.5247e-04 - val_loss: 3.3446e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4231e-04 - val_loss: 3.3194e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3419e-04 - val_loss: 3.0814e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3625e-04 - val_loss: 3.0546e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2301e-04 - val_loss: 3.1659e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4294e-04 - val_loss: 3.2015e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.3327e-04 - val_loss: 3.7527e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3612e-04 - val_loss: 3.0704e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2769e-04 - val_loss: 3.2471e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3710e-04 - val_loss: 3.1531e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.2457e-04 - val_loss: 3.4276e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.2682e-04 - val_loss: 3.1350e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1743e-04 - val_loss: 3.0887e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2294e-04 - val_loss: 3.1757e-04\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2140e-04 - val_loss: 3.2567e-04\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1726e-04 - val_loss: 3.2032e-04\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2360e-04 - val_loss: 3.0164e-04\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3226e-04 - val_loss: 3.1616e-04\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4570e-04 - val_loss: 3.1672e-04\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2193e-04 - val_loss: 3.1240e-04\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2179e-04 - val_loss: 3.0359e-04\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2814e-04 - val_loss: 3.0928e-04\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4213e-04 - val_loss: 3.1925e-04\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3488e-04 - val_loss: 3.2233e-04\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2017e-04 - val_loss: 3.1596e-04\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2014e-04 - val_loss: 3.1413e-04\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1476e-04 - val_loss: 3.2790e-04\n",
            "Epoch 36/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2545e-04 - val_loss: 3.2268e-04\n",
            "Epoch 37/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1036e-04 - val_loss: 3.3269e-04\n",
            "Epoch 38/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1565e-04 - val_loss: 3.2230e-04\n",
            "Epoch 39/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1871e-04 - val_loss: 3.9746e-04\n",
            "Epoch 40/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2454e-04 - val_loss: 3.2184e-04\n",
            "training:  lstm_cv_vwap  df:  26\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/58 [===>..........................] - ETA: 0s - loss: 1.1031e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6020e-04 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3735e-04 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3023e-04 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3531e-04 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2638e-04 - val_loss: 0.0015\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2732e-04 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2279e-04 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2253e-04 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2143e-04 - val_loss: 0.0016\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1574e-04 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2156e-04 - val_loss: 0.0015\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1375e-04 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3280e-04 - val_loss: 0.0016\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1519e-04 - val_loss: 0.0015\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1592e-04 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0928e-04 - val_loss: 0.0016\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0783e-04 - val_loss: 0.0016\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0813e-04 - val_loss: 0.0015\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1666e-04 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0957e-04 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0825e-04 - val_loss: 0.0016\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1881e-04 - val_loss: 0.0016\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5547e-04 - val_loss: 0.0015\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1156e-04 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1806e-04 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0912e-04 - val_loss: 0.0015\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0998e-04 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1116e-04 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0762e-04 - val_loss: 0.0015\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1002e-04 - val_loss: 0.0015\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1505e-04 - val_loss: 0.0015\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1432e-04 - val_loss: 0.0016\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1470e-04 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3348e-04 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0858e-04 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1324e-04 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0647e-04 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0933e-04 - val_loss: 0.0015\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0737e-04 - val_loss: 0.0015\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0816e-04 - val_loss: 0.0015\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0893e-04 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0860e-04 - val_loss: 0.0015\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1443e-04 - val_loss: 0.0015\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0969e-04 - val_loss: 0.0015\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0789e-04 - val_loss: 0.0015\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1616e-04 - val_loss: 0.0015\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0860e-04 - val_loss: 0.0015\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0708e-04 - val_loss: 0.0015\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.0918e-04 - val_loss: 0.0015\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.0803e-04 - val_loss: 0.0015\n",
            "Epoch 51/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0547e-04 - val_loss: 0.0015\n",
            "Epoch 52/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0597e-04 - val_loss: 0.0015\n",
            "Epoch 53/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0529e-04 - val_loss: 0.0015\n",
            "Epoch 54/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 9.9416e-05 - val_loss: 0.0015\n",
            "Epoch 55/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0679e-04 - val_loss: 0.0015\n",
            "Epoch 56/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1249e-04 - val_loss: 0.0015\n",
            "Epoch 57/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0514e-04 - val_loss: 0.0015\n",
            "Epoch 58/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0726e-04 - val_loss: 0.0015\n",
            "Epoch 59/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0856e-04 - val_loss: 0.0015\n",
            "Epoch 60/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1039e-04 - val_loss: 0.0015\n",
            "Epoch 61/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0797e-04 - val_loss: 0.0015\n",
            "Epoch 62/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1033e-04 - val_loss: 0.0015\n",
            "Epoch 63/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0349e-04 - val_loss: 0.0015\n",
            "Epoch 64/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0070e-04 - val_loss: 0.0015\n",
            "Epoch 65/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1474e-04 - val_loss: 0.0015\n",
            "Epoch 66/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0834e-04 - val_loss: 0.0015\n",
            "Epoch 67/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0093e-04 - val_loss: 0.0015\n",
            "Epoch 68/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0599e-04 - val_loss: 0.0015\n",
            "Epoch 69/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1661e-04 - val_loss: 0.0015\n",
            "Epoch 70/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0837e-04 - val_loss: 0.0015\n",
            "Epoch 71/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0559e-04 - val_loss: 0.0015\n",
            "Epoch 72/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0573e-04 - val_loss: 0.0015\n",
            "Epoch 73/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0861e-04 - val_loss: 0.0015\n",
            "Epoch 74/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1397e-04 - val_loss: 0.0015\n",
            "Epoch 75/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0468e-04 - val_loss: 0.0015\n",
            "Epoch 76/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0699e-04 - val_loss: 0.0015\n",
            "training:  lstm_cv_vwap  df:  27\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/46 [====>.........................] - ETA: 0s - loss: 7.0134e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 9ms/step - loss: 4.0879e-04 - val_loss: 4.4754e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4717e-04 - val_loss: 4.8048e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2125e-04 - val_loss: 6.1236e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5692e-04 - val_loss: 4.4199e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2894e-04 - val_loss: 4.0847e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2014e-04 - val_loss: 4.4075e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0866e-04 - val_loss: 4.5610e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1423e-04 - val_loss: 4.2475e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2348e-04 - val_loss: 5.8216e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1545e-04 - val_loss: 6.0115e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0289e-04 - val_loss: 4.4331e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0025e-04 - val_loss: 4.7715e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0007e-04 - val_loss: 4.7440e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3472e-04 - val_loss: 5.9639e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1472e-04 - val_loss: 4.3708e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0244e-04 - val_loss: 4.9551e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9483e-04 - val_loss: 4.5139e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.8333e-04 - val_loss: 4.2456e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.8954e-04 - val_loss: 4.6189e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.8398e-04 - val_loss: 4.8155e-04\n",
            "training:  lstm_cv_vwap  df:  28\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/171 [..............................] - ETA: 1s - loss: 1.1172e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3107e-05 - val_loss: 3.4024e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7453e-05 - val_loss: 3.2944e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1095e-05 - val_loss: 3.5088e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.2550e-05 - val_loss: 3.9819e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3574e-05 - val_loss: 3.6535e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.4145e-05 - val_loss: 3.8950e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1889e-05 - val_loss: 4.6880e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.2738e-05 - val_loss: 4.1333e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1687e-05 - val_loss: 3.7231e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0622e-05 - val_loss: 3.8123e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0825e-05 - val_loss: 4.0642e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1140e-05 - val_loss: 5.4299e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1603e-05 - val_loss: 3.9480e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.8616e-05 - val_loss: 4.4879e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0905e-05 - val_loss: 3.6393e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0128e-05 - val_loss: 4.2519e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0060e-05 - val_loss: 7.0464e-04\n",
            "training:  lstm_cv_vwap  df:  29\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 4.3750e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.9380e-05 - val_loss: 3.8655e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5622e-05 - val_loss: 3.7133e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0758e-05 - val_loss: 3.5531e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9949e-05 - val_loss: 3.5980e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0093e-05 - val_loss: 3.6337e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0082e-05 - val_loss: 3.5031e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8815e-05 - val_loss: 3.7186e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7982e-05 - val_loss: 3.8977e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7578e-05 - val_loss: 3.8409e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9203e-05 - val_loss: 3.8541e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8616e-05 - val_loss: 3.9682e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7630e-05 - val_loss: 4.2246e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7753e-05 - val_loss: 4.2099e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7756e-05 - val_loss: 4.3528e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7464e-05 - val_loss: 4.2692e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7267e-05 - val_loss: 4.4158e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7122e-05 - val_loss: 4.5338e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6923e-05 - val_loss: 4.5467e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7981e-05 - val_loss: 4.7000e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6546e-05 - val_loss: 4.9498e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6974e-05 - val_loss: 4.9661e-04\n",
            "training:  lstm_cv_vwap  df:  30\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 1.7758e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6805e-05 - val_loss: 5.3523e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5986e-05 - val_loss: 5.3061e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6518e-05 - val_loss: 6.4479e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7064e-05 - val_loss: 5.9643e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7171e-05 - val_loss: 6.0835e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6846e-05 - val_loss: 6.2410e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6831e-05 - val_loss: 6.6138e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6222e-05 - val_loss: 6.8317e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5568e-05 - val_loss: 7.1184e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5956e-05 - val_loss: 7.8137e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6152e-05 - val_loss: 7.4897e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6846e-05 - val_loss: 7.4733e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6933e-05 - val_loss: 8.3825e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6840e-05 - val_loss: 8.4069e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5290e-05 - val_loss: 8.7394e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6160e-05 - val_loss: 9.5945e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5299e-05 - val_loss: 0.0010\n",
            "training:  lstm_cv_vwap  df:  31\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6771e-05 - val_loss: 3.2303e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0740e-05 - val_loss: 3.3135e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7300e-05 - val_loss: 4.0991e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6004e-05 - val_loss: 3.1792e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3831e-05 - val_loss: 3.6231e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7263e-05 - val_loss: 4.1893e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3314e-05 - val_loss: 4.2716e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4818e-05 - val_loss: 3.4205e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3654e-05 - val_loss: 3.9516e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3493e-05 - val_loss: 4.1675e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2368e-05 - val_loss: 3.4198e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2502e-05 - val_loss: 3.4433e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1238e-05 - val_loss: 4.6054e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1143e-05 - val_loss: 3.1358e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2674e-05 - val_loss: 3.3143e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2652e-05 - val_loss: 3.2136e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1335e-05 - val_loss: 1.5532e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5169e-05 - val_loss: 8.2244e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3191e-05 - val_loss: 3.3848e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0484e-05 - val_loss: 3.1076e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1575e-05 - val_loss: 4.5021e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9676e-05 - val_loss: 1.1062e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2795e-05 - val_loss: 4.4459e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1644e-05 - val_loss: 3.1805e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1527e-05 - val_loss: 3.5047e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9308e-05 - val_loss: 4.2160e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9920e-05 - val_loss: 4.9800e-05\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1433e-05 - val_loss: 4.9634e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8559e-05 - val_loss: 7.4779e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1054e-05 - val_loss: 3.6726e-05\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2128e-05 - val_loss: 3.1069e-05\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.7916e-05 - val_loss: 3.1400e-05\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1781e-05 - val_loss: 2.9723e-05\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1288e-05 - val_loss: 3.6767e-05\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1663e-05 - val_loss: 2.8733e-05\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1218e-05 - val_loss: 3.0444e-05\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0790e-05 - val_loss: 4.3445e-05\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2200e-05 - val_loss: 3.3065e-05\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1334e-05 - val_loss: 2.8903e-05\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.7906e-05 - val_loss: 5.1794e-05\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1230e-05 - val_loss: 3.3729e-05\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1327e-05 - val_loss: 3.8745e-05\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1307e-05 - val_loss: 1.1032e-04\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1491e-05 - val_loss: 3.4801e-05\n",
            "Epoch 45/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9494e-05 - val_loss: 3.2138e-05\n",
            "Epoch 46/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1831e-05 - val_loss: 9.6430e-05\n",
            "Epoch 47/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1909e-05 - val_loss: 3.9012e-05\n",
            "Epoch 48/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9048e-05 - val_loss: 3.4860e-05\n",
            "Epoch 49/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2344e-05 - val_loss: 3.4230e-05\n",
            "Epoch 50/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9362e-05 - val_loss: 3.4046e-05\n",
            "training:  lstm_cv_vwap  df:  32\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4032e-05 - val_loss: 2.1815e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2011e-05 - val_loss: 1.6411e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0242e-05 - val_loss: 1.6962e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9411e-05 - val_loss: 2.4311e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8389e-05 - val_loss: 1.8572e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8159e-05 - val_loss: 1.6129e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8455e-05 - val_loss: 1.7558e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8191e-05 - val_loss: 1.5775e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8339e-05 - val_loss: 1.6805e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8637e-05 - val_loss: 1.7058e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8472e-05 - val_loss: 1.8966e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8214e-05 - val_loss: 2.1455e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7871e-05 - val_loss: 2.2253e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8239e-05 - val_loss: 2.9054e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7315e-05 - val_loss: 3.2427e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7960e-05 - val_loss: 2.7636e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8092e-05 - val_loss: 4.7382e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8360e-05 - val_loss: 4.7463e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8136e-05 - val_loss: 5.4790e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7352e-05 - val_loss: 6.3414e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7199e-05 - val_loss: 0.0013\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7107e-05 - val_loss: 0.0012\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7088e-05 - val_loss: 0.0015\n",
            "training:  lstm_cv_vwap  df:  33\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 4.1526e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 8ms/step - loss: 1.1949e-04 - val_loss: 1.8504e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.8135e-05 - val_loss: 2.9898e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.9023e-05 - val_loss: 2.2252e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.8438e-05 - val_loss: 1.4406e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.4621e-05 - val_loss: 2.3573e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1151e-05 - val_loss: 1.5707e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1621e-05 - val_loss: 5.8766e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.0847e-05 - val_loss: 2.4038e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 7.5961e-05 - val_loss: 2.3518e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.8378e-05 - val_loss: 2.2693e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.3225e-05 - val_loss: 1.4426e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1125e-05 - val_loss: 1.9727e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.2507e-05 - val_loss: 2.7428e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 7.5841e-05 - val_loss: 3.9223e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1293e-05 - val_loss: 2.0204e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 7.8316e-05 - val_loss: 1.9759e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.0195e-05 - val_loss: 2.2644e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.0196e-05 - val_loss: 4.6747e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.2611e-05 - val_loss: 2.1127e-04\n",
            "training:  lstm_cv_vwap  df:  34\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9719e-05 - val_loss: 5.1393e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8799e-05 - val_loss: 5.6301e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7004e-05 - val_loss: 6.5646e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6166e-05 - val_loss: 5.8848e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6022e-05 - val_loss: 5.4373e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6546e-05 - val_loss: 6.6347e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6148e-05 - val_loss: 5.8929e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6594e-05 - val_loss: 5.0390e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5905e-05 - val_loss: 5.6865e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5019e-05 - val_loss: 5.5452e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5171e-05 - val_loss: 5.5764e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5370e-05 - val_loss: 5.5261e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5526e-05 - val_loss: 5.7421e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5704e-05 - val_loss: 4.3900e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5775e-05 - val_loss: 7.4226e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5868e-05 - val_loss: 4.7618e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5328e-05 - val_loss: 6.2298e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5473e-05 - val_loss: 7.8919e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5557e-05 - val_loss: 4.4461e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5192e-05 - val_loss: 7.0337e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6032e-05 - val_loss: 7.5787e-04\n",
            "Epoch 22/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4397e-05 - val_loss: 8.2185e-04\n",
            "Epoch 23/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4735e-05 - val_loss: 0.0010\n",
            "Epoch 24/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5281e-05 - val_loss: 8.4912e-04\n",
            "Epoch 25/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5583e-05 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4945e-05 - val_loss: 0.0012\n",
            "Epoch 27/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5389e-05 - val_loss: 0.0016\n",
            "Epoch 28/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5470e-05 - val_loss: 0.0025\n",
            "Epoch 29/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4697e-05 - val_loss: 0.0024\n",
            "training:  lstm_cv_vwap  df:  35\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/314 [..............................] - ETA: 2s - loss: 2.9053e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 2s 8ms/step - loss: 2.7798e-05 - val_loss: 0.0053\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3192e-05 - val_loss: 0.0045\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3597e-05 - val_loss: 0.0088\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.1234e-05 - val_loss: 0.0115\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1563e-05 - val_loss: 0.0094\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0995e-05 - val_loss: 0.0103\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0883e-05 - val_loss: 0.0119\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1706e-05 - val_loss: 0.0167\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2234e-05 - val_loss: 0.0185\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1046e-05 - val_loss: 0.0215\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 1.9914e-05 - val_loss: 0.0175\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 1.9821e-05 - val_loss: 0.0207\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1037e-05 - val_loss: 0.0192\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0200e-05 - val_loss: 0.0145\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 1.9336e-05 - val_loss: 0.0214\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0647e-05 - val_loss: 0.0180\n",
            "Epoch 17/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 1.9662e-05 - val_loss: 0.0182\n",
            "training:  lstm_cv_vwap  df:  36\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/118 [=>............................] - ETA: 0s - loss: 4.7192e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3347e-05 - val_loss: 0.0083\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3218e-05 - val_loss: 0.0106\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2250e-05 - val_loss: 0.0106\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7864e-05 - val_loss: 0.0110\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7617e-05 - val_loss: 0.0107\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7371e-05 - val_loss: 0.0118\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6350e-05 - val_loss: 0.0115\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7964e-05 - val_loss: 0.0104\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8004e-05 - val_loss: 0.0122\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9002e-05 - val_loss: 0.0130\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6806e-05 - val_loss: 0.0121\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.5872e-05 - val_loss: 0.0119\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.5729e-05 - val_loss: 0.0101\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.5472e-05 - val_loss: 0.0146\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6924e-05 - val_loss: 0.0160\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7582e-05 - val_loss: 0.0140\n",
            "training:  lstm_cv_vwap  df:  37\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 2s - loss: 3.1144e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7437e-05 - val_loss: 0.0132\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5594e-05 - val_loss: 0.0122\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4479e-05 - val_loss: 0.0123\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5162e-05 - val_loss: 0.0119\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5305e-05 - val_loss: 0.0122\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4636e-05 - val_loss: 0.0133\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5298e-05 - val_loss: 0.0143\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5224e-05 - val_loss: 0.0143\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4194e-05 - val_loss: 0.0151\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5139e-05 - val_loss: 0.0129\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5792e-05 - val_loss: 0.0153\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5184e-05 - val_loss: 0.0136\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4134e-05 - val_loss: 0.0119\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4645e-05 - val_loss: 0.0120\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3699e-05 - val_loss: 0.0121\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5383e-05 - val_loss: 0.0127\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4828e-05 - val_loss: 0.0149\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3530e-05 - val_loss: 0.0151\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3129e-05 - val_loss: 0.0129\n",
            "Epoch 20/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4838e-05 - val_loss: 0.0118\n",
            "Epoch 21/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3496e-05 - val_loss: 0.0114\n",
            "Epoch 22/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4705e-05 - val_loss: 0.0115\n",
            "Epoch 23/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4019e-05 - val_loss: 0.0129\n",
            "Epoch 24/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4087e-05 - val_loss: 0.0131\n",
            "Epoch 25/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4668e-05 - val_loss: 0.0153\n",
            "Epoch 26/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4438e-05 - val_loss: 0.0112\n",
            "Epoch 27/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3740e-05 - val_loss: 0.0134\n",
            "Epoch 28/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5091e-05 - val_loss: 0.0133\n",
            "Epoch 29/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3461e-05 - val_loss: 0.0163\n",
            "Epoch 30/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3526e-05 - val_loss: 0.0189\n",
            "Epoch 31/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.6273e-05 - val_loss: 0.0140\n",
            "Epoch 32/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3304e-05 - val_loss: 0.0185\n",
            "Epoch 33/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3361e-05 - val_loss: 0.0162\n",
            "Epoch 34/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3636e-05 - val_loss: 0.0188\n",
            "Epoch 35/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3702e-05 - val_loss: 0.0187\n",
            "Epoch 36/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4319e-05 - val_loss: 0.0176\n",
            "Epoch 37/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4377e-05 - val_loss: 0.0171\n",
            "Epoch 38/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4017e-05 - val_loss: 0.0163\n",
            "Epoch 39/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4902e-05 - val_loss: 0.0153\n",
            "Epoch 40/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3627e-05 - val_loss: 0.0126\n",
            "Epoch 41/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.2522e-05 - val_loss: 0.0142\n",
            "training:  lstm_cv_vwap  df:  38\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/99 [=>............................] - ETA: 0s - loss: 0.0060"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 8.6954e-04 - val_loss: 4.3074e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7426e-04 - val_loss: 4.2212e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6556e-04 - val_loss: 4.7706e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5580e-04 - val_loss: 4.2654e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5903e-04 - val_loss: 4.3596e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6013e-04 - val_loss: 5.3973e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5250e-04 - val_loss: 4.5141e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5699e-04 - val_loss: 4.2729e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5045e-04 - val_loss: 4.3684e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6011e-04 - val_loss: 4.2690e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4947e-04 - val_loss: 4.2691e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5331e-04 - val_loss: 4.2952e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5065e-04 - val_loss: 4.3443e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6010e-04 - val_loss: 4.3682e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5269e-04 - val_loss: 4.4229e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5386e-04 - val_loss: 4.4770e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4946e-04 - val_loss: 4.4501e-04\n",
            "training:  lstm_cv_vwap  df:  39\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 3.9019e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 3.3360e-05 - val_loss: 1.6209e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0698e-05 - val_loss: 1.5581e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0054e-05 - val_loss: 1.5887e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7861e-05 - val_loss: 1.9840e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2602e-05 - val_loss: 1.6010e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9196e-05 - val_loss: 1.5814e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.8951e-05 - val_loss: 1.9862e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.8359e-05 - val_loss: 1.5767e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9159e-05 - val_loss: 2.5426e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.8757e-05 - val_loss: 3.1276e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2963e-05 - val_loss: 1.5917e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.8649e-05 - val_loss: 2.6425e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0652e-05 - val_loss: 1.9575e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9049e-05 - val_loss: 1.6466e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9312e-05 - val_loss: 1.6617e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7350e-05 - val_loss: 1.6107e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7596e-05 - val_loss: 1.8360e-04\n",
            "training:  lstm_cv_vwap  df:  40\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 1.8954e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 4.8880e-05 - val_loss: 2.8013e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0467e-05 - val_loss: 2.6563e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0174e-05 - val_loss: 2.8908e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0373e-05 - val_loss: 2.8878e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0388e-05 - val_loss: 2.7587e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9584e-05 - val_loss: 2.8806e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9932e-05 - val_loss: 2.9912e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9668e-05 - val_loss: 3.0521e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9165e-05 - val_loss: 5.0303e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8998e-05 - val_loss: 3.4264e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7256e-05 - val_loss: 5.0395e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8617e-05 - val_loss: 4.3160e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9053e-05 - val_loss: 3.7283e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9370e-05 - val_loss: 3.5800e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7987e-05 - val_loss: 4.6454e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8353e-05 - val_loss: 3.9451e-04\n",
            "Epoch 17/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8323e-05 - val_loss: 3.2801e-04\n",
            "training:  lstm_cv_vwap  df:  41\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 2.4688e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8963e-05 - val_loss: 5.8170e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8158e-05 - val_loss: 4.4709e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7473e-05 - val_loss: 3.6722e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9059e-05 - val_loss: 4.6271e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9196e-05 - val_loss: 6.3063e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8538e-05 - val_loss: 5.0093e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8583e-05 - val_loss: 5.1120e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9862e-05 - val_loss: 4.3410e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8721e-05 - val_loss: 5.7052e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9169e-05 - val_loss: 9.5536e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8521e-05 - val_loss: 6.7560e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7744e-05 - val_loss: 6.3212e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8176e-05 - val_loss: 8.9836e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8297e-05 - val_loss: 7.7197e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8555e-05 - val_loss: 8.4721e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7872e-05 - val_loss: 7.9974e-04\n",
            "Epoch 17/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9612e-05 - val_loss: 0.0012\n",
            "Epoch 18/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9148e-05 - val_loss: 0.0012\n",
            "training:  lstm_cv_vwap  df:  42\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 3.3172e-05 - val_loss: 0.0011\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0267e-05 - val_loss: 0.0022\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9018e-05 - val_loss: 0.0019\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.7852e-05 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9658e-05 - val_loss: 0.0024\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.7723e-05 - val_loss: 0.0024\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.8128e-05 - val_loss: 0.0019\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.6147e-05 - val_loss: 0.0032\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.7783e-05 - val_loss: 0.0031\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.7052e-05 - val_loss: 0.0045\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.7703e-05 - val_loss: 0.0032\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.7882e-05 - val_loss: 0.0043\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.6684e-05 - val_loss: 0.0076\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.5982e-05 - val_loss: 0.0074\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.5981e-05 - val_loss: 0.0061\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.6611e-05 - val_loss: 0.0080\n",
            "training:  lstm_cv_vwap  df:  43\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/64 [==>...........................] - ETA: 0s - loss: 0.0017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 8ms/step - loss: 6.1192e-04 - val_loss: 5.7591e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.4463e-04 - val_loss: 7.0277e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.0084e-04 - val_loss: 7.4320e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1903e-04 - val_loss: 8.7098e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9936e-04 - val_loss: 8.1460e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1357e-04 - val_loss: 8.1586e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0159e-04 - val_loss: 7.3704e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9972e-04 - val_loss: 8.2868e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0345e-04 - val_loss: 8.0318e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9698e-04 - val_loss: 6.9369e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 2.9353e-04 - val_loss: 8.0593e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.8530e-04 - val_loss: 7.4530e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 2.8209e-04 - val_loss: 6.9793e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9315e-04 - val_loss: 9.0404e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0909e-04 - val_loss: 8.4725e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0534e-04 - val_loss: 6.5367e-04\n",
            "training:  lstm_cv_vwap  df:  44\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 5.4046e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4141e-04 - val_loss: 1.6218e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3519e-04 - val_loss: 1.7305e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3492e-04 - val_loss: 1.6700e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3244e-04 - val_loss: 1.5918e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3053e-04 - val_loss: 1.9225e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3197e-04 - val_loss: 1.6823e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2986e-04 - val_loss: 1.6552e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3299e-04 - val_loss: 1.7113e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3224e-04 - val_loss: 2.2367e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3519e-04 - val_loss: 1.9164e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3194e-04 - val_loss: 1.7821e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3051e-04 - val_loss: 1.6604e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3386e-04 - val_loss: 1.7436e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3136e-04 - val_loss: 1.7921e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3407e-04 - val_loss: 1.7181e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2919e-04 - val_loss: 1.8276e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3262e-04 - val_loss: 1.9517e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2955e-04 - val_loss: 1.8399e-04\n",
            "Epoch 19/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3128e-04 - val_loss: 2.7197e-04\n",
            "training:  lstm_cv_vwap  df:  45\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/174 [>.............................] - ETA: 1s - loss: 3.8593e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0854e-04 - val_loss: 1.8709e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8317e-04 - val_loss: 1.8537e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7922e-04 - val_loss: 1.8992e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8235e-04 - val_loss: 1.8204e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7666e-04 - val_loss: 2.3912e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8045e-04 - val_loss: 2.0379e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8603e-04 - val_loss: 2.4008e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8549e-04 - val_loss: 1.8909e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7684e-04 - val_loss: 1.9819e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7693e-04 - val_loss: 1.8892e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8080e-04 - val_loss: 1.8856e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7904e-04 - val_loss: 1.9951e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7331e-04 - val_loss: 1.8325e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7434e-04 - val_loss: 1.7942e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7463e-04 - val_loss: 1.9281e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7289e-04 - val_loss: 1.9605e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7350e-04 - val_loss: 2.0447e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8001e-04 - val_loss: 1.7809e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7309e-04 - val_loss: 1.9760e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7840e-04 - val_loss: 1.8965e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7408e-04 - val_loss: 1.8348e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7843e-04 - val_loss: 1.8148e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7219e-04 - val_loss: 1.8051e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8157e-04 - val_loss: 2.0583e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7330e-04 - val_loss: 2.0571e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7436e-04 - val_loss: 2.1244e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8215e-04 - val_loss: 2.0448e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7611e-04 - val_loss: 1.9015e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7326e-04 - val_loss: 1.8932e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7741e-04 - val_loss: 1.8276e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7553e-04 - val_loss: 1.7423e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.6420e-04 - val_loss: 1.8673e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7346e-04 - val_loss: 1.8857e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7618e-04 - val_loss: 1.7991e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7262e-04 - val_loss: 1.8359e-04\n",
            "Epoch 36/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7273e-04 - val_loss: 1.9115e-04\n",
            "Epoch 37/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7230e-04 - val_loss: 1.8096e-04\n",
            "Epoch 38/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7743e-04 - val_loss: 1.9023e-04\n",
            "Epoch 39/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7244e-04 - val_loss: 1.9105e-04\n",
            "Epoch 40/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7725e-04 - val_loss: 1.8214e-04\n",
            "Epoch 41/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7227e-04 - val_loss: 1.8037e-04\n",
            "Epoch 42/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7445e-04 - val_loss: 1.8295e-04\n",
            "Epoch 43/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7469e-04 - val_loss: 1.8842e-04\n",
            "Epoch 44/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7759e-04 - val_loss: 1.8917e-04\n",
            "Epoch 45/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7432e-04 - val_loss: 1.7811e-04\n",
            "Epoch 46/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.6687e-04 - val_loss: 1.7676e-04\n",
            "training:  lstm_cv_vwap  df:  46\n",
            "Training model: lstm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3335e-05 - val_loss: 1.0180e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3820e-05 - val_loss: 9.9029e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1948e-05 - val_loss: 1.0069e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1257e-05 - val_loss: 9.9679e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2981e-05 - val_loss: 1.1825e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1623e-05 - val_loss: 1.0658e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0003e-05 - val_loss: 1.0725e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9241e-05 - val_loss: 1.0278e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1331e-05 - val_loss: 1.0560e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9920e-05 - val_loss: 1.0651e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9378e-05 - val_loss: 1.3297e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4058e-05 - val_loss: 1.1357e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1698e-05 - val_loss: 9.8976e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7942e-05 - val_loss: 1.1554e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1271e-05 - val_loss: 1.0645e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2949e-05 - val_loss: 1.1923e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1513e-05 - val_loss: 1.0303e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9855e-05 - val_loss: 1.0885e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1432e-05 - val_loss: 1.0519e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1426e-05 - val_loss: 1.0203e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0261e-05 - val_loss: 1.0843e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7303e-05 - val_loss: 1.0408e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0549e-05 - val_loss: 9.7732e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0185e-05 - val_loss: 1.0601e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1757e-05 - val_loss: 1.0574e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0220e-05 - val_loss: 1.1154e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.7790e-05 - val_loss: 1.3063e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9985e-05 - val_loss: 1.0342e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6141e-05 - val_loss: 1.1210e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1404e-05 - val_loss: 1.0255e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1226e-05 - val_loss: 9.9446e-05\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8915e-05 - val_loss: 1.0850e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1964e-05 - val_loss: 9.9084e-05\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8477e-05 - val_loss: 1.1190e-04\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3399e-05 - val_loss: 1.0979e-04\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9409e-05 - val_loss: 9.8099e-05\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0562e-05 - val_loss: 1.0813e-04\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8455e-05 - val_loss: 1.0412e-04\n",
            "training:  lstm_cv_vwap  df:  47\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 7.8471e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3353e-04 - val_loss: 1.8387e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2323e-04 - val_loss: 2.8646e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2164e-04 - val_loss: 1.4764e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1880e-04 - val_loss: 1.7723e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2388e-04 - val_loss: 1.7125e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2401e-04 - val_loss: 1.6109e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2048e-04 - val_loss: 1.6984e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2205e-04 - val_loss: 2.2785e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1705e-04 - val_loss: 1.9108e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2088e-04 - val_loss: 1.6959e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1752e-04 - val_loss: 1.9294e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1663e-04 - val_loss: 4.8719e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1792e-04 - val_loss: 2.0734e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1951e-04 - val_loss: 2.8471e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1734e-04 - val_loss: 2.0548e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1850e-04 - val_loss: 1.7332e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1618e-04 - val_loss: 1.6869e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1819e-04 - val_loss: 1.8982e-04\n",
            "training:  lstm_cv_vwap  df:  48\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.3402e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1818e-04 - val_loss: 1.0129e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1447e-04 - val_loss: 7.9775e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0731e-04 - val_loss: 7.5628e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1157e-04 - val_loss: 7.8091e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0839e-04 - val_loss: 7.5883e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0597e-04 - val_loss: 8.2020e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1094e-04 - val_loss: 7.8123e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0967e-04 - val_loss: 8.3090e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1144e-04 - val_loss: 9.1033e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0898e-04 - val_loss: 7.4369e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0937e-04 - val_loss: 9.1314e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1063e-04 - val_loss: 7.7828e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0784e-04 - val_loss: 7.6915e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1037e-04 - val_loss: 8.1240e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0662e-04 - val_loss: 9.6267e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1190e-04 - val_loss: 7.9569e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0779e-04 - val_loss: 8.0545e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1184e-04 - val_loss: 1.0762e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0615e-04 - val_loss: 9.4250e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0768e-04 - val_loss: 7.6428e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0721e-04 - val_loss: 7.9489e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1027e-04 - val_loss: 7.4870e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0695e-04 - val_loss: 7.9242e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0832e-04 - val_loss: 7.7855e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1007e-04 - val_loss: 8.0403e-05\n",
            "training:  lstm_cv_vwap  df:  49\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 6.6612e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4436e-05 - val_loss: 1.0081e-04\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.3979e-05 - val_loss: 9.4352e-05\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2039e-05 - val_loss: 1.0863e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1657e-05 - val_loss: 9.0889e-05\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0725e-05 - val_loss: 9.5341e-05\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2630e-05 - val_loss: 9.8486e-05\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1315e-05 - val_loss: 9.9352e-05\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0596e-05 - val_loss: 1.1088e-04\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.5510e-05 - val_loss: 9.2914e-05\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1420e-05 - val_loss: 9.2491e-05\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0655e-05 - val_loss: 9.9330e-05\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2072e-05 - val_loss: 9.2866e-05\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.9750e-05 - val_loss: 1.2573e-04\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.3826e-05 - val_loss: 1.0118e-04\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.9534e-05 - val_loss: 9.5463e-05\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2876e-05 - val_loss: 9.2204e-05\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1280e-05 - val_loss: 9.8364e-05\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.9466e-05 - val_loss: 9.9408e-05\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8298e-05 - val_loss: 9.6473e-05\n",
            "training:  lstm_cv_vwap  df:  50\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8805e-04 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.4952e-04 - val_loss: 0.0019\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.1465e-04 - val_loss: 0.0018\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.0776e-04 - val_loss: 0.0019\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 8.9372e-04 - val_loss: 0.0018\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5338e-04 - val_loss: 0.0019\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.7350e-04 - val_loss: 0.0025\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.2776e-04 - val_loss: 0.0019\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.3495e-04 - val_loss: 0.0019\n",
            "training:  lstm_cv_vwap  df:  51\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/106 [=>............................] - ETA: 0s - loss: 2.5690e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 9ms/step - loss: 2.6333e-04 - val_loss: 6.7514e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3191e-04 - val_loss: 6.7454e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2341e-04 - val_loss: 6.5687e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2323e-04 - val_loss: 6.5380e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2470e-04 - val_loss: 6.5970e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1814e-04 - val_loss: 6.7709e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2408e-04 - val_loss: 6.6706e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1335e-04 - val_loss: 6.9057e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1967e-04 - val_loss: 6.5304e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1797e-04 - val_loss: 7.0233e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1674e-04 - val_loss: 6.6695e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1184e-04 - val_loss: 6.5727e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1438e-04 - val_loss: 6.8533e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1267e-04 - val_loss: 6.8149e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1157e-04 - val_loss: 6.7936e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2278e-04 - val_loss: 6.8598e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1771e-04 - val_loss: 6.9490e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.0888e-04 - val_loss: 6.6941e-04\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1815e-04 - val_loss: 6.8415e-04\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1279e-04 - val_loss: 6.9817e-04\n",
            "Epoch 21/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1869e-04 - val_loss: 6.6569e-04\n",
            "Epoch 22/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1373e-04 - val_loss: 6.6495e-04\n",
            "Epoch 23/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1894e-04 - val_loss: 6.6184e-04\n",
            "Epoch 24/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1601e-04 - val_loss: 6.6060e-04\n",
            "training:  lstm_cv_vwap  df:  52\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 3s - loss: 3.6326e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2981e-05 - val_loss: 1.7577e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7931e-05 - val_loss: 1.6494e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7487e-05 - val_loss: 1.6277e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6389e-05 - val_loss: 1.7099e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6459e-05 - val_loss: 1.7490e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5782e-05 - val_loss: 1.5959e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6377e-05 - val_loss: 1.5766e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6048e-05 - val_loss: 1.6983e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7577e-05 - val_loss: 1.6722e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4877e-05 - val_loss: 1.6267e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5292e-05 - val_loss: 1.6720e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5801e-05 - val_loss: 1.6350e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5314e-05 - val_loss: 1.7431e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5361e-05 - val_loss: 1.7674e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5981e-05 - val_loss: 1.7063e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5149e-05 - val_loss: 1.7969e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5313e-05 - val_loss: 1.7248e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5281e-05 - val_loss: 1.7749e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5821e-05 - val_loss: 1.9414e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4816e-05 - val_loss: 1.9279e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5430e-05 - val_loss: 1.9140e-04\n",
            "Epoch 22/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5336e-05 - val_loss: 2.0969e-04\n",
            "training:  lstm_cv_vwap  df:  53\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/79 [==>...........................] - ETA: 0s - loss: 1.0661e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 9.9708e-05 - val_loss: 0.0015\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3969e-05 - val_loss: 0.0015\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0808e-05 - val_loss: 0.0014\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1626e-05 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1898e-05 - val_loss: 0.0016\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1210e-05 - val_loss: 0.0015\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8481e-05 - val_loss: 0.0015\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7279e-05 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7525e-05 - val_loss: 0.0020\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0225e-05 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9765e-05 - val_loss: 0.0021\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.4550e-05 - val_loss: 0.0018\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.5248e-05 - val_loss: 0.0025\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0014e-05 - val_loss: 0.0027\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.5195e-05 - val_loss: 0.0025\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.6763e-05 - val_loss: 0.0024\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8258e-05 - val_loss: 0.0024\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.3639e-05 - val_loss: 0.0017\n",
            "training:  lstm_cv_vwap  df:  54\n",
            "Training model: lstm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 6.4855e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9843e-05 - val_loss: 4.2828e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5451e-05 - val_loss: 5.1417e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4019e-05 - val_loss: 3.5217e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3828e-05 - val_loss: 4.2190e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2449e-05 - val_loss: 1.9039e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1340e-05 - val_loss: 2.4021e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2986e-05 - val_loss: 2.5550e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2772e-05 - val_loss: 2.9479e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1552e-05 - val_loss: 2.6437e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1265e-05 - val_loss: 2.8423e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2824e-05 - val_loss: 1.7339e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3663e-05 - val_loss: 2.3868e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5236e-05 - val_loss: 2.7859e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2610e-05 - val_loss: 2.8279e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.0900e-05 - val_loss: 1.9826e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1899e-05 - val_loss: 2.5321e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1208e-05 - val_loss: 2.4473e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3571e-05 - val_loss: 2.3021e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.0526e-05 - val_loss: 5.3170e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2864e-05 - val_loss: 3.5648e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1169e-05 - val_loss: 4.1399e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1984e-05 - val_loss: 2.0323e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.0951e-05 - val_loss: 4.7811e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2673e-05 - val_loss: 2.6684e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.1764e-05 - val_loss: 3.4851e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.2610e-05 - val_loss: 2.5680e-04\n",
            "build model: lstm_ohlc  features: 5\n",
            "training:  lstm_ohlc\n",
            "lstm_ohlc  should train on stocks\n",
            "training dfs: 55\n",
            "training:  lstm_ohlc  df:  0\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 13ms/step - loss: 0.0137 - val_loss: 0.3757\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.3125\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0928\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0949\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 8.2683e-04 - val_loss: 0.0996\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.8942e-04 - val_loss: 0.0933\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.7143e-04 - val_loss: 0.0887\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.9977e-04 - val_loss: 0.0942\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.7292e-04 - val_loss: 0.0921\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.5758e-04 - val_loss: 0.0880\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.1589e-04 - val_loss: 0.0896\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.2782e-04 - val_loss: 0.0892\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.0319e-04 - val_loss: 0.0875\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.9469e-04 - val_loss: 0.0885\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 2.8705e-04 - val_loss: 0.0897\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.7420e-04 - val_loss: 0.0862\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.2975e-04 - val_loss: 0.0845\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.1517e-04 - val_loss: 0.0812\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.9870e-04 - val_loss: 0.0797\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.8608e-04 - val_loss: 0.0813\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.4925e-04 - val_loss: 0.0755\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.5780e-04 - val_loss: 0.0837\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.2797e-04 - val_loss: 0.0753\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.5953e-04 - val_loss: 0.0812\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 1.4768e-04 - val_loss: 0.0786\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.6256e-04 - val_loss: 0.0802\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0989e-04 - val_loss: 0.0793\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.1141e-04 - val_loss: 0.0828\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0952e-04 - val_loss: 0.0796\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.3652e-04 - val_loss: 0.0827\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0309e-04 - val_loss: 0.0796\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.8526e-05 - val_loss: 0.0837\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.1967e-05 - val_loss: 0.0802\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.6293e-05 - val_loss: 0.0806\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.1121e-05 - val_loss: 0.0803\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0492e-04 - val_loss: 0.0821\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.4914e-05 - val_loss: 0.0851\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.6607e-05 - val_loss: 0.0792\n",
            "training:  lstm_ohlc  df:  1\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 7/80 [=>............................] - ETA: 0s - loss: 7.0607e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 9ms/step - loss: 1.7205e-04 - val_loss: 0.0922\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 5.9510e-05 - val_loss: 0.0908\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.7389e-05 - val_loss: 0.0924\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.5758e-05 - val_loss: 0.0965\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.4861e-05 - val_loss: 0.0981\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.0836e-05 - val_loss: 0.1039\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.9105e-05 - val_loss: 0.1059\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.4944e-05 - val_loss: 0.1075\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.5677e-05 - val_loss: 0.1204\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.2666e-05 - val_loss: 0.1237\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3704e-05 - val_loss: 0.1340\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3793e-05 - val_loss: 0.1190\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3060e-05 - val_loss: 0.1217\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.7100e-05 - val_loss: 0.1233\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6393e-05 - val_loss: 0.1173\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.1377e-05 - val_loss: 0.1195\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.8438e-05 - val_loss: 0.1221\n",
            "training:  lstm_ohlc  df:  2\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 3.3771e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 8ms/step - loss: 9.1971e-06 - val_loss: 0.0880\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 6.5343e-06 - val_loss: 0.0910\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 6.4433e-06 - val_loss: 0.0933\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.3068e-06 - val_loss: 0.0957\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.3221e-06 - val_loss: 0.0976\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.8246e-06 - val_loss: 0.1080\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.5962e-06 - val_loss: 0.1146\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.9025e-06 - val_loss: 0.1218\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.7574e-06 - val_loss: 0.1301\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 5.0247e-06 - val_loss: 0.1233\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.3148e-06 - val_loss: 0.1262\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.8871e-06 - val_loss: 0.1286\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.9536e-06 - val_loss: 0.1262\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.1784e-06 - val_loss: 0.1296\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.2720e-06 - val_loss: 0.1337\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 5.3716e-06 - val_loss: 0.1317\n",
            "training:  lstm_ohlc  df:  3\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 0.0011 - val_loss: 0.0241\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6761e-04 - val_loss: 0.0238\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5100e-04 - val_loss: 0.0232\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1734e-04 - val_loss: 0.0195\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0404e-04 - val_loss: 0.0185\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0943e-04 - val_loss: 0.0202\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0384e-04 - val_loss: 0.0184\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4338e-05 - val_loss: 0.0201\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6387e-05 - val_loss: 0.0164\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0067e-04 - val_loss: 0.0159\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4812e-05 - val_loss: 0.0189\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0363e-04 - val_loss: 0.0205\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7436e-05 - val_loss: 0.0151\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3661e-05 - val_loss: 0.0173\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6185e-05 - val_loss: 0.0150\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3000e-05 - val_loss: 0.0151\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0442e-05 - val_loss: 0.0129\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2470e-05 - val_loss: 0.0169\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0224e-05 - val_loss: 0.0177\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9637e-05 - val_loss: 0.0195\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3788e-05 - val_loss: 0.0118\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8288e-05 - val_loss: 0.0138\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6129e-05 - val_loss: 0.0163\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4766e-05 - val_loss: 0.0136\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8124e-05 - val_loss: 0.0167\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2585e-05 - val_loss: 0.0175\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2529e-05 - val_loss: 0.0196\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2265e-05 - val_loss: 0.0189\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4406e-05 - val_loss: 0.0189\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5857e-05 - val_loss: 0.0137\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9901e-05 - val_loss: 0.0169\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5874e-05 - val_loss: 0.0187\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5917e-05 - val_loss: 0.0166\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1291e-05 - val_loss: 0.0181\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2883e-05 - val_loss: 0.0148\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5192e-05 - val_loss: 0.0149\n",
            "training:  lstm_ohlc  df:  4\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 0.0021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 2.2550e-04 - val_loss: 8.5313e-05\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.6483e-04 - val_loss: 1.0408e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.4952e-04 - val_loss: 9.3522e-05\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3699e-04 - val_loss: 1.1448e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.5404e-04 - val_loss: 8.4346e-05\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3740e-04 - val_loss: 1.1615e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2556e-04 - val_loss: 1.0389e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2714e-04 - val_loss: 1.0953e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4854e-04 - val_loss: 1.7127e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2543e-04 - val_loss: 1.1164e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2123e-04 - val_loss: 1.1040e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2675e-04 - val_loss: 1.2929e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2466e-04 - val_loss: 1.2574e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1493e-04 - val_loss: 9.9090e-05\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2405e-04 - val_loss: 8.4487e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2669e-04 - val_loss: 1.5430e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1807e-04 - val_loss: 8.5710e-05\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.3177e-04 - val_loss: 9.0431e-05\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1910e-04 - val_loss: 8.7830e-05\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1362e-04 - val_loss: 9.4642e-05\n",
            "training:  lstm_ohlc  df:  5\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.6921e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9351e-05 - val_loss: 7.6792e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7897e-05 - val_loss: 7.8422e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6665e-05 - val_loss: 7.5565e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6316e-05 - val_loss: 7.4454e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7161e-05 - val_loss: 6.6217e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7229e-05 - val_loss: 6.1982e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7339e-05 - val_loss: 7.3386e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8181e-05 - val_loss: 6.3635e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6276e-05 - val_loss: 6.6774e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8470e-05 - val_loss: 9.0774e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5513e-05 - val_loss: 9.4482e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5425e-05 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8026e-05 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6023e-05 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6194e-05 - val_loss: 0.0025\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5461e-05 - val_loss: 0.0034\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8643e-05 - val_loss: 0.0023\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4363e-05 - val_loss: 0.0035\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6546e-05 - val_loss: 0.0031\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3256e-05 - val_loss: 0.0043\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5453e-05 - val_loss: 0.0040\n",
            "training:  lstm_ohlc  df:  6\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 0.0160"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 3.6660e-04 - val_loss: 1.6881e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.8462e-04 - val_loss: 1.3533e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.6841e-04 - val_loss: 1.1879e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.6632e-04 - val_loss: 1.6122e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.7179e-04 - val_loss: 2.7481e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5943e-04 - val_loss: 1.5619e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.6476e-04 - val_loss: 1.2174e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5588e-04 - val_loss: 1.6773e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5463e-04 - val_loss: 1.5432e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4680e-04 - val_loss: 2.4012e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4174e-04 - val_loss: 1.4846e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4520e-04 - val_loss: 1.5207e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5387e-04 - val_loss: 1.2532e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4124e-04 - val_loss: 1.3923e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.4541e-04 - val_loss: 1.3704e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4787e-04 - val_loss: 1.3133e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4004e-04 - val_loss: 1.6063e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4566e-04 - val_loss: 1.9847e-04\n",
            "training:  lstm_ohlc  df:  7\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 1.0354e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 6.3904e-05 - val_loss: 4.1421e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.5563e-05 - val_loss: 4.9290e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.0762e-05 - val_loss: 7.1893e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9765e-05 - val_loss: 6.9425e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9652e-05 - val_loss: 7.7338e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9417e-05 - val_loss: 8.2817e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.7168e-05 - val_loss: 7.6360e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.9184e-05 - val_loss: 9.4012e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.6917e-05 - val_loss: 7.3691e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.6240e-05 - val_loss: 0.0010\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.7703e-05 - val_loss: 9.0315e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.5309e-05 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.6377e-05 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.7199e-05 - val_loss: 0.0011\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.2985e-05 - val_loss: 0.0014\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.7230e-05 - val_loss: 0.0013\n",
            "training:  lstm_ohlc  df:  8\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/68 [==>...........................] - ETA: 0s - loss: 2.2959e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 1.6817e-04 - val_loss: 0.0037\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4182e-04 - val_loss: 0.0027\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4233e-04 - val_loss: 0.0030\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.5376e-04 - val_loss: 0.0026\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4654e-04 - val_loss: 0.0068\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2076e-04 - val_loss: 0.0031\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4743e-04 - val_loss: 0.0034\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1662e-04 - val_loss: 0.0038\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1250e-04 - val_loss: 0.0045\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2461e-04 - val_loss: 0.0036\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2849e-04 - val_loss: 0.0037\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1176e-04 - val_loss: 0.0041\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2895e-04 - val_loss: 0.0032\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.2678e-04 - val_loss: 0.0044\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0886e-04 - val_loss: 0.0049\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1642e-04 - val_loss: 0.0035\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2649e-04 - val_loss: 0.0039\n",
            "Epoch 18/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2570e-04 - val_loss: 0.0048\n",
            "Epoch 19/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2289e-04 - val_loss: 0.0041\n",
            "training:  lstm_ohlc  df:  9\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/162 [>.............................] - ETA: 1s - loss: 2.0325e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 4.9887e-05 - val_loss: 0.0043\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6355e-05 - val_loss: 0.0062\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.4661e-05 - val_loss: 0.0098\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.4403e-05 - val_loss: 0.0116\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.2727e-05 - val_loss: 0.0122\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0978e-05 - val_loss: 0.0145\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1742e-05 - val_loss: 0.0150\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1702e-05 - val_loss: 0.0161\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0128e-05 - val_loss: 0.0129\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.9641e-06 - val_loss: 0.0128\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1765e-05 - val_loss: 0.0146\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1410e-05 - val_loss: 0.0132\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1783e-05 - val_loss: 0.0120\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.2050e-05 - val_loss: 0.0093\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.9202e-06 - val_loss: 0.0102\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0589e-05 - val_loss: 0.0101\n",
            "training:  lstm_ohlc  df:  10\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1759e-05 - val_loss: 9.2693e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1934e-05 - val_loss: 5.9651e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2852e-05 - val_loss: 3.9300e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5023e-05 - val_loss: 5.1286e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9062e-05 - val_loss: 5.4479e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2245e-05 - val_loss: 5.2097e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1917e-05 - val_loss: 5.0387e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8728e-05 - val_loss: 8.3740e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0137e-05 - val_loss: 5.3587e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4593e-05 - val_loss: 6.3581e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3746e-05 - val_loss: 7.5015e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0478e-05 - val_loss: 7.5386e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8146e-05 - val_loss: 7.7901e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0697e-05 - val_loss: 7.6519e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9736e-05 - val_loss: 5.1309e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9885e-05 - val_loss: 4.5141e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0769e-05 - val_loss: 7.0159e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2592e-05 - val_loss: 5.4852e-04\n",
            "training:  lstm_ohlc  df:  11\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0400e-04 - val_loss: 2.0278e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.9543e-05 - val_loss: 1.0197e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8533e-05 - val_loss: 8.1073e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1754e-05 - val_loss: 9.1890e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8663e-05 - val_loss: 8.2428e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2751e-05 - val_loss: 1.0997e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0811e-05 - val_loss: 8.0920e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9103e-05 - val_loss: 7.4096e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3514e-05 - val_loss: 8.7242e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7420e-05 - val_loss: 2.0562e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3625e-05 - val_loss: 8.6450e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8162e-05 - val_loss: 1.0329e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0445e-05 - val_loss: 1.5255e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7822e-05 - val_loss: 7.3265e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1550e-05 - val_loss: 1.0555e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1712e-05 - val_loss: 1.0705e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8991e-05 - val_loss: 7.5991e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3855e-05 - val_loss: 2.3689e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3540e-05 - val_loss: 8.2955e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5701e-05 - val_loss: 1.4094e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2458e-05 - val_loss: 8.2226e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6278e-05 - val_loss: 2.2255e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4903e-05 - val_loss: 9.8116e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2353e-05 - val_loss: 9.7181e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4027e-05 - val_loss: 7.5055e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6998e-05 - val_loss: 2.5278e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3581e-05 - val_loss: 1.4731e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3248e-05 - val_loss: 1.3181e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0534e-05 - val_loss: 7.3749e-05\n",
            "training:  lstm_ohlc  df:  12\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0030\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0039\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0034\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0025\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0038\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "training:  lstm_ohlc  df:  13\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/132 [>.............................] - ETA: 0s - loss: 2.3553e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 8ms/step - loss: 4.7510e-05 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.3610e-05 - val_loss: 0.0014\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.0411e-05 - val_loss: 0.0014\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9756e-05 - val_loss: 0.0014\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9224e-05 - val_loss: 0.0014\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9089e-05 - val_loss: 0.0014\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7654e-05 - val_loss: 0.0013\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5702e-05 - val_loss: 0.0014\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5912e-05 - val_loss: 0.0014\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5217e-05 - val_loss: 0.0014\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6383e-05 - val_loss: 0.0014\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.1101e-05 - val_loss: 0.0014\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9558e-05 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7318e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5552e-05 - val_loss: 0.0013\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6008e-05 - val_loss: 0.0013\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4688e-05 - val_loss: 0.0013\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4342e-05 - val_loss: 0.0013\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6662e-05 - val_loss: 0.0013\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4250e-05 - val_loss: 0.0013\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5329e-05 - val_loss: 0.0013\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.4165e-05 - val_loss: 0.0014\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4401e-05 - val_loss: 0.0014\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6607e-05 - val_loss: 0.0013\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2762e-05 - val_loss: 0.0013\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2151e-05 - val_loss: 0.0013\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7374e-05 - val_loss: 0.0014\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5401e-05 - val_loss: 0.0014\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8775e-05 - val_loss: 0.0014\n",
            "Epoch 30/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3671e-05 - val_loss: 0.0014\n",
            "Epoch 31/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3982e-05 - val_loss: 0.0014\n",
            "Epoch 32/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5040e-05 - val_loss: 0.0014\n",
            "Epoch 33/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3944e-05 - val_loss: 0.0014\n",
            "Epoch 34/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2325e-05 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1771e-05 - val_loss: 0.0014\n",
            "training:  lstm_ohlc  df:  14\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/26 [========>.....................] - ETA: 0s - loss: 9.1675e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 10ms/step - loss: 6.1275e-04 - val_loss: 2.8885e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 5.5798e-04 - val_loss: 3.9003e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 6.4195e-04 - val_loss: 7.7525e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.1938e-04 - val_loss: 2.7952e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.2620e-04 - val_loss: 5.5752e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.4376e-04 - val_loss: 5.2155e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.2583e-04 - val_loss: 3.1219e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.6407e-04 - val_loss: 2.6499e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.9269e-04 - val_loss: 3.4091e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.8403e-04 - val_loss: 2.8404e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2867e-04 - val_loss: 3.3260e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.6573e-04 - val_loss: 7.6900e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.9468e-04 - val_loss: 3.4663e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3427e-04 - val_loss: 2.4333e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.9285e-04 - val_loss: 2.6569e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3174e-04 - val_loss: 3.2228e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9790e-04 - val_loss: 2.5156e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9644e-04 - val_loss: 2.4934e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9550e-04 - val_loss: 2.6490e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1406e-04 - val_loss: 3.0147e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.6105e-04 - val_loss: 2.8987e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3631e-04 - val_loss: 3.1034e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2790e-04 - val_loss: 3.8220e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3155e-04 - val_loss: 3.5567e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2431e-04 - val_loss: 2.7579e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1173e-04 - val_loss: 2.5038e-04\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0153e-04 - val_loss: 2.7799e-04\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1989e-04 - val_loss: 2.5199e-04\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7025e-04 - val_loss: 2.5391e-04\n",
            "training:  lstm_ohlc  df:  15\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2194e-05 - val_loss: 4.4629e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.8051e-06 - val_loss: 4.6064e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9667e-06 - val_loss: 4.5412e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7303e-06 - val_loss: 4.4847e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6263e-06 - val_loss: 4.3479e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2797e-06 - val_loss: 4.7244e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2627e-06 - val_loss: 4.9820e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8840e-06 - val_loss: 5.2022e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2151e-06 - val_loss: 5.2145e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5967e-06 - val_loss: 5.2697e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1964e-06 - val_loss: 5.4122e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9983e-06 - val_loss: 4.8977e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8778e-06 - val_loss: 5.0274e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2913e-06 - val_loss: 5.6916e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3945e-06 - val_loss: 6.7165e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6900e-06 - val_loss: 7.5717e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1334e-06 - val_loss: 6.0281e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3598e-06 - val_loss: 6.7533e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3561e-06 - val_loss: 8.6243e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5076e-06 - val_loss: 9.8734e-04\n",
            "training:  lstm_ohlc  df:  16\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.9788e-05 - val_loss: 0.0048\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8149e-05 - val_loss: 0.0059\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8347e-05 - val_loss: 0.0064\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9207e-05 - val_loss: 0.0063\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5700e-05 - val_loss: 0.0072\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5879e-05 - val_loss: 0.0065\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7595e-05 - val_loss: 0.0082\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5858e-05 - val_loss: 0.0084\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6432e-05 - val_loss: 0.0104\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5657e-05 - val_loss: 0.0102\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5230e-05 - val_loss: 0.0146\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5514e-05 - val_loss: 0.0155\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5994e-05 - val_loss: 0.0162\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4944e-05 - val_loss: 0.0185\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5621e-05 - val_loss: 0.0194\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4371e-05 - val_loss: 0.0232\n",
            "training:  lstm_ohlc  df:  17\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 4.1819e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 3s 8ms/step - loss: 8.8690e-06 - val_loss: 0.0268\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.4100e-06 - val_loss: 0.0288\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.2740e-06 - val_loss: 0.0312\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.5724e-06 - val_loss: 0.0322\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.6196e-06 - val_loss: 0.0327\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 5.8007e-06 - val_loss: 0.0331\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.1227e-06 - val_loss: 0.0371\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.1850e-06 - val_loss: 0.0409\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.0250e-06 - val_loss: 0.0376\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.5906e-06 - val_loss: 0.0380\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.0475e-06 - val_loss: 0.0416\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 6.0707e-06 - val_loss: 0.0445\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.8510e-06 - val_loss: 0.0421\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.7532e-06 - val_loss: 0.0488\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.8111e-06 - val_loss: 0.0507\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.1534e-06 - val_loss: 0.0499\n",
            "training:  lstm_ohlc  df:  18\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/174 [>.............................] - ETA: 1s - loss: 0.0110"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 9.8130e-04 - val_loss: 2.8887e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.9058e-04 - val_loss: 2.4683e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.6745e-04 - val_loss: 2.4313e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.4966e-04 - val_loss: 2.3809e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.5935e-04 - val_loss: 2.7623e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.4076e-04 - val_loss: 2.4614e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.5051e-04 - val_loss: 2.1819e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3657e-04 - val_loss: 2.5286e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3806e-04 - val_loss: 2.2747e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2904e-04 - val_loss: 2.1720e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2748e-04 - val_loss: 2.3717e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3337e-04 - val_loss: 2.0981e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2345e-04 - val_loss: 2.1178e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2192e-04 - val_loss: 2.1212e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2747e-04 - val_loss: 3.6477e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3029e-04 - val_loss: 2.1340e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3085e-04 - val_loss: 2.2233e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2813e-04 - val_loss: 2.6087e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2402e-04 - val_loss: 2.1088e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2637e-04 - val_loss: 2.1053e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2760e-04 - val_loss: 2.1121e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2306e-04 - val_loss: 2.1727e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1579e-04 - val_loss: 2.3666e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2901e-04 - val_loss: 2.1901e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2788e-04 - val_loss: 2.1698e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2354e-04 - val_loss: 2.1998e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1216e-04 - val_loss: 2.1531e-04\n",
            "training:  lstm_ohlc  df:  19\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/47 [====>.........................] - ETA: 0s - loss: 2.4976e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 9ms/step - loss: 2.2654e-04 - val_loss: 1.9974e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1276e-04 - val_loss: 2.2075e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0768e-04 - val_loss: 2.2832e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1076e-04 - val_loss: 2.3783e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0161e-04 - val_loss: 2.6218e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.2544e-04 - val_loss: 2.2715e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1743e-04 - val_loss: 2.2435e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0753e-04 - val_loss: 2.6431e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.3342e-04 - val_loss: 1.9276e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9609e-04 - val_loss: 2.1051e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0119e-04 - val_loss: 2.1683e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.1493e-04 - val_loss: 1.8516e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0275e-04 - val_loss: 2.2952e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0499e-04 - val_loss: 1.8599e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1081e-04 - val_loss: 2.6290e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.2539e-04 - val_loss: 2.3462e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.2258e-04 - val_loss: 2.9995e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.1127e-04 - val_loss: 1.8238e-04\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0830e-04 - val_loss: 2.0566e-04\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.1725e-04 - val_loss: 1.9252e-04\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0417e-04 - val_loss: 1.9587e-04\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9463e-04 - val_loss: 2.1564e-04\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1837e-04 - val_loss: 1.9933e-04\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1375e-04 - val_loss: 1.9379e-04\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9713e-04 - val_loss: 2.1057e-04\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1129e-04 - val_loss: 2.0223e-04\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0860e-04 - val_loss: 3.0312e-04\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0527e-04 - val_loss: 2.0306e-04\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8320e-04 - val_loss: 1.9713e-04\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0820e-04 - val_loss: 1.9509e-04\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0873e-04 - val_loss: 1.8537e-04\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9957e-04 - val_loss: 1.8476e-04\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9216e-04 - val_loss: 2.0299e-04\n",
            "training:  lstm_ohlc  df:  20\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/151 [>.............................] - ETA: 1s - loss: 1.7444e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 2.4439e-05 - val_loss: 7.1561e-04\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.6728e-06 - val_loss: 0.0014\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.2768e-06 - val_loss: 0.0015\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.1386e-06 - val_loss: 0.0015\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.4748e-06 - val_loss: 0.0013\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.6092e-06 - val_loss: 0.0013\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.4700e-06 - val_loss: 0.0012\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.4121e-06 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.6160e-06 - val_loss: 0.0012\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.9263e-06 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.0331e-06 - val_loss: 0.0011\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.5366e-06 - val_loss: 0.0011\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.8529e-06 - val_loss: 0.0011\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.1326e-06 - val_loss: 0.0011\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.5601e-06 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.1104e-06 - val_loss: 0.0012\n",
            "training:  lstm_ohlc  df:  21\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 1.2180e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 7.5398e-05 - val_loss: 2.7599e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 6.1339e-05 - val_loss: 2.9847e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6701e-05 - val_loss: 3.6698e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 6.1957e-05 - val_loss: 3.3765e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9324e-05 - val_loss: 2.0889e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.6000e-05 - val_loss: 2.1762e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.2150e-05 - val_loss: 2.5587e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.4729e-05 - val_loss: 3.8806e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.6469e-05 - val_loss: 3.1744e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.7549e-05 - val_loss: 3.1130e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.4234e-05 - val_loss: 3.4720e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6668e-05 - val_loss: 3.6590e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.4968e-05 - val_loss: 2.6644e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.8882e-05 - val_loss: 2.8282e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.5184e-05 - val_loss: 3.6577e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.6679e-05 - val_loss: 5.6119e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.5426e-05 - val_loss: 5.5770e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6172e-05 - val_loss: 4.6095e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.4209e-05 - val_loss: 3.8997e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6576e-05 - val_loss: 4.0885e-04\n",
            "training:  lstm_ohlc  df:  22\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/317 [..............................] - ETA: 3s - loss: 1.9229e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 3s 8ms/step - loss: 2.4290e-05 - val_loss: 0.0022\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.4300e-05 - val_loss: 0.0022\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.3052e-05 - val_loss: 0.0025\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2387e-05 - val_loss: 0.0027\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.3075e-05 - val_loss: 0.0027\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.4794e-05 - val_loss: 0.0032\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2542e-05 - val_loss: 0.0036\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.3153e-05 - val_loss: 0.0037\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2000e-05 - val_loss: 0.0043\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.3270e-05 - val_loss: 0.0045\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1685e-05 - val_loss: 0.0050\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2491e-05 - val_loss: 0.0053\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.3315e-05 - val_loss: 0.0052\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1510e-05 - val_loss: 0.0064\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.2458e-05 - val_loss: 0.0069\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.0996e-05 - val_loss: 0.0082\n",
            "Epoch 17/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.1749e-05 - val_loss: 0.0081\n",
            "training:  lstm_ohlc  df:  23\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/180 [>.............................] - ETA: 1s - loss: 3.3421e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.1537e-04 - val_loss: 2.1035e-05\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.9293e-04 - val_loss: 5.9317e-06\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.7996e-04 - val_loss: 8.9760e-06\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6894e-04 - val_loss: 2.2962e-05\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5481e-04 - val_loss: 4.4443e-05\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5777e-04 - val_loss: 2.3764e-05\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5753e-04 - val_loss: 2.1938e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5056e-04 - val_loss: 8.2451e-06\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5780e-04 - val_loss: 5.9719e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4702e-04 - val_loss: 2.6451e-05\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5098e-04 - val_loss: 2.3470e-05\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5307e-04 - val_loss: 1.8545e-05\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5012e-04 - val_loss: 1.5509e-05\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4709e-04 - val_loss: 6.3369e-06\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5550e-04 - val_loss: 9.0092e-06\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4752e-04 - val_loss: 8.0199e-06\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5168e-04 - val_loss: 8.7354e-06\n",
            "training:  lstm_ohlc  df:  24\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 2.4659e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.5595e-04 - val_loss: 9.0979e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4103e-04 - val_loss: 9.6656e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3756e-04 - val_loss: 1.0631e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3967e-04 - val_loss: 1.0375e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3665e-04 - val_loss: 1.3608e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3419e-04 - val_loss: 8.2966e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3133e-04 - val_loss: 8.5399e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3475e-04 - val_loss: 9.5717e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3032e-04 - val_loss: 8.1156e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3335e-04 - val_loss: 7.7693e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2980e-04 - val_loss: 1.0282e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3175e-04 - val_loss: 8.8612e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3079e-04 - val_loss: 8.2030e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2925e-04 - val_loss: 1.0436e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2844e-04 - val_loss: 1.0217e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2859e-04 - val_loss: 8.1704e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3247e-04 - val_loss: 1.2683e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3870e-04 - val_loss: 9.2890e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3046e-04 - val_loss: 9.5455e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2966e-04 - val_loss: 8.5420e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3121e-04 - val_loss: 1.0501e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2891e-04 - val_loss: 8.2205e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2716e-04 - val_loss: 8.3003e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2802e-04 - val_loss: 1.0179e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3555e-04 - val_loss: 7.7708e-05\n",
            "training:  lstm_ohlc  df:  25\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/53 [===>..........................] - ETA: 0s - loss: 2.9593e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 9ms/step - loss: 2.6809e-04 - val_loss: 3.3807e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.8320e-04 - val_loss: 3.3403e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6027e-04 - val_loss: 3.4837e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.7017e-04 - val_loss: 3.3619e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5868e-04 - val_loss: 3.5799e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5882e-04 - val_loss: 4.1782e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5781e-04 - val_loss: 3.3954e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5951e-04 - val_loss: 3.3031e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5973e-04 - val_loss: 3.7913e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5601e-04 - val_loss: 3.3678e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4711e-04 - val_loss: 3.4519e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6985e-04 - val_loss: 3.3981e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4692e-04 - val_loss: 4.0607e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6857e-04 - val_loss: 3.4944e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3860e-04 - val_loss: 3.3422e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5838e-04 - val_loss: 3.7353e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3538e-04 - val_loss: 3.5931e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4745e-04 - val_loss: 4.2246e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4859e-04 - val_loss: 4.2157e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4108e-04 - val_loss: 3.4118e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5282e-04 - val_loss: 4.0515e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5073e-04 - val_loss: 3.7933e-04\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5597e-04 - val_loss: 3.6272e-04\n",
            "training:  lstm_ohlc  df:  26\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 9/58 [===>..........................] - ETA: 0s - loss: 1.4303e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 9ms/step - loss: 1.6430e-04 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5497e-04 - val_loss: 0.0019\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.0244e-04 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6349e-04 - val_loss: 0.0021\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4859e-04 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3965e-04 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4239e-04 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3669e-04 - val_loss: 0.0020\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4537e-04 - val_loss: 0.0021\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4804e-04 - val_loss: 0.0022\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3977e-04 - val_loss: 0.0021\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3741e-04 - val_loss: 0.0021\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3925e-04 - val_loss: 0.0021\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4925e-04 - val_loss: 0.0021\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4451e-04 - val_loss: 0.0019\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4361e-04 - val_loss: 0.0020\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4695e-04 - val_loss: 0.0020\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4195e-04 - val_loss: 0.0020\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4030e-04 - val_loss: 0.0020\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3354e-04 - val_loss: 0.0022\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.3702e-04 - val_loss: 0.0020\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.2883e-04 - val_loss: 0.0021\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3647e-04 - val_loss: 0.0020\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3702e-04 - val_loss: 0.0020\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3906e-04 - val_loss: 0.0020\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2722e-04 - val_loss: 0.0020\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4811e-04 - val_loss: 0.0020\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3186e-04 - val_loss: 0.0020\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5717e-04 - val_loss: 0.0019\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3033e-04 - val_loss: 0.0020\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3333e-04 - val_loss: 0.0020\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5252e-04 - val_loss: 0.0020\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2174e-04 - val_loss: 0.0020\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3492e-04 - val_loss: 0.0019\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4483e-04 - val_loss: 0.0019\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3741e-04 - val_loss: 0.0020\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2421e-04 - val_loss: 0.0019\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.3036e-04 - val_loss: 0.0019\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3446e-04 - val_loss: 0.0020\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1992e-04 - val_loss: 0.0020\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1854e-04 - val_loss: 0.0020\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4313e-04 - val_loss: 0.0021\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3651e-04 - val_loss: 0.0021\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1517e-04 - val_loss: 0.0020\n",
            "training:  lstm_ohlc  df:  27\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/46 [====>.........................] - ETA: 0s - loss: 3.9467e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 9ms/step - loss: 3.8576e-04 - val_loss: 5.8966e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.2281e-04 - val_loss: 5.3339e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6145e-04 - val_loss: 7.6402e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5300e-04 - val_loss: 5.8588e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3574e-04 - val_loss: 5.5430e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1498e-04 - val_loss: 5.6556e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4057e-04 - val_loss: 5.4461e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.5017e-04 - val_loss: 5.8994e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3063e-04 - val_loss: 8.0668e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.6623e-04 - val_loss: 5.3285e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2013e-04 - val_loss: 4.9856e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3579e-04 - val_loss: 5.4688e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4975e-04 - val_loss: 6.6213e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2501e-04 - val_loss: 4.8639e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0016e-04 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7947e-04 - val_loss: 5.2926e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1127e-04 - val_loss: 5.2213e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1811e-04 - val_loss: 5.0234e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1592e-04 - val_loss: 5.4331e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3921e-04 - val_loss: 8.0583e-04\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3791e-04 - val_loss: 6.6914e-04\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2642e-04 - val_loss: 7.2700e-04\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.9119e-04 - val_loss: 6.1565e-04\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2611e-04 - val_loss: 5.3230e-04\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.4078e-04 - val_loss: 5.0918e-04\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.4077e-04 - val_loss: 4.9197e-04\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9999e-04 - val_loss: 6.2167e-04\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0998e-04 - val_loss: 5.5818e-04\n",
            "Epoch 29/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1763e-04 - val_loss: 5.0675e-04\n",
            "training:  lstm_ohlc  df:  28\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/171 [>.............................] - ETA: 1s - loss: 7.7277e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 8ms/step - loss: 7.7275e-05 - val_loss: 2.8809e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0186e-05 - val_loss: 3.0855e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0215e-05 - val_loss: 2.8719e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9538e-05 - val_loss: 3.3410e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9056e-05 - val_loss: 2.9730e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0690e-05 - val_loss: 2.9424e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9739e-05 - val_loss: 3.1313e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9486e-05 - val_loss: 2.8158e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.4741e-05 - val_loss: 2.8788e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3105e-05 - val_loss: 3.5520e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0310e-05 - val_loss: 2.9209e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5510e-05 - val_loss: 2.8433e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9154e-05 - val_loss: 3.0049e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0923e-05 - val_loss: 3.1920e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7645e-05 - val_loss: 3.1250e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9815e-05 - val_loss: 3.3293e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3335e-05 - val_loss: 3.3795e-04\n",
            "Epoch 18/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7862e-05 - val_loss: 3.0971e-04\n",
            "Epoch 19/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9247e-05 - val_loss: 3.5222e-04\n",
            "Epoch 20/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8107e-05 - val_loss: 3.4143e-04\n",
            "Epoch 21/200\n",
            "171/171 [==============================] - 2s 10ms/step - loss: 6.7144e-05 - val_loss: 3.2081e-04\n",
            "Epoch 22/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.7130e-05 - val_loss: 4.0013e-04\n",
            "Epoch 23/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9472e-05 - val_loss: 4.3803e-04\n",
            "training:  lstm_ohlc  df:  29\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 3.8050e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6126e-05 - val_loss: 4.3345e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5088e-05 - val_loss: 4.4307e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3140e-05 - val_loss: 4.5233e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1642e-05 - val_loss: 4.6543e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1273e-05 - val_loss: 4.6475e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1566e-05 - val_loss: 4.5528e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1816e-05 - val_loss: 5.1797e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0858e-05 - val_loss: 5.4341e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0637e-05 - val_loss: 5.5583e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1012e-05 - val_loss: 5.4525e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0262e-05 - val_loss: 6.2140e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2243e-05 - val_loss: 6.1427e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9640e-05 - val_loss: 6.5091e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8947e-05 - val_loss: 7.5253e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9638e-05 - val_loss: 7.3800e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0551e-05 - val_loss: 7.7402e-04\n",
            "training:  lstm_ohlc  df:  30\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 2.6640e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9416e-05 - val_loss: 8.3943e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8499e-05 - val_loss: 8.7365e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7727e-05 - val_loss: 9.3440e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9677e-05 - val_loss: 0.0010\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7995e-05 - val_loss: 9.7281e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7862e-05 - val_loss: 0.0010\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8122e-05 - val_loss: 0.0010\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9698e-05 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7994e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7932e-05 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9075e-05 - val_loss: 0.0013\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9103e-05 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6654e-05 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7467e-05 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6791e-05 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7854e-05 - val_loss: 0.0018\n",
            "training:  lstm_ohlc  df:  31\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7474e-05 - val_loss: 4.8310e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1665e-05 - val_loss: 3.7191e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8994e-05 - val_loss: 3.6657e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0943e-05 - val_loss: 5.6606e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8717e-05 - val_loss: 4.1752e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9816e-05 - val_loss: 5.2926e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6541e-05 - val_loss: 7.4323e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9351e-05 - val_loss: 3.2554e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5823e-05 - val_loss: 3.7471e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5441e-05 - val_loss: 3.2751e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7355e-05 - val_loss: 3.8431e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6154e-05 - val_loss: 4.5070e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8705e-05 - val_loss: 6.5889e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7142e-05 - val_loss: 4.2224e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8357e-05 - val_loss: 3.0668e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6521e-05 - val_loss: 3.4694e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6899e-05 - val_loss: 4.2258e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7876e-05 - val_loss: 4.1798e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7902e-05 - val_loss: 4.3900e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8805e-05 - val_loss: 8.3996e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6785e-05 - val_loss: 3.4600e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6699e-05 - val_loss: 7.1096e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6185e-05 - val_loss: 1.1115e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6090e-05 - val_loss: 3.0207e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6359e-05 - val_loss: 8.5839e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5268e-05 - val_loss: 4.9322e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5520e-05 - val_loss: 3.7983e-05\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5118e-05 - val_loss: 4.2461e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5174e-05 - val_loss: 3.8616e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7246e-05 - val_loss: 3.1939e-05\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3983e-05 - val_loss: 4.5522e-05\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6053e-05 - val_loss: 8.1637e-05\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5324e-05 - val_loss: 3.0632e-05\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6806e-05 - val_loss: 5.4110e-05\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6358e-05 - val_loss: 3.8313e-05\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3231e-05 - val_loss: 4.1215e-05\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6212e-05 - val_loss: 3.6364e-05\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3898e-05 - val_loss: 3.9287e-05\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8690e-05 - val_loss: 5.1635e-05\n",
            "training:  lstm_ohlc  df:  32\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.5234e-05 - val_loss: 2.3300e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1171e-05 - val_loss: 2.2465e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0502e-05 - val_loss: 2.1714e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1591e-05 - val_loss: 2.1622e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0941e-05 - val_loss: 1.9457e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2399e-05 - val_loss: 2.3930e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0045e-05 - val_loss: 2.2528e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1178e-05 - val_loss: 2.4604e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0722e-05 - val_loss: 2.0530e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1229e-05 - val_loss: 2.3149e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9575e-05 - val_loss: 3.0644e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0976e-05 - val_loss: 3.7140e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8755e-05 - val_loss: 2.5272e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1599e-05 - val_loss: 7.0217e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1218e-05 - val_loss: 5.9703e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1026e-05 - val_loss: 6.3615e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9954e-05 - val_loss: 5.3707e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9793e-05 - val_loss: 7.2499e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1678e-05 - val_loss: 4.0492e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0053e-05 - val_loss: 4.4113e-04\n",
            "training:  lstm_ohlc  df:  33\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 7.0525e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 8ms/step - loss: 1.2515e-04 - val_loss: 1.3563e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.6379e-05 - val_loss: 5.8972e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0063e-04 - val_loss: 3.0604e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.4065e-05 - val_loss: 2.3664e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0041e-04 - val_loss: 1.8414e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.9185e-05 - val_loss: 2.7333e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.6829e-05 - val_loss: 1.7009e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.5006e-05 - val_loss: 1.4832e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.4764e-05 - val_loss: 1.1958e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1434e-05 - val_loss: 1.8593e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3450e-05 - val_loss: 2.5334e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5291e-05 - val_loss: 1.6204e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.8165e-05 - val_loss: 2.1903e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.6431e-05 - val_loss: 2.0657e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0395e-05 - val_loss: 2.1934e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2218e-05 - val_loss: 4.1950e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2582e-05 - val_loss: 1.5680e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2794e-05 - val_loss: 1.5100e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0669e-05 - val_loss: 2.2752e-04\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0135e-05 - val_loss: 1.3733e-04\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0005e-05 - val_loss: 2.4384e-04\n",
            "Epoch 22/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2956e-05 - val_loss: 3.3525e-04\n",
            "Epoch 23/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.4840e-05 - val_loss: 8.3161e-04\n",
            "Epoch 24/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3856e-05 - val_loss: 3.6830e-04\n",
            "training:  lstm_ohlc  df:  34\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 3s - loss: 3.2051e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9967e-05 - val_loss: 5.8429e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8734e-05 - val_loss: 5.1813e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8683e-05 - val_loss: 4.6068e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8521e-05 - val_loss: 4.4776e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7221e-05 - val_loss: 4.8795e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7924e-05 - val_loss: 4.7672e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8923e-05 - val_loss: 4.7135e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7309e-05 - val_loss: 4.7924e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6800e-05 - val_loss: 4.4114e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8792e-05 - val_loss: 4.6229e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9479e-05 - val_loss: 4.0952e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8309e-05 - val_loss: 4.6566e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8151e-05 - val_loss: 4.7748e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7897e-05 - val_loss: 4.3994e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8167e-05 - val_loss: 3.7395e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6611e-05 - val_loss: 4.9258e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6251e-05 - val_loss: 4.0500e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7476e-05 - val_loss: 4.9942e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8044e-05 - val_loss: 4.1630e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8478e-05 - val_loss: 5.0772e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7049e-05 - val_loss: 7.5499e-04\n",
            "Epoch 22/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7210e-05 - val_loss: 5.9828e-04\n",
            "Epoch 23/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6996e-05 - val_loss: 6.5367e-04\n",
            "Epoch 24/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7365e-05 - val_loss: 9.4214e-04\n",
            "Epoch 25/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7617e-05 - val_loss: 0.0011\n",
            "Epoch 26/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8060e-05 - val_loss: 0.0011\n",
            "Epoch 27/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6199e-05 - val_loss: 0.0011\n",
            "Epoch 28/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7277e-05 - val_loss: 0.0017\n",
            "Epoch 29/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6555e-05 - val_loss: 0.0014\n",
            "Epoch 30/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6317e-05 - val_loss: 0.0017\n",
            "training:  lstm_ohlc  df:  35\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/314 [..............................] - ETA: 3s - loss: 3.9926e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 3s 8ms/step - loss: 2.9556e-05 - val_loss: 0.0093\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.6101e-05 - val_loss: 0.0102\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4447e-05 - val_loss: 0.0081\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3427e-05 - val_loss: 0.0097\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4032e-05 - val_loss: 0.0095\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.3068e-05 - val_loss: 0.0107\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1793e-05 - val_loss: 0.0106\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3758e-05 - val_loss: 0.0143\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2641e-05 - val_loss: 0.0099\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3408e-05 - val_loss: 0.0122\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2742e-05 - val_loss: 0.0105\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2633e-05 - val_loss: 0.0101\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.3630e-05 - val_loss: 0.0102\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1385e-05 - val_loss: 0.0093\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2512e-05 - val_loss: 0.0109\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3196e-05 - val_loss: 0.0115\n",
            "Epoch 17/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2087e-05 - val_loss: 0.0127\n",
            "Epoch 18/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1266e-05 - val_loss: 0.0115\n",
            "training:  lstm_ohlc  df:  36\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/118 [=>............................] - ETA: 0s - loss: 5.4134e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 5.3128e-05 - val_loss: 0.0064\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.8242e-05 - val_loss: 0.0059\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4598e-05 - val_loss: 0.0065\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1119e-05 - val_loss: 0.0067\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5483e-05 - val_loss: 0.0066\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.7625e-05 - val_loss: 0.0049\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8897e-05 - val_loss: 0.0048\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9504e-05 - val_loss: 0.0051\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1903e-05 - val_loss: 0.0054\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0700e-05 - val_loss: 0.0066\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9499e-05 - val_loss: 0.0058\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2762e-05 - val_loss: 0.0076\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0735e-05 - val_loss: 0.0074\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.2753e-05 - val_loss: 0.0064\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0179e-05 - val_loss: 0.0069\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0538e-05 - val_loss: 0.0076\n",
            "Epoch 17/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.1839e-05 - val_loss: 0.0079\n",
            "Epoch 18/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8480e-05 - val_loss: 0.0094\n",
            "Epoch 19/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8737e-05 - val_loss: 0.0108\n",
            "Epoch 20/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0762e-05 - val_loss: 0.0106\n",
            "Epoch 21/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.0091e-05 - val_loss: 0.0104\n",
            "Epoch 22/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1658e-05 - val_loss: 0.0111\n",
            "training:  lstm_ohlc  df:  37\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.8797e-05 - val_loss: 0.0083\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6213e-05 - val_loss: 0.0092\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6440e-05 - val_loss: 0.0087\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6948e-05 - val_loss: 0.0070\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5950e-05 - val_loss: 0.0088\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5883e-05 - val_loss: 0.0079\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.7646e-05 - val_loss: 0.0085\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.5574e-05 - val_loss: 0.0110\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6890e-05 - val_loss: 0.0108\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8037e-05 - val_loss: 0.0112\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6764e-05 - val_loss: 0.0126\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6102e-05 - val_loss: 0.0095\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6523e-05 - val_loss: 0.0110\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8085e-05 - val_loss: 0.0089\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6662e-05 - val_loss: 0.0112\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6122e-05 - val_loss: 0.0087\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.6163e-05 - val_loss: 0.0071\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.8437e-05 - val_loss: 0.0083\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.6156e-05 - val_loss: 0.0091\n",
            "training:  lstm_ohlc  df:  38\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/99 [=>............................] - ETA: 0s - loss: 0.0040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 6.5216e-04 - val_loss: 5.2067e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 2.0727e-04 - val_loss: 5.6768e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.9177e-04 - val_loss: 5.6217e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.9673e-04 - val_loss: 5.3731e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.9768e-04 - val_loss: 5.1206e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8883e-04 - val_loss: 6.0026e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8350e-04 - val_loss: 5.3508e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8331e-04 - val_loss: 5.0070e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7603e-04 - val_loss: 4.9170e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8458e-04 - val_loss: 5.0303e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8115e-04 - val_loss: 4.7020e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7390e-04 - val_loss: 4.8220e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7528e-04 - val_loss: 4.8955e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7209e-04 - val_loss: 4.7715e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6851e-04 - val_loss: 5.1183e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7149e-04 - val_loss: 4.6592e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8319e-04 - val_loss: 5.0528e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7060e-04 - val_loss: 4.8024e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7649e-04 - val_loss: 5.4451e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7890e-04 - val_loss: 4.7158e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7506e-04 - val_loss: 5.2313e-04\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6789e-04 - val_loss: 4.8976e-04\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7192e-04 - val_loss: 4.7601e-04\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7446e-04 - val_loss: 5.7524e-04\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7954e-04 - val_loss: 4.8132e-04\n",
            "Epoch 26/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6946e-04 - val_loss: 4.8082e-04\n",
            "Epoch 27/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6883e-04 - val_loss: 4.8502e-04\n",
            "Epoch 28/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8080e-04 - val_loss: 4.8124e-04\n",
            "Epoch 29/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7787e-04 - val_loss: 4.8037e-04\n",
            "Epoch 30/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7335e-04 - val_loss: 4.9472e-04\n",
            "Epoch 31/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8329e-04 - val_loss: 5.1452e-04\n",
            "training:  lstm_ohlc  df:  39\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 3s - loss: 4.2741e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 3.5345e-05 - val_loss: 1.9743e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1900e-05 - val_loss: 1.9747e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.4253e-05 - val_loss: 2.3008e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0258e-05 - val_loss: 2.6471e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9170e-05 - val_loss: 2.1432e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.8851e-05 - val_loss: 2.2243e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9402e-05 - val_loss: 2.7683e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9474e-05 - val_loss: 2.1053e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0321e-05 - val_loss: 6.3035e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.3910e-05 - val_loss: 5.8250e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9800e-05 - val_loss: 5.8104e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.9591e-05 - val_loss: 4.0150e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2595e-05 - val_loss: 3.4662e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.3265e-05 - val_loss: 4.4321e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1606e-05 - val_loss: 3.2544e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 4.4564e-05 - val_loss: 5.7632e-04\n",
            "training:  lstm_ohlc  df:  40\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 2.7583e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5858e-05 - val_loss: 3.2231e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3013e-05 - val_loss: 3.8617e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4405e-05 - val_loss: 3.9195e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3760e-05 - val_loss: 3.8359e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2207e-05 - val_loss: 4.3843e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2908e-05 - val_loss: 5.4485e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4334e-05 - val_loss: 4.6293e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2228e-05 - val_loss: 4.6231e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3411e-05 - val_loss: 4.3155e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2879e-05 - val_loss: 4.7978e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3481e-05 - val_loss: 4.5551e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1580e-05 - val_loss: 5.6175e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2269e-05 - val_loss: 4.9865e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2431e-05 - val_loss: 6.2036e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2128e-05 - val_loss: 4.6413e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3221e-05 - val_loss: 5.3529e-04\n",
            "training:  lstm_ohlc  df:  41\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 1s - loss: 3.5438e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1152e-05 - val_loss: 4.9520e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1410e-05 - val_loss: 6.1140e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1611e-05 - val_loss: 6.2003e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1329e-05 - val_loss: 4.9730e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3501e-05 - val_loss: 6.3177e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1340e-05 - val_loss: 5.7638e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2157e-05 - val_loss: 6.9418e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.2320e-05 - val_loss: 7.5873e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0773e-05 - val_loss: 7.9021e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0513e-05 - val_loss: 6.4350e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1241e-05 - val_loss: 0.0010\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1255e-05 - val_loss: 8.9110e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4211e-05 - val_loss: 9.9532e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1783e-05 - val_loss: 0.0011\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1368e-05 - val_loss: 9.8406e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0252e-05 - val_loss: 0.0011\n",
            "training:  lstm_ohlc  df:  42\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 1.0169e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 3.1407e-05 - val_loss: 0.0011\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.1944e-05 - val_loss: 0.0013\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0188e-05 - val_loss: 0.0021\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0277e-05 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.9625e-05 - val_loss: 0.0022\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9359e-05 - val_loss: 0.0025\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0188e-05 - val_loss: 0.0027\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9548e-05 - val_loss: 0.0025\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.0474e-05 - val_loss: 0.0026\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.8600e-05 - val_loss: 0.0030\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9911e-05 - val_loss: 0.0039\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8695e-05 - val_loss: 0.0046\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0141e-05 - val_loss: 0.0048\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9191e-05 - val_loss: 0.0042\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9793e-05 - val_loss: 0.0042\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8880e-05 - val_loss: 0.0047\n",
            "training:  lstm_ohlc  df:  43\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/64 [==>...........................] - ETA: 0s - loss: 0.0011    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 9ms/step - loss: 5.2874e-04 - val_loss: 8.6876e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 4.2769e-04 - val_loss: 6.6737e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.6302e-04 - val_loss: 6.1233e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.5678e-04 - val_loss: 7.1394e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.5251e-04 - val_loss: 6.9567e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.5336e-04 - val_loss: 7.7925e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.5719e-04 - val_loss: 7.6713e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3746e-04 - val_loss: 7.1398e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3665e-04 - val_loss: 7.5276e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3400e-04 - val_loss: 7.1211e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.2809e-04 - val_loss: 7.7124e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.6365e-04 - val_loss: 7.8533e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3719e-04 - val_loss: 8.2869e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.2783e-04 - val_loss: 8.5465e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3453e-04 - val_loss: 6.9424e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.3747e-04 - val_loss: 7.1728e-04\n",
            "Epoch 17/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1169e-04 - val_loss: 7.4504e-04\n",
            "Epoch 18/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1409e-04 - val_loss: 8.3543e-04\n",
            "training:  lstm_ohlc  df:  44\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 3s - loss: 2.1461e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4910e-04 - val_loss: 1.8399e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4525e-04 - val_loss: 1.8847e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4423e-04 - val_loss: 2.0091e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4786e-04 - val_loss: 2.0487e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4606e-04 - val_loss: 2.1694e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.5205e-04 - val_loss: 1.9522e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4318e-04 - val_loss: 2.0060e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4952e-04 - val_loss: 3.2624e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4287e-04 - val_loss: 2.0796e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4505e-04 - val_loss: 2.4122e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.6087e-04 - val_loss: 2.0404e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.5074e-04 - val_loss: 2.3410e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4174e-04 - val_loss: 2.2957e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4339e-04 - val_loss: 2.2144e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4749e-04 - val_loss: 2.4254e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4722e-04 - val_loss: 2.4876e-04\n",
            "training:  lstm_ohlc  df:  45\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/174 [>.............................] - ETA: 1s - loss: 2.2739e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3281e-04 - val_loss: 2.4136e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1388e-04 - val_loss: 1.9866e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0036e-04 - val_loss: 2.0946e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0421e-04 - val_loss: 1.9633e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0476e-04 - val_loss: 2.0278e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0460e-04 - val_loss: 2.5985e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9871e-04 - val_loss: 2.1069e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9797e-04 - val_loss: 2.1058e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0061e-04 - val_loss: 2.0864e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9535e-04 - val_loss: 1.9840e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9188e-04 - val_loss: 2.0847e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9964e-04 - val_loss: 2.1404e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9893e-04 - val_loss: 2.1870e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9745e-04 - val_loss: 1.9350e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9510e-04 - val_loss: 2.0756e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9321e-04 - val_loss: 2.0781e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0043e-04 - val_loss: 2.0196e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9285e-04 - val_loss: 1.9854e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0001e-04 - val_loss: 2.2580e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9916e-04 - val_loss: 2.0755e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9327e-04 - val_loss: 2.0865e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9899e-04 - val_loss: 2.0082e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9562e-04 - val_loss: 2.2064e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0034e-04 - val_loss: 2.0079e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9597e-04 - val_loss: 1.9901e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0106e-04 - val_loss: 1.9761e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9560e-04 - val_loss: 2.1945e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9929e-04 - val_loss: 1.9352e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9068e-04 - val_loss: 2.0029e-04\n",
            "training:  lstm_ohlc  df:  46\n",
            "Training model: lstm_ohlc  features: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7169e-05 - val_loss: 1.4726e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1898e-05 - val_loss: 1.1882e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9263e-05 - val_loss: 1.0676e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0266e-05 - val_loss: 1.0910e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0713e-05 - val_loss: 1.1391e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0556e-05 - val_loss: 1.1432e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4241e-05 - val_loss: 1.0964e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9816e-05 - val_loss: 1.4329e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3552e-05 - val_loss: 1.5323e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9739e-05 - val_loss: 1.0929e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9479e-05 - val_loss: 1.0982e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4870e-05 - val_loss: 1.1799e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2208e-05 - val_loss: 1.4155e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3644e-05 - val_loss: 1.0826e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7392e-05 - val_loss: 1.1230e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3005e-05 - val_loss: 1.0540e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6966e-05 - val_loss: 1.0945e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1846e-05 - val_loss: 1.1605e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9830e-05 - val_loss: 1.2655e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8779e-05 - val_loss: 1.1182e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9773e-05 - val_loss: 1.2067e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7426e-05 - val_loss: 1.1742e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0988e-05 - val_loss: 1.1524e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0489e-05 - val_loss: 1.3732e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0555e-05 - val_loss: 1.1331e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9691e-05 - val_loss: 1.0918e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.3567e-05 - val_loss: 1.1649e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0374e-05 - val_loss: 1.1954e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9449e-05 - val_loss: 1.1148e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7952e-05 - val_loss: 1.0881e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0889e-05 - val_loss: 1.1668e-04\n",
            "training:  lstm_ohlc  df:  47\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 2.3050e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4209e-04 - val_loss: 2.1409e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3184e-04 - val_loss: 2.5223e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3339e-04 - val_loss: 2.2784e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2759e-04 - val_loss: 2.0883e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2504e-04 - val_loss: 2.0842e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2621e-04 - val_loss: 2.0584e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2701e-04 - val_loss: 1.8426e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2284e-04 - val_loss: 1.5793e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2833e-04 - val_loss: 2.0231e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2366e-04 - val_loss: 2.3834e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2492e-04 - val_loss: 1.9320e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2834e-04 - val_loss: 1.6268e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2707e-04 - val_loss: 2.6885e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2449e-04 - val_loss: 1.8047e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2768e-04 - val_loss: 2.3528e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2293e-04 - val_loss: 1.9497e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1991e-04 - val_loss: 1.7489e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2598e-04 - val_loss: 3.8940e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2493e-04 - val_loss: 4.5510e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2974e-04 - val_loss: 2.2009e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2149e-04 - val_loss: 2.8778e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2341e-04 - val_loss: 2.1303e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2527e-04 - val_loss: 2.3203e-04\n",
            "training:  lstm_ohlc  df:  48\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.2501e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2028e-04 - val_loss: 7.9811e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1789e-04 - val_loss: 7.9271e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1457e-04 - val_loss: 7.2722e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1821e-04 - val_loss: 7.9304e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1900e-04 - val_loss: 8.7745e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1406e-04 - val_loss: 7.4755e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1713e-04 - val_loss: 8.3983e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1536e-04 - val_loss: 8.5419e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1747e-04 - val_loss: 9.9274e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1683e-04 - val_loss: 7.9050e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1231e-04 - val_loss: 7.9883e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1587e-04 - val_loss: 8.3445e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1808e-04 - val_loss: 9.0923e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2168e-04 - val_loss: 8.3264e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1714e-04 - val_loss: 9.0602e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2198e-04 - val_loss: 9.4427e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1647e-04 - val_loss: 8.3920e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1587e-04 - val_loss: 7.9901e-05\n",
            "training:  lstm_ohlc  df:  49\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 6.9374e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 9.2625e-05 - val_loss: 1.1227e-04\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7071e-05 - val_loss: 1.0247e-04\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8618e-05 - val_loss: 1.1766e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9725e-05 - val_loss: 1.0346e-04\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.3692e-05 - val_loss: 1.1101e-04\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6450e-05 - val_loss: 1.0601e-04\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7180e-05 - val_loss: 1.0147e-04\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8476e-05 - val_loss: 1.0154e-04\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8527e-05 - val_loss: 1.0507e-04\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6751e-05 - val_loss: 1.0246e-04\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6531e-05 - val_loss: 1.3884e-04\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.3416e-05 - val_loss: 1.0249e-04\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7347e-05 - val_loss: 1.2577e-04\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.0093e-05 - val_loss: 1.0504e-04\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9807e-05 - val_loss: 1.0668e-04\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.0041e-05 - val_loss: 1.2770e-04\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7962e-05 - val_loss: 1.0318e-04\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.8255e-05 - val_loss: 1.1330e-04\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6580e-05 - val_loss: 1.0427e-04\n",
            "Epoch 20/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7192e-05 - val_loss: 1.0425e-04\n",
            "Epoch 21/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9855e-05 - val_loss: 1.1194e-04\n",
            "Epoch 22/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.0298e-05 - val_loss: 1.1400e-04\n",
            "training:  lstm_ohlc  df:  50\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/13 [=================>............] - ETA: 0s - loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0029\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0035\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0025\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0021\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.9519e-04 - val_loss: 0.0029\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.5978e-04 - val_loss: 0.0025\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8777e-04 - val_loss: 0.0023\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.4522e-04 - val_loss: 0.0024\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.3993e-04 - val_loss: 0.0024\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.5051e-04 - val_loss: 0.0027\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.6890e-04 - val_loss: 0.0023\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.3406e-04 - val_loss: 0.0027\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.9243e-04 - val_loss: 0.0022\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.1857e-04 - val_loss: 0.0025\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.0076e-04 - val_loss: 0.0029\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 8.8758e-04 - val_loss: 0.0027\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.6508e-04 - val_loss: 0.0027\n",
            "training:  lstm_ohlc  df:  51\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  8/106 [=>............................] - ETA: 0s - loss: 4.0697e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.7326e-04 - val_loss: 8.1030e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.4380e-04 - val_loss: 8.4197e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.4168e-04 - val_loss: 8.5892e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4002e-04 - val_loss: 8.5257e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3331e-04 - val_loss: 9.6981e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3563e-04 - val_loss: 8.4263e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3050e-04 - val_loss: 8.9857e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3469e-04 - val_loss: 8.4331e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3537e-04 - val_loss: 8.5280e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3680e-04 - val_loss: 8.0627e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3237e-04 - val_loss: 8.4003e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3350e-04 - val_loss: 8.4180e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3836e-04 - val_loss: 8.9895e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3989e-04 - val_loss: 8.2271e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2686e-04 - val_loss: 8.2660e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2914e-04 - val_loss: 8.8481e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3735e-04 - val_loss: 8.4797e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2354e-04 - val_loss: 8.7606e-04\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2760e-04 - val_loss: 8.2972e-04\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2650e-04 - val_loss: 9.4830e-04\n",
            "Epoch 21/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2525e-04 - val_loss: 8.7967e-04\n",
            "Epoch 22/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3133e-04 - val_loss: 9.8774e-04\n",
            "Epoch 23/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3593e-04 - val_loss: 8.8383e-04\n",
            "Epoch 24/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2751e-04 - val_loss: 8.1658e-04\n",
            "Epoch 25/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2737e-04 - val_loss: 8.1725e-04\n",
            "training:  lstm_ohlc  df:  52\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 1.5315e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 2.5393e-05 - val_loss: 2.5371e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9572e-05 - val_loss: 2.5455e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8929e-05 - val_loss: 2.2899e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8921e-05 - val_loss: 2.2755e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7825e-05 - val_loss: 2.1325e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7411e-05 - val_loss: 2.1756e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7840e-05 - val_loss: 2.0175e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7080e-05 - val_loss: 2.0935e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8105e-05 - val_loss: 2.1606e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6672e-05 - val_loss: 2.1972e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6679e-05 - val_loss: 2.2258e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6765e-05 - val_loss: 2.3460e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6903e-05 - val_loss: 2.3035e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8831e-05 - val_loss: 2.3306e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8073e-05 - val_loss: 2.3135e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8000e-05 - val_loss: 2.5959e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6737e-05 - val_loss: 2.7078e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6580e-05 - val_loss: 2.7341e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6895e-05 - val_loss: 3.9458e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7317e-05 - val_loss: 3.9981e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6997e-05 - val_loss: 3.4680e-04\n",
            "Epoch 22/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6672e-05 - val_loss: 3.5638e-04\n",
            "training:  lstm_ohlc  df:  53\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n",
            " 8/79 [==>...........................] - ETA: 0s - loss: 1.2363e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 1.0320e-04 - val_loss: 0.0039\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0949e-05 - val_loss: 0.0026\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.2961e-05 - val_loss: 0.0021\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4359e-05 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.3872e-05 - val_loss: 0.0024\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4331e-05 - val_loss: 0.0026\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.9222e-05 - val_loss: 0.0029\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0918e-05 - val_loss: 0.0025\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9826e-05 - val_loss: 0.0022\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7836e-05 - val_loss: 0.0022\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0901e-05 - val_loss: 0.0029\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4317e-05 - val_loss: 0.0024\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9608e-05 - val_loss: 0.0025\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.0605e-05 - val_loss: 0.0023\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1405e-05 - val_loss: 0.0025\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9492e-05 - val_loss: 0.0026\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9724e-05 - val_loss: 0.0030\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3836e-05 - val_loss: 0.0033\n",
            "Epoch 19/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.6869e-05 - val_loss: 0.0035\n",
            "training:  lstm_ohlc  df:  54\n",
            "Training model: lstm_ohlc  features: 5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1564e-05 - val_loss: 2.8688e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.8771e-05 - val_loss: 3.0758e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.6097e-05 - val_loss: 3.9918e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7478e-05 - val_loss: 2.0708e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3914e-05 - val_loss: 1.8267e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4533e-05 - val_loss: 2.3973e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6331e-05 - val_loss: 2.2342e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.6138e-05 - val_loss: 1.6221e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2141e-05 - val_loss: 1.6315e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5935e-05 - val_loss: 1.8393e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.6823e-05 - val_loss: 1.5953e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4214e-05 - val_loss: 1.5828e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3931e-05 - val_loss: 1.6233e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5401e-05 - val_loss: 1.7684e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5973e-05 - val_loss: 1.3356e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5126e-05 - val_loss: 1.6048e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3269e-05 - val_loss: 1.9071e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5398e-05 - val_loss: 1.2756e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3437e-05 - val_loss: 1.3418e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5890e-05 - val_loss: 1.5514e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.6737e-05 - val_loss: 1.6116e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4506e-05 - val_loss: 2.6146e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4662e-05 - val_loss: 1.2058e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5956e-05 - val_loss: 2.1680e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.5379e-05 - val_loss: 1.5717e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4446e-05 - val_loss: 1.5452e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2712e-05 - val_loss: 1.4132e-04\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.5450e-05 - val_loss: 1.5205e-04\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4585e-05 - val_loss: 2.1257e-04\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4317e-05 - val_loss: 3.0167e-04\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4836e-05 - val_loss: 1.4277e-04\n",
            "Epoch 32/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.7724e-05 - val_loss: 2.0170e-04\n",
            "Epoch 33/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3130e-05 - val_loss: 1.5614e-04\n",
            "Epoch 34/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2451e-05 - val_loss: 1.5987e-04\n",
            "Epoch 35/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4861e-05 - val_loss: 1.5167e-04\n",
            "Epoch 36/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4062e-05 - val_loss: 1.3311e-04\n",
            "Epoch 37/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4583e-05 - val_loss: 1.4727e-04\n",
            "Epoch 38/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.3663e-05 - val_loss: 1.3753e-04\n",
            "build model: svm_cv  features: 2\n",
            "training:  svm_cv\n",
            "svm_cv  should train on stocks\n",
            "training dfs: 55\n",
            "training:  svm_cv  df:  0\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 15ms/step - loss: 0.0036 - val_loss: 0.3032\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 5.4754e-04 - val_loss: 0.2746\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 4.2861e-04 - val_loss: 0.1607\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.5873e-04 - val_loss: 0.0522\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 3.2437e-04 - val_loss: 0.0213\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.8023e-04 - val_loss: 0.0107\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.8240e-04 - val_loss: 0.0236\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.7963e-04 - val_loss: 0.0147\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.9144e-04 - val_loss: 0.0297\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.4586e-04 - val_loss: 0.0149\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.0521e-04 - val_loss: 0.0192\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.0590e-04 - val_loss: 0.0144\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.0633e-04 - val_loss: 0.0185\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.2216e-04 - val_loss: 0.0158\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.7184e-04 - val_loss: 0.0077\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.0942e-04 - val_loss: 0.0201\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.0367e-04 - val_loss: 0.0241\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.2816e-04 - val_loss: 0.0136\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.1868e-04 - val_loss: 0.0178\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 2.5715e-04 - val_loss: 0.0289\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.7120e-04 - val_loss: 0.0188\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.6050e-04 - val_loss: 0.0195\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.6981e-04 - val_loss: 0.0318\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.8817e-04 - val_loss: 0.0340\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.2753e-04 - val_loss: 0.0309\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.3615e-04 - val_loss: 0.0440\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.4342e-04 - val_loss: 0.0380\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 1.4191e-04 - val_loss: 0.0464\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.4373e-04 - val_loss: 0.0490\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.3135e-04 - val_loss: 0.0622\n",
            "training:  svm_cv  df:  1\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/80 [==>...........................] - ETA: 0s - loss: 3.1286e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 8ms/step - loss: 1.3484e-04 - val_loss: 0.0365\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 6.6233e-05 - val_loss: 0.0556\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.0091e-04 - val_loss: 0.0831\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.9432e-05 - val_loss: 0.0887\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.4787e-05 - val_loss: 0.1042\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.2143e-05 - val_loss: 0.1012\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 3.1898e-05 - val_loss: 0.0967\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 2.9287e-05 - val_loss: 0.1201\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 2.9944e-05 - val_loss: 0.1205\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.2489e-05 - val_loss: 0.1205\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 2.7240e-05 - val_loss: 0.1062\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 3.2187e-05 - val_loss: 0.1232\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 8.8301e-05 - val_loss: 0.1100\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.0282e-05 - val_loss: 0.1081\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.8703e-05 - val_loss: 0.1021\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3129e-05 - val_loss: 0.0818\n",
            "training:  svm_cv  df:  2\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 7.9792e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 8ms/step - loss: 1.5067e-05 - val_loss: 0.0779\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.0088e-05 - val_loss: 0.0859\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 9.0699e-06 - val_loss: 0.0891\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 9.6306e-06 - val_loss: 0.0974\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 9.1066e-06 - val_loss: 0.0958\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.4725e-06 - val_loss: 0.1058\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 9.4506e-06 - val_loss: 0.1075\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.4164e-06 - val_loss: 0.1000\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.1390e-05 - val_loss: 0.1031\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 8.1259e-06 - val_loss: 0.1037\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 9.0072e-06 - val_loss: 0.1041\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 7.8101e-06 - val_loss: 0.1057\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.0476e-06 - val_loss: 0.1010\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.0838e-05 - val_loss: 0.1088\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 8.2638e-06 - val_loss: 0.1029\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 9.1838e-06 - val_loss: 0.1111\n",
            "training:  svm_cv  df:  3\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3630e-04 - val_loss: 0.0205\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1836e-04 - val_loss: 0.0158\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7769e-04 - val_loss: 0.0199\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.6167e-04 - val_loss: 0.0215\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.4596e-04 - val_loss: 0.0200\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.3834e-04 - val_loss: 0.0210\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2022e-04 - val_loss: 0.0204\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2245e-04 - val_loss: 0.0202\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2622e-04 - val_loss: 0.0145\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2158e-04 - val_loss: 0.0156\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0750e-04 - val_loss: 0.0151\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0834e-04 - val_loss: 0.0173\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2161e-04 - val_loss: 0.0129\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0647e-04 - val_loss: 0.0220\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0299e-04 - val_loss: 0.0134\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0254e-04 - val_loss: 0.0130\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0407e-04 - val_loss: 0.0172\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1564e-05 - val_loss: 0.0127\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0872e-04 - val_loss: 0.0164\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.8283e-05 - val_loss: 0.0151\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.0079e-04 - val_loss: 0.0140\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9070e-05 - val_loss: 0.0152\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1332e-05 - val_loss: 0.0072\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.4967e-05 - val_loss: 0.0103\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4175e-05 - val_loss: 0.0151\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.9462e-05 - val_loss: 0.0140\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2577e-05 - val_loss: 0.0133\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0335e-05 - val_loss: 0.0178\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6163e-05 - val_loss: 0.0124\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.2849e-05 - val_loss: 0.0146\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.2233e-05 - val_loss: 0.0103\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.1675e-05 - val_loss: 0.0114\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.3819e-05 - val_loss: 0.0125\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.4969e-05 - val_loss: 0.0127\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.5806e-05 - val_loss: 0.0140\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.3817e-05 - val_loss: 0.0116\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.3150e-05 - val_loss: 0.0144\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9351e-05 - val_loss: 0.0139\n",
            "training:  svm_cv  df:  4\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 3.1840e-04 - val_loss: 7.7444e-05\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.8624e-04 - val_loss: 2.3055e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.7833e-04 - val_loss: 9.0594e-05\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.7752e-04 - val_loss: 1.2175e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5810e-04 - val_loss: 1.0773e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5890e-04 - val_loss: 9.8314e-05\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5236e-04 - val_loss: 8.7896e-05\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4288e-04 - val_loss: 2.2526e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4914e-04 - val_loss: 1.9323e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4066e-04 - val_loss: 6.8343e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5608e-04 - val_loss: 6.9611e-05\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4983e-04 - val_loss: 7.0091e-05\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.4633e-04 - val_loss: 1.0828e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4915e-04 - val_loss: 7.1638e-05\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3307e-04 - val_loss: 6.7536e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4111e-04 - val_loss: 1.0230e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3937e-04 - val_loss: 6.7278e-05\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3347e-04 - val_loss: 6.1472e-05\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4143e-04 - val_loss: 8.8043e-05\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3153e-04 - val_loss: 7.4937e-05\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.4312e-04 - val_loss: 9.8827e-05\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3232e-04 - val_loss: 7.5024e-05\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3626e-04 - val_loss: 9.3716e-05\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.3007e-04 - val_loss: 9.4341e-05\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2389e-04 - val_loss: 6.0458e-05\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2888e-04 - val_loss: 8.8295e-05\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2321e-04 - val_loss: 9.4199e-05\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2571e-04 - val_loss: 8.4507e-05\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3744e-04 - val_loss: 1.0455e-04\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2792e-04 - val_loss: 2.6721e-04\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2797e-04 - val_loss: 2.2187e-04\n",
            "Epoch 32/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2670e-04 - val_loss: 6.3988e-05\n",
            "Epoch 33/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2099e-04 - val_loss: 6.6905e-05\n",
            "Epoch 34/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2250e-04 - val_loss: 7.0430e-05\n",
            "Epoch 35/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2581e-04 - val_loss: 7.5892e-05\n",
            "Epoch 36/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3408e-04 - val_loss: 1.0301e-04\n",
            "Epoch 37/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2588e-04 - val_loss: 6.9764e-05\n",
            "Epoch 38/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2389e-04 - val_loss: 1.3150e-04\n",
            "Epoch 39/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.3318e-04 - val_loss: 7.6409e-05\n",
            "Epoch 40/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.2086e-04 - val_loss: 9.1111e-05\n",
            "training:  svm_cv  df:  5\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1132e-05 - val_loss: 0.0013\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.8860e-05 - val_loss: 0.0013\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.6809e-05 - val_loss: 0.0014\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4363e-05 - val_loss: 0.0012\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2134e-05 - val_loss: 0.0019\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1746e-05 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1059e-05 - val_loss: 0.0027\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1215e-05 - val_loss: 0.0029\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1676e-05 - val_loss: 0.0031\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0941e-05 - val_loss: 0.0042\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.1367e-05 - val_loss: 0.0030\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0070e-05 - val_loss: 0.0050\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9296e-05 - val_loss: 0.0045\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8599e-05 - val_loss: 0.0040\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0822e-05 - val_loss: 0.0036\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.7545e-05 - val_loss: 0.0039\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9199e-05 - val_loss: 0.0036\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9229e-05 - val_loss: 0.0056\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8104e-05 - val_loss: 0.0044\n",
            "training:  svm_cv  df:  6\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 3.6459e-04 - val_loss: 3.8287e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.9319e-04 - val_loss: 1.0652e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.8970e-04 - val_loss: 1.0945e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5740e-04 - val_loss: 1.0178e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.6303e-04 - val_loss: 1.0459e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5624e-04 - val_loss: 1.1954e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5496e-04 - val_loss: 1.2742e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5502e-04 - val_loss: 2.1342e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.6539e-04 - val_loss: 2.4041e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5606e-04 - val_loss: 9.7095e-05\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5110e-04 - val_loss: 1.1194e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.5474e-04 - val_loss: 1.1283e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5131e-04 - val_loss: 1.1143e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4789e-04 - val_loss: 1.1005e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4018e-04 - val_loss: 1.1579e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4524e-04 - val_loss: 1.8806e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4792e-04 - val_loss: 1.2585e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4941e-04 - val_loss: 1.1631e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3684e-04 - val_loss: 1.4852e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3864e-04 - val_loss: 1.0146e-04\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4576e-04 - val_loss: 1.2552e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4033e-04 - val_loss: 9.9869e-05\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.4147e-04 - val_loss: 1.2970e-04\n",
            "Epoch 24/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3663e-04 - val_loss: 1.0475e-04\n",
            "Epoch 25/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.3385e-04 - val_loss: 1.7675e-04\n",
            "training:  svm_cv  df:  7\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 8.8965e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 7.1497e-05 - val_loss: 3.1973e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.8616e-05 - val_loss: 3.3599e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.6758e-05 - val_loss: 3.1658e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.4988e-05 - val_loss: 4.3221e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.1889e-05 - val_loss: 4.4602e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.2670e-05 - val_loss: 4.6587e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.0067e-05 - val_loss: 6.9148e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.9722e-05 - val_loss: 8.1570e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.8082e-05 - val_loss: 7.6744e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 5.3463e-05 - val_loss: 9.7831e-04\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.9034e-05 - val_loss: 8.7264e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.7020e-05 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 7ms/step - loss: 4.8090e-05 - val_loss: 9.6254e-04\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.8650e-05 - val_loss: 0.0012\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.1435e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 5.0660e-05 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.5441e-05 - val_loss: 0.0028\n",
            "Epoch 18/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.5661e-05 - val_loss: 0.0024\n",
            "training:  svm_cv  df:  8\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/68 [==>...........................] - ETA: 0s - loss: 1.9090e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 2.9254e-04 - val_loss: 0.0032\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 2.1110e-04 - val_loss: 0.0037\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3532e-04 - val_loss: 0.0057\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2984e-04 - val_loss: 0.0037\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2655e-04 - val_loss: 0.0041\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2779e-04 - val_loss: 0.0037\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4058e-04 - val_loss: 0.0040\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2284e-04 - val_loss: 0.0032\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2913e-04 - val_loss: 0.0032\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3416e-04 - val_loss: 0.0027\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1950e-04 - val_loss: 0.0029\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3873e-04 - val_loss: 0.0038\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2401e-04 - val_loss: 0.0035\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1780e-04 - val_loss: 0.0036\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1202e-04 - val_loss: 0.0037\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2158e-04 - val_loss: 0.0035\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1272e-04 - val_loss: 0.0037\n",
            "Epoch 18/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.1634e-04 - val_loss: 0.0037\n",
            "Epoch 19/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2010e-04 - val_loss: 0.0029\n",
            "Epoch 20/200\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 1.1838e-04 - val_loss: 0.0045\n",
            "Epoch 21/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2454e-04 - val_loss: 0.0028\n",
            "Epoch 22/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.2132e-04 - val_loss: 0.0035\n",
            "Epoch 23/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0203e-04 - val_loss: 0.0034\n",
            "Epoch 24/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1506e-04 - val_loss: 0.0044\n",
            "Epoch 25/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1177e-04 - val_loss: 0.0038\n",
            "training:  svm_cv  df:  9\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/162 [>.............................] - ETA: 1s - loss: 1.4148e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 5.0202e-05 - val_loss: 0.0042\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.7306e-05 - val_loss: 0.0042\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.4830e-05 - val_loss: 0.0043\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.3407e-05 - val_loss: 0.0042\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.2031e-05 - val_loss: 0.0046\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.9774e-05 - val_loss: 0.0047\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.0678e-05 - val_loss: 0.0052\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.9551e-05 - val_loss: 0.0052\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8509e-05 - val_loss: 0.0054\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.7877e-05 - val_loss: 0.0055\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.8442e-05 - val_loss: 0.0056\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8198e-05 - val_loss: 0.0056\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.8210e-05 - val_loss: 0.0060\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.9171e-05 - val_loss: 0.0059\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.9176e-05 - val_loss: 0.0061\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.7016e-05 - val_loss: 0.0060\n",
            "Epoch 17/200\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.5916e-05 - val_loss: 0.0063\n",
            "training:  svm_cv  df:  10\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0238e-04 - val_loss: 0.0010\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 7.0165e-05 - val_loss: 6.2382e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.3981e-05 - val_loss: 7.9850e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2437e-05 - val_loss: 7.9038e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1904e-05 - val_loss: 6.3468e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7471e-05 - val_loss: 6.8585e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9338e-05 - val_loss: 5.0904e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3897e-05 - val_loss: 0.0011\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7261e-05 - val_loss: 5.9721e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0332e-05 - val_loss: 5.3789e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5458e-05 - val_loss: 7.2793e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9607e-05 - val_loss: 6.0506e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8242e-05 - val_loss: 0.0011\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5311e-05 - val_loss: 5.8725e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3728e-05 - val_loss: 3.1246e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9774e-05 - val_loss: 6.8570e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.6803e-05 - val_loss: 7.1036e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7098e-05 - val_loss: 5.8727e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3657e-05 - val_loss: 7.4355e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8530e-05 - val_loss: 6.4201e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.3996e-05 - val_loss: 6.2958e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.4568e-05 - val_loss: 8.5689e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.2079e-05 - val_loss: 7.4307e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5258e-05 - val_loss: 7.8566e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.0442e-05 - val_loss: 7.7049e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.1180e-05 - val_loss: 8.1559e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2995e-05 - val_loss: 6.9694e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.5232e-05 - val_loss: 7.5020e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4619e-05 - val_loss: 7.4193e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3618e-05 - val_loss: 7.2766e-04\n",
            "training:  svm_cv  df:  11\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3421e-04 - val_loss: 3.9299e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0510e-04 - val_loss: 1.9674e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4205e-05 - val_loss: 8.8378e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6970e-05 - val_loss: 1.2801e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.7357e-05 - val_loss: 1.1169e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.8752e-05 - val_loss: 7.6077e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.5206e-05 - val_loss: 1.2122e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4980e-05 - val_loss: 8.5260e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.4254e-05 - val_loss: 1.1132e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1169e-05 - val_loss: 1.0722e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0542e-05 - val_loss: 7.5967e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0605e-05 - val_loss: 1.0054e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1494e-05 - val_loss: 9.0570e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0375e-05 - val_loss: 8.1612e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0914e-05 - val_loss: 8.5872e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0623e-05 - val_loss: 7.3143e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2616e-05 - val_loss: 8.2779e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0408e-05 - val_loss: 9.2994e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7342e-05 - val_loss: 7.6702e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9210e-05 - val_loss: 9.1469e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7338e-05 - val_loss: 8.9353e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.5005e-05 - val_loss: 9.9726e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7791e-05 - val_loss: 1.4125e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7317e-05 - val_loss: 2.2899e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6116e-05 - val_loss: 7.6918e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5439e-05 - val_loss: 1.1081e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0818e-05 - val_loss: 1.0639e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8641e-05 - val_loss: 9.8318e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.6705e-05 - val_loss: 9.0080e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.4302e-05 - val_loss: 1.5216e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1681e-05 - val_loss: 2.7002e-04\n",
            "training:  svm_cv  df:  12\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 8/13 [=================>............] - ETA: 0s - loss: 0.0019"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "training:  svm_cv  df:  13\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/132 [=>............................] - ETA: 0s - loss: 2.5137e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 8ms/step - loss: 5.1882e-05 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.4183e-05 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.2691e-05 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 2.0799e-05 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.9366e-05 - val_loss: 0.0016\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8770e-05 - val_loss: 0.0016\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.8832e-05 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7332e-05 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6454e-05 - val_loss: 0.0016\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7500e-05 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.7279e-05 - val_loss: 0.0016\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5493e-05 - val_loss: 0.0016\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5441e-05 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6038e-05 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5335e-05 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5653e-05 - val_loss: 0.0015\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4463e-05 - val_loss: 0.0015\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3734e-05 - val_loss: 0.0015\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4120e-05 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6363e-05 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3699e-05 - val_loss: 0.0015\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4295e-05 - val_loss: 0.0015\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4922e-05 - val_loss: 0.0015\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4108e-05 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3406e-05 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3268e-05 - val_loss: 0.0014\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5067e-05 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2605e-05 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3505e-05 - val_loss: 0.0014\n",
            "Epoch 30/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2556e-05 - val_loss: 0.0015\n",
            "Epoch 31/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3541e-05 - val_loss: 0.0014\n",
            "Epoch 32/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2959e-05 - val_loss: 0.0014\n",
            "Epoch 33/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2708e-05 - val_loss: 0.0014\n",
            "Epoch 34/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2310e-05 - val_loss: 0.0014\n",
            "Epoch 35/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3278e-05 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2000e-05 - val_loss: 0.0014\n",
            "Epoch 37/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2429e-05 - val_loss: 0.0014\n",
            "Epoch 38/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3202e-05 - val_loss: 0.0014\n",
            "Epoch 39/200\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.2030e-05 - val_loss: 0.0014\n",
            "Epoch 40/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1427e-05 - val_loss: 0.0014\n",
            "Epoch 41/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2896e-05 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2681e-05 - val_loss: 0.0014\n",
            "Epoch 43/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1367e-05 - val_loss: 0.0015\n",
            "Epoch 44/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2541e-05 - val_loss: 0.0015\n",
            "Epoch 45/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1716e-05 - val_loss: 0.0015\n",
            "Epoch 46/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1544e-05 - val_loss: 0.0015\n",
            "Epoch 47/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2422e-05 - val_loss: 0.0015\n",
            "Epoch 48/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1323e-05 - val_loss: 0.0015\n",
            "training:  svm_cv  df:  14\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/26 [=========>....................] - ETA: 0s - loss: 0.0010    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 9ms/step - loss: 8.7927e-04 - val_loss: 2.5461e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 7.8552e-04 - val_loss: 6.5140e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6054e-04 - val_loss: 3.6417e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.7035e-04 - val_loss: 6.6283e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.7000e-04 - val_loss: 2.7001e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0910e-04 - val_loss: 2.3165e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6149e-04 - val_loss: 2.6374e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1206e-04 - val_loss: 2.7428e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0320e-04 - val_loss: 4.1500e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9951e-04 - val_loss: 2.9678e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7591e-04 - val_loss: 2.4647e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1222e-04 - val_loss: 2.8949e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3209e-04 - val_loss: 3.7269e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.6224e-04 - val_loss: 3.9208e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0228e-04 - val_loss: 2.7010e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.2448e-04 - val_loss: 2.1520e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.4362e-04 - val_loss: 2.7806e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9073e-04 - val_loss: 2.1966e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.7464e-04 - val_loss: 2.3055e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.6251e-04 - val_loss: 3.4666e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1507e-04 - val_loss: 2.6062e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8749e-04 - val_loss: 2.6573e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1615e-04 - val_loss: 3.0015e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.8061e-04 - val_loss: 2.4644e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6908e-04 - val_loss: 2.1578e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.1645e-04 - val_loss: 3.2146e-04\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.3353e-04 - val_loss: 2.3463e-04\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6186e-04 - val_loss: 2.4349e-04\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 4.0479e-04 - val_loss: 3.1925e-04\n",
            "Epoch 30/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.4291e-04 - val_loss: 3.1065e-04\n",
            "Epoch 31/200\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3.9038e-04 - val_loss: 2.4719e-04\n",
            "training:  svm_cv  df:  15\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9560e-05 - val_loss: 3.3612e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3660e-05 - val_loss: 3.6230e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2967e-05 - val_loss: 3.9771e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.2326e-05 - val_loss: 4.3540e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1723e-05 - val_loss: 4.7450e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1925e-05 - val_loss: 5.2026e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1397e-05 - val_loss: 5.4911e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1746e-05 - val_loss: 6.3443e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1770e-05 - val_loss: 7.5750e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.1022e-05 - val_loss: 8.7393e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1140e-05 - val_loss: 0.0011\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0763e-05 - val_loss: 0.0012\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0759e-05 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0494e-05 - val_loss: 0.0015\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0724e-05 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0992e-05 - val_loss: 0.0016\n",
            "training:  svm_cv  df:  16\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.5014e-05 - val_loss: 0.0050\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4881e-05 - val_loss: 0.0055\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.5029e-05 - val_loss: 0.0072\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1416e-05 - val_loss: 0.0074\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1143e-05 - val_loss: 0.0077\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1011e-05 - val_loss: 0.0091\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0182e-05 - val_loss: 0.0076\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1060e-05 - val_loss: 0.0087\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9745e-05 - val_loss: 0.0113\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9463e-05 - val_loss: 0.0131\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.0043e-05 - val_loss: 0.0118\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.9162e-05 - val_loss: 0.0166\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8953e-05 - val_loss: 0.0162\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 1.8441e-05 - val_loss: 0.0170\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8432e-05 - val_loss: 0.0180\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8541e-05 - val_loss: 0.0191\n",
            "training:  svm_cv  df:  17\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 9.5579e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3984e-05 - val_loss: 0.0193\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 1.0342e-05 - val_loss: 0.0202\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 9.3091e-06 - val_loss: 0.0216\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.8343e-06 - val_loss: 0.0227\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.6553e-06 - val_loss: 0.0248\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.5408e-06 - val_loss: 0.0269\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 8.0205e-06 - val_loss: 0.0298\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.8040e-06 - val_loss: 0.0318\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.5460e-06 - val_loss: 0.0335\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.5555e-06 - val_loss: 0.0344\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.3236e-06 - val_loss: 0.0342\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.0320e-06 - val_loss: 0.0344\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 7.4783e-06 - val_loss: 0.0354\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.3636e-06 - val_loss: 0.0372\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 7.5389e-06 - val_loss: 0.0392\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 7ms/step - loss: 6.9520e-06 - val_loss: 0.0409\n",
            "training:  svm_cv  df:  18\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 9.8936e-04 - val_loss: 1.9363e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.7188e-04 - val_loss: 1.8574e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.5328e-04 - val_loss: 1.8617e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.4638e-04 - val_loss: 2.0320e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3306e-04 - val_loss: 1.8770e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2901e-04 - val_loss: 2.6217e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.3199e-04 - val_loss: 1.9131e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2392e-04 - val_loss: 1.9016e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1971e-04 - val_loss: 1.8732e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1698e-04 - val_loss: 2.0731e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2382e-04 - val_loss: 1.8155e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.3307e-04 - val_loss: 1.9877e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2447e-04 - val_loss: 1.8970e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.2000e-04 - val_loss: 2.0770e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2177e-04 - val_loss: 1.9270e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1878e-04 - val_loss: 1.8421e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0278e-04 - val_loss: 1.8616e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1238e-04 - val_loss: 1.7620e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2594e-04 - val_loss: 2.5831e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1003e-04 - val_loss: 2.2123e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1745e-04 - val_loss: 1.9166e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1750e-04 - val_loss: 1.8440e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1324e-04 - val_loss: 1.9107e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.1238e-04 - val_loss: 1.9696e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0702e-04 - val_loss: 1.8871e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0644e-04 - val_loss: 1.8834e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1600e-04 - val_loss: 2.6203e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1747e-04 - val_loss: 1.9258e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0714e-04 - val_loss: 1.7913e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0540e-04 - val_loss: 1.8207e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0833e-04 - val_loss: 1.7952e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1053e-04 - val_loss: 1.8038e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1167e-04 - val_loss: 2.0722e-04\n",
            "training:  svm_cv  df:  19\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/47 [====>.........................] - ETA: 0s - loss: 2.2745e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 8ms/step - loss: 2.1984e-04 - val_loss: 1.6477e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8833e-04 - val_loss: 1.5888e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9923e-04 - val_loss: 1.7965e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0001e-04 - val_loss: 1.9093e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9305e-04 - val_loss: 1.8696e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9632e-04 - val_loss: 1.8109e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7636e-04 - val_loss: 1.7411e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8595e-04 - val_loss: 1.7841e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9481e-04 - val_loss: 1.5949e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8857e-04 - val_loss: 1.6711e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8844e-04 - val_loss: 1.8658e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9037e-04 - val_loss: 1.8731e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8817e-04 - val_loss: 1.6436e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8267e-04 - val_loss: 2.2235e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9274e-04 - val_loss: 2.4318e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9437e-04 - val_loss: 2.0334e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8138e-04 - val_loss: 1.5887e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8089e-04 - val_loss: 1.9293e-04\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8902e-04 - val_loss: 2.0521e-04\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0012e-04 - val_loss: 1.6953e-04\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0131e-04 - val_loss: 2.2481e-04\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8892e-04 - val_loss: 2.0064e-04\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8502e-04 - val_loss: 1.8536e-04\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7273e-04 - val_loss: 1.9244e-04\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8997e-04 - val_loss: 1.7012e-04\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9956e-04 - val_loss: 2.0312e-04\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8411e-04 - val_loss: 2.2183e-04\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7991e-04 - val_loss: 2.4088e-04\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8272e-04 - val_loss: 1.8640e-04\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8355e-04 - val_loss: 1.6483e-04\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9186e-04 - val_loss: 2.0466e-04\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8753e-04 - val_loss: 1.6169e-04\n",
            "training:  svm_cv  df:  20\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/151 [>.............................] - ETA: 0s - loss: 6.3518e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 6.5523e-05 - val_loss: 0.0011\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.3936e-05 - val_loss: 0.0011\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.0361e-05 - val_loss: 9.9410e-04\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 8.8961e-06 - val_loss: 9.6289e-04\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.2023e-06 - val_loss: 0.0010\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.8407e-06 - val_loss: 9.6050e-04\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.9149e-06 - val_loss: 9.5896e-04\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.4698e-06 - val_loss: 9.9722e-04\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.4496e-06 - val_loss: 0.0010\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.9887e-06 - val_loss: 9.7360e-04\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 7.5627e-06 - val_loss: 0.0010\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.0702e-06 - val_loss: 9.8486e-04\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.9678e-06 - val_loss: 0.0010\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.4389e-06 - val_loss: 0.0010\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.1524e-06 - val_loss: 0.0010\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.9393e-06 - val_loss: 9.9349e-04\n",
            "Epoch 17/200\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 6.0805e-06 - val_loss: 9.7005e-04\n",
            "Epoch 18/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.6502e-06 - val_loss: 0.0010\n",
            "Epoch 19/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.9526e-06 - val_loss: 0.0010\n",
            "Epoch 20/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.0030e-06 - val_loss: 0.0011\n",
            "Epoch 21/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.0201e-06 - val_loss: 0.0011\n",
            "Epoch 22/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.5070e-06 - val_loss: 0.0011\n",
            "training:  svm_cv  df:  21\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 8.7452e-05 - val_loss: 2.1588e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 7.4574e-05 - val_loss: 1.0203e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 7.0827e-05 - val_loss: 1.5240e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.3485e-05 - val_loss: 1.2388e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.2327e-05 - val_loss: 1.2580e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.5126e-05 - val_loss: 1.8637e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.4570e-05 - val_loss: 2.7376e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.2029e-05 - val_loss: 1.4189e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.9660e-05 - val_loss: 1.4898e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 6.0247e-05 - val_loss: 2.7373e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.6916e-05 - val_loss: 2.0534e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8834e-05 - val_loss: 1.3893e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.7565e-05 - val_loss: 2.1103e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.8783e-05 - val_loss: 1.8567e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 6.0245e-05 - val_loss: 2.6417e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.6945e-05 - val_loss: 1.2681e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.7374e-05 - val_loss: 1.5835e-04\n",
            "training:  svm_cv  df:  22\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/317 [..............................] - ETA: 3s - loss: 5.1209e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 2s 8ms/step - loss: 3.1460e-05 - val_loss: 6.6019e-04\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.9116e-05 - val_loss: 8.3190e-04\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.6919e-05 - val_loss: 9.4703e-04\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 3.0577e-05 - val_loss: 0.0011\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6311e-05 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.7048e-05 - val_loss: 0.0021\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.8476e-05 - val_loss: 0.0018\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.6329e-05 - val_loss: 0.0021\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6957e-05 - val_loss: 0.0022\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.6043e-05 - val_loss: 0.0022\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5647e-05 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.7752e-05 - val_loss: 0.0021\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 2s 8ms/step - loss: 2.5082e-05 - val_loss: 0.0026\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.5953e-05 - val_loss: 0.0033\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.7032e-05 - val_loss: 0.0040\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 2s 7ms/step - loss: 2.4691e-05 - val_loss: 0.0045\n",
            "training:  svm_cv  df:  23\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 2s - loss: 2.1736e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6296e-04 - val_loss: 3.8471e-05\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6530e-04 - val_loss: 4.9364e-06\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.7051e-04 - val_loss: 1.8235e-05\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6012e-04 - val_loss: 3.0197e-05\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.6072e-04 - val_loss: 8.8674e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.6093e-04 - val_loss: 9.5513e-06\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5343e-04 - val_loss: 1.1000e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4418e-04 - val_loss: 5.2569e-06\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5189e-04 - val_loss: 9.5749e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5632e-04 - val_loss: 5.8147e-06\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4913e-04 - val_loss: 2.1971e-05\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5525e-04 - val_loss: 5.2943e-06\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5924e-04 - val_loss: 1.8736e-05\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5239e-04 - val_loss: 7.5767e-06\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.5167e-04 - val_loss: 8.9169e-06\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4758e-04 - val_loss: 9.2926e-06\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 1.4659e-04 - val_loss: 6.1906e-06\n",
            "training:  svm_cv  df:  24\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 6.4542e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.7483e-04 - val_loss: 8.2625e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.5875e-04 - val_loss: 1.4362e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4652e-04 - val_loss: 1.1166e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4588e-04 - val_loss: 9.5742e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4857e-04 - val_loss: 7.8923e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3784e-04 - val_loss: 9.3325e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3902e-04 - val_loss: 1.0407e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3746e-04 - val_loss: 9.8795e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3634e-04 - val_loss: 8.3469e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3606e-04 - val_loss: 8.5848e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4103e-04 - val_loss: 1.7501e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3774e-04 - val_loss: 8.0381e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3696e-04 - val_loss: 8.1897e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3671e-04 - val_loss: 7.7311e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3418e-04 - val_loss: 8.5600e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4160e-04 - val_loss: 1.2367e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3411e-04 - val_loss: 1.1001e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3716e-04 - val_loss: 9.1100e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4637e-04 - val_loss: 1.0020e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3677e-04 - val_loss: 8.0529e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3743e-04 - val_loss: 8.6412e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3288e-04 - val_loss: 8.4696e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3788e-04 - val_loss: 8.3143e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3212e-04 - val_loss: 8.3365e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3656e-04 - val_loss: 8.5294e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3441e-04 - val_loss: 2.0136e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3536e-04 - val_loss: 9.1267e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3169e-04 - val_loss: 1.0593e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.4053e-04 - val_loss: 8.4192e-05\n",
            "training:  svm_cv  df:  25\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 8/53 [===>..........................] - ETA: 0s - loss: 1.8037e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5444e-04 - val_loss: 3.2216e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.7611e-04 - val_loss: 3.3630e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4982e-04 - val_loss: 3.8765e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.9338e-04 - val_loss: 3.2282e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4751e-04 - val_loss: 3.4097e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5819e-04 - val_loss: 3.0390e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.7174e-04 - val_loss: 3.2837e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4865e-04 - val_loss: 3.2139e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3977e-04 - val_loss: 3.3343e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4885e-04 - val_loss: 3.0892e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5674e-04 - val_loss: 3.3777e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5047e-04 - val_loss: 3.1675e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5019e-04 - val_loss: 3.2744e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5161e-04 - val_loss: 3.1757e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5024e-04 - val_loss: 3.0862e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4571e-04 - val_loss: 3.3561e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5645e-04 - val_loss: 3.0730e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4072e-04 - val_loss: 3.1466e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3728e-04 - val_loss: 3.0856e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4920e-04 - val_loss: 2.9602e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4241e-04 - val_loss: 3.0786e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3538e-04 - val_loss: 3.0715e-04\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6048e-04 - val_loss: 3.0244e-04\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3360e-04 - val_loss: 3.0045e-04\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6030e-04 - val_loss: 3.3320e-04\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4874e-04 - val_loss: 3.5639e-04\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4686e-04 - val_loss: 3.1268e-04\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5492e-04 - val_loss: 3.1659e-04\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5448e-04 - val_loss: 3.0619e-04\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4223e-04 - val_loss: 3.1379e-04\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3461e-04 - val_loss: 3.2136e-04\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5944e-04 - val_loss: 3.3434e-04\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3630e-04 - val_loss: 3.2234e-04\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3935e-04 - val_loss: 3.3519e-04\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3591e-04 - val_loss: 3.1536e-04\n",
            "training:  svm_cv  df:  26\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/58 [===>..........................] - ETA: 0s - loss: 1.4808e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7537e-04 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4917e-04 - val_loss: 0.0015\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4823e-04 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5613e-04 - val_loss: 0.0015\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4171e-04 - val_loss: 0.0015\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4785e-04 - val_loss: 0.0015\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3294e-04 - val_loss: 0.0015\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3775e-04 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4565e-04 - val_loss: 0.0015\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4032e-04 - val_loss: 0.0015\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4292e-04 - val_loss: 0.0015\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4588e-04 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2591e-04 - val_loss: 0.0015\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2413e-04 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4100e-04 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2429e-04 - val_loss: 0.0015\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2776e-04 - val_loss: 0.0015\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2492e-04 - val_loss: 0.0015\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2664e-04 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1809e-04 - val_loss: 0.0015\n",
            "training:  svm_cv  df:  27\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/46 [====>.........................] - ETA: 0s - loss: 5.5786e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 8ms/step - loss: 3.4417e-04 - val_loss: 6.2637e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7415e-04 - val_loss: 6.0847e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3944e-04 - val_loss: 4.8740e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2675e-04 - val_loss: 4.6447e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3034e-04 - val_loss: 5.1598e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3719e-04 - val_loss: 5.1030e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1972e-04 - val_loss: 5.0127e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2849e-04 - val_loss: 4.7929e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.2547e-04 - val_loss: 7.2989e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.5208e-04 - val_loss: 4.3057e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3820e-04 - val_loss: 4.4422e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1633e-04 - val_loss: 6.1174e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1626e-04 - val_loss: 4.2804e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1067e-04 - val_loss: 5.4506e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2749e-04 - val_loss: 5.1067e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1576e-04 - val_loss: 4.4829e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1575e-04 - val_loss: 4.9408e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0101e-04 - val_loss: 5.5931e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1849e-04 - val_loss: 4.5369e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2211e-04 - val_loss: 4.9754e-04\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.3981e-04 - val_loss: 4.6525e-04\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1715e-04 - val_loss: 4.9894e-04\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1877e-04 - val_loss: 4.7696e-04\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0807e-04 - val_loss: 4.6738e-04\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9447e-04 - val_loss: 4.3409e-04\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0797e-04 - val_loss: 5.5852e-04\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0745e-04 - val_loss: 5.0898e-04\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1168e-04 - val_loss: 4.7131e-04\n",
            "training:  svm_cv  df:  28\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/171 [..............................] - ETA: 1s - loss: 2.7503e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 8ms/step - loss: 9.2481e-05 - val_loss: 2.9041e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.7094e-05 - val_loss: 2.7493e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.3839e-05 - val_loss: 3.2371e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.4984e-05 - val_loss: 2.9648e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.7157e-05 - val_loss: 2.8000e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.1747e-05 - val_loss: 2.9568e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.4726e-05 - val_loss: 3.1640e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0163e-05 - val_loss: 3.4549e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 7.2577e-05 - val_loss: 3.0312e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 6.9423e-05 - val_loss: 3.5542e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.1459e-05 - val_loss: 3.9714e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.6534e-05 - val_loss: 3.9427e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8829e-05 - val_loss: 3.5536e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9254e-05 - val_loss: 4.5239e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.8570e-05 - val_loss: 3.9195e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9564e-05 - val_loss: 3.5272e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 7.0672e-05 - val_loss: 3.8506e-04\n",
            "training:  svm_cv  df:  29\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 5.1126e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 3.6656e-05 - val_loss: 4.3313e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 3.2761e-05 - val_loss: 5.2303e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.9890e-05 - val_loss: 5.5537e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.9677e-05 - val_loss: 6.3918e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.7277e-05 - val_loss: 7.7723e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.8135e-05 - val_loss: 8.1385e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5944e-05 - val_loss: 8.5741e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5190e-05 - val_loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6169e-05 - val_loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.5730e-05 - val_loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.6842e-05 - val_loss: 0.0016\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.4986e-05 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3581e-05 - val_loss: 0.0019\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.4004e-05 - val_loss: 0.0021\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3883e-05 - val_loss: 0.0021\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2948e-05 - val_loss: 0.0019\n",
            "training:  svm_cv  df:  30\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/116 [=>............................] - ETA: 0s - loss: 2.6958e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3365e-05 - val_loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2691e-05 - val_loss: 0.0023\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3592e-05 - val_loss: 0.0029\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.5204e-05 - val_loss: 0.0027\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2363e-05 - val_loss: 0.0025\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0967e-05 - val_loss: 0.0027\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2685e-05 - val_loss: 0.0029\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2251e-05 - val_loss: 0.0033\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.4191e-05 - val_loss: 0.0030\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.2312e-05 - val_loss: 0.0029\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.3040e-05 - val_loss: 0.0044\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1552e-05 - val_loss: 0.0042\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0322e-05 - val_loss: 0.0043\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.9973e-05 - val_loss: 0.0051\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.3324e-05 - val_loss: 0.0049\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.1601e-05 - val_loss: 0.0053\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 2.2677e-05 - val_loss: 0.0052\n",
            "training:  svm_cv  df:  31\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.8855e-05 - val_loss: 5.4333e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.0148e-05 - val_loss: 3.0414e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.4324e-05 - val_loss: 3.4080e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.6279e-05 - val_loss: 7.3994e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.6528e-05 - val_loss: 5.4538e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.2850e-05 - val_loss: 4.5964e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1415e-05 - val_loss: 7.4969e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0114e-05 - val_loss: 2.9935e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8413e-05 - val_loss: 3.6611e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5177e-05 - val_loss: 1.2817e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.5214e-05 - val_loss: 3.9922e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9639e-05 - val_loss: 4.2468e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0051e-05 - val_loss: 4.2515e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.0488e-05 - val_loss: 9.6660e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 6.1053e-05 - val_loss: 3.2589e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9852e-05 - val_loss: 3.6488e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0794e-05 - val_loss: 6.7977e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3452e-05 - val_loss: 5.9403e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5928e-05 - val_loss: 3.1307e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.8207e-05 - val_loss: 3.7249e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.9821e-05 - val_loss: 3.4733e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2405e-05 - val_loss: 3.0188e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 5.7643e-05 - val_loss: 3.8848e-05\n",
            "training:  svm_cv  df:  32\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 3.0239e-05 - val_loss: 1.8561e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.7248e-05 - val_loss: 1.7066e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.8055e-05 - val_loss: 1.3779e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.5715e-05 - val_loss: 1.3108e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.5128e-05 - val_loss: 1.6532e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.4982e-05 - val_loss: 1.7384e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3634e-05 - val_loss: 1.5887e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3486e-05 - val_loss: 1.9440e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.3567e-05 - val_loss: 2.7645e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2446e-05 - val_loss: 2.2383e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3242e-05 - val_loss: 3.6198e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.3236e-05 - val_loss: 3.3268e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2834e-05 - val_loss: 2.8655e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2519e-05 - val_loss: 5.4025e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2631e-05 - val_loss: 3.9025e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2522e-05 - val_loss: 5.8294e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2059e-05 - val_loss: 4.5617e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1799e-05 - val_loss: 6.8219e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 2.2266e-05 - val_loss: 4.2461e-04\n",
            "training:  svm_cv  df:  33\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 3.9815e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 8ms/step - loss: 1.3585e-04 - val_loss: 5.8074e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0772e-04 - val_loss: 2.0396e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 1.0922e-04 - val_loss: 3.1656e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0290e-04 - val_loss: 1.7221e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0249e-04 - val_loss: 1.6114e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.9474e-05 - val_loss: 9.0861e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0104e-04 - val_loss: 3.3086e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.4515e-05 - val_loss: 6.3891e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.5437e-05 - val_loss: 2.2902e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.3509e-05 - val_loss: 2.5636e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.6844e-05 - val_loss: 1.7052e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0412e-04 - val_loss: 5.7822e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0372e-04 - val_loss: 1.5581e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.8357e-05 - val_loss: 1.8858e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0049e-04 - val_loss: 4.0661e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0611e-05 - val_loss: 6.4087e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.2180e-05 - val_loss: 1.4391e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.9721e-05 - val_loss: 1.6866e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2854e-05 - val_loss: 2.3555e-04\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1316e-05 - val_loss: 6.2409e-04\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.0998e-05 - val_loss: 3.2353e-04\n",
            "Epoch 22/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.9033e-05 - val_loss: 4.4402e-04\n",
            "Epoch 23/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0035e-05 - val_loss: 2.8850e-04\n",
            "Epoch 24/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.0553e-05 - val_loss: 2.5995e-04\n",
            "Epoch 25/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.2153e-05 - val_loss: 4.2967e-04\n",
            "Epoch 26/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9918e-05 - val_loss: 2.1327e-04\n",
            "Epoch 27/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 9.5339e-05 - val_loss: 1.9039e-04\n",
            "Epoch 28/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.6773e-05 - val_loss: 1.8941e-04\n",
            "Epoch 29/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.7152e-05 - val_loss: 5.4815e-04\n",
            "Epoch 30/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.1097e-05 - val_loss: 1.9626e-04\n",
            "Epoch 31/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 9.6681e-05 - val_loss: 1.8050e-04\n",
            "Epoch 32/200\n",
            "208/208 [==============================] - 2s 7ms/step - loss: 8.5356e-05 - val_loss: 4.0494e-04\n",
            "training:  svm_cv  df:  34\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 1.2259e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 3.1032e-05 - val_loss: 2.4059e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4013e-05 - val_loss: 3.8867e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4152e-05 - val_loss: 4.0675e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2062e-05 - val_loss: 5.8465e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.2687e-05 - val_loss: 6.0196e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1568e-05 - val_loss: 0.0012\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.1272e-05 - val_loss: 9.9723e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0705e-05 - val_loss: 0.0010\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 1.9817e-05 - val_loss: 9.1595e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0503e-05 - val_loss: 0.0010\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1173e-05 - val_loss: 0.0012\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0304e-05 - val_loss: 0.0014\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9386e-05 - val_loss: 0.0011\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0931e-05 - val_loss: 0.0021\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1086e-05 - val_loss: 0.0011\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8956e-05 - val_loss: 0.0012\n",
            "training:  svm_cv  df:  35\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/314 [..............................] - ETA: 3s - loss: 5.6456e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 2s 8ms/step - loss: 4.4210e-05 - val_loss: 9.6124e-04\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 3.1993e-05 - val_loss: 0.0010\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.0715e-05 - val_loss: 5.6748e-04\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.9407e-05 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.1866e-05 - val_loss: 0.0019\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9085e-05 - val_loss: 0.0011\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8796e-05 - val_loss: 0.0023\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.9776e-05 - val_loss: 0.0012\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8506e-05 - val_loss: 0.0013\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 3.0378e-05 - val_loss: 0.0013\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.6463e-05 - val_loss: 0.0014\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.7918e-05 - val_loss: 0.0011\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.8571e-05 - val_loss: 9.3790e-04\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7089e-05 - val_loss: 0.0015\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7830e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.9628e-05 - val_loss: 0.0011\n",
            "Epoch 17/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.5588e-05 - val_loss: 8.7656e-04\n",
            "Epoch 18/200\n",
            "314/314 [==============================] - 2s 7ms/step - loss: 2.7056e-05 - val_loss: 9.9257e-04\n",
            "training:  svm_cv  df:  36\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  8/118 [=>............................] - ETA: 0s - loss: 8.5367e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 6.1581e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 5.0454e-05 - val_loss: 0.0013\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.8818e-05 - val_loss: 0.0014\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.8289e-05 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.8750e-05 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.5516e-05 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.7307e-05 - val_loss: 0.0024\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.6725e-05 - val_loss: 0.0025\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 4.8691e-05 - val_loss: 0.0026\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4200e-05 - val_loss: 0.0027\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4028e-05 - val_loss: 0.0031\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5201e-05 - val_loss: 0.0034\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.6655e-05 - val_loss: 0.0042\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.5421e-05 - val_loss: 0.0038\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1481e-05 - val_loss: 0.0037\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.4032e-05 - val_loss: 0.0045\n",
            "training:  svm_cv  df:  37\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 1s - loss: 1.4378e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 1s 8ms/step - loss: 4.1682e-05 - val_loss: 0.0026\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.3262e-05 - val_loss: 0.0024\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.2075e-05 - val_loss: 0.0037\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.2110e-05 - val_loss: 0.0023\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0562e-05 - val_loss: 0.0026\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1556e-05 - val_loss: 0.0018\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0469e-05 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0210e-05 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1541e-05 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0704e-05 - val_loss: 0.0022\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0199e-05 - val_loss: 0.0022\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1776e-05 - val_loss: 0.0032\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.2415e-05 - val_loss: 0.0023\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0005e-05 - val_loss: 0.0026\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0494e-05 - val_loss: 0.0024\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0356e-05 - val_loss: 0.0025\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.0084e-05 - val_loss: 0.0024\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0003e-05 - val_loss: 0.0024\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.0318e-05 - val_loss: 0.0023\n",
            "Epoch 20/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 3.1526e-05 - val_loss: 0.0018\n",
            "Epoch 21/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1447e-05 - val_loss: 0.0024\n",
            "Epoch 22/200\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.1456e-05 - val_loss: 0.0028\n",
            "training:  svm_cv  df:  38\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/99 [=>............................] - ETA: 0s - loss: 0.0028"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 5.8721e-04 - val_loss: 5.6538e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 2.0784e-04 - val_loss: 4.5233e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 2.1715e-04 - val_loss: 4.8471e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8638e-04 - val_loss: 4.4476e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8206e-04 - val_loss: 4.4505e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7192e-04 - val_loss: 4.4068e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6828e-04 - val_loss: 4.3750e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7899e-04 - val_loss: 4.5358e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8082e-04 - val_loss: 5.5306e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7798e-04 - val_loss: 4.8012e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.8176e-04 - val_loss: 4.6021e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7161e-04 - val_loss: 4.5295e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6494e-04 - val_loss: 4.3951e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6127e-04 - val_loss: 4.4606e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6225e-04 - val_loss: 4.5130e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6743e-04 - val_loss: 4.5790e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6488e-04 - val_loss: 4.5553e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6095e-04 - val_loss: 4.7445e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6696e-04 - val_loss: 4.7188e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6714e-04 - val_loss: 4.3465e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6405e-04 - val_loss: 4.3628e-04\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6905e-04 - val_loss: 4.4932e-04\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5418e-04 - val_loss: 4.5948e-04\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6130e-04 - val_loss: 5.6895e-04\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6035e-04 - val_loss: 4.3917e-04\n",
            "Epoch 26/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6170e-04 - val_loss: 4.6755e-04\n",
            "Epoch 27/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5704e-04 - val_loss: 4.4148e-04\n",
            "Epoch 28/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.7164e-04 - val_loss: 4.4925e-04\n",
            "Epoch 29/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6869e-04 - val_loss: 4.4200e-04\n",
            "Epoch 30/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6647e-04 - val_loss: 4.6261e-04\n",
            "Epoch 31/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6672e-04 - val_loss: 4.6896e-04\n",
            "Epoch 32/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5967e-04 - val_loss: 4.5104e-04\n",
            "Epoch 33/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6076e-04 - val_loss: 4.5609e-04\n",
            "Epoch 34/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6991e-04 - val_loss: 4.7196e-04\n",
            "Epoch 35/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6384e-04 - val_loss: 4.3753e-04\n",
            "training:  svm_cv  df:  39\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 1.6892e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 5.4020e-05 - val_loss: 2.3939e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 5.4365e-05 - val_loss: 1.9807e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.4442e-05 - val_loss: 1.9441e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8990e-05 - val_loss: 2.7069e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9431e-05 - val_loss: 2.4991e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 4.0166e-05 - val_loss: 2.5364e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6733e-05 - val_loss: 3.2325e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.9180e-05 - val_loss: 2.1545e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.8377e-05 - val_loss: 2.5536e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.6681e-05 - val_loss: 2.4500e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9418e-05 - val_loss: 2.8625e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.7017e-05 - val_loss: 2.5685e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 3.9521e-05 - val_loss: 2.9418e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.2261e-05 - val_loss: 3.5884e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.6331e-05 - val_loss: 2.8896e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.4988e-05 - val_loss: 4.4395e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.0362e-05 - val_loss: 3.0106e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 4.0880e-05 - val_loss: 4.3098e-04\n",
            "training:  svm_cv  df:  40\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 0s - loss: 8.4391e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 4.8941e-05 - val_loss: 4.1926e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.8862e-05 - val_loss: 3.7752e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7680e-05 - val_loss: 3.6079e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7038e-05 - val_loss: 3.2332e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6152e-05 - val_loss: 3.7534e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5243e-05 - val_loss: 3.1378e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6648e-05 - val_loss: 2.9365e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6800e-05 - val_loss: 2.9753e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6803e-05 - val_loss: 2.9053e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6309e-05 - val_loss: 2.7207e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7174e-05 - val_loss: 3.0335e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.8648e-05 - val_loss: 3.0022e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6067e-05 - val_loss: 2.8486e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4864e-05 - val_loss: 2.7353e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6641e-05 - val_loss: 3.0495e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6170e-05 - val_loss: 3.6488e-04\n",
            "Epoch 17/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4481e-05 - val_loss: 3.1738e-04\n",
            "Epoch 18/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4868e-05 - val_loss: 3.9511e-04\n",
            "Epoch 19/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5623e-05 - val_loss: 3.2844e-04\n",
            "Epoch 20/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5748e-05 - val_loss: 3.5039e-04\n",
            "Epoch 21/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4461e-05 - val_loss: 3.3886e-04\n",
            "Epoch 22/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4710e-05 - val_loss: 2.9700e-04\n",
            "Epoch 23/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4132e-05 - val_loss: 3.3706e-04\n",
            "Epoch 24/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5641e-05 - val_loss: 3.6712e-04\n",
            "Epoch 25/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5795e-05 - val_loss: 5.8014e-04\n",
            "training:  svm_cv  df:  41\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/153 [>.............................] - ETA: 1s - loss: 3.4226e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6759e-05 - val_loss: 4.0256e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6339e-05 - val_loss: 4.2860e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3702e-05 - val_loss: 7.2045e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3367e-05 - val_loss: 5.6248e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5647e-05 - val_loss: 3.8239e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5227e-05 - val_loss: 5.7168e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7337e-05 - val_loss: 6.5718e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.7389e-05 - val_loss: 9.7722e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3909e-05 - val_loss: 4.9313e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6831e-05 - val_loss: 4.4661e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4801e-05 - val_loss: 3.9987e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4823e-05 - val_loss: 3.3938e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3504e-05 - val_loss: 4.0875e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3495e-05 - val_loss: 6.5255e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5959e-05 - val_loss: 8.0886e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5379e-05 - val_loss: 5.9003e-04\n",
            "Epoch 17/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3830e-05 - val_loss: 4.6239e-04\n",
            "Epoch 18/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6416e-05 - val_loss: 9.0446e-04\n",
            "Epoch 19/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5352e-05 - val_loss: 0.0013\n",
            "Epoch 20/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3932e-05 - val_loss: 9.4701e-04\n",
            "Epoch 21/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.4781e-05 - val_loss: 0.0011\n",
            "Epoch 22/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5747e-05 - val_loss: 0.0011\n",
            "Epoch 23/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5151e-05 - val_loss: 0.0022\n",
            "Epoch 24/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5473e-05 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5210e-05 - val_loss: 0.0019\n",
            "Epoch 26/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.3938e-05 - val_loss: 0.0025\n",
            "Epoch 27/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.6217e-05 - val_loss: 0.0022\n",
            "training:  svm_cv  df:  42\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 9.7249e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 7ms/step - loss: 4.7775e-05 - val_loss: 6.1509e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.6374e-05 - val_loss: 4.9239e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.9169e-05 - val_loss: 4.6894e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 3.6016e-05 - val_loss: 5.2497e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4883e-05 - val_loss: 6.6493e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4668e-05 - val_loss: 9.7695e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4503e-05 - val_loss: 0.0018\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.6509e-05 - val_loss: 5.5352e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4130e-05 - val_loss: 9.1971e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3087e-05 - val_loss: 5.1814e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5197e-05 - val_loss: 5.5057e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4971e-05 - val_loss: 3.9894e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3544e-05 - val_loss: 5.0619e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4872e-05 - val_loss: 6.6495e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.4872e-05 - val_loss: 4.8787e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5313e-05 - val_loss: 0.0010\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3163e-05 - val_loss: 0.0011\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.2537e-05 - val_loss: 7.6610e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3356e-05 - val_loss: 0.0013\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.2009e-05 - val_loss: 0.0018\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3916e-05 - val_loss: 8.7037e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.3760e-05 - val_loss: 0.0012\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.1908e-05 - val_loss: 0.0013\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.5459e-05 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.2064e-05 - val_loss: 0.0010\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.2578e-05 - val_loss: 7.5676e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 3.1408e-05 - val_loss: 7.6622e-04\n",
            "training:  svm_cv  df:  43\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/64 [===>..........................] - ETA: 0s - loss: 9.3153e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 8ms/step - loss: 6.2780e-04 - val_loss: 6.5960e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.9777e-04 - val_loss: 7.0406e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.6087e-04 - val_loss: 7.3152e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.4755e-04 - val_loss: 9.0773e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.3830e-04 - val_loss: 7.4183e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.4017e-04 - val_loss: 7.4057e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.4217e-04 - val_loss: 7.0071e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.4163e-04 - val_loss: 7.9513e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.1660e-04 - val_loss: 7.6284e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.2467e-04 - val_loss: 7.2598e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.2642e-04 - val_loss: 7.8178e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 3.2522e-04 - val_loss: 7.6306e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1662e-04 - val_loss: 7.7072e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1371e-04 - val_loss: 7.8945e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.2393e-04 - val_loss: 7.7705e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1229e-04 - val_loss: 6.8682e-04\n",
            "training:  svm_cv  df:  44\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 1.5010e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 1.5036e-04 - val_loss: 1.6627e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3991e-04 - val_loss: 1.8520e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4264e-04 - val_loss: 1.9524e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4503e-04 - val_loss: 1.7079e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4256e-04 - val_loss: 1.7436e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4233e-04 - val_loss: 1.9284e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4134e-04 - val_loss: 1.6745e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3832e-04 - val_loss: 2.2800e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4174e-04 - val_loss: 1.8932e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4277e-04 - val_loss: 1.7270e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3629e-04 - val_loss: 1.8167e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4473e-04 - val_loss: 1.9312e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4137e-04 - val_loss: 1.6601e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3936e-04 - val_loss: 1.7916e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4193e-04 - val_loss: 1.9598e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3935e-04 - val_loss: 1.9140e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4693e-04 - val_loss: 2.1059e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4491e-04 - val_loss: 1.7423e-04\n",
            "Epoch 19/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4050e-04 - val_loss: 1.7969e-04\n",
            "Epoch 20/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4028e-04 - val_loss: 1.8643e-04\n",
            "Epoch 21/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4023e-04 - val_loss: 1.9107e-04\n",
            "Epoch 22/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4072e-04 - val_loss: 2.0155e-04\n",
            "Epoch 23/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4140e-04 - val_loss: 1.7560e-04\n",
            "Epoch 24/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4084e-04 - val_loss: 1.9531e-04\n",
            "Epoch 25/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.3885e-04 - val_loss: 2.1126e-04\n",
            "Epoch 26/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4203e-04 - val_loss: 1.9711e-04\n",
            "Epoch 27/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4760e-04 - val_loss: 1.9476e-04\n",
            "Epoch 28/200\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 1.4115e-04 - val_loss: 1.9423e-04\n",
            "training:  svm_cv  df:  45\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  9/174 [>.............................] - ETA: 1s - loss: 2.7801e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2207e-04 - val_loss: 1.8592e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1165e-04 - val_loss: 1.8187e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9276e-04 - val_loss: 1.8516e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9250e-04 - val_loss: 1.8297e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 2.0111e-04 - val_loss: 1.8259e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8549e-04 - val_loss: 1.8086e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8834e-04 - val_loss: 1.8929e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9552e-04 - val_loss: 1.7760e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9346e-04 - val_loss: 1.7877e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9763e-04 - val_loss: 1.7966e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9399e-04 - val_loss: 1.8895e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9754e-04 - val_loss: 1.8394e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9206e-04 - val_loss: 1.8728e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9583e-04 - val_loss: 1.9502e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9352e-04 - val_loss: 1.8083e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9391e-04 - val_loss: 1.8334e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 7ms/step - loss: 1.9360e-04 - val_loss: 1.8717e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8240e-04 - val_loss: 2.5466e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8838e-04 - val_loss: 1.8382e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9124e-04 - val_loss: 1.8898e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9439e-04 - val_loss: 1.8177e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8904e-04 - val_loss: 1.9314e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9178e-04 - val_loss: 2.0852e-04\n",
            "training:  svm_cv  df:  46\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.7613e-05 - val_loss: 1.0578e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.3840e-05 - val_loss: 1.0739e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0614e-05 - val_loss: 1.0035e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1185e-05 - val_loss: 1.1499e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1750e-05 - val_loss: 1.0885e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1680e-05 - val_loss: 9.9742e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0799e-05 - val_loss: 1.0217e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0457e-05 - val_loss: 1.0133e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1862e-05 - val_loss: 1.0214e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0743e-05 - val_loss: 1.0254e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8283e-05 - val_loss: 1.0469e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8490e-05 - val_loss: 9.8008e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0624e-05 - val_loss: 1.0263e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9574e-05 - val_loss: 9.8894e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9168e-05 - val_loss: 1.0026e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1310e-05 - val_loss: 1.0757e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1460e-05 - val_loss: 1.7927e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8376e-05 - val_loss: 1.0416e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.0125e-05 - val_loss: 1.0002e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2733e-05 - val_loss: 1.3562e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.8537e-05 - val_loss: 1.0282e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2544e-05 - val_loss: 9.7607e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0537e-05 - val_loss: 1.3267e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7253e-05 - val_loss: 1.1215e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8853e-05 - val_loss: 1.0805e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8956e-05 - val_loss: 1.0650e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8216e-05 - val_loss: 1.1210e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.2788e-05 - val_loss: 1.0190e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.1401e-05 - val_loss: 1.0567e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 9.0748e-05 - val_loss: 1.0209e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9224e-05 - val_loss: 1.0712e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8498e-05 - val_loss: 1.1266e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1235e-05 - val_loss: 1.1514e-04\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.6410e-05 - val_loss: 1.0621e-04\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.7860e-05 - val_loss: 1.0223e-04\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.8840e-05 - val_loss: 1.1419e-04\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 7ms/step - loss: 8.9069e-05 - val_loss: 9.8449e-05\n",
            "training:  svm_cv  df:  47\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 2.0811e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 7ms/step - loss: 1.6319e-04 - val_loss: 2.6641e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4462e-04 - val_loss: 1.9173e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3951e-04 - val_loss: 2.1275e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.4318e-04 - val_loss: 2.6304e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3185e-04 - val_loss: 3.7545e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3242e-04 - val_loss: 1.8147e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3220e-04 - val_loss: 1.5836e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3505e-04 - val_loss: 1.8052e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3584e-04 - val_loss: 1.9387e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2916e-04 - val_loss: 1.9779e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3576e-04 - val_loss: 1.7633e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3325e-04 - val_loss: 3.9541e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2910e-04 - val_loss: 2.9100e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3362e-04 - val_loss: 2.1160e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2855e-04 - val_loss: 2.1338e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3502e-04 - val_loss: 2.4242e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3301e-04 - val_loss: 2.1547e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3294e-04 - val_loss: 1.9501e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2904e-04 - val_loss: 2.0599e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2851e-04 - val_loss: 2.2112e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3062e-04 - val_loss: 2.3598e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2886e-04 - val_loss: 3.1675e-04\n",
            "training:  svm_cv  df:  48\n",
            "Training model: svm_cv  features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2857e-04 - val_loss: 9.7677e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2673e-04 - val_loss: 1.0124e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2401e-04 - val_loss: 8.1596e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2396e-04 - val_loss: 8.5598e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2088e-04 - val_loss: 7.6638e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2308e-04 - val_loss: 8.2103e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2064e-04 - val_loss: 9.2869e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2211e-04 - val_loss: 8.7688e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2184e-04 - val_loss: 8.7451e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2405e-04 - val_loss: 8.8110e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2791e-04 - val_loss: 7.9655e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2127e-04 - val_loss: 9.1162e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2148e-04 - val_loss: 7.3382e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2174e-04 - val_loss: 9.3238e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2171e-04 - val_loss: 1.1481e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2386e-04 - val_loss: 7.4965e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2756e-04 - val_loss: 8.0751e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1700e-04 - val_loss: 9.0364e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1453e-04 - val_loss: 7.8635e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1916e-04 - val_loss: 9.0488e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2043e-04 - val_loss: 8.5248e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1984e-04 - val_loss: 9.2795e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2003e-04 - val_loss: 8.4418e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2514e-04 - val_loss: 9.9586e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2011e-04 - val_loss: 9.2654e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2188e-04 - val_loss: 1.0467e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.2086e-04 - val_loss: 8.6848e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.1876e-04 - val_loss: 8.3329e-05\n",
            "training:  svm_cv  df:  49\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 7.4109e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 1.0157e-04 - val_loss: 1.1723e-04\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.6110e-05 - val_loss: 1.1552e-04\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.6531e-05 - val_loss: 1.1155e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.4014e-05 - val_loss: 9.7776e-05\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.5579e-05 - val_loss: 9.7838e-05\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.3026e-05 - val_loss: 9.5288e-05\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.1848e-05 - val_loss: 9.2037e-05\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2104e-05 - val_loss: 9.7056e-05\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.7125e-05 - val_loss: 1.1060e-04\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.3818e-05 - val_loss: 9.3941e-05\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.1596e-05 - val_loss: 9.6188e-05\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.8825e-05 - val_loss: 9.2868e-05\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.0801e-05 - val_loss: 9.2600e-05\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1817e-05 - val_loss: 9.2221e-05\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.2638e-05 - val_loss: 1.0016e-04\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1924e-05 - val_loss: 9.5266e-05\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 8.7846e-05 - val_loss: 1.0667e-04\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 9.1330e-05 - val_loss: 9.5447e-05\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.3162e-05 - val_loss: 9.5997e-05\n",
            "Epoch 20/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.1874e-05 - val_loss: 9.4273e-05\n",
            "Epoch 21/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.2431e-05 - val_loss: 1.0803e-04\n",
            "Epoch 22/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 9.5726e-05 - val_loss: 1.0758e-04\n",
            "training:  svm_cv  df:  50\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 8/13 [=================>............] - ETA: 0s - loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0027\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.9238e-04 - val_loss: 0.0017\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.2214e-04 - val_loss: 0.0018\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "training:  svm_cv  df:  51\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  8/106 [=>............................] - ETA: 0s - loss: 3.7313e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.9226e-04 - val_loss: 6.4828e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.5178e-04 - val_loss: 6.5760e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3382e-04 - val_loss: 6.7732e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3669e-04 - val_loss: 6.5781e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3124e-04 - val_loss: 7.1008e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2764e-04 - val_loss: 6.4831e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.4298e-04 - val_loss: 6.9832e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3560e-04 - val_loss: 6.5022e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3041e-04 - val_loss: 6.5879e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3251e-04 - val_loss: 6.5848e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3565e-04 - val_loss: 6.7063e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2721e-04 - val_loss: 6.6005e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3011e-04 - val_loss: 6.8537e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.3038e-04 - val_loss: 6.5171e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2673e-04 - val_loss: 6.7516e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2875e-04 - val_loss: 6.7267e-04\n",
            "training:  svm_cv  df:  52\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 2s - loss: 5.8352e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 4.5355e-05 - val_loss: 1.6399e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.6268e-05 - val_loss: 1.7001e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.4381e-05 - val_loss: 1.6671e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1912e-05 - val_loss: 1.6383e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2801e-05 - val_loss: 1.6426e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1532e-05 - val_loss: 1.6593e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 7ms/step - loss: 2.0753e-05 - val_loss: 1.6523e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.1696e-05 - val_loss: 1.7046e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2134e-05 - val_loss: 1.7406e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9970e-05 - val_loss: 1.8091e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9632e-05 - val_loss: 1.9141e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0158e-05 - val_loss: 1.8365e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 2.0528e-05 - val_loss: 1.9228e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9718e-05 - val_loss: 2.0303e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9029e-05 - val_loss: 2.1060e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9438e-05 - val_loss: 1.9632e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8368e-05 - val_loss: 2.0118e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.9291e-05 - val_loss: 2.0513e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8873e-05 - val_loss: 2.2265e-04\n",
            "training:  svm_cv  df:  53\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            " 9/79 [==>...........................] - ETA: 0s - loss: 1.3883e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 1.1455e-04 - val_loss: 0.0014\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 1.0609e-04 - val_loss: 9.4616e-04\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.7911e-05 - val_loss: 0.0012\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.9969e-05 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 1.0080e-04 - val_loss: 0.0011\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.8971e-05 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0872e-05 - val_loss: 0.0016\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.9187e-05 - val_loss: 0.0018\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.6828e-05 - val_loss: 0.0015\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.6126e-05 - val_loss: 0.0018\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4472e-05 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.3122e-05 - val_loss: 0.0013\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.6466e-05 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.5160e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.8633e-05 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.7105e-05 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 9.0671e-05 - val_loss: 0.0016\n",
            "training:  svm_cv  df:  54\n",
            "Training model: svm_cv  features: 2\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 7.9349e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 2s 8ms/step - loss: 5.6497e-05 - val_loss: 1.2155e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.2070e-05 - val_loss: 2.5403e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.2058e-05 - val_loss: 1.9916e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.2410e-05 - val_loss: 4.0715e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9959e-05 - val_loss: 1.9093e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.0109e-05 - val_loss: 2.3352e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9552e-05 - val_loss: 1.2838e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9731e-05 - val_loss: 1.3759e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9945e-05 - val_loss: 1.4937e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9957e-05 - val_loss: 1.8709e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 4.9292e-05 - val_loss: 1.8266e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.7785e-05 - val_loss: 1.6738e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 5.2279e-05 - val_loss: 1.4988e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.1359e-05 - val_loss: 1.6014e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.0303e-05 - val_loss: 2.6804e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.9101e-05 - val_loss: 1.4408e-04\n",
            "build model: svm_cv_vwap  features: 4\n",
            "training:  svm_cv_vwap\n",
            "svm_cv_vwap  should train on stocks\n",
            "training dfs: 55\n",
            "training:  svm_cv_vwap  df:  0\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 6s 13ms/step - loss: 0.0108 - val_loss: 0.3666\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.2707\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.1356\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.1307\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.2105e-04 - val_loss: 0.1469\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.1336e-04 - val_loss: 0.1343\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.8979e-04 - val_loss: 0.1223\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.9498e-04 - val_loss: 0.1325\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.8879e-04 - val_loss: 0.1185\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.0789e-04 - val_loss: 0.1252\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.0268e-04 - val_loss: 0.1066\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.3038e-04 - val_loss: 0.1000\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.1337e-04 - val_loss: 0.1030\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 2.0820e-04 - val_loss: 0.0976\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.8428e-04 - val_loss: 0.0956\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.5747e-04 - val_loss: 0.0942\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.4182e-04 - val_loss: 0.0962\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.2623e-04 - val_loss: 0.1027\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.3362e-04 - val_loss: 0.1031\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.1605e-04 - val_loss: 0.0974\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0621e-04 - val_loss: 0.0994\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.2807e-04 - val_loss: 0.0914\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0456e-04 - val_loss: 0.1016\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0845e-04 - val_loss: 0.0966\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0148e-04 - val_loss: 0.1004\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.2656e-05 - val_loss: 0.1066\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 9.3534e-05 - val_loss: 0.1035\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.9538e-05 - val_loss: 0.1027\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.0449e-05 - val_loss: 0.0988\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 1.0021e-04 - val_loss: 0.1009\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.2247e-05 - val_loss: 0.1068\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.6893e-05 - val_loss: 0.1029\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 8.5306e-05 - val_loss: 0.0973\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 8.3734e-05 - val_loss: 0.1017\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.7738e-05 - val_loss: 0.1032\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 8.5209e-05 - val_loss: 0.1013\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.7821e-05 - val_loss: 0.0882\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.5535e-05 - val_loss: 0.0896\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.6945e-05 - val_loss: 0.0813\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.6809e-05 - val_loss: 0.0805\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.9372e-05 - val_loss: 0.0912\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.9924e-05 - val_loss: 0.0943\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.4562e-05 - val_loss: 0.0974\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.9237e-05 - val_loss: 0.0814\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.1026e-05 - val_loss: 0.0928\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 7.0556e-05 - val_loss: 0.0864\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.4570e-05 - val_loss: 0.0812\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.1535e-05 - val_loss: 0.0778\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.8255e-05 - val_loss: 0.0761\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 6.3518e-05 - val_loss: 0.0747\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.6158e-05 - val_loss: 0.0716\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.4547e-05 - val_loss: 0.0773\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.1795e-05 - val_loss: 0.0818\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 5.3841e-05 - val_loss: 0.0727\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.0970e-05 - val_loss: 0.0690\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.2164e-05 - val_loss: 0.0782\n",
            "Epoch 57/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.7532e-05 - val_loss: 0.0798\n",
            "Epoch 58/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.7747e-05 - val_loss: 0.0827\n",
            "Epoch 59/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.4696e-05 - val_loss: 0.0745\n",
            "Epoch 60/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6329e-05 - val_loss: 0.0755\n",
            "Epoch 61/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.3699e-05 - val_loss: 0.0641\n",
            "Epoch 62/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.6610e-05 - val_loss: 0.0721\n",
            "Epoch 63/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.9152e-05 - val_loss: 0.0745\n",
            "Epoch 64/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 4.8540e-05 - val_loss: 0.0809\n",
            "Epoch 65/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.9093e-05 - val_loss: 0.0799\n",
            "Epoch 66/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 5.4516e-05 - val_loss: 0.0828\n",
            "Epoch 67/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 3.8111e-05 - val_loss: 0.0771\n",
            "Epoch 68/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.7248e-05 - val_loss: 0.0729\n",
            "Epoch 69/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.2953e-05 - val_loss: 0.0821\n",
            "Epoch 70/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.4546e-05 - val_loss: 0.0794\n",
            "Epoch 71/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.2402e-05 - val_loss: 0.0806\n",
            "Epoch 72/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.9708e-05 - val_loss: 0.0878\n",
            "Epoch 73/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.2126e-05 - val_loss: 0.0899\n",
            "Epoch 74/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 4.1597e-05 - val_loss: 0.0805\n",
            "Epoch 75/200\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 4.5422e-05 - val_loss: 0.0844\n",
            "Epoch 76/200\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 4.8100e-05 - val_loss: 0.0817\n",
            "training:  svm_cv_vwap  df:  1\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/80 [==>...........................] - ETA: 0s - loss: 6.5034e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 8ms/step - loss: 1.4574e-04 - val_loss: 0.1354\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.6251e-05 - val_loss: 0.1410\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 4.7942e-05 - val_loss: 0.1544\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.8264e-05 - val_loss: 0.1527\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 3.0327e-05 - val_loss: 0.1523\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.1123e-05 - val_loss: 0.1730\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.6310e-05 - val_loss: 0.1717\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.3603e-05 - val_loss: 0.1661\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6144e-05 - val_loss: 0.1653\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6478e-05 - val_loss: 0.1803\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5530e-05 - val_loss: 0.1793\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5558e-05 - val_loss: 0.1905\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.3161e-05 - val_loss: 0.1797\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.6955e-05 - val_loss: 0.1785\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 2.6068e-05 - val_loss: 0.1785\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.5124e-05 - val_loss: 0.1909\n",
            "training:  svm_cv_vwap  df:  2\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/266 [..............................] - ETA: 2s - loss: 3.2256e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266/266 [==============================] - 2s 8ms/step - loss: 7.3190e-06 - val_loss: 0.1475\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.3882e-06 - val_loss: 0.1403\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.9793e-06 - val_loss: 0.1420\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.8582e-06 - val_loss: 0.1444\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.7677e-06 - val_loss: 0.1355\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.4324e-06 - val_loss: 0.1334\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.2960e-06 - val_loss: 0.1260\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.6077e-06 - val_loss: 0.1311\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.5002e-06 - val_loss: 0.1217\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.8882e-06 - val_loss: 0.1326\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.8741e-06 - val_loss: 0.1272\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.5795e-06 - val_loss: 0.1235\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.3824e-06 - val_loss: 0.1250\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.5458e-06 - val_loss: 0.1233\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.6763e-06 - val_loss: 0.1264\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.9248e-06 - val_loss: 0.1291\n",
            "Epoch 17/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.9781e-06 - val_loss: 0.1193\n",
            "Epoch 18/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.3083e-06 - val_loss: 0.1214\n",
            "Epoch 19/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.7260e-06 - val_loss: 0.1371\n",
            "Epoch 20/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.4472e-06 - val_loss: 0.1317\n",
            "Epoch 21/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 2.9262e-06 - val_loss: 0.1306\n",
            "Epoch 22/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.4167e-06 - val_loss: 0.1279\n",
            "Epoch 23/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.5354e-06 - val_loss: 0.1276\n",
            "Epoch 24/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 4.5224e-06 - val_loss: 0.1298\n",
            "Epoch 25/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.5453e-06 - val_loss: 0.1293\n",
            "Epoch 26/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.2787e-06 - val_loss: 0.1424\n",
            "Epoch 27/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 2.9841e-06 - val_loss: 0.1342\n",
            "Epoch 28/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.1128e-06 - val_loss: 0.1338\n",
            "Epoch 29/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.3422e-06 - val_loss: 0.1378\n",
            "Epoch 30/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.5874e-06 - val_loss: 0.1429\n",
            "Epoch 31/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 3.2832e-06 - val_loss: 0.1413\n",
            "Epoch 32/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 2.7461e-06 - val_loss: 0.1372\n",
            "training:  svm_cv_vwap  df:  3\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1230e-04 - val_loss: 0.0265\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.0390e-04 - val_loss: 0.0240\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.6549e-05 - val_loss: 0.0231\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.2053e-05 - val_loss: 0.0187\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5123e-05 - val_loss: 0.0192\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7303e-05 - val_loss: 0.0178\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4356e-05 - val_loss: 0.0201\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6551e-05 - val_loss: 0.0175\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3672e-05 - val_loss: 0.0174\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8104e-05 - val_loss: 0.0170\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9841e-05 - val_loss: 0.0165\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1601e-05 - val_loss: 0.0168\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9973e-05 - val_loss: 0.0178\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3838e-05 - val_loss: 0.0166\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9644e-05 - val_loss: 0.0205\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5782e-05 - val_loss: 0.0184\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5453e-05 - val_loss: 0.0198\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3645e-05 - val_loss: 0.0155\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.2755e-05 - val_loss: 0.0142\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3640e-05 - val_loss: 0.0190\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7109e-05 - val_loss: 0.0140\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2543e-05 - val_loss: 0.0165\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9425e-05 - val_loss: 0.0163\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0154e-05 - val_loss: 0.0186\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8064e-05 - val_loss: 0.0147\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3466e-05 - val_loss: 0.0147\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1525e-05 - val_loss: 0.0183\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8283e-05 - val_loss: 0.0153\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5665e-05 - val_loss: 0.0150\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9220e-05 - val_loss: 0.0148\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9781e-05 - val_loss: 0.0169\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6985e-05 - val_loss: 0.0159\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4687e-05 - val_loss: 0.0168\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1006e-05 - val_loss: 0.0177\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6081e-05 - val_loss: 0.0168\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9788e-05 - val_loss: 0.0196\n",
            "training:  svm_cv_vwap  df:  4\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 8.1609e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 2.3220e-04 - val_loss: 1.0467e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.3055e-04 - val_loss: 6.5112e-05\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2941e-04 - val_loss: 6.4518e-05\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2153e-04 - val_loss: 7.3600e-05\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1889e-04 - val_loss: 7.0764e-05\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1550e-04 - val_loss: 7.0167e-05\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1387e-04 - val_loss: 6.8505e-05\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1638e-04 - val_loss: 7.4481e-05\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.1156e-04 - val_loss: 8.2426e-05\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0940e-04 - val_loss: 8.1847e-05\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.1550e-04 - val_loss: 9.2161e-05\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0575e-04 - val_loss: 6.7212e-05\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0893e-04 - val_loss: 7.6692e-05\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0097e-04 - val_loss: 7.0617e-05\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.2207e-04 - val_loss: 8.4104e-05\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 1.0551e-04 - val_loss: 7.5686e-05\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0921e-04 - val_loss: 9.4056e-05\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.0641e-04 - val_loss: 7.0352e-05\n",
            "training:  svm_cv_vwap  df:  5\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.2728e-05 - val_loss: 0.0044\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.2546e-05 - val_loss: 0.0045\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0310e-05 - val_loss: 0.0039\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.1428e-05 - val_loss: 0.0030\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9156e-05 - val_loss: 0.0024\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7206e-05 - val_loss: 0.0027\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7412e-05 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8181e-05 - val_loss: 0.0019\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6351e-05 - val_loss: 0.0022\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6794e-05 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5810e-05 - val_loss: 0.0014\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5777e-05 - val_loss: 0.0014\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4457e-05 - val_loss: 0.0012\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4580e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3982e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4401e-05 - val_loss: 0.0014\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3607e-05 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3973e-05 - val_loss: 0.0027\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3142e-05 - val_loss: 0.0028\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3608e-05 - val_loss: 0.0026\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3597e-05 - val_loss: 0.0028\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3395e-05 - val_loss: 0.0035\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4233e-05 - val_loss: 0.0030\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3758e-05 - val_loss: 0.0036\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3522e-05 - val_loss: 0.0038\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2123e-05 - val_loss: 0.0056\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2150e-05 - val_loss: 0.0063\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2746e-05 - val_loss: 0.0081\n",
            "training:  svm_cv_vwap  df:  6\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/315 [..............................] - ETA: 3s - loss: 0.0127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 2s 8ms/step - loss: 3.4939e-04 - val_loss: 1.3681e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.5325e-04 - val_loss: 1.3396e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.4314e-04 - val_loss: 1.0967e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3106e-04 - val_loss: 1.3666e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2627e-04 - val_loss: 1.1607e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3025e-04 - val_loss: 9.8595e-05\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.2666e-04 - val_loss: 1.0769e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2402e-04 - val_loss: 9.7742e-05\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.3003e-04 - val_loss: 1.8065e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1951e-04 - val_loss: 1.1556e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2166e-04 - val_loss: 9.6227e-05\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1477e-04 - val_loss: 1.3131e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1916e-04 - val_loss: 1.0119e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2407e-04 - val_loss: 9.3447e-05\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2006e-04 - val_loss: 1.1700e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.2362e-04 - val_loss: 1.0399e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1473e-04 - val_loss: 1.1310e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1473e-04 - val_loss: 1.7091e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1626e-04 - val_loss: 1.7085e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1923e-04 - val_loss: 9.7840e-05\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1847e-04 - val_loss: 1.6018e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1875e-04 - val_loss: 1.2683e-04\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.0987e-04 - val_loss: 1.6438e-04\n",
            "Epoch 24/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1476e-04 - val_loss: 1.0150e-04\n",
            "Epoch 25/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1280e-04 - val_loss: 9.3997e-05\n",
            "Epoch 26/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1344e-04 - val_loss: 1.1006e-04\n",
            "Epoch 27/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.0978e-04 - val_loss: 8.9972e-05\n",
            "Epoch 28/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1252e-04 - val_loss: 9.5209e-05\n",
            "Epoch 29/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1206e-04 - val_loss: 1.4874e-04\n",
            "Epoch 30/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1708e-04 - val_loss: 1.7665e-04\n",
            "Epoch 31/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1218e-04 - val_loss: 1.0079e-04\n",
            "Epoch 32/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.0956e-04 - val_loss: 1.0630e-04\n",
            "Epoch 33/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1135e-04 - val_loss: 1.0762e-04\n",
            "Epoch 34/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 1.1027e-04 - val_loss: 1.0410e-04\n",
            "Epoch 35/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1238e-04 - val_loss: 1.1675e-04\n",
            "Epoch 36/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1186e-04 - val_loss: 9.8322e-05\n",
            "Epoch 37/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1977e-04 - val_loss: 9.6907e-05\n",
            "Epoch 38/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1072e-04 - val_loss: 1.2975e-04\n",
            "Epoch 39/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1031e-04 - val_loss: 1.3310e-04\n",
            "Epoch 40/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1030e-04 - val_loss: 9.2195e-05\n",
            "Epoch 41/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1068e-04 - val_loss: 1.0701e-04\n",
            "Epoch 42/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.2306e-04 - val_loss: 1.1023e-04\n",
            "training:  svm_cv_vwap  df:  7\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 2s - loss: 7.3324e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 8ms/step - loss: 4.7019e-05 - val_loss: 2.4608e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.4086e-05 - val_loss: 2.8768e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.1638e-05 - val_loss: 3.0472e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.7588e-05 - val_loss: 2.9740e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.8250e-05 - val_loss: 3.6731e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.9101e-05 - val_loss: 3.4691e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 4.1904e-05 - val_loss: 3.6540e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.5652e-05 - val_loss: 3.8004e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.5579e-05 - val_loss: 4.3480e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.8177e-05 - val_loss: 5.1247e-04\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.8030e-05 - val_loss: 5.0078e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.5623e-05 - val_loss: 5.2395e-04\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.6872e-05 - val_loss: 6.5584e-04\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.5720e-05 - val_loss: 6.7713e-04\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.6041e-05 - val_loss: 7.4818e-04\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.6828e-05 - val_loss: 7.1666e-04\n",
            "training:  svm_cv_vwap  df:  8\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/68 [==>...........................] - ETA: 0s - loss: 1.1912e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3738e-04 - val_loss: 0.0022\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.4870e-04 - val_loss: 0.0029\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.3411e-04 - val_loss: 0.0039\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1194e-04 - val_loss: 0.0027\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.1675e-04 - val_loss: 0.0036\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0650e-04 - val_loss: 0.0045\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 9.9800e-05 - val_loss: 0.0046\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0181e-04 - val_loss: 0.0055\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 9.8441e-05 - val_loss: 0.0043\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0347e-04 - val_loss: 0.0029\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0402e-04 - val_loss: 0.0030\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0134e-04 - val_loss: 0.0034\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0364e-04 - val_loss: 0.0034\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0117e-04 - val_loss: 0.0039\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 1.0137e-04 - val_loss: 0.0044\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 9.6664e-05 - val_loss: 0.0054\n",
            "training:  svm_cv_vwap  df:  9\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/162 [>.............................] - ETA: 1s - loss: 3.7379e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 8ms/step - loss: 4.8630e-05 - val_loss: 0.0101\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.6626e-05 - val_loss: 0.0104\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.2597e-05 - val_loss: 0.0104\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.2973e-05 - val_loss: 0.0105\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.2046e-05 - val_loss: 0.0107\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1151e-05 - val_loss: 0.0111\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0676e-05 - val_loss: 0.0108\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0480e-05 - val_loss: 0.0111\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0560e-05 - val_loss: 0.0106\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0187e-05 - val_loss: 0.0113\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0273e-05 - val_loss: 0.0117\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.0734e-05 - val_loss: 0.0131\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.0430e-06 - val_loss: 0.0123\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.2463e-06 - val_loss: 0.0132\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.2992e-06 - val_loss: 0.0140\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.2098e-06 - val_loss: 0.0134\n",
            "training:  svm_cv_vwap  df:  10\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3213e-05 - val_loss: 6.3606e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.7420e-05 - val_loss: 8.6629e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9008e-05 - val_loss: 6.2739e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6181e-05 - val_loss: 5.5224e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6824e-05 - val_loss: 8.4344e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.6781e-05 - val_loss: 6.3425e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3685e-05 - val_loss: 7.4636e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4582e-05 - val_loss: 6.6942e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8076e-05 - val_loss: 6.7434e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3861e-05 - val_loss: 4.6253e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4067e-05 - val_loss: 7.5839e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4160e-05 - val_loss: 6.3239e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.5120e-05 - val_loss: 5.6883e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3571e-05 - val_loss: 5.6771e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4211e-05 - val_loss: 6.6578e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1326e-05 - val_loss: 6.6725e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4110e-05 - val_loss: 5.0334e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4964e-05 - val_loss: 6.9714e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2869e-05 - val_loss: 5.0507e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.0576e-05 - val_loss: 4.9973e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2811e-05 - val_loss: 4.9684e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.0235e-05 - val_loss: 4.1729e-04\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1261e-05 - val_loss: 4.1741e-04\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2564e-05 - val_loss: 8.7639e-04\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.0646e-05 - val_loss: 7.2894e-04\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4145e-05 - val_loss: 6.1887e-04\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1627e-05 - val_loss: 7.0379e-04\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2796e-05 - val_loss: 3.9132e-04\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8648e-05 - val_loss: 3.9975e-04\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4383e-05 - val_loss: 4.2418e-04\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2359e-05 - val_loss: 8.2218e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1287e-05 - val_loss: 6.2529e-04\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1768e-05 - val_loss: 6.0522e-04\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8403e-05 - val_loss: 5.1028e-04\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.2714e-05 - val_loss: 6.3418e-04\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.9097e-05 - val_loss: 6.8104e-04\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8817e-05 - val_loss: 6.3785e-04\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.9204e-05 - val_loss: 7.2150e-04\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8122e-05 - val_loss: 7.0695e-04\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8830e-05 - val_loss: 8.7325e-04\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.7849e-05 - val_loss: 3.3140e-04\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.9124e-05 - val_loss: 3.9357e-04\n",
            "Epoch 43/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.0957e-05 - val_loss: 5.4806e-04\n",
            "Epoch 44/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.0891e-05 - val_loss: 8.1956e-04\n",
            "Epoch 45/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1200e-05 - val_loss: 5.4202e-04\n",
            "Epoch 46/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.9933e-05 - val_loss: 7.4513e-04\n",
            "Epoch 47/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.9800e-05 - val_loss: 6.1399e-04\n",
            "Epoch 48/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.9164e-05 - val_loss: 8.0616e-04\n",
            "Epoch 49/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3023e-05 - val_loss: 8.1246e-04\n",
            "Epoch 50/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8336e-05 - val_loss: 8.4921e-04\n",
            "Epoch 51/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 3.8253e-05 - val_loss: 7.5628e-04\n",
            "Epoch 52/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.7418e-05 - val_loss: 6.8149e-04\n",
            "Epoch 53/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.8629e-05 - val_loss: 4.1559e-04\n",
            "Epoch 54/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.6211e-05 - val_loss: 7.3772e-04\n",
            "Epoch 55/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.9613e-05 - val_loss: 6.4095e-04\n",
            "Epoch 56/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.1137e-05 - val_loss: 6.3525e-04\n",
            "training:  svm_cv_vwap  df:  11\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.9870e-05 - val_loss: 6.5906e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6129e-05 - val_loss: 7.7046e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5937e-05 - val_loss: 1.2908e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4322e-05 - val_loss: 8.4526e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4096e-05 - val_loss: 6.9876e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4322e-05 - val_loss: 1.3226e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4451e-05 - val_loss: 7.2227e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9064e-05 - val_loss: 1.2631e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3586e-05 - val_loss: 7.0781e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.1805e-05 - val_loss: 7.5990e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9339e-05 - val_loss: 8.8958e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.2606e-05 - val_loss: 1.5872e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.3039e-05 - val_loss: 7.7685e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 6.5912e-05 - val_loss: 7.6360e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.0873e-05 - val_loss: 1.0775e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.4127e-05 - val_loss: 6.6437e-05\n",
            "training:  svm_cv_vwap  df:  12\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/13 [=================>............] - ETA: 0s - loss: 9.5651e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.4201e-04 - val_loss: 0.0022\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.8802e-04 - val_loss: 0.0027\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.9146e-04 - val_loss: 0.0019\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 9.6008e-04 - val_loss: 0.0019\n",
            "training:  svm_cv_vwap  df:  13\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/132 [>.............................] - ETA: 0s - loss: 2.0342e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 9ms/step - loss: 4.4808e-05 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 2.1448e-05 - val_loss: 0.0019\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6972e-05 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.7585e-05 - val_loss: 0.0019\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4372e-05 - val_loss: 0.0019\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4243e-05 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3642e-05 - val_loss: 0.0019\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2254e-05 - val_loss: 0.0019\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2620e-05 - val_loss: 0.0019\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2612e-05 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3756e-05 - val_loss: 0.0019\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6249e-05 - val_loss: 0.0019\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5256e-05 - val_loss: 0.0018\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1715e-05 - val_loss: 0.0018\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1502e-05 - val_loss: 0.0018\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4117e-05 - val_loss: 0.0018\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.1740e-05 - val_loss: 0.0018\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.1521e-05 - val_loss: 0.0018\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1462e-05 - val_loss: 0.0018\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2444e-05 - val_loss: 0.0018\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0489e-05 - val_loss: 0.0018\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0171e-05 - val_loss: 0.0018\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1245e-05 - val_loss: 0.0017\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0125e-05 - val_loss: 0.0017\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0800e-05 - val_loss: 0.0017\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0939e-05 - val_loss: 0.0017\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1147e-05 - val_loss: 0.0017\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1923e-05 - val_loss: 0.0017\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0695e-05 - val_loss: 0.0017\n",
            "Epoch 30/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0162e-05 - val_loss: 0.0016\n",
            "Epoch 31/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2738e-05 - val_loss: 0.0016\n",
            "Epoch 32/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.6449e-06 - val_loss: 0.0016\n",
            "Epoch 33/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0240e-05 - val_loss: 0.0016\n",
            "Epoch 34/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0871e-05 - val_loss: 0.0016\n",
            "Epoch 35/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0108e-05 - val_loss: 0.0016\n",
            "Epoch 36/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1577e-05 - val_loss: 0.0016\n",
            "Epoch 37/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0079e-05 - val_loss: 0.0016\n",
            "Epoch 38/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3921e-05 - val_loss: 0.0016\n",
            "Epoch 39/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0552e-05 - val_loss: 0.0016\n",
            "Epoch 40/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1237e-05 - val_loss: 0.0016\n",
            "Epoch 41/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1223e-05 - val_loss: 0.0016\n",
            "Epoch 42/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.6671e-06 - val_loss: 0.0016\n",
            "Epoch 43/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.7877e-06 - val_loss: 0.0016\n",
            "Epoch 44/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.6647e-06 - val_loss: 0.0016\n",
            "Epoch 45/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 9.9617e-06 - val_loss: 0.0016\n",
            "Epoch 46/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.7324e-06 - val_loss: 0.0016\n",
            "Epoch 47/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.5825e-06 - val_loss: 0.0016\n",
            "Epoch 48/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.5996e-06 - val_loss: 0.0016\n",
            "Epoch 49/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0239e-05 - val_loss: 0.0016\n",
            "Epoch 50/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.9375e-06 - val_loss: 0.0016\n",
            "Epoch 51/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.8632e-06 - val_loss: 0.0016\n",
            "Epoch 52/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.9229e-06 - val_loss: 0.0016\n",
            "Epoch 53/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.3729e-06 - val_loss: 0.0016\n",
            "Epoch 54/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1811e-05 - val_loss: 0.0016\n",
            "Epoch 55/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.7466e-06 - val_loss: 0.0016\n",
            "Epoch 56/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.3788e-06 - val_loss: 0.0016\n",
            "Epoch 57/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0154e-05 - val_loss: 0.0015\n",
            "Epoch 58/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0162e-05 - val_loss: 0.0016\n",
            "Epoch 59/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0285e-05 - val_loss: 0.0016\n",
            "Epoch 60/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0012e-05 - val_loss: 0.0015\n",
            "Epoch 61/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1072e-05 - val_loss: 0.0015\n",
            "Epoch 62/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0625e-05 - val_loss: 0.0015\n",
            "Epoch 63/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.5192e-06 - val_loss: 0.0016\n",
            "Epoch 64/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0128e-05 - val_loss: 0.0015\n",
            "Epoch 65/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.7702e-06 - val_loss: 0.0015\n",
            "Epoch 66/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1856e-05 - val_loss: 0.0015\n",
            "Epoch 67/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.7122e-06 - val_loss: 0.0015\n",
            "Epoch 68/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.5297e-06 - val_loss: 0.0015\n",
            "Epoch 69/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.2039e-06 - val_loss: 0.0015\n",
            "Epoch 70/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.3212e-06 - val_loss: 0.0014\n",
            "Epoch 71/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.7157e-06 - val_loss: 0.0014\n",
            "Epoch 72/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.0388e-06 - val_loss: 0.0014\n",
            "Epoch 73/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.3916e-06 - val_loss: 0.0014\n",
            "Epoch 74/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 7.9825e-06 - val_loss: 0.0014\n",
            "Epoch 75/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.6080e-06 - val_loss: 0.0013\n",
            "Epoch 76/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 8.9606e-06 - val_loss: 0.0013\n",
            "Epoch 77/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.8651e-06 - val_loss: 0.0013\n",
            "Epoch 78/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.3732e-06 - val_loss: 0.0013\n",
            "Epoch 79/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.1008e-06 - val_loss: 0.0013\n",
            "Epoch 80/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.2113e-06 - val_loss: 0.0013\n",
            "Epoch 81/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.4325e-06 - val_loss: 0.0012\n",
            "Epoch 82/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.5759e-06 - val_loss: 0.0012\n",
            "Epoch 83/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.6334e-06 - val_loss: 0.0012\n",
            "Epoch 84/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 7.9187e-06 - val_loss: 0.0012\n",
            "Epoch 85/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.3956e-06 - val_loss: 0.0012\n",
            "Epoch 86/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.8277e-06 - val_loss: 0.0012\n",
            "Epoch 87/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 9.0778e-06 - val_loss: 0.0013\n",
            "Epoch 88/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.2949e-06 - val_loss: 0.0013\n",
            "Epoch 89/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 7.8902e-06 - val_loss: 0.0013\n",
            "Epoch 90/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.3065e-06 - val_loss: 0.0013\n",
            "Epoch 91/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.3323e-06 - val_loss: 0.0014\n",
            "Epoch 92/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 7.9844e-06 - val_loss: 0.0015\n",
            "Epoch 93/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.1432e-06 - val_loss: 0.0015\n",
            "Epoch 94/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.2464e-06 - val_loss: 0.0017\n",
            "Epoch 95/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.7712e-06 - val_loss: 0.0018\n",
            "Epoch 96/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.2891e-06 - val_loss: 0.0019\n",
            "Epoch 97/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.4684e-06 - val_loss: 0.0021\n",
            "Epoch 98/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 7.6907e-06 - val_loss: 0.0022\n",
            "Epoch 99/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.6237e-06 - val_loss: 0.0027\n",
            "Epoch 100/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 8.1856e-06 - val_loss: 0.0029\n",
            "training:  svm_cv_vwap  df:  14\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "15/26 [================>.............] - ETA: 0s - loss: 0.0017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 5.8347e-04\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.7369e-04 - val_loss: 3.7363e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2676e-04 - val_loss: 3.2214e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.1721e-04 - val_loss: 2.7540e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.1241e-04 - val_loss: 2.7091e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9935e-04 - val_loss: 2.6329e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2777e-04 - val_loss: 2.0661e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6103e-04 - val_loss: 2.5010e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6764e-04 - val_loss: 2.8513e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9054e-04 - val_loss: 4.2180e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.4568e-04 - val_loss: 3.6172e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9908e-04 - val_loss: 2.3327e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.7343e-04 - val_loss: 3.0068e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1831e-04 - val_loss: 3.8073e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8610e-04 - val_loss: 2.6381e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8927e-04 - val_loss: 3.0695e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.5659e-04 - val_loss: 2.3029e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.3896e-04 - val_loss: 2.1859e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.1839e-04 - val_loss: 2.3131e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.3631e-04 - val_loss: 2.4374e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.6762e-04 - val_loss: 2.4291e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8166e-04 - val_loss: 3.0731e-04\n",
            "training:  svm_cv_vwap  df:  15\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.1138e-05 - val_loss: 0.0051\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6938e-06 - val_loss: 0.0049\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.8985e-06 - val_loss: 0.0047\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.0039e-06 - val_loss: 0.0048\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9151e-06 - val_loss: 0.0047\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5659e-06 - val_loss: 0.0046\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.6298e-06 - val_loss: 0.0044\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.9746e-06 - val_loss: 0.0044\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5275e-06 - val_loss: 0.0046\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.4303e-06 - val_loss: 0.0044\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5956e-06 - val_loss: 0.0044\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3547e-06 - val_loss: 0.0044\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3471e-06 - val_loss: 0.0043\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.5493e-06 - val_loss: 0.0042\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.6113e-06 - val_loss: 0.0040\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9722e-06 - val_loss: 0.0038\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1983e-06 - val_loss: 0.0038\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.7544e-06 - val_loss: 0.0033\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6766e-06 - val_loss: 0.0032\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6431e-06 - val_loss: 0.0032\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.0118e-06 - val_loss: 0.0024\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9016e-06 - val_loss: 0.0029\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.4147e-06 - val_loss: 0.0023\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4140e-06 - val_loss: 0.0018\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6206e-06 - val_loss: 0.0019\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.8879e-06 - val_loss: 0.0015\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4733e-06 - val_loss: 0.0011\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5811e-06 - val_loss: 0.0011\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4419e-06 - val_loss: 0.0012\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6422e-06 - val_loss: 0.0013\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2446e-06 - val_loss: 0.0021\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3760e-06 - val_loss: 0.0028\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2560e-06 - val_loss: 0.0039\n",
            "Epoch 34/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7449e-06 - val_loss: 0.0064\n",
            "Epoch 35/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.7585e-06 - val_loss: 0.0090\n",
            "Epoch 36/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3038e-06 - val_loss: 0.0096\n",
            "Epoch 37/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3809e-06 - val_loss: 0.0115\n",
            "Epoch 38/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0946e-06 - val_loss: 0.0150\n",
            "Epoch 39/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2743e-06 - val_loss: 0.0176\n",
            "Epoch 40/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1565e-06 - val_loss: 0.0217\n",
            "Epoch 41/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0363e-06 - val_loss: 0.0216\n",
            "Epoch 42/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5706e-06 - val_loss: 0.0207\n",
            "training:  svm_cv_vwap  df:  16\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.4770e-05 - val_loss: 0.0153\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8550e-05 - val_loss: 0.0191\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6041e-05 - val_loss: 0.0158\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3801e-05 - val_loss: 0.0158\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4786e-05 - val_loss: 0.0188\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4076e-05 - val_loss: 0.0193\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3820e-05 - val_loss: 0.0206\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3145e-05 - val_loss: 0.0184\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3023e-05 - val_loss: 0.0197\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2632e-05 - val_loss: 0.0167\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3192e-05 - val_loss: 0.0190\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3594e-05 - val_loss: 0.0175\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3412e-05 - val_loss: 0.0167\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3606e-05 - val_loss: 0.0168\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2587e-05 - val_loss: 0.0183\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2079e-05 - val_loss: 0.0171\n",
            "training:  svm_cv_vwap  df:  17\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 7.6877e-06 - val_loss: 0.0198\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 5.0055e-06 - val_loss: 0.0208\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 5.1451e-06 - val_loss: 0.0222\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 4.4508e-06 - val_loss: 0.0239\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.6662e-06 - val_loss: 0.0265\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.5699e-06 - val_loss: 0.0273\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.2697e-06 - val_loss: 0.0270\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.4600e-06 - val_loss: 0.0281\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.1642e-06 - val_loss: 0.0298\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.2400e-06 - val_loss: 0.0294\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.1986e-06 - val_loss: 0.0299\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.1269e-06 - val_loss: 0.0313\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.4084e-06 - val_loss: 0.0321\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 4.1846e-06 - val_loss: 0.0354\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 3.8323e-06 - val_loss: 0.0363\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 2s 8ms/step - loss: 3.7902e-06 - val_loss: 0.0365\n",
            "training:  svm_cv_vwap  df:  18\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/174 [>.............................] - ETA: 1s - loss: 0.0056"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 5.4424e-04 - val_loss: 2.0083e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1876e-04 - val_loss: 2.1069e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1156e-04 - val_loss: 1.9560e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0196e-04 - val_loss: 1.9013e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0201e-04 - val_loss: 1.8540e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0806e-04 - val_loss: 1.8379e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.0384e-04 - val_loss: 2.3748e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9376e-04 - val_loss: 1.9820e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9928e-04 - val_loss: 2.0605e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8828e-04 - val_loss: 1.8509e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9500e-04 - val_loss: 1.8485e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9125e-04 - val_loss: 1.9253e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9321e-04 - val_loss: 1.9065e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8661e-04 - val_loss: 2.0450e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8752e-04 - val_loss: 1.8045e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9010e-04 - val_loss: 1.7784e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9298e-04 - val_loss: 1.9500e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8907e-04 - val_loss: 1.8633e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9717e-04 - val_loss: 1.9166e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9080e-04 - val_loss: 1.8088e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9092e-04 - val_loss: 1.8048e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8530e-04 - val_loss: 1.9553e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9168e-04 - val_loss: 1.9943e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7990e-04 - val_loss: 2.0058e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8889e-04 - val_loss: 1.9060e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8325e-04 - val_loss: 1.8319e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8990e-04 - val_loss: 1.9632e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8601e-04 - val_loss: 1.7579e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9408e-04 - val_loss: 1.9359e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8736e-04 - val_loss: 1.8549e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9395e-04 - val_loss: 1.8398e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8776e-04 - val_loss: 2.2348e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8647e-04 - val_loss: 1.8903e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8594e-04 - val_loss: 1.9622e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9399e-04 - val_loss: 2.0172e-04\n",
            "Epoch 36/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8210e-04 - val_loss: 2.1016e-04\n",
            "Epoch 37/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8681e-04 - val_loss: 1.8877e-04\n",
            "Epoch 38/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8906e-04 - val_loss: 1.7746e-04\n",
            "Epoch 39/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8722e-04 - val_loss: 1.7693e-04\n",
            "Epoch 40/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8087e-04 - val_loss: 2.0828e-04\n",
            "Epoch 41/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8465e-04 - val_loss: 1.8383e-04\n",
            "Epoch 42/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8946e-04 - val_loss: 1.7860e-04\n",
            "Epoch 43/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8733e-04 - val_loss: 1.8481e-04\n",
            "training:  svm_cv_vwap  df:  19\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/47 [====>.........................] - ETA: 0s - loss: 2.9130e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9030e-04 - val_loss: 1.6742e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9226e-04 - val_loss: 1.8474e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7229e-04 - val_loss: 1.8337e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8801e-04 - val_loss: 1.7472e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6949e-04 - val_loss: 1.7748e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7803e-04 - val_loss: 1.7275e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.0572e-04 - val_loss: 1.8221e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7697e-04 - val_loss: 1.9277e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7645e-04 - val_loss: 2.0274e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7281e-04 - val_loss: 2.0283e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7244e-04 - val_loss: 1.7111e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9357e-04 - val_loss: 1.7166e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9324e-04 - val_loss: 2.1427e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.8252e-04 - val_loss: 2.0407e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.6431e-04 - val_loss: 1.7674e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.8141e-04 - val_loss: 1.9776e-04\n",
            "training:  svm_cv_vwap  df:  20\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/151 [..............................] - ETA: 1s - loss: 0.0320"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 8ms/step - loss: 2.5872e-04 - val_loss: 0.0027\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 1.1495e-05 - val_loss: 0.0024\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 9.0409e-06 - val_loss: 0.0023\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 8.1118e-06 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.6921e-06 - val_loss: 0.0022\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 7.2574e-06 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.8065e-06 - val_loss: 0.0022\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.3532e-06 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 6.0460e-06 - val_loss: 0.0021\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.4427e-06 - val_loss: 0.0021\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.2019e-06 - val_loss: 0.0021\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.9605e-06 - val_loss: 0.0021\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.4795e-06 - val_loss: 0.0021\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.7908e-06 - val_loss: 0.0022\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.6650e-06 - val_loss: 0.0021\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.8242e-06 - val_loss: 0.0021\n",
            "Epoch 17/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.4564e-06 - val_loss: 0.0021\n",
            "Epoch 18/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.6839e-06 - val_loss: 0.0022\n",
            "Epoch 19/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.4026e-06 - val_loss: 0.0021\n",
            "Epoch 20/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.7688e-06 - val_loss: 0.0022\n",
            "Epoch 21/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.7139e-06 - val_loss: 0.0020\n",
            "Epoch 22/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.3472e-06 - val_loss: 0.0020\n",
            "Epoch 23/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.2401e-06 - val_loss: 0.0021\n",
            "Epoch 24/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.3853e-06 - val_loss: 0.0019\n",
            "Epoch 25/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.5323e-06 - val_loss: 0.0019\n",
            "Epoch 26/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 3.9897e-06 - val_loss: 0.0021\n",
            "Epoch 27/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 3.9344e-06 - val_loss: 0.0019\n",
            "Epoch 28/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.2120e-06 - val_loss: 0.0020\n",
            "Epoch 29/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.2862e-06 - val_loss: 0.0023\n",
            "Epoch 30/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.3408e-06 - val_loss: 0.0022\n",
            "Epoch 31/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.1742e-06 - val_loss: 0.0022\n",
            "Epoch 32/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 3.9981e-06 - val_loss: 0.0020\n",
            "Epoch 33/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 3.8746e-06 - val_loss: 0.0022\n",
            "Epoch 34/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.4267e-06 - val_loss: 0.0020\n",
            "Epoch 35/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.0960e-06 - val_loss: 0.0020\n",
            "Epoch 36/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 3.9511e-06 - val_loss: 0.0020\n",
            "Epoch 37/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 3.6752e-06 - val_loss: 0.0020\n",
            "Epoch 38/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.4260e-06 - val_loss: 0.0020\n",
            "Epoch 39/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.3277e-06 - val_loss: 0.0020\n",
            "training:  svm_cv_vwap  df:  21\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 7.9611e-05 - val_loss: 1.7869e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6068e-05 - val_loss: 1.9671e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.3155e-05 - val_loss: 1.6449e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 5.3934e-05 - val_loss: 1.9377e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9243e-05 - val_loss: 3.3161e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.3894e-05 - val_loss: 1.9447e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9429e-05 - val_loss: 2.7780e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.2785e-05 - val_loss: 3.3934e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9897e-05 - val_loss: 3.5029e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.0300e-05 - val_loss: 4.7864e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9955e-05 - val_loss: 3.6688e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9234e-05 - val_loss: 5.3404e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9532e-05 - val_loss: 3.6994e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.7983e-05 - val_loss: 4.1556e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9046e-05 - val_loss: 6.7234e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.8502e-05 - val_loss: 6.1074e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.8710e-05 - val_loss: 5.6237e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.8577e-05 - val_loss: 5.6647e-04\n",
            "training:  svm_cv_vwap  df:  22\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 3s 8ms/step - loss: 2.2041e-05 - val_loss: 0.0038\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.1246e-05 - val_loss: 0.0041\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.1743e-05 - val_loss: 0.0042\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.2092e-05 - val_loss: 0.0043\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.8944e-05 - val_loss: 0.0048\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.0357e-05 - val_loss: 0.0059\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.9237e-05 - val_loss: 0.0058\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.9486e-05 - val_loss: 0.0059\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.0352e-05 - val_loss: 0.0076\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.9587e-05 - val_loss: 0.0079\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.9287e-05 - val_loss: 0.0078\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.9295e-05 - val_loss: 0.0089\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.8358e-05 - val_loss: 0.0093\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.8377e-05 - val_loss: 0.0108\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.7525e-05 - val_loss: 0.0101\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.8716e-05 - val_loss: 0.0095\n",
            "training:  svm_cv_vwap  df:  23\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 4.2450e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 1s 8ms/step - loss: 2.0574e-04 - val_loss: 6.4440e-06\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.6191e-04 - val_loss: 1.5427e-05\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.5115e-04 - val_loss: 6.5330e-06\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4672e-04 - val_loss: 1.1579e-05\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4449e-04 - val_loss: 1.2515e-05\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4455e-04 - val_loss: 6.2433e-06\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4050e-04 - val_loss: 3.8518e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4479e-04 - val_loss: 3.2474e-05\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3580e-04 - val_loss: 8.0086e-06\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4505e-04 - val_loss: 7.1870e-06\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3798e-04 - val_loss: 4.4641e-05\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3665e-04 - val_loss: 8.2860e-06\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4287e-04 - val_loss: 8.6349e-06\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4023e-04 - val_loss: 8.1211e-06\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3990e-04 - val_loss: 1.4834e-05\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3223e-04 - val_loss: 2.6108e-05\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4238e-04 - val_loss: 5.5323e-06\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.2766e-04 - val_loss: 2.6624e-05\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3935e-04 - val_loss: 1.6472e-05\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3876e-04 - val_loss: 1.0646e-05\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3804e-04 - val_loss: 8.1755e-06\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4067e-04 - val_loss: 5.7667e-06\n",
            "Epoch 23/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.4293e-04 - val_loss: 2.7461e-05\n",
            "Epoch 24/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3815e-04 - val_loss: 2.2165e-05\n",
            "Epoch 25/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3571e-04 - val_loss: 6.7139e-06\n",
            "Epoch 26/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3778e-04 - val_loss: 3.6359e-05\n",
            "Epoch 27/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3927e-04 - val_loss: 1.1226e-05\n",
            "Epoch 28/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3392e-04 - val_loss: 2.4636e-05\n",
            "Epoch 29/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3596e-04 - val_loss: 1.0287e-05\n",
            "Epoch 30/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3542e-04 - val_loss: 6.4132e-06\n",
            "Epoch 31/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3646e-04 - val_loss: 5.6655e-06\n",
            "Epoch 32/200\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 1.3805e-04 - val_loss: 6.5740e-06\n",
            "training:  svm_cv_vwap  df:  24\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 5.4714e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3159e-04 - val_loss: 9.6291e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2129e-04 - val_loss: 1.0079e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2149e-04 - val_loss: 8.0913e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1702e-04 - val_loss: 8.9754e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1700e-04 - val_loss: 9.2371e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1777e-04 - val_loss: 8.5378e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1775e-04 - val_loss: 1.0186e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2123e-04 - val_loss: 9.1925e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1383e-04 - val_loss: 8.0888e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1708e-04 - val_loss: 1.0165e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1875e-04 - val_loss: 8.0001e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1562e-04 - val_loss: 1.0256e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1484e-04 - val_loss: 8.2714e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1960e-04 - val_loss: 1.0058e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1619e-04 - val_loss: 8.2172e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1327e-04 - val_loss: 8.3144e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1605e-04 - val_loss: 9.6491e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2194e-04 - val_loss: 8.4382e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1818e-04 - val_loss: 9.4387e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2002e-04 - val_loss: 8.5593e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0943e-04 - val_loss: 8.3434e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1838e-04 - val_loss: 9.8756e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1701e-04 - val_loss: 8.3839e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2131e-04 - val_loss: 1.5284e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0945e-04 - val_loss: 1.4054e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1936e-04 - val_loss: 8.1431e-05\n",
            "training:  svm_cv_vwap  df:  25\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/53 [===>..........................] - ETA: 0s - loss: 2.5663e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 9ms/step - loss: 2.3423e-04 - val_loss: 3.0947e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.3954e-04 - val_loss: 3.6115e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.6679e-04 - val_loss: 3.3170e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4249e-04 - val_loss: 3.0653e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.3803e-04 - val_loss: 3.1480e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.3713e-04 - val_loss: 3.0604e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2593e-04 - val_loss: 2.9600e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4076e-04 - val_loss: 3.0797e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.5992e-04 - val_loss: 3.9941e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4191e-04 - val_loss: 3.1467e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4341e-04 - val_loss: 3.1552e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1845e-04 - val_loss: 3.1426e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2370e-04 - val_loss: 3.0025e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.2251e-04 - val_loss: 3.0293e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4297e-04 - val_loss: 3.0294e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.2126e-04 - val_loss: 3.0404e-04\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.2753e-04 - val_loss: 2.9963e-04\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2774e-04 - val_loss: 3.3391e-04\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.4492e-04 - val_loss: 3.1631e-04\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2974e-04 - val_loss: 3.0912e-04\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.1702e-04 - val_loss: 3.3686e-04\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 2.2082e-04 - val_loss: 3.3585e-04\n",
            "training:  svm_cv_vwap  df:  26\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/58 [===>..........................] - ETA: 0s - loss: 1.0264e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5593e-04 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3547e-04 - val_loss: 0.0016\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2129e-04 - val_loss: 0.0016\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2867e-04 - val_loss: 0.0016\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2153e-04 - val_loss: 0.0015\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2790e-04 - val_loss: 0.0015\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2530e-04 - val_loss: 0.0015\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1598e-04 - val_loss: 0.0016\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1546e-04 - val_loss: 0.0015\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1891e-04 - val_loss: 0.0015\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1528e-04 - val_loss: 0.0016\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1513e-04 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.1460e-04 - val_loss: 0.0016\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1448e-04 - val_loss: 0.0015\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.1018e-04 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2547e-04 - val_loss: 0.0015\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1486e-04 - val_loss: 0.0016\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1209e-04 - val_loss: 0.0015\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1810e-04 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1831e-04 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1260e-04 - val_loss: 0.0015\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1393e-04 - val_loss: 0.0016\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1580e-04 - val_loss: 0.0016\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.1584e-04 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1486e-04 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0946e-04 - val_loss: 0.0015\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1872e-04 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0915e-04 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1064e-04 - val_loss: 0.0015\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0934e-04 - val_loss: 0.0015\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1266e-04 - val_loss: 0.0015\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.0923e-04 - val_loss: 0.0015\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.1241e-04 - val_loss: 0.0015\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0654e-04 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0885e-04 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2895e-04 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1181e-04 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1224e-04 - val_loss: 0.0015\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0439e-04 - val_loss: 0.0015\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0864e-04 - val_loss: 0.0015\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0829e-04 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1055e-04 - val_loss: 0.0016\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4336e-04 - val_loss: 0.0015\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.1582e-04 - val_loss: 0.0015\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1138e-04 - val_loss: 0.0015\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0900e-04 - val_loss: 0.0015\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0642e-04 - val_loss: 0.0015\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2346e-04 - val_loss: 0.0015\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1046e-04 - val_loss: 0.0015\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0663e-04 - val_loss: 0.0015\n",
            "Epoch 51/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0581e-04 - val_loss: 0.0015\n",
            "Epoch 52/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1095e-04 - val_loss: 0.0015\n",
            "Epoch 53/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0655e-04 - val_loss: 0.0015\n",
            "Epoch 54/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1473e-04 - val_loss: 0.0015\n",
            "Epoch 55/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.0214e-04 - val_loss: 0.0015\n",
            "Epoch 56/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0401e-04 - val_loss: 0.0015\n",
            "Epoch 57/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1018e-04 - val_loss: 0.0015\n",
            "Epoch 58/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2036e-04 - val_loss: 0.0015\n",
            "Epoch 59/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1034e-04 - val_loss: 0.0015\n",
            "Epoch 60/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.0396e-04 - val_loss: 0.0015\n",
            "Epoch 61/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1264e-04 - val_loss: 0.0015\n",
            "Epoch 62/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0877e-04 - val_loss: 0.0015\n",
            "Epoch 63/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0434e-04 - val_loss: 0.0015\n",
            "Epoch 64/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0643e-04 - val_loss: 0.0015\n",
            "Epoch 65/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0629e-04 - val_loss: 0.0015\n",
            "Epoch 66/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0365e-04 - val_loss: 0.0015\n",
            "Epoch 67/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3512e-04 - val_loss: 0.0016\n",
            "Epoch 68/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3287e-04 - val_loss: 0.0015\n",
            "Epoch 69/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1406e-04 - val_loss: 0.0015\n",
            "Epoch 70/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0872e-04 - val_loss: 0.0015\n",
            "Epoch 71/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0665e-04 - val_loss: 0.0015\n",
            "Epoch 72/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0391e-04 - val_loss: 0.0015\n",
            "Epoch 73/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2637e-04 - val_loss: 0.0015\n",
            "Epoch 74/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1263e-04 - val_loss: 0.0015\n",
            "Epoch 75/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0937e-04 - val_loss: 0.0015\n",
            "Epoch 76/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.0753e-04 - val_loss: 0.0015\n",
            "Epoch 77/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0375e-04 - val_loss: 0.0015\n",
            "Epoch 78/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0851e-04 - val_loss: 0.0015\n",
            "Epoch 79/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0859e-04 - val_loss: 0.0015\n",
            "training:  svm_cv_vwap  df:  27\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/46 [====>.........................] - ETA: 0s - loss: 5.1153e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 9ms/step - loss: 4.0721e-04 - val_loss: 7.5465e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.7662e-04 - val_loss: 4.6096e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.4269e-04 - val_loss: 4.2542e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.2341e-04 - val_loss: 4.0739e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.1544e-04 - val_loss: 4.9014e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2630e-04 - val_loss: 4.2411e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1146e-04 - val_loss: 4.5980e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.2967e-04 - val_loss: 4.4179e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2666e-04 - val_loss: 4.5762e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0121e-04 - val_loss: 4.6660e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0740e-04 - val_loss: 4.6481e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9703e-04 - val_loss: 4.1147e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9910e-04 - val_loss: 8.7417e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 3.3145e-04 - val_loss: 4.0215e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.9342e-04 - val_loss: 4.6843e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0851e-04 - val_loss: 4.4015e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9694e-04 - val_loss: 4.3717e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9229e-04 - val_loss: 4.3771e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2655e-04 - val_loss: 4.3991e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.9999e-04 - val_loss: 5.4573e-04\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.9787e-04 - val_loss: 4.9618e-04\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.9878e-04 - val_loss: 4.6093e-04\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.0055e-04 - val_loss: 4.1969e-04\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9389e-04 - val_loss: 4.4781e-04\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9954e-04 - val_loss: 4.2483e-04\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 1.9431e-04 - val_loss: 5.3434e-04\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.0446e-04 - val_loss: 6.2321e-04\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 2.2210e-04 - val_loss: 4.2823e-04\n",
            "Epoch 29/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 1.8390e-04 - val_loss: 4.4279e-04\n",
            "training:  svm_cv_vwap  df:  28\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/171 [..............................] - ETA: 1s - loss: 2.0991e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 8ms/step - loss: 6.9011e-05 - val_loss: 3.3683e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.2275e-05 - val_loss: 2.5929e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0467e-05 - val_loss: 2.6030e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0905e-05 - val_loss: 2.8445e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.9540e-05 - val_loss: 2.5398e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0903e-05 - val_loss: 2.7497e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1740e-05 - val_loss: 2.7609e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0965e-05 - val_loss: 2.6626e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.8522e-05 - val_loss: 2.8711e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.9871e-05 - val_loss: 2.5047e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.8778e-05 - val_loss: 2.4813e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.9145e-05 - val_loss: 2.4632e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.9250e-05 - val_loss: 2.7150e-04\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1481e-05 - val_loss: 2.6170e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0257e-05 - val_loss: 2.4953e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.9331e-05 - val_loss: 2.5269e-04\n",
            "Epoch 17/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.6924e-05 - val_loss: 2.4762e-04\n",
            "Epoch 18/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.1074e-05 - val_loss: 2.9330e-04\n",
            "Epoch 19/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.3576e-05 - val_loss: 2.6657e-04\n",
            "Epoch 20/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0779e-05 - val_loss: 2.6380e-04\n",
            "Epoch 21/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.8107e-05 - val_loss: 2.5714e-04\n",
            "Epoch 22/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.7800e-05 - val_loss: 3.0012e-04\n",
            "Epoch 23/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0750e-05 - val_loss: 2.6915e-04\n",
            "Epoch 24/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.2141e-05 - val_loss: 2.7102e-04\n",
            "Epoch 25/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.9096e-05 - val_loss: 2.8900e-04\n",
            "Epoch 26/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 5.7515e-05 - val_loss: 2.7318e-04\n",
            "Epoch 27/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.0716e-05 - val_loss: 2.9282e-04\n",
            "training:  svm_cv_vwap  df:  29\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 3.4165e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 2.9771e-05 - val_loss: 4.1504e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.4864e-05 - val_loss: 4.4742e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 2.0708e-05 - val_loss: 4.7114e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7950e-05 - val_loss: 4.7678e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8097e-05 - val_loss: 5.0621e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.8065e-05 - val_loss: 5.3519e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7774e-05 - val_loss: 5.7428e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6612e-05 - val_loss: 5.8349e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7893e-05 - val_loss: 6.6229e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6662e-05 - val_loss: 6.9258e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5912e-05 - val_loss: 6.4510e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6687e-05 - val_loss: 6.5769e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6720e-05 - val_loss: 7.2398e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5544e-05 - val_loss: 7.5139e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6543e-05 - val_loss: 7.8116e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7301e-05 - val_loss: 8.1216e-04\n",
            "training:  svm_cv_vwap  df:  30\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 2.0540e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5985e-05 - val_loss: 8.0001e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5809e-05 - val_loss: 8.8634e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5580e-05 - val_loss: 9.3776e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.7321e-05 - val_loss: 9.3322e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6197e-05 - val_loss: 9.7521e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5613e-05 - val_loss: 0.0010\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6971e-05 - val_loss: 8.5174e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5343e-05 - val_loss: 9.8004e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5260e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5044e-05 - val_loss: 0.0010\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6052e-05 - val_loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5334e-05 - val_loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.6146e-05 - val_loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5882e-05 - val_loss: 0.0012\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5302e-05 - val_loss: 0.0014\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.4516e-05 - val_loss: 0.0015\n",
            "training:  svm_cv_vwap  df:  31\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.0124e-05 - val_loss: 3.2320e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.5693e-05 - val_loss: 3.1133e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3587e-05 - val_loss: 3.7497e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3713e-05 - val_loss: 3.5987e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0854e-05 - val_loss: 3.5270e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9253e-05 - val_loss: 3.1320e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9964e-05 - val_loss: 5.8422e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4833e-05 - val_loss: 6.2945e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1282e-05 - val_loss: 2.9229e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0565e-05 - val_loss: 3.7755e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9022e-05 - val_loss: 3.1040e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0839e-05 - val_loss: 2.8178e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0181e-05 - val_loss: 6.0005e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2051e-05 - val_loss: 3.6942e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1290e-05 - val_loss: 3.2457e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9716e-05 - val_loss: 3.2542e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2085e-05 - val_loss: 5.1185e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0711e-05 - val_loss: 2.8764e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9889e-05 - val_loss: 3.5231e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8111e-05 - val_loss: 5.1119e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0910e-05 - val_loss: 4.6485e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8574e-05 - val_loss: 3.7937e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9879e-05 - val_loss: 3.0636e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9662e-05 - val_loss: 7.5358e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.8974e-05 - val_loss: 3.3972e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9499e-05 - val_loss: 3.9548e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9124e-05 - val_loss: 3.2242e-05\n",
            "training:  svm_cv_vwap  df:  32\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0005e-05 - val_loss: 1.2079e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8874e-05 - val_loss: 1.4907e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.9343e-05 - val_loss: 1.5061e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8004e-05 - val_loss: 3.2825e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8507e-05 - val_loss: 1.4844e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7824e-05 - val_loss: 2.2294e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7773e-05 - val_loss: 1.6648e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8712e-05 - val_loss: 2.5558e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7335e-05 - val_loss: 1.6046e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7362e-05 - val_loss: 2.4123e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7934e-05 - val_loss: 2.4397e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7603e-05 - val_loss: 2.0300e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7407e-05 - val_loss: 2.8573e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7951e-05 - val_loss: 2.2420e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7313e-05 - val_loss: 3.4047e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7641e-05 - val_loss: 3.8302e-04\n",
            "training:  svm_cv_vwap  df:  33\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 9.9682e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 8ms/step - loss: 1.0180e-04 - val_loss: 2.6684e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9037e-05 - val_loss: 1.4411e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.8228e-05 - val_loss: 1.3441e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.5116e-05 - val_loss: 1.5513e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1884e-05 - val_loss: 1.9520e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.9260e-05 - val_loss: 1.4818e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1930e-05 - val_loss: 1.9925e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.3710e-05 - val_loss: 2.3403e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.0449e-05 - val_loss: 3.6912e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.0180e-05 - val_loss: 1.3860e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 7.9600e-05 - val_loss: 1.3895e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 7.9209e-05 - val_loss: 1.7513e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 7.9300e-05 - val_loss: 1.5762e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.2902e-05 - val_loss: 2.1581e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 7.4444e-05 - val_loss: 2.0350e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1927e-05 - val_loss: 1.9717e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.0533e-05 - val_loss: 2.4027e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.1336e-05 - val_loss: 1.8824e-04\n",
            "training:  svm_cv_vwap  df:  34\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 3s - loss: 4.3961e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8341e-05 - val_loss: 3.0149e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5985e-05 - val_loss: 2.4567e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6714e-05 - val_loss: 2.2500e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7340e-05 - val_loss: 2.1123e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6149e-05 - val_loss: 2.2015e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6069e-05 - val_loss: 2.3790e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5821e-05 - val_loss: 1.9406e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5874e-05 - val_loss: 2.1787e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5688e-05 - val_loss: 2.0494e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5090e-05 - val_loss: 2.1068e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5011e-05 - val_loss: 1.9801e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6054e-05 - val_loss: 2.2165e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5146e-05 - val_loss: 2.0415e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4836e-05 - val_loss: 2.0276e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5471e-05 - val_loss: 2.1671e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5300e-05 - val_loss: 2.1943e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5774e-05 - val_loss: 2.4776e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5657e-05 - val_loss: 2.5494e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6628e-05 - val_loss: 3.2572e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4899e-05 - val_loss: 2.8764e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5312e-05 - val_loss: 3.1556e-04\n",
            "Epoch 22/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4813e-05 - val_loss: 4.7291e-04\n",
            "training:  svm_cv_vwap  df:  35\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/314 [..............................] - ETA: 3s - loss: 1.9138e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 3s 8ms/step - loss: 2.6699e-05 - val_loss: 0.0013\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.4195e-05 - val_loss: 0.0020\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.3052e-05 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.2886e-05 - val_loss: 0.0015\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1383e-05 - val_loss: 0.0015\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1694e-05 - val_loss: 0.0035\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0960e-05 - val_loss: 0.0050\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.1390e-05 - val_loss: 0.0036\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.0623e-05 - val_loss: 0.0032\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0939e-05 - val_loss: 0.0036\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 1.9992e-05 - val_loss: 0.0019\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0736e-05 - val_loss: 0.0023\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0368e-05 - val_loss: 0.0032\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0071e-05 - val_loss: 0.0034\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 2s 8ms/step - loss: 2.0464e-05 - val_loss: 0.0028\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 1.9217e-05 - val_loss: 0.0031\n",
            "training:  svm_cv_vwap  df:  36\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/118 [=>............................] - ETA: 0s - loss: 5.5090e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 8ms/step - loss: 4.3175e-05 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9214e-05 - val_loss: 0.0020\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9878e-05 - val_loss: 0.0024\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9453e-05 - val_loss: 0.0026\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 4.1986e-05 - val_loss: 0.0027\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.5862e-05 - val_loss: 0.0024\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6844e-05 - val_loss: 0.0031\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6142e-05 - val_loss: 0.0029\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.8333e-05 - val_loss: 0.0024\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6697e-05 - val_loss: 0.0025\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.5274e-05 - val_loss: 0.0031\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.5394e-05 - val_loss: 0.0025\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.9688e-05 - val_loss: 0.0026\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.7212e-05 - val_loss: 0.0028\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.6776e-05 - val_loss: 0.0033\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 3.4992e-05 - val_loss: 0.0030\n",
            "training:  svm_cv_vwap  df:  37\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.8100e-05 - val_loss: 0.0026\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.5302e-05 - val_loss: 0.0023\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4672e-05 - val_loss: 0.0023\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.5323e-05 - val_loss: 0.0033\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4980e-05 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4120e-05 - val_loss: 0.0023\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4288e-05 - val_loss: 0.0025\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4716e-05 - val_loss: 0.0020\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4110e-05 - val_loss: 0.0021\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4150e-05 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.5565e-05 - val_loss: 0.0019\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4641e-05 - val_loss: 0.0025\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.5023e-05 - val_loss: 0.0029\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.3909e-05 - val_loss: 0.0026\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4245e-05 - val_loss: 0.0026\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.3929e-05 - val_loss: 0.0026\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4543e-05 - val_loss: 0.0022\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.3902e-05 - val_loss: 0.0026\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.5342e-05 - val_loss: 0.0019\n",
            "Epoch 20/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4893e-05 - val_loss: 0.0024\n",
            "Epoch 21/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3261e-05 - val_loss: 0.0027\n",
            "Epoch 22/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.3885e-05 - val_loss: 0.0026\n",
            "Epoch 23/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4174e-05 - val_loss: 0.0027\n",
            "Epoch 24/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.2988e-05 - val_loss: 0.0024\n",
            "Epoch 25/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4070e-05 - val_loss: 0.0024\n",
            "Epoch 26/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3625e-05 - val_loss: 0.0032\n",
            "Epoch 27/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4987e-05 - val_loss: 0.0033\n",
            "Epoch 28/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.3691e-05 - val_loss: 0.0025\n",
            "Epoch 29/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3828e-05 - val_loss: 0.0037\n",
            "Epoch 30/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.2484e-05 - val_loss: 0.0033\n",
            "Epoch 31/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3453e-05 - val_loss: 0.0035\n",
            "Epoch 32/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.3271e-05 - val_loss: 0.0032\n",
            "Epoch 33/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.4257e-05 - val_loss: 0.0030\n",
            "Epoch 34/200\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 2.2912e-05 - val_loss: 0.0029\n",
            "training:  svm_cv_vwap  df:  38\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/99 [=>............................] - ETA: 0s - loss: 0.0012    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 9ms/step - loss: 4.3977e-04 - val_loss: 4.3319e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6612e-04 - val_loss: 4.4770e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6449e-04 - val_loss: 4.4208e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6995e-04 - val_loss: 4.8415e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6196e-04 - val_loss: 4.9669e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5724e-04 - val_loss: 4.4923e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5344e-04 - val_loss: 4.5444e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5147e-04 - val_loss: 4.5015e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4923e-04 - val_loss: 4.3535e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5278e-04 - val_loss: 4.5155e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4854e-04 - val_loss: 4.4260e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5191e-04 - val_loss: 4.6074e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4485e-04 - val_loss: 4.4336e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.6415e-04 - val_loss: 4.2979e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5191e-04 - val_loss: 4.7257e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4777e-04 - val_loss: 4.6823e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5142e-04 - val_loss: 4.5902e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4713e-04 - val_loss: 4.6641e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4975e-04 - val_loss: 4.4628e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5747e-04 - val_loss: 4.7829e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5127e-04 - val_loss: 4.3132e-04\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4041e-04 - val_loss: 4.5233e-04\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5339e-04 - val_loss: 4.8713e-04\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4444e-04 - val_loss: 4.4448e-04\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4787e-04 - val_loss: 4.9189e-04\n",
            "Epoch 26/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5019e-04 - val_loss: 4.6859e-04\n",
            "Epoch 27/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.5025e-04 - val_loss: 4.5355e-04\n",
            "Epoch 28/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4693e-04 - val_loss: 4.7582e-04\n",
            "Epoch 29/200\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4805e-04 - val_loss: 4.3610e-04\n",
            "training:  svm_cv_vwap  df:  39\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 3.0392e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 3.2768e-05 - val_loss: 1.6123e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0175e-05 - val_loss: 1.6475e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0832e-05 - val_loss: 1.6973e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7935e-05 - val_loss: 1.6175e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7268e-05 - val_loss: 2.8747e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.1852e-05 - val_loss: 2.5894e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.8706e-05 - val_loss: 1.8206e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7571e-05 - val_loss: 1.9291e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.8259e-05 - val_loss: 2.0319e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7808e-05 - val_loss: 1.9906e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7747e-05 - val_loss: 1.8132e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.6791e-05 - val_loss: 1.6969e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7436e-05 - val_loss: 2.1192e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7362e-05 - val_loss: 1.7861e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7769e-05 - val_loss: 2.3224e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7294e-05 - val_loss: 2.0764e-04\n",
            "training:  svm_cv_vwap  df:  40\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 3.3585e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 3.1919e-05 - val_loss: 1.7276e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0749e-05 - val_loss: 1.7351e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0431e-05 - val_loss: 1.7438e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9455e-05 - val_loss: 1.8147e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9282e-05 - val_loss: 1.8438e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9582e-05 - val_loss: 2.0513e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.0037e-05 - val_loss: 2.1221e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8935e-05 - val_loss: 2.2032e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 2.9249e-05 - val_loss: 2.0109e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9254e-05 - val_loss: 2.0400e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8685e-05 - val_loss: 2.0199e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8255e-05 - val_loss: 2.0203e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8310e-05 - val_loss: 2.0212e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8292e-05 - val_loss: 1.8968e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9406e-05 - val_loss: 2.5524e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8776e-05 - val_loss: 2.5129e-04\n",
            "training:  svm_cv_vwap  df:  41\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 3.3300e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7939e-05 - val_loss: 2.0219e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8487e-05 - val_loss: 2.3680e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7414e-05 - val_loss: 2.2242e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9338e-05 - val_loss: 2.5715e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8845e-05 - val_loss: 2.3946e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7727e-05 - val_loss: 2.1787e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8985e-05 - val_loss: 2.8996e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8399e-05 - val_loss: 2.9873e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.7035e-05 - val_loss: 2.4409e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.6795e-05 - val_loss: 2.4605e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8395e-05 - val_loss: 2.8288e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.9025e-05 - val_loss: 3.5186e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.5874e-05 - val_loss: 4.1242e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8497e-05 - val_loss: 4.5323e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.8602e-05 - val_loss: 3.4945e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 2.6783e-05 - val_loss: 4.3625e-04\n",
            "training:  svm_cv_vwap  df:  42\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.2935e-05 - val_loss: 2.1918e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9752e-05 - val_loss: 2.6231e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.7910e-05 - val_loss: 2.8756e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8144e-05 - val_loss: 4.8139e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8104e-05 - val_loss: 0.0015\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6378e-05 - val_loss: 9.5326e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8586e-05 - val_loss: 0.0011\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6937e-05 - val_loss: 0.0024\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6508e-05 - val_loss: 0.0024\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 2.6758e-05 - val_loss: 0.0024\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6652e-05 - val_loss: 0.0026\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.7895e-05 - val_loss: 0.0027\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6907e-05 - val_loss: 0.0025\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6579e-05 - val_loss: 0.0020\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6523e-05 - val_loss: 0.0015\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.6771e-05 - val_loss: 0.0010\n",
            "training:  svm_cv_vwap  df:  43\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/64 [==>...........................] - ETA: 0s - loss: 7.8171e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 9ms/step - loss: 4.8369e-04 - val_loss: 5.7687e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.5299e-04 - val_loss: 7.3788e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0107e-04 - val_loss: 6.8527e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0400e-04 - val_loss: 7.3851e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0241e-04 - val_loss: 8.2562e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.9594e-04 - val_loss: 7.8843e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9532e-04 - val_loss: 8.1381e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9241e-04 - val_loss: 9.7650e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1504e-04 - val_loss: 0.0010\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9059e-04 - val_loss: 9.2906e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.9642e-04 - val_loss: 9.1682e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.8699e-04 - val_loss: 9.8194e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.1335e-04 - val_loss: 8.4536e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.8766e-04 - val_loss: 7.7386e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 3.0804e-04 - val_loss: 8.4192e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 2.8664e-04 - val_loss: 8.5115e-04\n",
            "training:  svm_cv_vwap  df:  44\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 2s - loss: 2.3464e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3645e-04 - val_loss: 1.7012e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3246e-04 - val_loss: 1.7329e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3120e-04 - val_loss: 1.6434e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3037e-04 - val_loss: 1.7232e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3133e-04 - val_loss: 1.6368e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3385e-04 - val_loss: 1.7275e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2984e-04 - val_loss: 1.8063e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3061e-04 - val_loss: 2.0574e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3129e-04 - val_loss: 1.6334e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2958e-04 - val_loss: 1.8165e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2928e-04 - val_loss: 1.7190e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2839e-04 - val_loss: 1.8869e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3119e-04 - val_loss: 1.8030e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2921e-04 - val_loss: 1.8118e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2816e-04 - val_loss: 1.8936e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3234e-04 - val_loss: 1.7856e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3038e-04 - val_loss: 1.8872e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3103e-04 - val_loss: 2.0800e-04\n",
            "Epoch 19/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2893e-04 - val_loss: 1.9793e-04\n",
            "Epoch 20/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2976e-04 - val_loss: 1.8043e-04\n",
            "Epoch 21/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2961e-04 - val_loss: 1.9793e-04\n",
            "Epoch 22/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2959e-04 - val_loss: 2.0723e-04\n",
            "Epoch 23/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.2874e-04 - val_loss: 2.2496e-04\n",
            "Epoch 24/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.3032e-04 - val_loss: 2.4025e-04\n",
            "training:  svm_cv_vwap  df:  45\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/174 [>.............................] - ETA: 1s - loss: 1.9663e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9340e-04 - val_loss: 1.9740e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8453e-04 - val_loss: 1.9785e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7513e-04 - val_loss: 2.0024e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7892e-04 - val_loss: 1.8954e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7732e-04 - val_loss: 1.7924e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8057e-04 - val_loss: 1.8295e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8180e-04 - val_loss: 1.7850e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7206e-04 - val_loss: 1.9170e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7818e-04 - val_loss: 1.9262e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7835e-04 - val_loss: 1.8099e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8332e-04 - val_loss: 1.8555e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7701e-04 - val_loss: 1.8140e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8272e-04 - val_loss: 1.8607e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7945e-04 - val_loss: 1.9849e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7980e-04 - val_loss: 1.7700e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7926e-04 - val_loss: 1.8065e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7645e-04 - val_loss: 2.0737e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7633e-04 - val_loss: 2.1445e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7548e-04 - val_loss: 1.9822e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7611e-04 - val_loss: 1.8652e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7152e-04 - val_loss: 1.7817e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7610e-04 - val_loss: 2.0795e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.8111e-04 - val_loss: 1.8116e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7566e-04 - val_loss: 1.8582e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7537e-04 - val_loss: 1.9220e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.6898e-04 - val_loss: 1.8678e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7134e-04 - val_loss: 2.0364e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7922e-04 - val_loss: 2.3152e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7935e-04 - val_loss: 2.0786e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.7410e-04 - val_loss: 1.8781e-04\n",
            "training:  svm_cv_vwap  df:  46\n",
            "Training model: svm_cv_vwap  features: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.3328e-05 - val_loss: 1.0422e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8708e-05 - val_loss: 9.6915e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0294e-05 - val_loss: 1.0967e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1586e-05 - val_loss: 1.2943e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0594e-05 - val_loss: 1.2044e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9692e-05 - val_loss: 1.1899e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1272e-05 - val_loss: 1.0155e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8456e-05 - val_loss: 1.0259e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1055e-05 - val_loss: 9.8742e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.9834e-05 - val_loss: 1.2580e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1798e-05 - val_loss: 1.5407e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1556e-05 - val_loss: 9.8116e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0776e-05 - val_loss: 9.9928e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8860e-05 - val_loss: 1.0690e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.1218e-05 - val_loss: 1.1575e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.0588e-05 - val_loss: 1.0436e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8326e-05 - val_loss: 1.0831e-04\n",
            "training:  svm_cv_vwap  df:  47\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.1156e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3756e-04 - val_loss: 1.6696e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3907e-04 - val_loss: 2.4322e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2491e-04 - val_loss: 1.8630e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2118e-04 - val_loss: 1.7395e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1702e-04 - val_loss: 2.4124e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1951e-04 - val_loss: 1.6444e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1814e-04 - val_loss: 1.6011e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2140e-04 - val_loss: 1.9280e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1685e-04 - val_loss: 2.6739e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2207e-04 - val_loss: 1.8375e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1650e-04 - val_loss: 2.3156e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1859e-04 - val_loss: 1.7415e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1771e-04 - val_loss: 2.2003e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1979e-04 - val_loss: 1.7146e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1619e-04 - val_loss: 1.6839e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1836e-04 - val_loss: 1.9878e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1562e-04 - val_loss: 1.5392e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1965e-04 - val_loss: 1.4880e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2099e-04 - val_loss: 2.3014e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2133e-04 - val_loss: 1.7392e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1599e-04 - val_loss: 1.5553e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1884e-04 - val_loss: 1.7042e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1772e-04 - val_loss: 1.8682e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1862e-04 - val_loss: 1.8101e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1492e-04 - val_loss: 1.6918e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1647e-04 - val_loss: 1.5272e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1754e-04 - val_loss: 1.9584e-04\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1947e-04 - val_loss: 1.8814e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1723e-04 - val_loss: 2.1118e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1821e-04 - val_loss: 1.7530e-04\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1384e-04 - val_loss: 1.9045e-04\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1700e-04 - val_loss: 1.5448e-04\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1764e-04 - val_loss: 1.9500e-04\n",
            "training:  svm_cv_vwap  df:  48\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 7.7542e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1362e-04 - val_loss: 8.6934e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0970e-04 - val_loss: 1.1361e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1467e-04 - val_loss: 8.0590e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0792e-04 - val_loss: 8.2485e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1118e-04 - val_loss: 8.0852e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0918e-04 - val_loss: 7.4291e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0741e-04 - val_loss: 7.8567e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1358e-04 - val_loss: 7.4472e-05\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0827e-04 - val_loss: 7.5813e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0755e-04 - val_loss: 8.5330e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1410e-04 - val_loss: 1.2553e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0689e-04 - val_loss: 7.4102e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1090e-04 - val_loss: 7.9792e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0738e-04 - val_loss: 8.1819e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1006e-04 - val_loss: 8.4783e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0449e-04 - val_loss: 8.6359e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0927e-04 - val_loss: 8.2508e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0680e-04 - val_loss: 8.3632e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1066e-04 - val_loss: 7.9099e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0510e-04 - val_loss: 9.1096e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1005e-04 - val_loss: 8.2563e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0814e-04 - val_loss: 8.0601e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0515e-04 - val_loss: 1.0196e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0842e-04 - val_loss: 1.0447e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0892e-04 - val_loss: 9.2076e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0724e-04 - val_loss: 8.0271e-05\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0725e-04 - val_loss: 1.0019e-04\n",
            "training:  svm_cv_vwap  df:  49\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 1.0261e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6307e-05 - val_loss: 1.0331e-04\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2764e-05 - val_loss: 9.7998e-05\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4884e-05 - val_loss: 1.0297e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2811e-05 - val_loss: 9.8701e-05\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0547e-05 - val_loss: 9.7667e-05\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0101e-05 - val_loss: 9.7016e-05\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1752e-05 - val_loss: 1.2475e-04\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4359e-05 - val_loss: 9.9363e-05\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2411e-05 - val_loss: 1.0110e-04\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2035e-05 - val_loss: 1.0345e-04\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8511e-05 - val_loss: 1.0456e-04\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1101e-05 - val_loss: 1.0246e-04\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.7929e-05 - val_loss: 9.5737e-05\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2443e-05 - val_loss: 9.3823e-05\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0573e-05 - val_loss: 9.7004e-05\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2485e-05 - val_loss: 1.3339e-04\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1596e-05 - val_loss: 1.1892e-04\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.3467e-05 - val_loss: 9.8278e-05\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0882e-05 - val_loss: 1.0395e-04\n",
            "Epoch 20/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8900e-05 - val_loss: 9.9195e-05\n",
            "Epoch 21/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8214e-05 - val_loss: 1.1252e-04\n",
            "Epoch 22/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2349e-05 - val_loss: 9.7595e-05\n",
            "Epoch 23/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1582e-05 - val_loss: 9.2902e-05\n",
            "Epoch 24/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0659e-05 - val_loss: 9.5134e-05\n",
            "Epoch 25/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0332e-05 - val_loss: 1.1929e-04\n",
            "Epoch 26/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1196e-05 - val_loss: 1.0533e-04\n",
            "Epoch 27/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2063e-05 - val_loss: 9.3625e-05\n",
            "Epoch 28/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2233e-05 - val_loss: 1.0347e-04\n",
            "Epoch 29/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0086e-05 - val_loss: 1.0545e-04\n",
            "Epoch 30/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.9290e-05 - val_loss: 1.0902e-04\n",
            "Epoch 31/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4908e-05 - val_loss: 1.0297e-04\n",
            "Epoch 32/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.4369e-05 - val_loss: 9.1885e-05\n",
            "Epoch 33/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0399e-05 - val_loss: 9.3765e-05\n",
            "Epoch 34/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.7237e-05 - val_loss: 1.0414e-04\n",
            "Epoch 35/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.3714e-05 - val_loss: 1.0314e-04\n",
            "Epoch 36/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8995e-05 - val_loss: 9.2193e-05\n",
            "Epoch 37/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1836e-05 - val_loss: 9.5177e-05\n",
            "Epoch 38/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8091e-05 - val_loss: 1.0017e-04\n",
            "Epoch 39/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.9794e-05 - val_loss: 9.7125e-05\n",
            "Epoch 40/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.3980e-05 - val_loss: 9.3279e-05\n",
            "Epoch 41/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8644e-05 - val_loss: 1.0355e-04\n",
            "Epoch 42/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2910e-05 - val_loss: 1.0200e-04\n",
            "Epoch 43/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.2081e-05 - val_loss: 9.2599e-05\n",
            "Epoch 44/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.8495e-05 - val_loss: 1.0216e-04\n",
            "Epoch 45/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 7.9630e-05 - val_loss: 9.4416e-05\n",
            "Epoch 46/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.0603e-05 - val_loss: 1.0776e-04\n",
            "Epoch 47/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.1119e-05 - val_loss: 9.6305e-05\n",
            "training:  svm_cv_vwap  df:  50\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.9692e-04 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.8030e-04 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.5911e-04 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6804e-04 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7856e-04 - val_loss: 0.0019\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8644e-04 - val_loss: 0.0018\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.7369e-04 - val_loss: 0.0019\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6511e-04 - val_loss: 0.0019\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 8.8925e-04 - val_loss: 0.0017\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.4706e-04 - val_loss: 0.0018\n",
            "training:  svm_cv_vwap  df:  51\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  8/106 [=>............................] - ETA: 0s - loss: 3.0424e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 8ms/step - loss: 2.5902e-04 - val_loss: 6.9501e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2775e-04 - val_loss: 6.5899e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2177e-04 - val_loss: 6.3968e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1824e-04 - val_loss: 6.7043e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2193e-04 - val_loss: 6.8127e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2370e-04 - val_loss: 6.5824e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1703e-04 - val_loss: 6.6645e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2162e-04 - val_loss: 6.6781e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1837e-04 - val_loss: 6.5824e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1482e-04 - val_loss: 6.7099e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2124e-04 - val_loss: 6.9870e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2065e-04 - val_loss: 6.4354e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1696e-04 - val_loss: 6.5258e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1611e-04 - val_loss: 6.9629e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2081e-04 - val_loss: 7.0312e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1388e-04 - val_loss: 6.5602e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.1493e-04 - val_loss: 6.5992e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2.2916e-04 - val_loss: 6.6313e-04\n",
            "training:  svm_cv_vwap  df:  52\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/270 [..............................] - ETA: 3s - loss: 1.1604e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 8ms/step - loss: 2.2209e-05 - val_loss: 2.1472e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.7094e-05 - val_loss: 2.0999e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6440e-05 - val_loss: 2.0922e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5660e-05 - val_loss: 2.0863e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5173e-05 - val_loss: 2.1052e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5098e-05 - val_loss: 2.1272e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5744e-05 - val_loss: 2.1648e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5266e-05 - val_loss: 2.1943e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4808e-05 - val_loss: 2.2236e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5408e-05 - val_loss: 2.2639e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6042e-05 - val_loss: 2.3062e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5090e-05 - val_loss: 2.3508e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4761e-05 - val_loss: 2.4520e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4824e-05 - val_loss: 2.6645e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5137e-05 - val_loss: 2.6687e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4883e-05 - val_loss: 2.6969e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5086e-05 - val_loss: 2.7952e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4429e-05 - val_loss: 2.8388e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5445e-05 - val_loss: 3.2753e-04\n",
            "training:  svm_cv_vwap  df:  53\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            " 8/79 [==>...........................] - ETA: 0s - loss: 9.2637e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step - loss: 9.2936e-05 - val_loss: 0.0019\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.4644e-05 - val_loss: 0.0023\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.6424e-05 - val_loss: 0.0023\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 8.1863e-05 - val_loss: 0.0026\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7060e-05 - val_loss: 0.0023\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.6509e-05 - val_loss: 0.0029\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7664e-05 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.5695e-05 - val_loss: 0.0021\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.8010e-05 - val_loss: 0.0024\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.9364e-05 - val_loss: 0.0027\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.6394e-05 - val_loss: 0.0028\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.5105e-05 - val_loss: 0.0030\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7812e-05 - val_loss: 0.0029\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7076e-05 - val_loss: 0.0029\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.7833e-05 - val_loss: 0.0033\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 7.4593e-05 - val_loss: 0.0029\n",
            "training:  svm_cv_vwap  df:  54\n",
            "Training model: svm_cv_vwap  features: 4\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 7.3810e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 8ms/step - loss: 4.7772e-05 - val_loss: 4.9401e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4135e-05 - val_loss: 4.6183e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2482e-05 - val_loss: 2.0477e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 2s 8ms/step - loss: 4.4890e-05 - val_loss: 3.2722e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3014e-05 - val_loss: 3.6867e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2448e-05 - val_loss: 4.1348e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3298e-05 - val_loss: 2.4938e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2007e-05 - val_loss: 4.0719e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3606e-05 - val_loss: 3.5118e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2744e-05 - val_loss: 3.0063e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.1575e-05 - val_loss: 2.4045e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2403e-05 - val_loss: 4.6171e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.1352e-05 - val_loss: 3.2557e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.1937e-05 - val_loss: 4.4737e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.1899e-05 - val_loss: 2.4565e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3178e-05 - val_loss: 3.5468e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.0780e-05 - val_loss: 2.9611e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.1803e-05 - val_loss: 2.7935e-04\n",
            "build model: lstm_xgb_cols  features: 9\n",
            "training:  lstm_xgb_cols\n",
            "lstm_xgb_cols  should train on stocks\n",
            "training dfs: 55\n",
            "training:  lstm_xgb_cols  df:  0\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 15ms/step - loss: 0.0152 - val_loss: 0.3261\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 0.0018 - val_loss: 0.0831\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0735\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 8.7371e-04 - val_loss: 0.0568\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 8.7600e-04 - val_loss: 0.0869\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 7.4602e-04 - val_loss: 0.0656\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 6.5567e-04 - val_loss: 0.0713\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 5.2085e-04 - val_loss: 0.0854\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 5.2735e-04 - val_loss: 0.0783\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 4.7171e-04 - val_loss: 0.0827\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 4.1840e-04 - val_loss: 0.0824\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 4.0328e-04 - val_loss: 0.0837\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 3.8226e-04 - val_loss: 0.0803\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 3.1870e-04 - val_loss: 0.0776\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 2.3384e-04 - val_loss: 0.0783\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 1.6574e-04 - val_loss: 0.0796\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 2.0879e-04 - val_loss: 0.0867\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 1.6548e-04 - val_loss: 0.0788\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 1.4974e-04 - val_loss: 0.0799\n",
            "training:  lstm_xgb_cols  df:  1\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 8/80 [==>...........................] - ETA: 0s - loss: 0.0020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1s 9ms/step - loss: 3.7130e-04 - val_loss: 0.1510\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 7.7033e-05 - val_loss: 0.1145\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.0291e-04 - val_loss: 0.1165\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 5.8773e-05 - val_loss: 0.1006\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 4.4695e-05 - val_loss: 0.1083\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 4.2885e-05 - val_loss: 0.1257\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 4.0068e-05 - val_loss: 0.1381\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 3.1446e-05 - val_loss: 0.1369\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 3.0979e-05 - val_loss: 0.1470\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.9601e-05 - val_loss: 0.1450\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 3.2635e-05 - val_loss: 0.1567\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.7300e-05 - val_loss: 0.1547\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 3.1115e-05 - val_loss: 0.1514\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.7989e-05 - val_loss: 0.1609\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.6050e-05 - val_loss: 0.1658\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.1787e-05 - val_loss: 0.1670\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.3967e-05 - val_loss: 0.1619\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.4981e-05 - val_loss: 0.1718\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 2.2795e-05 - val_loss: 0.1706\n",
            "training:  lstm_xgb_cols  df:  2\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 2.4609e-05 - val_loss: 0.1243\n",
            "Epoch 2/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.0673e-05 - val_loss: 0.1297\n",
            "Epoch 3/200\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 9.6980e-06 - val_loss: 0.1326\n",
            "Epoch 4/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.0779e-05 - val_loss: 0.1358\n",
            "Epoch 5/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 8.5384e-06 - val_loss: 0.1377\n",
            "Epoch 6/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.2385e-05 - val_loss: 0.1401\n",
            "Epoch 7/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.0101e-05 - val_loss: 0.1398\n",
            "Epoch 8/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 9.5364e-06 - val_loss: 0.1407\n",
            "Epoch 9/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 8.6715e-06 - val_loss: 0.1407\n",
            "Epoch 10/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 7.9988e-06 - val_loss: 0.1409\n",
            "Epoch 11/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 9.0720e-06 - val_loss: 0.1442\n",
            "Epoch 12/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 8.7525e-06 - val_loss: 0.1437\n",
            "Epoch 13/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.0844e-05 - val_loss: 0.1458\n",
            "Epoch 14/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 9.4902e-06 - val_loss: 0.1459\n",
            "Epoch 15/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 9.6791e-06 - val_loss: 0.1481\n",
            "Epoch 16/200\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 8.8329e-06 - val_loss: 0.1491\n",
            "training:  lstm_xgb_cols  df:  3\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 0.0032 - val_loss: 0.0203\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 2.3970e-04 - val_loss: 0.0180\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.9219e-04 - val_loss: 0.0204\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.6817e-04 - val_loss: 0.0146\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7625e-04 - val_loss: 0.0205\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4338e-04 - val_loss: 0.0189\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.2540e-04 - val_loss: 0.0164\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.1539e-04 - val_loss: 0.0147\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.2394e-04 - val_loss: 0.0184\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4554e-04 - val_loss: 0.0133\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 0.0011 - val_loss: 0.0234\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 3.6446e-04 - val_loss: 0.0198\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0452e-04 - val_loss: 0.0179\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4613e-04 - val_loss: 0.0184\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4399e-04 - val_loss: 0.0170\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.3569e-04 - val_loss: 0.0180\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.2572e-04 - val_loss: 0.0151\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4491e-04 - val_loss: 0.0187\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4336e-04 - val_loss: 0.0214\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.1238e-04 - val_loss: 0.0146\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.1769e-04 - val_loss: 0.0178\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.0536e-04 - val_loss: 0.0205\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.1917e-04 - val_loss: 0.0181\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.3304e-04 - val_loss: 0.0145\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 9.3125e-05 - val_loss: 0.0144\n",
            "training:  lstm_xgb_cols  df:  4\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 0.0015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 9ms/step - loss: 4.2274e-04 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.4827e-04 - val_loss: 1.0285e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.8506e-04 - val_loss: 7.7531e-05\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.7352e-04 - val_loss: 9.3579e-05\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.8639e-04 - val_loss: 3.3851e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.6260e-04 - val_loss: 2.1304e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.9262e-04 - val_loss: 1.2758e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.6405e-04 - val_loss: 1.1309e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.4835e-04 - val_loss: 7.5583e-05\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.5125e-04 - val_loss: 5.7271e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.6844e-04 - val_loss: 9.7800e-05\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.5110e-04 - val_loss: 9.5822e-05\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.7921e-04 - val_loss: 2.1904e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.5083e-04 - val_loss: 2.0063e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.3797e-04 - val_loss: 1.0973e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.3810e-04 - val_loss: 1.2736e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.4960e-04 - val_loss: 1.2021e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.4662e-04 - val_loss: 1.0031e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.6197e-04 - val_loss: 7.2462e-05\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.7479e-04 - val_loss: 1.2680e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.4180e-04 - val_loss: 2.2223e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.5133e-04 - val_loss: 1.7323e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2176e-04 - val_loss: 7.3366e-05\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.3148e-04 - val_loss: 7.6128e-05\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.3651e-04 - val_loss: 1.7747e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.4470e-04 - val_loss: 7.5181e-05\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.2050e-04 - val_loss: 2.9332e-04\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.3356e-04 - val_loss: 2.2055e-04\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.2420e-04 - val_loss: 7.3002e-05\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.5127e-04 - val_loss: 2.7040e-04\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.2927e-04 - val_loss: 1.1391e-04\n",
            "Epoch 32/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.2400e-04 - val_loss: 1.2204e-04\n",
            "Epoch 33/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.2683e-04 - val_loss: 7.4606e-05\n",
            "Epoch 34/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.1743e-04 - val_loss: 1.0658e-04\n",
            "training:  lstm_xgb_cols  df:  5\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 2.5004e-05 - val_loss: 9.0246e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 2.0587e-05 - val_loss: 7.7738e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7521e-05 - val_loss: 8.9160e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7482e-05 - val_loss: 7.2616e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.8458e-05 - val_loss: 0.0010\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7017e-05 - val_loss: 7.5704e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.8020e-05 - val_loss: 7.5143e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.8253e-05 - val_loss: 8.6657e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7607e-05 - val_loss: 0.0010\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.6859e-05 - val_loss: 0.0011\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6324e-05 - val_loss: 0.0014\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4721e-05 - val_loss: 0.0013\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.9291e-05 - val_loss: 0.0013\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6049e-05 - val_loss: 0.0020\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7642e-05 - val_loss: 0.0028\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4476e-05 - val_loss: 0.0042\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.6306e-05 - val_loss: 0.0048\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6242e-05 - val_loss: 0.0048\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.5661e-05 - val_loss: 0.0048\n",
            "training:  lstm_xgb_cols  df:  6\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 3s 9ms/step - loss: 4.3858e-04 - val_loss: 1.6531e-04\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.6027e-04 - val_loss: 1.2770e-04\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.4733e-04 - val_loss: 2.5201e-04\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.4575e-04 - val_loss: 3.3859e-04\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.3230e-04 - val_loss: 1.1651e-04\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.3934e-04 - val_loss: 1.5781e-04\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.4397e-04 - val_loss: 1.7128e-04\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.3545e-04 - val_loss: 1.3248e-04\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.3035e-04 - val_loss: 1.4087e-04\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.3133e-04 - val_loss: 1.1605e-04\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.4034e-04 - val_loss: 1.0870e-04\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.4727e-04 - val_loss: 1.2474e-04\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.3134e-04 - val_loss: 1.3808e-04\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.3916e-04 - val_loss: 1.1905e-04\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.2778e-04 - val_loss: 1.7335e-04\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.2633e-04 - val_loss: 1.7495e-04\n",
            "Epoch 17/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.3648e-04 - val_loss: 2.3387e-04\n",
            "Epoch 18/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.2770e-04 - val_loss: 1.3226e-04\n",
            "Epoch 19/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2472e-04 - val_loss: 1.9981e-04\n",
            "Epoch 20/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2645e-04 - val_loss: 1.2052e-04\n",
            "Epoch 21/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2881e-04 - val_loss: 1.2552e-04\n",
            "Epoch 22/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2363e-04 - val_loss: 1.4379e-04\n",
            "Epoch 23/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.2247e-04 - val_loss: 1.2575e-04\n",
            "Epoch 24/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2955e-04 - val_loss: 2.9399e-04\n",
            "Epoch 25/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.1732e-04 - val_loss: 1.1685e-04\n",
            "Epoch 26/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2602e-04 - val_loss: 1.0146e-04\n",
            "Epoch 27/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2822e-04 - val_loss: 1.3478e-04\n",
            "Epoch 28/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2385e-04 - val_loss: 1.0735e-04\n",
            "Epoch 29/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2422e-04 - val_loss: 1.1230e-04\n",
            "Epoch 30/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.1629e-04 - val_loss: 1.3462e-04\n",
            "Epoch 31/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2476e-04 - val_loss: 1.0850e-04\n",
            "Epoch 32/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.2016e-04 - val_loss: 1.5262e-04\n",
            "Epoch 33/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.3587e-04 - val_loss: 2.1648e-04\n",
            "Epoch 34/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.3198e-04 - val_loss: 2.1420e-04\n",
            "Epoch 35/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 1.1484e-04 - val_loss: 1.8654e-04\n",
            "Epoch 36/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.1376e-04 - val_loss: 1.8928e-04\n",
            "Epoch 37/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.1667e-04 - val_loss: 1.8412e-04\n",
            "Epoch 38/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.1148e-04 - val_loss: 1.6659e-04\n",
            "Epoch 39/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2349e-04 - val_loss: 1.2738e-04\n",
            "Epoch 40/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2394e-04 - val_loss: 1.2379e-04\n",
            "Epoch 41/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 1.1690e-04 - val_loss: 1.4061e-04\n",
            "training:  lstm_xgb_cols  df:  7\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/268 [..............................] - ETA: 3s - loss: 1.4047e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 9ms/step - loss: 6.1348e-05 - val_loss: 3.1551e-04\n",
            "Epoch 2/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.9328e-05 - val_loss: 3.2281e-04\n",
            "Epoch 3/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.5739e-05 - val_loss: 3.4336e-04\n",
            "Epoch 4/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.3468e-05 - val_loss: 3.3582e-04\n",
            "Epoch 5/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.8709e-05 - val_loss: 4.1156e-04\n",
            "Epoch 6/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.8203e-05 - val_loss: 3.1412e-04\n",
            "Epoch 7/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.7002e-05 - val_loss: 3.3834e-04\n",
            "Epoch 8/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.3465e-05 - val_loss: 3.4243e-04\n",
            "Epoch 9/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.7011e-05 - val_loss: 4.0112e-04\n",
            "Epoch 10/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.8017e-05 - val_loss: 3.9744e-04\n",
            "Epoch 11/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.9496e-05 - val_loss: 4.6235e-04\n",
            "Epoch 12/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.6757e-05 - val_loss: 5.1228e-04\n",
            "Epoch 13/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.4972e-05 - val_loss: 5.0738e-04\n",
            "Epoch 14/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.2073e-05 - val_loss: 5.8981e-04\n",
            "Epoch 15/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.7153e-05 - val_loss: 5.8962e-04\n",
            "Epoch 16/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 4.0556e-05 - val_loss: 7.3841e-04\n",
            "Epoch 17/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.6860e-05 - val_loss: 7.6655e-04\n",
            "Epoch 18/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.4169e-05 - val_loss: 9.5119e-04\n",
            "Epoch 19/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.5620e-05 - val_loss: 0.0011\n",
            "Epoch 20/200\n",
            "268/268 [==============================] - 2s 9ms/step - loss: 3.3182e-05 - val_loss: 0.0012\n",
            "Epoch 21/200\n",
            "268/268 [==============================] - 2s 8ms/step - loss: 3.7154e-05 - val_loss: 0.0010\n",
            "training:  lstm_xgb_cols  df:  8\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 8/68 [==>...........................] - ETA: 0s - loss: 1.0457e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 9ms/step - loss: 1.4558e-04 - val_loss: 0.0024\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.1199e-04 - val_loss: 0.0064\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.1394e-04 - val_loss: 0.0026\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.2478e-04 - val_loss: 0.0047\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.0097e-04 - val_loss: 0.0033\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.0349e-04 - val_loss: 0.0044\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.0154e-04 - val_loss: 0.0035\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 9.5450e-05 - val_loss: 0.0034\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.0704e-04 - val_loss: 0.0038\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.0171e-04 - val_loss: 0.0046\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.1286e-04 - val_loss: 0.0037\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.0825e-04 - val_loss: 0.0045\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.2284e-04 - val_loss: 0.0037\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 1.1534e-04 - val_loss: 0.0046\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 9.9032e-05 - val_loss: 0.0039\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 9.8337e-05 - val_loss: 0.0055\n",
            "training:  lstm_xgb_cols  df:  9\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/162 [..............................] - ETA: 1s - loss: 2.1620e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 9ms/step - loss: 1.5512e-05 - val_loss: 0.0099\n",
            "Epoch 2/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 9.4759e-06 - val_loss: 0.0104\n",
            "Epoch 3/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 8.4721e-06 - val_loss: 0.0110\n",
            "Epoch 4/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 8.8051e-06 - val_loss: 0.0111\n",
            "Epoch 5/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 8.4723e-06 - val_loss: 0.0109\n",
            "Epoch 6/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 6.8192e-06 - val_loss: 0.0110\n",
            "Epoch 7/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 6.5756e-06 - val_loss: 0.0112\n",
            "Epoch 8/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 6.5250e-06 - val_loss: 0.0114\n",
            "Epoch 9/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 1.1370e-05 - val_loss: 0.0115\n",
            "Epoch 10/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 7.8135e-06 - val_loss: 0.0116\n",
            "Epoch 11/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 7.4722e-06 - val_loss: 0.0116\n",
            "Epoch 12/200\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 7.5449e-06 - val_loss: 0.0117\n",
            "Epoch 13/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 6.9700e-06 - val_loss: 0.0118\n",
            "Epoch 14/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 7.7362e-06 - val_loss: 0.0121\n",
            "Epoch 15/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 7.4616e-06 - val_loss: 0.0119\n",
            "Epoch 16/200\n",
            "162/162 [==============================] - 1s 9ms/step - loss: 6.2366e-06 - val_loss: 0.0121\n",
            "training:  lstm_xgb_cols  df:  10\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 6.2263e-05 - val_loss: 7.0914e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9877e-05 - val_loss: 7.6154e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4949e-05 - val_loss: 7.4129e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.3037e-05 - val_loss: 9.9953e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.1972e-05 - val_loss: 7.9303e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.4916e-05 - val_loss: 8.8798e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.9448e-05 - val_loss: 0.0012\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.0444e-05 - val_loss: 7.2558e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.1695e-05 - val_loss: 7.4818e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.5419e-05 - val_loss: 7.1523e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.2592e-05 - val_loss: 7.6833e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 4.4550e-05 - val_loss: 9.9176e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.0313e-05 - val_loss: 8.6719e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.4615e-05 - val_loss: 7.1328e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 4.0210e-05 - val_loss: 0.0013\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 3.8901e-05 - val_loss: 7.6181e-04\n",
            "training:  lstm_xgb_cols  df:  11\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.0138e-04 - val_loss: 3.8225e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 9.5151e-05 - val_loss: 7.2256e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.0776e-05 - val_loss: 7.7468e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.6049e-05 - val_loss: 2.3584e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.1887e-05 - val_loss: 8.1605e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 7.2673e-05 - val_loss: 2.3935e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.2796e-05 - val_loss: 3.4992e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.2995e-04 - val_loss: 8.9066e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.3826e-05 - val_loss: 7.3716e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 7.9986e-05 - val_loss: 8.2943e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 7.7245e-05 - val_loss: 7.3608e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 7.4854e-05 - val_loss: 8.4499e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.5213e-05 - val_loss: 2.7691e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.4047e-05 - val_loss: 2.4434e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 7.8351e-05 - val_loss: 1.2416e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 7.7223e-05 - val_loss: 8.4013e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 7.8859e-05 - val_loss: 1.8705e-04\n",
            "training:  lstm_xgb_cols  df:  12\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0025\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0039\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "training:  lstm_xgb_cols  df:  13\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/132 [..............................] - ETA: 1s - loss: 7.4041e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 9ms/step - loss: 2.3482e-05 - val_loss: 0.0022\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.6332e-05 - val_loss: 0.0021\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.5927e-05 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.6868e-05 - val_loss: 0.0019\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3353e-05 - val_loss: 0.0019\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.4861e-05 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 1.4689e-05 - val_loss: 0.0018\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3518e-05 - val_loss: 0.0019\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2957e-05 - val_loss: 0.0018\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.1996e-05 - val_loss: 0.0018\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3012e-05 - val_loss: 0.0018\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2333e-05 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2206e-05 - val_loss: 0.0016\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3301e-05 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.5050e-05 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3970e-05 - val_loss: 0.0016\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.6667e-05 - val_loss: 0.0015\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3343e-05 - val_loss: 0.0015\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3644e-05 - val_loss: 0.0015\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2746e-05 - val_loss: 0.0015\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.1828e-05 - val_loss: 0.0015\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.1971e-05 - val_loss: 0.0015\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.7210e-05 - val_loss: 0.0015\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0799e-05 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2707e-05 - val_loss: 0.0015\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.6108e-05 - val_loss: 0.0015\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.5394e-05 - val_loss: 0.0015\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.5720e-05 - val_loss: 0.0015\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2075e-05 - val_loss: 0.0015\n",
            "Epoch 30/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3194e-05 - val_loss: 0.0015\n",
            "Epoch 31/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.5900e-05 - val_loss: 0.0015\n",
            "Epoch 32/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3213e-05 - val_loss: 0.0015\n",
            "Epoch 33/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3400e-05 - val_loss: 0.0014\n",
            "Epoch 34/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2224e-05 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3792e-05 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2426e-05 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.1552e-05 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2236e-05 - val_loss: 0.0015\n",
            "Epoch 39/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2827e-05 - val_loss: 0.0014\n",
            "Epoch 40/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3192e-05 - val_loss: 0.0014\n",
            "Epoch 41/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0299e-05 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1400e-05 - val_loss: 0.0014\n",
            "Epoch 43/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2161e-05 - val_loss: 0.0015\n",
            "Epoch 44/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0355e-05 - val_loss: 0.0015\n",
            "Epoch 45/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2055e-05 - val_loss: 0.0014\n",
            "Epoch 46/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2489e-05 - val_loss: 0.0015\n",
            "Epoch 47/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0395e-05 - val_loss: 0.0015\n",
            "Epoch 48/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0778e-05 - val_loss: 0.0014\n",
            "Epoch 49/200\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.3311e-05 - val_loss: 0.0015\n",
            "Epoch 50/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 2.0499e-05 - val_loss: 0.0015\n",
            "Epoch 51/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3061e-05 - val_loss: 0.0016\n",
            "Epoch 52/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2195e-05 - val_loss: 0.0016\n",
            "Epoch 53/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0961e-05 - val_loss: 0.0015\n",
            "Epoch 54/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.1563e-05 - val_loss: 0.0016\n",
            "Epoch 55/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.3884e-05 - val_loss: 0.0019\n",
            "Epoch 56/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2140e-05 - val_loss: 0.0017\n",
            "Epoch 57/200\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.2656e-05 - val_loss: 0.0017\n",
            "training:  lstm_xgb_cols  df:  14\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 8/26 [========>.....................] - ETA: 0s - loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 7.4473e-04 - val_loss: 2.7465e-04\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.9564e-04 - val_loss: 2.9593e-04\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.7204e-04 - val_loss: 5.2426e-04\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.6795e-04 - val_loss: 3.6710e-04\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3553e-04 - val_loss: 3.8890e-04\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.6243e-04 - val_loss: 3.6074e-04\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.8399e-04 - val_loss: 2.7947e-04\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.8938e-04 - val_loss: 3.8753e-04\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.7406e-04 - val_loss: 2.6947e-04\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.5911e-04 - val_loss: 3.7739e-04\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 4.1876e-04 - val_loss: 2.6346e-04\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.2590e-04 - val_loss: 7.8154e-04\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.7382e-04 - val_loss: 2.5614e-04\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.6996e-04 - val_loss: 2.7734e-04\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2156e-04 - val_loss: 2.6002e-04\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 5.0311e-04 - val_loss: 3.0078e-04\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.4070e-04 - val_loss: 2.8807e-04\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3348e-04 - val_loss: 2.5440e-04\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9536e-04 - val_loss: 2.6134e-04\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1165e-04 - val_loss: 2.6989e-04\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.0051e-04 - val_loss: 2.6548e-04\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.6176e-04 - val_loss: 4.7030e-04\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3220e-04 - val_loss: 2.5936e-04\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.4519e-04 - val_loss: 2.5606e-04\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2458e-04 - val_loss: 3.3410e-04\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1477e-04 - val_loss: 2.7447e-04\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1309e-04 - val_loss: 2.5440e-04\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.0270e-04 - val_loss: 2.7752e-04\n",
            "Epoch 30/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 3.7729e-04 - val_loss: 2.5469e-04\n",
            "Epoch 31/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2194e-04 - val_loss: 2.4892e-04\n",
            "Epoch 32/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3214e-04 - val_loss: 2.8569e-04\n",
            "Epoch 33/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.3485e-04 - val_loss: 2.8949e-04\n",
            "Epoch 34/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.4519e-04 - val_loss: 2.7596e-04\n",
            "Epoch 35/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.9203e-04 - val_loss: 6.2941e-04\n",
            "Epoch 36/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.4528e-04 - val_loss: 2.6365e-04\n",
            "Epoch 37/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1537e-04 - val_loss: 2.8278e-04\n",
            "Epoch 38/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1887e-04 - val_loss: 4.0489e-04\n",
            "Epoch 39/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 4.0377e-04 - val_loss: 2.6230e-04\n",
            "Epoch 40/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8573e-04 - val_loss: 2.6362e-04\n",
            "Epoch 41/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.5338e-04 - val_loss: 3.5709e-04\n",
            "Epoch 42/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.2605e-04 - val_loss: 3.9858e-04\n",
            "Epoch 43/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.8619e-04 - val_loss: 3.3186e-04\n",
            "Epoch 44/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9921e-04 - val_loss: 2.7140e-04\n",
            "Epoch 45/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 4.1805e-04 - val_loss: 3.1467e-04\n",
            "Epoch 46/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3.9903e-04 - val_loss: 3.7081e-04\n",
            "training:  lstm_xgb_cols  df:  15\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.9837e-06 - val_loss: 4.8003e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 6.3417e-06 - val_loss: 4.7971e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 6.1442e-06 - val_loss: 4.7606e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.6344e-06 - val_loss: 4.9999e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.6567e-06 - val_loss: 4.9323e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6002e-06 - val_loss: 5.1965e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.3758e-06 - val_loss: 5.6244e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 6.0804e-06 - val_loss: 5.1705e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3335e-06 - val_loss: 6.0749e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.1446e-06 - val_loss: 7.1529e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 6.3325e-06 - val_loss: 6.5254e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.6888e-06 - val_loss: 7.3225e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.9676e-06 - val_loss: 6.5606e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 6.9333e-06 - val_loss: 8.7588e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6294e-06 - val_loss: 6.4961e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.9781e-06 - val_loss: 7.8192e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6074e-06 - val_loss: 7.4920e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.8037e-06 - val_loss: 9.2518e-04\n",
            "training:  lstm_xgb_cols  df:  16\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 2.3052e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6515e-05 - val_loss: 0.0014\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.5462e-05 - val_loss: 0.0014\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.5903e-05 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4080e-05 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.3627e-05 - val_loss: 0.0020\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4954e-05 - val_loss: 0.0022\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4442e-05 - val_loss: 0.0025\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.3231e-05 - val_loss: 0.0026\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.5946e-05 - val_loss: 0.0029\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.4130e-05 - val_loss: 0.0028\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.3577e-05 - val_loss: 0.0034\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3758e-05 - val_loss: 0.0034\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.3822e-05 - val_loss: 0.0035\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.3108e-05 - val_loss: 0.0039\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.4446e-05 - val_loss: 0.0047\n",
            "training:  lstm_xgb_cols  df:  17\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 3s 9ms/step - loss: 1.2120e-05 - val_loss: 0.0062\n",
            "Epoch 2/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.3382e-06 - val_loss: 0.0066\n",
            "Epoch 3/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 8.4617e-06 - val_loss: 0.0073\n",
            "Epoch 4/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 8.9854e-06 - val_loss: 0.0083\n",
            "Epoch 5/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.7153e-06 - val_loss: 0.0091\n",
            "Epoch 6/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 6.0294e-06 - val_loss: 0.0090\n",
            "Epoch 7/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 5.4318e-06 - val_loss: 0.0096\n",
            "Epoch 8/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 5.5942e-06 - val_loss: 0.0108\n",
            "Epoch 9/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.2043e-06 - val_loss: 0.0130\n",
            "Epoch 10/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 5.5770e-06 - val_loss: 0.0139\n",
            "Epoch 11/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 5.3024e-06 - val_loss: 0.0147\n",
            "Epoch 12/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 5.6835e-06 - val_loss: 0.0155\n",
            "Epoch 13/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 6.4178e-06 - val_loss: 0.0163\n",
            "Epoch 14/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 4.7174e-06 - val_loss: 0.0166\n",
            "Epoch 15/200\n",
            "315/315 [==============================] - 3s 9ms/step - loss: 4.8909e-06 - val_loss: 0.0168\n",
            "Epoch 16/200\n",
            "315/315 [==============================] - 3s 8ms/step - loss: 6.0777e-06 - val_loss: 0.0194\n",
            "training:  lstm_xgb_cols  df:  18\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  8/174 [>.............................] - ETA: 1s - loss: 0.0020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 2s 9ms/step - loss: 3.9853e-04 - val_loss: 2.3482e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.5183e-04 - val_loss: 3.1167e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.3943e-04 - val_loss: 2.4313e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.3132e-04 - val_loss: 2.2693e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.2838e-04 - val_loss: 2.7402e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.2714e-04 - val_loss: 2.2424e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.3905e-04 - val_loss: 2.4497e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1222e-04 - val_loss: 2.5555e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.2402e-04 - val_loss: 3.2557e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2107e-04 - val_loss: 2.8362e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1925e-04 - val_loss: 2.2017e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.3169e-04 - val_loss: 2.5116e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.2067e-04 - val_loss: 2.4598e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.3145e-04 - val_loss: 2.3992e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.2512e-04 - val_loss: 2.4387e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.2395e-04 - val_loss: 2.2467e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1495e-04 - val_loss: 2.1473e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.1392e-04 - val_loss: 2.1824e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1611e-04 - val_loss: 2.3277e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.2306e-04 - val_loss: 2.3159e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.1921e-04 - val_loss: 2.8374e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.2475e-04 - val_loss: 2.8552e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.3093e-04 - val_loss: 2.3958e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.1392e-04 - val_loss: 2.1407e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1986e-04 - val_loss: 2.1654e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1975e-04 - val_loss: 2.4245e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1437e-04 - val_loss: 2.1080e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1641e-04 - val_loss: 2.1655e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1243e-04 - val_loss: 2.1554e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1390e-04 - val_loss: 2.3152e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1513e-04 - val_loss: 2.2307e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.1569e-04 - val_loss: 2.5745e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.1635e-04 - val_loss: 2.1533e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.1042e-04 - val_loss: 2.8102e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1480e-04 - val_loss: 2.2750e-04\n",
            "Epoch 36/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1897e-04 - val_loss: 2.3048e-04\n",
            "Epoch 37/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 2.2040e-04 - val_loss: 2.2585e-04\n",
            "Epoch 38/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1560e-04 - val_loss: 2.2115e-04\n",
            "Epoch 39/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1485e-04 - val_loss: 2.1955e-04\n",
            "Epoch 40/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.1129e-04 - val_loss: 2.1147e-04\n",
            "Epoch 41/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.1766e-04 - val_loss: 2.3029e-04\n",
            "Epoch 42/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.2002e-04 - val_loss: 2.2061e-04\n",
            "training:  lstm_xgb_cols  df:  19\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 8/47 [====>.........................] - ETA: 0s - loss: 1.4375e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 10ms/step - loss: 2.2118e-04 - val_loss: 2.3894e-04\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0833e-04 - val_loss: 2.0563e-04\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.0698e-04 - val_loss: 2.0190e-04\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.1682e-04 - val_loss: 2.6843e-04\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0539e-04 - val_loss: 2.3315e-04\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0223e-04 - val_loss: 2.5409e-04\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0898e-04 - val_loss: 2.2393e-04\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9609e-04 - val_loss: 2.0817e-04\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0928e-04 - val_loss: 2.3290e-04\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0369e-04 - val_loss: 2.1970e-04\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9056e-04 - val_loss: 2.0480e-04\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.2357e-04 - val_loss: 2.1645e-04\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0092e-04 - val_loss: 2.1012e-04\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9878e-04 - val_loss: 2.1029e-04\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.1832e-04 - val_loss: 2.4472e-04\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0260e-04 - val_loss: 2.5085e-04\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9755e-04 - val_loss: 2.1237e-04\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9325e-04 - val_loss: 2.3694e-04\n",
            "training:  lstm_xgb_cols  df:  20\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  8/151 [>.............................] - ETA: 1s - loss: 3.0880e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 1s 9ms/step - loss: 3.4633e-05 - val_loss: 3.7809e-04\n",
            "Epoch 2/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 6.6671e-06 - val_loss: 3.4866e-04\n",
            "Epoch 3/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 6.0672e-06 - val_loss: 3.5848e-04\n",
            "Epoch 4/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 5.2934e-06 - val_loss: 3.5507e-04\n",
            "Epoch 5/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.7177e-06 - val_loss: 3.5786e-04\n",
            "Epoch 6/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.8844e-06 - val_loss: 3.6014e-04\n",
            "Epoch 7/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.4777e-06 - val_loss: 3.6278e-04\n",
            "Epoch 8/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.2901e-06 - val_loss: 3.6347e-04\n",
            "Epoch 9/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.0596e-06 - val_loss: 3.6382e-04\n",
            "Epoch 10/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.0744e-06 - val_loss: 3.5464e-04\n",
            "Epoch 11/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.1051e-06 - val_loss: 3.5620e-04\n",
            "Epoch 12/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.2476e-06 - val_loss: 3.5859e-04\n",
            "Epoch 13/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.0909e-06 - val_loss: 3.4915e-04\n",
            "Epoch 14/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.1086e-06 - val_loss: 3.6238e-04\n",
            "Epoch 15/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.4472e-06 - val_loss: 3.5113e-04\n",
            "Epoch 16/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 5.6290e-06 - val_loss: 3.4515e-04\n",
            "Epoch 17/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.6212e-06 - val_loss: 3.4270e-04\n",
            "Epoch 18/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.4430e-06 - val_loss: 3.4960e-04\n",
            "Epoch 19/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.2052e-06 - val_loss: 3.4242e-04\n",
            "Epoch 20/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.7659e-06 - val_loss: 3.4056e-04\n",
            "Epoch 21/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.6148e-06 - val_loss: 3.3760e-04\n",
            "Epoch 22/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.9072e-06 - val_loss: 3.4846e-04\n",
            "Epoch 23/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.3912e-06 - val_loss: 3.4984e-04\n",
            "Epoch 24/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.0595e-06 - val_loss: 3.5704e-04\n",
            "Epoch 25/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.3340e-06 - val_loss: 3.4930e-04\n",
            "Epoch 26/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.7768e-06 - val_loss: 3.3385e-04\n",
            "Epoch 27/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.7020e-06 - val_loss: 3.8491e-04\n",
            "Epoch 28/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.2594e-06 - val_loss: 3.3632e-04\n",
            "Epoch 29/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.5428e-06 - val_loss: 3.3524e-04\n",
            "Epoch 30/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 5.2353e-06 - val_loss: 3.4508e-04\n",
            "Epoch 31/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.2191e-06 - val_loss: 3.3943e-04\n",
            "Epoch 32/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.7959e-06 - val_loss: 3.7082e-04\n",
            "Epoch 33/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.4968e-06 - val_loss: 3.3909e-04\n",
            "Epoch 34/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.9304e-06 - val_loss: 3.7134e-04\n",
            "Epoch 35/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.3231e-06 - val_loss: 3.3528e-04\n",
            "Epoch 36/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 5.3663e-06 - val_loss: 3.4185e-04\n",
            "Epoch 37/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.3593e-06 - val_loss: 3.4524e-04\n",
            "Epoch 38/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.1544e-06 - val_loss: 3.3624e-04\n",
            "Epoch 39/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.1118e-06 - val_loss: 3.4129e-04\n",
            "Epoch 40/200\n",
            "151/151 [==============================] - 1s 9ms/step - loss: 4.8858e-06 - val_loss: 4.3985e-04\n",
            "Epoch 41/200\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 4.1700e-06 - val_loss: 3.4745e-04\n",
            "training:  lstm_xgb_cols  df:  21\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/320 [..............................] - ETA: 3s - loss: 8.8957e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 9ms/step - loss: 7.3383e-05 - val_loss: 7.0819e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6710e-05 - val_loss: 4.6300e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.4725e-05 - val_loss: 5.3306e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6474e-05 - val_loss: 4.8919e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.4375e-05 - val_loss: 4.3363e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.7244e-05 - val_loss: 4.0678e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.2898e-05 - val_loss: 3.4069e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.2704e-05 - val_loss: 3.2456e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.1483e-05 - val_loss: 2.9044e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.3157e-05 - val_loss: 3.1964e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.1719e-05 - val_loss: 3.6607e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.1922e-05 - val_loss: 2.4280e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.6123e-05 - val_loss: 6.7824e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.3244e-05 - val_loss: 7.7909e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.9469e-05 - val_loss: 7.0601e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.5465e-05 - val_loss: 7.7420e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.9847e-05 - val_loss: 8.1999e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.9505e-05 - val_loss: 6.8346e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.2539e-05 - val_loss: 6.7276e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.2338e-05 - val_loss: 0.0010\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.9777e-05 - val_loss: 4.8177e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.3569e-05 - val_loss: 0.0011\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.1459e-05 - val_loss: 6.4665e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.3142e-05 - val_loss: 4.5363e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.3502e-05 - val_loss: 7.0043e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 5.1400e-05 - val_loss: 5.2196e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 5.1911e-05 - val_loss: 7.1087e-04\n",
            "training:  lstm_xgb_cols  df:  22\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 2.0663e-05 - val_loss: 0.0024\n",
            "Epoch 2/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.0494e-05 - val_loss: 0.0025\n",
            "Epoch 3/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.8800e-05 - val_loss: 0.0030\n",
            "Epoch 4/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.9744e-05 - val_loss: 0.0030\n",
            "Epoch 5/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.9527e-05 - val_loss: 0.0035\n",
            "Epoch 6/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 2.0732e-05 - val_loss: 0.0037\n",
            "Epoch 7/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.8848e-05 - val_loss: 0.0038\n",
            "Epoch 8/200\n",
            "317/317 [==============================] - 3s 8ms/step - loss: 1.8970e-05 - val_loss: 0.0038\n",
            "Epoch 9/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 2.0276e-05 - val_loss: 0.0042\n",
            "Epoch 10/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.9113e-05 - val_loss: 0.0044\n",
            "Epoch 11/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.9003e-05 - val_loss: 0.0056\n",
            "Epoch 12/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.8773e-05 - val_loss: 0.0064\n",
            "Epoch 13/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.8970e-05 - val_loss: 0.0064\n",
            "Epoch 14/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.9385e-05 - val_loss: 0.0076\n",
            "Epoch 15/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 2.0511e-05 - val_loss: 0.0092\n",
            "Epoch 16/200\n",
            "317/317 [==============================] - 3s 9ms/step - loss: 1.9178e-05 - val_loss: 0.0080\n",
            "training:  lstm_xgb_cols  df:  23\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/180 [..............................] - ETA: 1s - loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 2s 9ms/step - loss: 2.2500e-04 - val_loss: 9.5044e-06\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.6357e-04 - val_loss: 1.2131e-05\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.6287e-04 - val_loss: 1.0454e-05\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.5880e-04 - val_loss: 1.0245e-05\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.4545e-04 - val_loss: 9.9765e-06\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4686e-04 - val_loss: 1.7216e-05\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.5695e-04 - val_loss: 3.3075e-05\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.4814e-04 - val_loss: 1.9170e-05\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4457e-04 - val_loss: 1.6615e-05\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4583e-04 - val_loss: 3.2109e-05\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4582e-04 - val_loss: 2.5015e-05\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.5264e-04 - val_loss: 1.6954e-05\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4339e-04 - val_loss: 9.5538e-06\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.4976e-04 - val_loss: 6.0123e-05\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4378e-04 - val_loss: 1.3077e-05\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.5209e-04 - val_loss: 7.6776e-06\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.5069e-04 - val_loss: 8.7392e-06\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4421e-04 - val_loss: 5.8699e-05\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4613e-04 - val_loss: 1.8090e-05\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4283e-04 - val_loss: 1.0566e-05\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4770e-04 - val_loss: 9.3569e-06\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4270e-04 - val_loss: 9.7771e-06\n",
            "Epoch 23/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4142e-04 - val_loss: 2.5446e-05\n",
            "Epoch 24/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4355e-04 - val_loss: 1.5170e-05\n",
            "Epoch 25/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.4367e-04 - val_loss: 1.6156e-05\n",
            "Epoch 26/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4473e-04 - val_loss: 1.9686e-05\n",
            "Epoch 27/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3989e-04 - val_loss: 1.9494e-05\n",
            "Epoch 28/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3814e-04 - val_loss: 1.4884e-05\n",
            "Epoch 29/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4434e-04 - val_loss: 6.9355e-06\n",
            "Epoch 30/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4326e-04 - val_loss: 7.8045e-06\n",
            "Epoch 31/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3798e-04 - val_loss: 2.0036e-05\n",
            "Epoch 32/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3706e-04 - val_loss: 1.8214e-05\n",
            "Epoch 33/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4856e-04 - val_loss: 1.4240e-05\n",
            "Epoch 34/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.3854e-04 - val_loss: 8.0390e-06\n",
            "Epoch 35/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.4440e-04 - val_loss: 1.1358e-05\n",
            "Epoch 36/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3752e-04 - val_loss: 8.2527e-06\n",
            "Epoch 37/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.4133e-04 - val_loss: 2.7296e-05\n",
            "Epoch 38/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3953e-04 - val_loss: 1.1473e-05\n",
            "Epoch 39/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.3802e-04 - val_loss: 1.5800e-05\n",
            "Epoch 40/200\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 1.4053e-04 - val_loss: 9.7433e-06\n",
            "Epoch 41/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3819e-04 - val_loss: 1.0478e-04\n",
            "Epoch 42/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3986e-04 - val_loss: 9.0296e-06\n",
            "Epoch 43/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.3821e-04 - val_loss: 7.1210e-06\n",
            "Epoch 44/200\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1.4432e-04 - val_loss: 1.1759e-05\n",
            "training:  lstm_xgb_cols  df:  24\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.2502e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 9ms/step - loss: 1.3365e-04 - val_loss: 8.6566e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2941e-04 - val_loss: 8.2968e-05\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2548e-04 - val_loss: 1.2237e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2486e-04 - val_loss: 8.6652e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2493e-04 - val_loss: 9.2545e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2550e-04 - val_loss: 8.6362e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2771e-04 - val_loss: 8.4872e-05\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.3330e-04 - val_loss: 1.0894e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.3162e-04 - val_loss: 8.5569e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2173e-04 - val_loss: 9.3960e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2826e-04 - val_loss: 8.8450e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2595e-04 - val_loss: 1.0667e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2390e-04 - val_loss: 8.2617e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2017e-04 - val_loss: 9.0139e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2191e-04 - val_loss: 8.8184e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2510e-04 - val_loss: 8.7954e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2394e-04 - val_loss: 1.3278e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2511e-04 - val_loss: 8.6082e-05\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2078e-04 - val_loss: 1.0933e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1965e-04 - val_loss: 8.1611e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2160e-04 - val_loss: 9.9944e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2057e-04 - val_loss: 1.4479e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.3025e-04 - val_loss: 9.1199e-05\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2334e-04 - val_loss: 1.1031e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.3096e-04 - val_loss: 8.0783e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2030e-04 - val_loss: 1.0001e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2460e-04 - val_loss: 8.1426e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2105e-04 - val_loss: 9.5568e-05\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2709e-04 - val_loss: 8.3437e-05\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2109e-04 - val_loss: 9.9957e-05\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2469e-04 - val_loss: 1.0893e-04\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2123e-04 - val_loss: 9.7879e-05\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2113e-04 - val_loss: 1.0836e-04\n",
            "Epoch 34/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2199e-04 - val_loss: 1.0168e-04\n",
            "Epoch 35/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2075e-04 - val_loss: 8.7143e-05\n",
            "Epoch 36/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2175e-04 - val_loss: 9.9523e-05\n",
            "Epoch 37/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.2011e-04 - val_loss: 1.0207e-04\n",
            "Epoch 38/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2586e-04 - val_loss: 9.8089e-05\n",
            "Epoch 39/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2129e-04 - val_loss: 8.3126e-05\n",
            "Epoch 40/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2438e-04 - val_loss: 8.8538e-05\n",
            "training:  lstm_xgb_cols  df:  25\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 8/53 [===>..........................] - ETA: 0s - loss: 3.5312e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 1s 10ms/step - loss: 2.6169e-04 - val_loss: 3.4468e-04\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.6082e-04 - val_loss: 3.7299e-04\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.5338e-04 - val_loss: 3.5751e-04\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4238e-04 - val_loss: 3.6641e-04\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.6105e-04 - val_loss: 3.9477e-04\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4693e-04 - val_loss: 4.0554e-04\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.5420e-04 - val_loss: 4.1215e-04\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.6250e-04 - val_loss: 3.5493e-04\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.5531e-04 - val_loss: 3.5646e-04\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4314e-04 - val_loss: 3.7348e-04\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.5428e-04 - val_loss: 3.7543e-04\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.6515e-04 - val_loss: 3.8962e-04\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.7536e-04 - val_loss: 3.9408e-04\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.6163e-04 - val_loss: 3.9337e-04\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.4159e-04 - val_loss: 3.9428e-04\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 2.5325e-04 - val_loss: 3.4487e-04\n",
            "training:  lstm_xgb_cols  df:  26\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 8/58 [===>..........................] - ETA: 0s - loss: 2.4395e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 9ms/step - loss: 1.7389e-04 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5943e-04 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5184e-04 - val_loss: 0.0017\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4237e-04 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4872e-04 - val_loss: 0.0018\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5080e-04 - val_loss: 0.0017\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5256e-04 - val_loss: 0.0017\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4554e-04 - val_loss: 0.0019\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.9933e-04 - val_loss: 0.0017\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5362e-04 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4799e-04 - val_loss: 0.0017\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4867e-04 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4580e-04 - val_loss: 0.0017\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4721e-04 - val_loss: 0.0017\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4470e-04 - val_loss: 0.0018\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5476e-04 - val_loss: 0.0017\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4348e-04 - val_loss: 0.0017\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.3898e-04 - val_loss: 0.0017\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5057e-04 - val_loss: 0.0018\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.4389e-04 - val_loss: 0.0017\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.5369e-04 - val_loss: 0.0018\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5235e-04 - val_loss: 0.0018\n",
            "training:  lstm_xgb_cols  df:  27\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 7/46 [===>..........................] - ETA: 0s - loss: 2.6956e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 10ms/step - loss: 2.4082e-04 - val_loss: 6.2069e-04\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1929e-04 - val_loss: 5.0611e-04\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.3257e-04 - val_loss: 6.5947e-04\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 3.2134e-04 - val_loss: 8.1241e-04\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.5428e-04 - val_loss: 5.7312e-04\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1337e-04 - val_loss: 6.2680e-04\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1521e-04 - val_loss: 5.2972e-04\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1113e-04 - val_loss: 5.3159e-04\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.2749e-04 - val_loss: 6.5956e-04\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.2894e-04 - val_loss: 5.8751e-04\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.3360e-04 - val_loss: 6.9517e-04\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.0100e-04 - val_loss: 5.9916e-04\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.0644e-04 - val_loss: 5.2763e-04\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 2.6830e-04 - val_loss: 5.0449e-04\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.5626e-04 - val_loss: 5.2755e-04\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.3714e-04 - val_loss: 7.0603e-04\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.9330e-04 - val_loss: 6.0097e-04\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1924e-04 - val_loss: 5.6724e-04\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1934e-04 - val_loss: 5.2978e-04\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1475e-04 - val_loss: 6.4205e-04\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.4352e-04 - val_loss: 5.3932e-04\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.0840e-04 - val_loss: 6.2640e-04\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1281e-04 - val_loss: 5.6999e-04\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1482e-04 - val_loss: 5.2415e-04\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1222e-04 - val_loss: 5.3062e-04\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.0135e-04 - val_loss: 5.5775e-04\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1348e-04 - val_loss: 6.7086e-04\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.2111e-04 - val_loss: 5.7669e-04\n",
            "Epoch 29/200\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 2.1993e-04 - val_loss: 5.3896e-04\n",
            "training:  lstm_xgb_cols  df:  28\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/171 [..............................] - ETA: 1s - loss: 4.6424e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171/171 [==============================] - 1s 9ms/step - loss: 7.2660e-05 - val_loss: 7.3535e-04\n",
            "Epoch 2/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.7734e-05 - val_loss: 7.4734e-04\n",
            "Epoch 3/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.5696e-05 - val_loss: 7.6124e-04\n",
            "Epoch 4/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.5333e-05 - val_loss: 8.4225e-04\n",
            "Epoch 5/200\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 6.5868e-05 - val_loss: 8.6383e-04\n",
            "Epoch 6/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.8500e-05 - val_loss: 9.7755e-04\n",
            "Epoch 7/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.6875e-05 - val_loss: 9.5005e-04\n",
            "Epoch 8/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.4040e-05 - val_loss: 8.4307e-04\n",
            "Epoch 9/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.7221e-05 - val_loss: 8.4039e-04\n",
            "Epoch 10/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.4100e-05 - val_loss: 9.9061e-04\n",
            "Epoch 11/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.6206e-05 - val_loss: 9.6204e-04\n",
            "Epoch 12/200\n",
            "171/171 [==============================] - 2s 9ms/step - loss: 6.7363e-05 - val_loss: 9.8145e-04\n",
            "Epoch 13/200\n",
            "171/171 [==============================] - 2s 9ms/step - loss: 6.5094e-05 - val_loss: 0.0011\n",
            "Epoch 14/200\n",
            "171/171 [==============================] - 2s 9ms/step - loss: 6.8317e-05 - val_loss: 9.9151e-04\n",
            "Epoch 15/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.8372e-05 - val_loss: 9.2941e-04\n",
            "Epoch 16/200\n",
            "171/171 [==============================] - 1s 9ms/step - loss: 6.7915e-05 - val_loss: 0.0010\n",
            "training:  lstm_xgb_cols  df:  29\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.9642e-05 - val_loss: 9.1297e-04\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.8314e-05 - val_loss: 9.3219e-04\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.8337e-05 - val_loss: 9.2584e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6507e-05 - val_loss: 9.2661e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5471e-05 - val_loss: 8.6198e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.7566e-05 - val_loss: 8.6287e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5887e-05 - val_loss: 8.5232e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5705e-05 - val_loss: 8.6080e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5707e-05 - val_loss: 8.8675e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6257e-05 - val_loss: 8.3146e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5656e-05 - val_loss: 8.0988e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6147e-05 - val_loss: 7.6603e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5653e-05 - val_loss: 7.5853e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4921e-05 - val_loss: 7.9212e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5952e-05 - val_loss: 8.0185e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5366e-05 - val_loss: 7.7615e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5647e-05 - val_loss: 7.9653e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4441e-05 - val_loss: 7.7610e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5233e-05 - val_loss: 7.9403e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5854e-05 - val_loss: 7.5481e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5099e-05 - val_loss: 7.7620e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5619e-05 - val_loss: 7.8741e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6598e-05 - val_loss: 7.3974e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6672e-05 - val_loss: 7.9670e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.7292e-05 - val_loss: 7.4919e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5640e-05 - val_loss: 7.7619e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.7542e-05 - val_loss: 7.3037e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6816e-05 - val_loss: 7.1771e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4387e-05 - val_loss: 7.3067e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5892e-05 - val_loss: 7.1257e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4300e-05 - val_loss: 7.5453e-04\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4899e-05 - val_loss: 8.1482e-04\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6303e-05 - val_loss: 7.5547e-04\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6186e-05 - val_loss: 7.7971e-04\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5677e-05 - val_loss: 8.0659e-04\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5205e-05 - val_loss: 8.2035e-04\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5840e-05 - val_loss: 8.5329e-04\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6161e-05 - val_loss: 8.9116e-04\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4842e-05 - val_loss: 8.8370e-04\n",
            "Epoch 40/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4610e-05 - val_loss: 8.8819e-04\n",
            "Epoch 41/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 1.5455e-05 - val_loss: 9.3194e-04\n",
            "Epoch 42/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5744e-05 - val_loss: 0.0010\n",
            "Epoch 43/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5634e-05 - val_loss: 0.0010\n",
            "Epoch 44/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4557e-05 - val_loss: 0.0011\n",
            "Epoch 45/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5040e-05 - val_loss: 0.0010\n",
            "training:  lstm_xgb_cols  df:  30\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  8/116 [=>............................] - ETA: 0s - loss: 1.8615e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6450e-05 - val_loss: 0.0010\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.5249e-05 - val_loss: 0.0012\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4726e-05 - val_loss: 0.0012\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4701e-05 - val_loss: 0.0012\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4703e-05 - val_loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4662e-05 - val_loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4859e-05 - val_loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.8934e-05 - val_loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4722e-05 - val_loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.6447e-05 - val_loss: 0.0014\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4838e-05 - val_loss: 0.0015\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4899e-05 - val_loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4831e-05 - val_loss: 0.0014\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4268e-05 - val_loss: 0.0016\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4648e-05 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 1.4409e-05 - val_loss: 0.0017\n",
            "training:  lstm_xgb_cols  df:  31\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 7.6985e-05 - val_loss: 4.3314e-05\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 6.2164e-05 - val_loss: 3.4058e-05\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.6728e-05 - val_loss: 3.7961e-05\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.5503e-05 - val_loss: 4.8734e-05\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0823e-05 - val_loss: 5.1258e-05\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.3924e-05 - val_loss: 3.7885e-05\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.1220e-05 - val_loss: 4.3524e-05\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.3708e-05 - val_loss: 3.5728e-05\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.3319e-05 - val_loss: 3.2786e-05\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.3767e-05 - val_loss: 5.0651e-05\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.2628e-05 - val_loss: 5.2601e-05\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.1296e-05 - val_loss: 9.3236e-05\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.7314e-05 - val_loss: 3.8849e-05\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.3269e-05 - val_loss: 4.1199e-05\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.1304e-05 - val_loss: 4.0461e-05\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.1921e-05 - val_loss: 3.9983e-05\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.2976e-05 - val_loss: 3.5936e-05\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2491e-05 - val_loss: 3.0071e-05\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.4055e-05 - val_loss: 3.4613e-05\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.1428e-05 - val_loss: 3.2154e-05\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.4387e-05 - val_loss: 4.1257e-05\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.4482e-05 - val_loss: 4.8401e-05\n",
            "Epoch 23/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.4188e-05 - val_loss: 4.0232e-05\n",
            "Epoch 24/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.1877e-05 - val_loss: 7.2442e-05\n",
            "Epoch 25/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.3464e-05 - val_loss: 7.1356e-05\n",
            "Epoch 26/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3052e-05 - val_loss: 3.2020e-05\n",
            "Epoch 27/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.1032e-05 - val_loss: 3.2865e-05\n",
            "Epoch 28/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2564e-05 - val_loss: 3.1223e-05\n",
            "Epoch 29/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.0945e-05 - val_loss: 8.0556e-05\n",
            "Epoch 30/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.1319e-05 - val_loss: 5.1272e-05\n",
            "Epoch 31/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.2466e-05 - val_loss: 1.0847e-04\n",
            "Epoch 32/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 5.3049e-05 - val_loss: 6.9819e-05\n",
            "Epoch 33/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 5.0932e-05 - val_loss: 4.9434e-05\n",
            "training:  lstm_xgb_cols  df:  32\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.8143e-05 - val_loss: 1.3097e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7620e-05 - val_loss: 1.2959e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.8205e-05 - val_loss: 1.2763e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6853e-05 - val_loss: 1.5133e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8291e-05 - val_loss: 1.4266e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.8594e-05 - val_loss: 1.3817e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6945e-05 - val_loss: 1.3012e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.6978e-05 - val_loss: 1.8187e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.8877e-05 - val_loss: 1.6756e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7661e-05 - val_loss: 1.8516e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7700e-05 - val_loss: 4.1861e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.5865e-05 - val_loss: 3.6165e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7950e-05 - val_loss: 2.6807e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7487e-05 - val_loss: 3.4854e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.7569e-05 - val_loss: 3.2468e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.6080e-05 - val_loss: 3.3493e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 1.7320e-05 - val_loss: 3.3651e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 1.6576e-05 - val_loss: 5.1299e-04\n",
            "training:  lstm_xgb_cols  df:  33\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/208 [..............................] - ETA: 2s - loss: 7.8456e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208/208 [==============================] - 2s 9ms/step - loss: 1.0978e-04 - val_loss: 3.4039e-04\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 9.3592e-05 - val_loss: 2.0273e-04\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 9.7471e-05 - val_loss: 2.0356e-04\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 9.3700e-05 - val_loss: 1.3370e-04\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 9.5709e-05 - val_loss: 1.6072e-04\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.7597e-05 - val_loss: 1.6230e-04\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.7718e-05 - val_loss: 2.2517e-04\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.5257e-05 - val_loss: 3.7570e-04\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.5769e-05 - val_loss: 1.8626e-04\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.7190e-05 - val_loss: 1.7500e-04\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.3089e-05 - val_loss: 1.6410e-04\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.3554e-05 - val_loss: 1.7939e-04\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 9.2625e-05 - val_loss: 1.3627e-04\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.4431e-05 - val_loss: 1.7721e-04\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 2s 8ms/step - loss: 8.2309e-05 - val_loss: 2.4534e-04\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 9.7603e-05 - val_loss: 1.8002e-04\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.6996e-05 - val_loss: 1.4157e-04\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.1578e-05 - val_loss: 1.5571e-04\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.5531e-05 - val_loss: 2.2893e-04\n",
            "training:  lstm_xgb_cols  df:  34\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6953e-05 - val_loss: 3.2702e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4704e-05 - val_loss: 3.1404e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.5153e-05 - val_loss: 3.2562e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5303e-05 - val_loss: 2.8767e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.6637e-05 - val_loss: 3.6704e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5218e-05 - val_loss: 2.9792e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5175e-05 - val_loss: 2.5202e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6831e-05 - val_loss: 3.1356e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4908e-05 - val_loss: 2.7393e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5286e-05 - val_loss: 3.1202e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5490e-05 - val_loss: 3.0507e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5234e-05 - val_loss: 3.2413e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6429e-05 - val_loss: 3.6376e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5855e-05 - val_loss: 3.9109e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4905e-05 - val_loss: 4.3978e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4762e-05 - val_loss: 4.7623e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4972e-05 - val_loss: 5.4606e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.8976e-05 - val_loss: 5.3694e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4674e-05 - val_loss: 5.0017e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.3948e-05 - val_loss: 5.4900e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5255e-05 - val_loss: 6.2176e-04\n",
            "Epoch 22/200\n",
            "270/270 [==============================] - 2s 8ms/step - loss: 1.4703e-05 - val_loss: 5.7650e-04\n",
            "training:  lstm_xgb_cols  df:  35\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314/314 [==============================] - 3s 9ms/step - loss: 2.4406e-05 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.0251e-05 - val_loss: 0.0021\n",
            "Epoch 3/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.1063e-05 - val_loss: 0.0020\n",
            "Epoch 4/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.0374e-05 - val_loss: 0.0017\n",
            "Epoch 5/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.0243e-05 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.1693e-05 - val_loss: 0.0031\n",
            "Epoch 7/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.0425e-05 - val_loss: 0.0025\n",
            "Epoch 8/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.1378e-05 - val_loss: 0.0026\n",
            "Epoch 9/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.0842e-05 - val_loss: 0.0022\n",
            "Epoch 10/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.0143e-05 - val_loss: 0.0026\n",
            "Epoch 11/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.0104e-05 - val_loss: 0.0028\n",
            "Epoch 12/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.1059e-05 - val_loss: 0.0026\n",
            "Epoch 13/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.1132e-05 - val_loss: 0.0028\n",
            "Epoch 14/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.0613e-05 - val_loss: 0.0027\n",
            "Epoch 15/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.1675e-05 - val_loss: 0.0029\n",
            "Epoch 16/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.0082e-05 - val_loss: 0.0030\n",
            "Epoch 17/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 1.9078e-05 - val_loss: 0.0041\n",
            "Epoch 18/200\n",
            "314/314 [==============================] - 3s 9ms/step - loss: 2.0513e-05 - val_loss: 0.0039\n",
            "Epoch 19/200\n",
            "314/314 [==============================] - 3s 8ms/step - loss: 2.0028e-05 - val_loss: 0.0039\n",
            "training:  lstm_xgb_cols  df:  36\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  8/118 [=>............................] - ETA: 0s - loss: 3.7309e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 1s 9ms/step - loss: 4.2777e-05 - val_loss: 0.0017\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.4010e-05 - val_loss: 0.0018\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.2477e-05 - val_loss: 0.0019\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.9400e-05 - val_loss: 0.0020\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.2982e-05 - val_loss: 0.0022\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.0018e-05 - val_loss: 0.0022\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.9845e-05 - val_loss: 0.0024\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.3225e-05 - val_loss: 0.0023\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.2721e-05 - val_loss: 0.0023\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.8882e-05 - val_loss: 0.0024\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.8011e-05 - val_loss: 0.0025\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 4.0998e-05 - val_loss: 0.0021\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.8761e-05 - val_loss: 0.0021\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.9749e-05 - val_loss: 0.0021\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.8917e-05 - val_loss: 0.0026\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 3.7601e-05 - val_loss: 0.0024\n",
            "training:  lstm_xgb_cols  df:  37\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/188 [..............................] - ETA: 2s - loss: 3.8878e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 2s 9ms/step - loss: 2.6106e-05 - val_loss: 0.0024\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.3982e-05 - val_loss: 0.0026\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4425e-05 - val_loss: 0.0026\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4502e-05 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4621e-05 - val_loss: 0.0025\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4333e-05 - val_loss: 0.0027\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4350e-05 - val_loss: 0.0027\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4160e-05 - val_loss: 0.0028\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.5430e-05 - val_loss: 0.0026\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.6177e-05 - val_loss: 0.0033\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4900e-05 - val_loss: 0.0031\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.3877e-05 - val_loss: 0.0031\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4463e-05 - val_loss: 0.0025\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4660e-05 - val_loss: 0.0027\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.5779e-05 - val_loss: 0.0027\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.6158e-05 - val_loss: 0.0027\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4642e-05 - val_loss: 0.0030\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.4694e-05 - val_loss: 0.0031\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.7308e-05 - val_loss: 0.0033\n",
            "training:  lstm_xgb_cols  df:  38\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 8/99 [=>............................] - ETA: 0s - loss: 7.2072e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 9ms/step - loss: 2.7283e-04 - val_loss: 7.5429e-04\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 2.0941e-04 - val_loss: 5.3414e-04\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.7395e-04 - val_loss: 4.9431e-04\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.7067e-04 - val_loss: 5.1687e-04\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.7173e-04 - val_loss: 4.9739e-04\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.7282e-04 - val_loss: 4.9650e-04\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6385e-04 - val_loss: 5.0751e-04\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6844e-04 - val_loss: 4.8499e-04\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.7403e-04 - val_loss: 4.8446e-04\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6922e-04 - val_loss: 4.9091e-04\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6592e-04 - val_loss: 4.8339e-04\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6735e-04 - val_loss: 4.8224e-04\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6479e-04 - val_loss: 4.8139e-04\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6187e-04 - val_loss: 5.3381e-04\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6764e-04 - val_loss: 4.7904e-04\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6495e-04 - val_loss: 4.8593e-04\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6069e-04 - val_loss: 4.8304e-04\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6704e-04 - val_loss: 4.7901e-04\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6099e-04 - val_loss: 4.9380e-04\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5901e-04 - val_loss: 5.0713e-04\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6192e-04 - val_loss: 4.8273e-04\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6310e-04 - val_loss: 4.8355e-04\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6499e-04 - val_loss: 4.8141e-04\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5930e-04 - val_loss: 5.5273e-04\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6635e-04 - val_loss: 4.8743e-04\n",
            "Epoch 26/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6784e-04 - val_loss: 4.9483e-04\n",
            "Epoch 27/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.7187e-04 - val_loss: 5.0749e-04\n",
            "Epoch 28/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6537e-04 - val_loss: 4.7512e-04\n",
            "Epoch 29/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5945e-04 - val_loss: 4.9388e-04\n",
            "Epoch 30/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6557e-04 - val_loss: 4.9482e-04\n",
            "Epoch 31/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5979e-04 - val_loss: 4.7385e-04\n",
            "Epoch 32/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5810e-04 - val_loss: 4.8291e-04\n",
            "Epoch 33/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6134e-04 - val_loss: 5.0403e-04\n",
            "Epoch 34/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6579e-04 - val_loss: 4.6864e-04\n",
            "Epoch 35/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5943e-04 - val_loss: 4.9633e-04\n",
            "Epoch 36/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6367e-04 - val_loss: 5.0577e-04\n",
            "Epoch 37/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 1.6277e-04 - val_loss: 5.3832e-04\n",
            "Epoch 38/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6511e-04 - val_loss: 4.6743e-04\n",
            "Epoch 39/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6356e-04 - val_loss: 4.7639e-04\n",
            "Epoch 40/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6040e-04 - val_loss: 4.7018e-04\n",
            "Epoch 41/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5732e-04 - val_loss: 4.8605e-04\n",
            "Epoch 42/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5878e-04 - val_loss: 4.6880e-04\n",
            "Epoch 43/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6178e-04 - val_loss: 4.8195e-04\n",
            "Epoch 44/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6156e-04 - val_loss: 4.8120e-04\n",
            "Epoch 45/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5928e-04 - val_loss: 4.8296e-04\n",
            "Epoch 46/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6433e-04 - val_loss: 5.0895e-04\n",
            "Epoch 47/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6667e-04 - val_loss: 5.0781e-04\n",
            "Epoch 48/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5980e-04 - val_loss: 4.7639e-04\n",
            "Epoch 49/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6292e-04 - val_loss: 5.2861e-04\n",
            "Epoch 50/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.5538e-04 - val_loss: 4.7761e-04\n",
            "Epoch 51/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6195e-04 - val_loss: 4.8245e-04\n",
            "Epoch 52/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6299e-04 - val_loss: 5.3219e-04\n",
            "Epoch 53/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 1.6569e-04 - val_loss: 4.7900e-04\n",
            "training:  lstm_xgb_cols  df:  39\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 3s - loss: 3.1860e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 9ms/step - loss: 2.9383e-05 - val_loss: 2.2514e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7015e-05 - val_loss: 2.6430e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.7752e-05 - val_loss: 1.9240e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.6439e-05 - val_loss: 1.8920e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.6380e-05 - val_loss: 2.6020e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7712e-05 - val_loss: 2.4755e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.7467e-05 - val_loss: 2.1344e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.6692e-05 - val_loss: 1.9494e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.6459e-05 - val_loss: 2.0720e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.9023e-05 - val_loss: 2.0368e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 2.7755e-05 - val_loss: 2.0993e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.7816e-05 - val_loss: 2.8360e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.9283e-05 - val_loss: 8.1174e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 3.1983e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 5.2846e-05 - val_loss: 0.0014\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 3.3997e-05 - val_loss: 0.0013\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 3.0238e-05 - val_loss: 0.0012\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 2.9855e-05 - val_loss: 0.0011\n",
            "Epoch 19/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 3.0844e-05 - val_loss: 0.0012\n",
            "training:  lstm_xgb_cols  df:  40\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  7/153 [>.............................] - ETA: 1s - loss: 6.6140e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 9ms/step - loss: 3.7468e-05 - val_loss: 5.3548e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.5238e-05 - val_loss: 5.6516e-04\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1782e-05 - val_loss: 5.5951e-04\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.4670e-05 - val_loss: 5.5852e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.2002e-05 - val_loss: 6.2116e-04\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1424e-05 - val_loss: 6.3678e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.3035e-05 - val_loss: 6.0879e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0915e-05 - val_loss: 6.6089e-04\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1049e-05 - val_loss: 6.6833e-04\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0238e-05 - val_loss: 7.6257e-04\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1074e-05 - val_loss: 7.0469e-04\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0091e-05 - val_loss: 7.7669e-04\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0419e-05 - val_loss: 7.3927e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.2237e-05 - val_loss: 8.6882e-04\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1160e-05 - val_loss: 8.7645e-04\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1535e-05 - val_loss: 7.5904e-04\n",
            "training:  lstm_xgb_cols  df:  41\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  8/153 [>.............................] - ETA: 1s - loss: 3.8900e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1789e-05 - val_loss: 8.8232e-04\n",
            "Epoch 2/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 2.9567e-05 - val_loss: 0.0010\n",
            "Epoch 3/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.2217e-05 - val_loss: 0.0011\n",
            "Epoch 4/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.2139e-05 - val_loss: 9.6154e-04\n",
            "Epoch 5/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 2.9354e-05 - val_loss: 0.0010\n",
            "Epoch 6/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1375e-05 - val_loss: 9.8958e-04\n",
            "Epoch 7/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0379e-05 - val_loss: 9.7620e-04\n",
            "Epoch 8/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1068e-05 - val_loss: 0.0011\n",
            "Epoch 9/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.3276e-05 - val_loss: 0.0011\n",
            "Epoch 10/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0455e-05 - val_loss: 0.0013\n",
            "Epoch 11/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.2102e-05 - val_loss: 0.0011\n",
            "Epoch 12/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.3166e-05 - val_loss: 0.0011\n",
            "Epoch 13/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0682e-05 - val_loss: 9.9022e-04\n",
            "Epoch 14/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.0188e-05 - val_loss: 0.0012\n",
            "Epoch 15/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1704e-05 - val_loss: 0.0012\n",
            "Epoch 16/200\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 3.1526e-05 - val_loss: 0.0011\n",
            "training:  lstm_xgb_cols  df:  42\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.4199e-05 - val_loss: 7.8651e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.2209e-05 - val_loss: 7.4595e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9333e-05 - val_loss: 8.2528e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.0846e-05 - val_loss: 8.4061e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8573e-05 - val_loss: 7.7812e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.0353e-05 - val_loss: 8.2719e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8824e-05 - val_loss: 6.7880e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.0749e-05 - val_loss: 8.3124e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9128e-05 - val_loss: 7.7663e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9350e-05 - val_loss: 6.8257e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.0312e-05 - val_loss: 6.1627e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0506e-05 - val_loss: 9.5397e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9911e-05 - val_loss: 9.0890e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9982e-05 - val_loss: 8.4899e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0277e-05 - val_loss: 8.2639e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0530e-05 - val_loss: 5.9643e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.1683e-05 - val_loss: 6.0146e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.8617e-05 - val_loss: 5.4202e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.8256e-05 - val_loss: 4.2896e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.8670e-05 - val_loss: 5.4224e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.0033e-05 - val_loss: 4.3777e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9843e-05 - val_loss: 4.5224e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0063e-05 - val_loss: 4.6059e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9076e-05 - val_loss: 5.2346e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 3.0628e-05 - val_loss: 4.2091e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9507e-05 - val_loss: 4.7841e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.8793e-05 - val_loss: 5.1928e-04\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9033e-05 - val_loss: 5.4181e-04\n",
            "Epoch 29/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9437e-05 - val_loss: 6.7130e-04\n",
            "Epoch 30/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.1231e-05 - val_loss: 6.3226e-04\n",
            "Epoch 31/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.7986e-05 - val_loss: 5.1628e-04\n",
            "Epoch 32/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.7661e-05 - val_loss: 5.6959e-04\n",
            "Epoch 33/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9526e-05 - val_loss: 5.9052e-04\n",
            "Epoch 34/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.9964e-05 - val_loss: 6.1085e-04\n",
            "Epoch 35/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9363e-05 - val_loss: 5.6096e-04\n",
            "Epoch 36/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8813e-05 - val_loss: 5.9368e-04\n",
            "Epoch 37/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.8460e-05 - val_loss: 5.5717e-04\n",
            "Epoch 38/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.0057e-05 - val_loss: 5.5361e-04\n",
            "Epoch 39/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 2.9014e-05 - val_loss: 5.2753e-04\n",
            "Epoch 40/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 2.8493e-05 - val_loss: 5.1661e-04\n",
            "training:  lstm_xgb_cols  df:  43\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 7/64 [==>...........................] - ETA: 0s - loss: 5.3645e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 9ms/step - loss: 4.1729e-04 - val_loss: 6.5084e-04\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.5129e-04 - val_loss: 5.9638e-04\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.7467e-04 - val_loss: 6.3535e-04\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.3623e-04 - val_loss: 6.8278e-04\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 3.4173e-04 - val_loss: 6.8216e-04\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 3.3021e-04 - val_loss: 6.3704e-04\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2788e-04 - val_loss: 6.2855e-04\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.3262e-04 - val_loss: 6.9972e-04\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.3814e-04 - val_loss: 7.4185e-04\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.4062e-04 - val_loss: 6.5995e-04\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2131e-04 - val_loss: 6.6996e-04\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2095e-04 - val_loss: 7.0515e-04\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2570e-04 - val_loss: 7.5671e-04\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2483e-04 - val_loss: 6.9165e-04\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1635e-04 - val_loss: 6.2724e-04\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2464e-04 - val_loss: 6.3557e-04\n",
            "Epoch 17/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.3094e-04 - val_loss: 7.6390e-04\n",
            "training:  lstm_xgb_cols  df:  44\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/271 [..............................] - ETA: 3s - loss: 8.6298e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 2s 9ms/step - loss: 1.5255e-04 - val_loss: 1.8859e-04\n",
            "Epoch 2/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4894e-04 - val_loss: 1.8227e-04\n",
            "Epoch 3/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4409e-04 - val_loss: 1.8587e-04\n",
            "Epoch 4/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4791e-04 - val_loss: 1.7835e-04\n",
            "Epoch 5/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4462e-04 - val_loss: 1.8785e-04\n",
            "Epoch 6/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4541e-04 - val_loss: 2.0500e-04\n",
            "Epoch 7/200\n",
            "271/271 [==============================] - 2s 8ms/step - loss: 1.4140e-04 - val_loss: 2.4212e-04\n",
            "Epoch 8/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4722e-04 - val_loss: 2.5268e-04\n",
            "Epoch 9/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.5029e-04 - val_loss: 1.9818e-04\n",
            "Epoch 10/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.3989e-04 - val_loss: 2.1327e-04\n",
            "Epoch 11/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4244e-04 - val_loss: 1.8461e-04\n",
            "Epoch 12/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.3897e-04 - val_loss: 2.0262e-04\n",
            "Epoch 13/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4392e-04 - val_loss: 1.8463e-04\n",
            "Epoch 14/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4568e-04 - val_loss: 1.7957e-04\n",
            "Epoch 15/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4404e-04 - val_loss: 2.1624e-04\n",
            "Epoch 16/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4174e-04 - val_loss: 2.0115e-04\n",
            "Epoch 17/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4071e-04 - val_loss: 1.8681e-04\n",
            "Epoch 18/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4062e-04 - val_loss: 1.8371e-04\n",
            "Epoch 19/200\n",
            "271/271 [==============================] - 2s 9ms/step - loss: 1.4648e-04 - val_loss: 2.1743e-04\n",
            "training:  lstm_xgb_cols  df:  45\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  7/174 [>.............................] - ETA: 1s - loss: 1.9318e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174/174 [==============================] - 2s 9ms/step - loss: 2.0662e-04 - val_loss: 2.4345e-04\n",
            "Epoch 2/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9956e-04 - val_loss: 2.1738e-04\n",
            "Epoch 3/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.0511e-04 - val_loss: 2.1637e-04\n",
            "Epoch 4/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9054e-04 - val_loss: 2.2091e-04\n",
            "Epoch 5/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9951e-04 - val_loss: 2.5006e-04\n",
            "Epoch 6/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9699e-04 - val_loss: 2.1131e-04\n",
            "Epoch 7/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9748e-04 - val_loss: 2.3444e-04\n",
            "Epoch 8/200\n",
            "174/174 [==============================] - 1s 8ms/step - loss: 1.9020e-04 - val_loss: 2.1742e-04\n",
            "Epoch 9/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9706e-04 - val_loss: 2.2487e-04\n",
            "Epoch 10/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 2.0024e-04 - val_loss: 2.3203e-04\n",
            "Epoch 11/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 2.0182e-04 - val_loss: 2.2330e-04\n",
            "Epoch 12/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9906e-04 - val_loss: 2.0699e-04\n",
            "Epoch 13/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9445e-04 - val_loss: 2.0328e-04\n",
            "Epoch 14/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.8837e-04 - val_loss: 2.2042e-04\n",
            "Epoch 15/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9393e-04 - val_loss: 2.2273e-04\n",
            "Epoch 16/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9152e-04 - val_loss: 2.0754e-04\n",
            "Epoch 17/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9182e-04 - val_loss: 2.2787e-04\n",
            "Epoch 18/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9855e-04 - val_loss: 2.1767e-04\n",
            "Epoch 19/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9473e-04 - val_loss: 2.1561e-04\n",
            "Epoch 20/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9344e-04 - val_loss: 2.0526e-04\n",
            "Epoch 21/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9122e-04 - val_loss: 2.2555e-04\n",
            "Epoch 22/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9447e-04 - val_loss: 2.0774e-04\n",
            "Epoch 23/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9378e-04 - val_loss: 2.0169e-04\n",
            "Epoch 24/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9091e-04 - val_loss: 2.1309e-04\n",
            "Epoch 25/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9458e-04 - val_loss: 2.0531e-04\n",
            "Epoch 26/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9552e-04 - val_loss: 2.0965e-04\n",
            "Epoch 27/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9065e-04 - val_loss: 2.1226e-04\n",
            "Epoch 28/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9409e-04 - val_loss: 2.2481e-04\n",
            "Epoch 29/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.8948e-04 - val_loss: 2.0179e-04\n",
            "Epoch 30/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.8988e-04 - val_loss: 2.0613e-04\n",
            "Epoch 31/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9609e-04 - val_loss: 2.2239e-04\n",
            "Epoch 32/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9182e-04 - val_loss: 2.0516e-04\n",
            "Epoch 33/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.8969e-04 - val_loss: 2.0272e-04\n",
            "Epoch 34/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.8769e-04 - val_loss: 2.0434e-04\n",
            "Epoch 35/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.8791e-04 - val_loss: 2.2948e-04\n",
            "Epoch 36/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.9188e-04 - val_loss: 2.4233e-04\n",
            "Epoch 37/200\n",
            "174/174 [==============================] - 2s 9ms/step - loss: 1.8941e-04 - val_loss: 2.0790e-04\n",
            "Epoch 38/200\n",
            "174/174 [==============================] - 1s 9ms/step - loss: 1.9065e-04 - val_loss: 2.1800e-04\n",
            "training:  lstm_xgb_cols  df:  46\n",
            "Training model: lstm_xgb_cols  features: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.8232e-05 - val_loss: 1.1580e-04\n",
            "Epoch 2/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.6256e-05 - val_loss: 1.0785e-04\n",
            "Epoch 3/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.4494e-05 - val_loss: 1.1634e-04\n",
            "Epoch 4/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.7154e-05 - val_loss: 1.2367e-04\n",
            "Epoch 5/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.8238e-05 - val_loss: 1.1770e-04\n",
            "Epoch 6/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 9.0624e-05 - val_loss: 1.0940e-04\n",
            "Epoch 7/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.6445e-05 - val_loss: 1.0769e-04\n",
            "Epoch 8/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.6916e-05 - val_loss: 1.1686e-04\n",
            "Epoch 9/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.5609e-05 - val_loss: 1.2788e-04\n",
            "Epoch 10/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.5805e-05 - val_loss: 1.3511e-04\n",
            "Epoch 11/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.5829e-05 - val_loss: 1.1040e-04\n",
            "Epoch 12/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.8466e-05 - val_loss: 1.0922e-04\n",
            "Epoch 13/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.6433e-05 - val_loss: 1.2302e-04\n",
            "Epoch 14/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.8368e-05 - val_loss: 1.2504e-04\n",
            "Epoch 15/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.6212e-05 - val_loss: 1.0798e-04\n",
            "Epoch 16/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.6566e-05 - val_loss: 1.0989e-04\n",
            "Epoch 17/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.9400e-05 - val_loss: 1.2813e-04\n",
            "Epoch 18/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 8.7997e-05 - val_loss: 1.1580e-04\n",
            "Epoch 19/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.6137e-05 - val_loss: 1.9965e-04\n",
            "Epoch 20/200\n",
            "385/385 [==============================] - 3s 8ms/step - loss: 9.1159e-05 - val_loss: 1.2152e-04\n",
            "Epoch 21/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.7523e-05 - val_loss: 1.1241e-04\n",
            "Epoch 22/200\n",
            "385/385 [==============================] - 3s 9ms/step - loss: 8.7103e-05 - val_loss: 1.1503e-04\n",
            "training:  lstm_xgb_cols  df:  47\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 1.6648e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 9ms/step - loss: 1.3194e-04 - val_loss: 1.6705e-04\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2498e-04 - val_loss: 2.5269e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2588e-04 - val_loss: 3.3024e-04\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2256e-04 - val_loss: 1.8318e-04\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2196e-04 - val_loss: 1.9047e-04\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2213e-04 - val_loss: 1.9216e-04\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2117e-04 - val_loss: 1.6863e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2608e-04 - val_loss: 3.0079e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2249e-04 - val_loss: 2.8140e-04\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2316e-04 - val_loss: 2.2598e-04\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2271e-04 - val_loss: 2.7436e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2010e-04 - val_loss: 1.7388e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2120e-04 - val_loss: 2.3012e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1864e-04 - val_loss: 1.9036e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2097e-04 - val_loss: 2.0589e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1834e-04 - val_loss: 3.8176e-04\n",
            "training:  lstm_xgb_cols  df:  48\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/247 [..............................] - ETA: 2s - loss: 3.2016e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1779e-04 - val_loss: 8.1130e-05\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1821e-04 - val_loss: 1.0125e-04\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1352e-04 - val_loss: 9.0836e-05\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1107e-04 - val_loss: 8.3816e-05\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1093e-04 - val_loss: 8.0632e-05\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1022e-04 - val_loss: 8.3011e-05\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1275e-04 - val_loss: 1.3298e-04\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1805e-04 - val_loss: 1.0053e-04\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1379e-04 - val_loss: 8.6246e-05\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1251e-04 - val_loss: 8.0562e-05\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1221e-04 - val_loss: 8.5655e-05\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1374e-04 - val_loss: 8.3209e-05\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1017e-04 - val_loss: 7.8832e-05\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1141e-04 - val_loss: 7.9527e-05\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1277e-04 - val_loss: 8.1806e-05\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.1315e-04 - val_loss: 9.2996e-05\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1708e-04 - val_loss: 9.3604e-05\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1139e-04 - val_loss: 1.0652e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1160e-04 - val_loss: 8.1858e-05\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1174e-04 - val_loss: 8.5595e-05\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1053e-04 - val_loss: 9.9801e-05\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1327e-04 - val_loss: 8.0374e-05\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1234e-04 - val_loss: 1.1110e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1272e-04 - val_loss: 8.8908e-05\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1038e-04 - val_loss: 9.6561e-05\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1105e-04 - val_loss: 8.8506e-05\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1117e-04 - val_loss: 7.7920e-05\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1515e-04 - val_loss: 7.9196e-05\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1336e-04 - val_loss: 9.6938e-05\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1131e-04 - val_loss: 9.0799e-05\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.2334e-04 - val_loss: 9.3631e-05\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.0816e-04 - val_loss: 1.0496e-04\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1304e-04 - val_loss: 8.2614e-05\n",
            "Epoch 34/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.0722e-04 - val_loss: 7.8914e-05\n",
            "Epoch 35/200\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.0663e-04 - val_loss: 8.1700e-05\n",
            "Epoch 36/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.0823e-04 - val_loss: 7.8835e-05\n",
            "Epoch 37/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1033e-04 - val_loss: 8.6374e-05\n",
            "Epoch 38/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1191e-04 - val_loss: 9.2065e-05\n",
            "Epoch 39/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.0860e-04 - val_loss: 7.9363e-05\n",
            "Epoch 40/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1021e-04 - val_loss: 7.8152e-05\n",
            "Epoch 41/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.1100e-04 - val_loss: 9.0295e-05\n",
            "Epoch 42/200\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.0990e-04 - val_loss: 7.9734e-05\n",
            "training:  lstm_xgb_cols  df:  49\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  1/236 [..............................] - ETA: 2s - loss: 7.7210e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 2s 9ms/step - loss: 8.7370e-05 - val_loss: 1.0521e-04\n",
            "Epoch 2/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6763e-05 - val_loss: 1.1104e-04\n",
            "Epoch 3/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.6550e-05 - val_loss: 1.1348e-04\n",
            "Epoch 4/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.6055e-05 - val_loss: 1.2925e-04\n",
            "Epoch 5/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.1818e-05 - val_loss: 1.0329e-04\n",
            "Epoch 6/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.9284e-05 - val_loss: 1.0653e-04\n",
            "Epoch 7/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.3527e-05 - val_loss: 1.4428e-04\n",
            "Epoch 8/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.8445e-05 - val_loss: 1.2167e-04\n",
            "Epoch 9/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.6214e-05 - val_loss: 1.4147e-04\n",
            "Epoch 10/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.6034e-05 - val_loss: 1.0439e-04\n",
            "Epoch 11/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.7751e-05 - val_loss: 1.0919e-04\n",
            "Epoch 12/200\n",
            "236/236 [==============================] - 2s 8ms/step - loss: 8.9448e-05 - val_loss: 1.0095e-04\n",
            "Epoch 13/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.3803e-05 - val_loss: 1.0585e-04\n",
            "Epoch 14/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.4263e-05 - val_loss: 1.0395e-04\n",
            "Epoch 15/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.2997e-05 - val_loss: 1.0839e-04\n",
            "Epoch 16/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.3834e-05 - val_loss: 1.0415e-04\n",
            "Epoch 17/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.3472e-05 - val_loss: 1.0667e-04\n",
            "Epoch 18/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.7884e-05 - val_loss: 1.0271e-04\n",
            "Epoch 19/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.4708e-05 - val_loss: 1.0429e-04\n",
            "Epoch 20/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.6884e-05 - val_loss: 1.0405e-04\n",
            "Epoch 21/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.5755e-05 - val_loss: 1.0638e-04\n",
            "Epoch 22/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.2329e-05 - val_loss: 1.0187e-04\n",
            "Epoch 23/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.8216e-05 - val_loss: 1.2142e-04\n",
            "Epoch 24/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.4402e-05 - val_loss: 1.3943e-04\n",
            "Epoch 25/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.4631e-05 - val_loss: 1.0909e-04\n",
            "Epoch 26/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.8446e-05 - val_loss: 1.0229e-04\n",
            "Epoch 27/200\n",
            "236/236 [==============================] - 2s 9ms/step - loss: 8.5252e-05 - val_loss: 1.0203e-04\n",
            "training:  lstm_xgb_cols  df:  50\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 7/13 [===============>..............] - ETA: 0s - loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0020\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0032\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "training:  lstm_xgb_cols  df:  51\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            "  8/106 [=>............................] - ETA: 0s - loss: 4.0494e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 9ms/step - loss: 2.7820e-04 - val_loss: 8.9950e-04\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4542e-04 - val_loss: 7.9441e-04\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4191e-04 - val_loss: 8.0882e-04\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4459e-04 - val_loss: 7.6735e-04\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4394e-04 - val_loss: 7.6654e-04\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3473e-04 - val_loss: 8.0956e-04\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4829e-04 - val_loss: 7.5950e-04\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3531e-04 - val_loss: 7.6580e-04\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3505e-04 - val_loss: 7.7491e-04\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4335e-04 - val_loss: 7.7818e-04\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3955e-04 - val_loss: 7.8644e-04\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3197e-04 - val_loss: 7.8089e-04\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3555e-04 - val_loss: 7.6516e-04\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3807e-04 - val_loss: 7.6242e-04\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4243e-04 - val_loss: 8.0051e-04\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3349e-04 - val_loss: 7.4974e-04\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3942e-04 - val_loss: 7.5198e-04\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3307e-04 - val_loss: 7.6459e-04\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3489e-04 - val_loss: 8.2752e-04\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3395e-04 - val_loss: 7.6788e-04\n",
            "Epoch 21/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4825e-04 - val_loss: 7.5343e-04\n",
            "Epoch 22/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3057e-04 - val_loss: 7.5882e-04\n",
            "Epoch 23/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.2844e-04 - val_loss: 7.7580e-04\n",
            "Epoch 24/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.2878e-04 - val_loss: 7.8141e-04\n",
            "Epoch 25/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.2738e-04 - val_loss: 8.2155e-04\n",
            "Epoch 26/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.2989e-04 - val_loss: 7.5391e-04\n",
            "Epoch 27/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3186e-04 - val_loss: 7.5654e-04\n",
            "Epoch 28/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4548e-04 - val_loss: 7.6489e-04\n",
            "Epoch 29/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.4008e-04 - val_loss: 7.5541e-04\n",
            "Epoch 30/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3377e-04 - val_loss: 7.6030e-04\n",
            "Epoch 31/200\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.3081e-04 - val_loss: 7.5078e-04\n",
            "training:  lstm_xgb_cols  df:  52\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270/270 [==============================] - 2s 9ms/step - loss: 2.6658e-05 - val_loss: 2.2544e-04\n",
            "Epoch 2/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.7219e-05 - val_loss: 2.2738e-04\n",
            "Epoch 3/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6002e-05 - val_loss: 2.2419e-04\n",
            "Epoch 4/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5342e-05 - val_loss: 2.3091e-04\n",
            "Epoch 5/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5696e-05 - val_loss: 2.3314e-04\n",
            "Epoch 6/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5700e-05 - val_loss: 2.0806e-04\n",
            "Epoch 7/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5534e-05 - val_loss: 2.1090e-04\n",
            "Epoch 8/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4809e-05 - val_loss: 2.4885e-04\n",
            "Epoch 9/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5677e-05 - val_loss: 2.2991e-04\n",
            "Epoch 10/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5232e-05 - val_loss: 2.4594e-04\n",
            "Epoch 11/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4804e-05 - val_loss: 2.3479e-04\n",
            "Epoch 12/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4893e-05 - val_loss: 2.1070e-04\n",
            "Epoch 13/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5418e-05 - val_loss: 2.2801e-04\n",
            "Epoch 14/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5239e-05 - val_loss: 3.0460e-04\n",
            "Epoch 15/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5400e-05 - val_loss: 2.9410e-04\n",
            "Epoch 16/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6117e-05 - val_loss: 2.9000e-04\n",
            "Epoch 17/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6312e-05 - val_loss: 3.0830e-04\n",
            "Epoch 18/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6390e-05 - val_loss: 3.2675e-04\n",
            "Epoch 19/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.4905e-05 - val_loss: 2.8269e-04\n",
            "Epoch 20/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.6086e-05 - val_loss: 3.0673e-04\n",
            "Epoch 21/200\n",
            "270/270 [==============================] - 2s 9ms/step - loss: 1.5522e-05 - val_loss: 2.8261e-04\n",
            "training:  lstm_xgb_cols  df:  53\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n",
            " 7/79 [=>............................] - ETA: 0s - loss: 9.7027e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 9ms/step - loss: 9.6055e-05 - val_loss: 0.0012\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.9230e-05 - val_loss: 0.0012\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.0581e-05 - val_loss: 0.0013\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.9036e-05 - val_loss: 0.0014\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.8941e-05 - val_loss: 0.0012\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.2409e-05 - val_loss: 0.0012\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.8997e-05 - val_loss: 0.0013\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.1547e-05 - val_loss: 0.0013\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.6275e-05 - val_loss: 0.0012\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.6069e-05 - val_loss: 0.0012\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.5488e-05 - val_loss: 0.0012\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 8.1482e-05 - val_loss: 0.0013\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.4274e-05 - val_loss: 0.0012\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.5715e-05 - val_loss: 0.0013\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.6430e-05 - val_loss: 0.0013\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.5742e-05 - val_loss: 0.0013\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 7.5778e-05 - val_loss: 0.0012\n",
            "training:  lstm_xgb_cols  df:  54\n",
            "Training model: lstm_xgb_cols  features: 9\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/arrays/datetimes.py:1143: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320/320 [==============================] - 3s 9ms/step - loss: 4.6849e-05 - val_loss: 4.1299e-04\n",
            "Epoch 2/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.7026e-05 - val_loss: 3.2438e-04\n",
            "Epoch 3/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.4724e-05 - val_loss: 3.8195e-04\n",
            "Epoch 4/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.4031e-05 - val_loss: 3.5126e-04\n",
            "Epoch 5/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.2434e-05 - val_loss: 3.3333e-04\n",
            "Epoch 6/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3193e-05 - val_loss: 3.1646e-04\n",
            "Epoch 7/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.2647e-05 - val_loss: 3.0336e-04\n",
            "Epoch 8/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3395e-05 - val_loss: 3.2321e-04\n",
            "Epoch 9/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.5770e-05 - val_loss: 3.2575e-04\n",
            "Epoch 10/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.6076e-05 - val_loss: 3.0507e-04\n",
            "Epoch 11/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3298e-05 - val_loss: 2.8163e-04\n",
            "Epoch 12/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3416e-05 - val_loss: 3.6964e-04\n",
            "Epoch 13/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.2317e-05 - val_loss: 2.6518e-04\n",
            "Epoch 14/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.4112e-05 - val_loss: 3.3317e-04\n",
            "Epoch 15/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.2917e-05 - val_loss: 3.2097e-04\n",
            "Epoch 16/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.1928e-05 - val_loss: 4.2086e-04\n",
            "Epoch 17/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3806e-05 - val_loss: 3.3504e-04\n",
            "Epoch 18/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3217e-05 - val_loss: 3.3525e-04\n",
            "Epoch 19/200\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 4.3473e-05 - val_loss: 4.2551e-04\n",
            "Epoch 20/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.4220e-05 - val_loss: 3.5688e-04\n",
            "Epoch 21/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.2345e-05 - val_loss: 4.2362e-04\n",
            "Epoch 22/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3818e-05 - val_loss: 3.5192e-04\n",
            "Epoch 23/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3051e-05 - val_loss: 3.7677e-04\n",
            "Epoch 24/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.2006e-05 - val_loss: 4.0966e-04\n",
            "Epoch 25/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.3585e-05 - val_loss: 4.1427e-04\n",
            "Epoch 26/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.2624e-05 - val_loss: 3.8257e-04\n",
            "Epoch 27/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.4173e-05 - val_loss: 4.2025e-04\n",
            "Epoch 28/200\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 4.5348e-05 - val_loss: 3.9581e-04\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 5s 960ms/step - loss: 0.4726 - val_loss: 0.2438\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3288 - val_loss: 0.2192\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2317 - val_loss: 0.2237\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0548 - val_loss: 0.2387\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1151 - val_loss: 0.2295\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0468 - val_loss: 0.2230\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0807 - val_loss: 0.2223\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0572 - val_loss: 0.0249\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0435 - val_loss: 0.0263\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0389 - val_loss: 0.0234\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0413 - val_loss: 0.0235\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0341 - val_loss: 0.0263\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0296 - val_loss: 0.0277\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0393 - val_loss: 0.0259\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0334 - val_loss: 0.0268\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0175 - val_loss: 0.1019\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0303 - val_loss: 0.1043\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0211 - val_loss: 0.0971\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0278 - val_loss: 0.0930\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0191 - val_loss: 0.0926\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0161 - val_loss: 0.0913\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0184 - val_loss: 0.0870\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0173 - val_loss: 0.0850\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0203 - val_loss: 0.0877\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0194 - val_loss: 0.0865\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0167 - val_loss: 0.0846\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0160 - val_loss: 0.0889\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0148 - val_loss: 0.0952\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0108 - val_loss: 0.0953\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0193 - val_loss: 0.0893\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0145 - val_loss: 0.0862\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0158 - val_loss: 0.1302\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0187 - val_loss: 0.1350\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0186 - val_loss: 0.1209\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0174 - val_loss: 0.1101\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0183 - val_loss: 0.1187\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0118 - val_loss: 0.1248\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0209 - val_loss: 0.1069\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0130 - val_loss: 0.0931\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0194 - val_loss: 0.1006\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0103 - val_loss: 0.1144\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0153 - val_loss: 0.1131\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0130 - val_loss: 0.0996\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0098 - val_loss: 0.0935\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0082 - val_loss: 0.1497\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0074 - val_loss: 0.1537\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0070 - val_loss: 0.1642\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0140 - val_loss: 0.1588\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0116 - val_loss: 0.1506\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.1463\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0057 - val_loss: 0.1508\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.1505\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0114 - val_loss: 0.1454\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0093 - val_loss: 0.1328\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0084 - val_loss: 0.1358\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0075 - val_loss: 0.1486\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0094 - val_loss: 0.1458\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0082 - val_loss: 0.1391\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0061 - val_loss: 0.1415\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0534 - val_loss: 0.4353\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0147 - val_loss: 0.5599\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0503 - val_loss: 0.4629\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0106 - val_loss: 0.3290\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0330 - val_loss: 0.3228\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0236 - val_loss: 0.4362\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0157 - val_loss: 0.4961\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0219 - val_loss: 0.4331\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0101 - val_loss: 0.3511\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0112 - val_loss: 0.3292\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0111 - val_loss: 0.0963\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0061 - val_loss: 0.0899\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0085 - val_loss: 0.0892\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0126 - val_loss: 0.1034\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0108 - val_loss: 0.1276\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0106 - val_loss: 0.1359\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0118 - val_loss: 0.1236\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0097 - val_loss: 0.1028\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0216 - val_loss: 0.3510\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0126 - val_loss: 0.4166\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.4598\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0122 - val_loss: 0.4336\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0113 - val_loss: 0.3525\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0076 - val_loss: 0.2873\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0086 - val_loss: 0.2889\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0103 - val_loss: 0.3402\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0057 - val_loss: 0.3927\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0090 - val_loss: 0.4120\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0074 - val_loss: 0.3775\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0097 - val_loss: 0.3829\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.3969\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0045 - val_loss: 0.4261\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0092 - val_loss: 0.4430\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0094 - val_loss: 0.4130\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0072 - val_loss: 0.3421\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0093 - val_loss: 0.2929\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0118 - val_loss: 0.3170\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0080 - val_loss: 0.3738\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0115 - val_loss: 0.3853\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0076 - val_loss: 0.3346\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0039 - val_loss: 0.2830\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0110 - val_loss: 0.2681\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0081 - val_loss: 0.3152\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0043 - val_loss: 0.3771\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0064 - val_loss: 0.3981\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0065 - val_loss: 0.3638\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.2992\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0083 - val_loss: 0.1618\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0057 - val_loss: 0.1240\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0108 - val_loss: 0.1357\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0069 - val_loss: 0.1755\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0069 - val_loss: 0.2015\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0098 - val_loss: 0.1932\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0075 - val_loss: 0.1559\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0072 - val_loss: 0.1438\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0114 - val_loss: 0.1366\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.1402\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.1446\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0098 - val_loss: 0.1609\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0056 - val_loss: 0.1737\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0071 - val_loss: 0.1649\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0119 - val_loss: 0.1140\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.1163\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0050 - val_loss: 0.1128\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0062 - val_loss: 0.1122\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0062 - val_loss: 0.1093\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0057 - val_loss: 0.1218\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0063 - val_loss: 0.1264\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0046 - val_loss: 0.1088\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.0933\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0890\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0056 - val_loss: 0.1028\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0058 - val_loss: 0.1142\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0048 - val_loss: 0.1183\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0045 - val_loss: 0.1055\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0039 - val_loss: 0.0972\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0110 - val_loss: 0.0070\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0063 - val_loss: 0.0042\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0072 - val_loss: 0.0038\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0043\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0057 - val_loss: 0.0050\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0049 - val_loss: 0.0053\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0059 - val_loss: 0.0047\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0088 - val_loss: 0.0116\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0109 - val_loss: 0.0171\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0044 - val_loss: 0.0205\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0220\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0226\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0040 - val_loss: 0.0233\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0143 - val_loss: 0.0841\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0085 - val_loss: 0.1239\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0117 - val_loss: 0.1287\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0103 - val_loss: 0.0956\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0064 - val_loss: 0.0648\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0078 - val_loss: 0.0565\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0648\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0041 - val_loss: 0.0685\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0685\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0069 - val_loss: 0.0720\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0039 - val_loss: 0.0655\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0151 - val_loss: 0.1388\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0062 - val_loss: 0.2087\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0141 - val_loss: 0.2647\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0131 - val_loss: 0.2323\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.1600\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0112 - val_loss: 0.1468\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0462 - val_loss: 0.0059\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0107 - val_loss: 0.0290\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0348 - val_loss: 0.0320\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0204 - val_loss: 0.0115\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0074 - val_loss: 0.0264\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0255 - val_loss: 0.0202\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0321 - val_loss: 0.0076\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0136 - val_loss: 0.0208\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0099 - val_loss: 0.0436\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0179 - val_loss: 0.0467\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0124 - val_loss: 0.0333\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0039 - val_loss: 0.0213\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0537 - val_loss: 0.1216\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0308 - val_loss: 0.2443\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0046 - val_loss: 0.4031\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0175 - val_loss: 0.4818\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0213 - val_loss: 0.4375\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0080 - val_loss: 0.3406\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0121 - val_loss: 0.2685\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.1730\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0099 - val_loss: 0.1388\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0106 - val_loss: 0.1587\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0093 - val_loss: 0.2102\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0050 - val_loss: 0.2626\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0046 - val_loss: 0.2852\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0063 - val_loss: 0.2643\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0198 - val_loss: 0.0697\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0095 - val_loss: 0.0305\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0098\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0107 - val_loss: 0.0053\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0128 - val_loss: 0.0080\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0099 - val_loss: 0.0166\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0298\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0063 - val_loss: 0.0430\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0087 - val_loss: 0.0461\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0315 - val_loss: 0.0088\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0161 - val_loss: 0.0172\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0036 - val_loss: 0.0289\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0119 - val_loss: 0.0349\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0156 - val_loss: 0.0335\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0325\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0067 - val_loss: 0.0149\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0074 - val_loss: 0.0149\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0090 - val_loss: 0.0163\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0107 - val_loss: 0.0167\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0047 - val_loss: 0.0175\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0071 - val_loss: 0.0183\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0050 - val_loss: 0.0179\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0170 - val_loss: 0.0084\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0100 - val_loss: 0.0116\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0192\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0073 - val_loss: 0.0297\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0063 - val_loss: 0.0364\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0097 - val_loss: 0.0356\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0113 - val_loss: 0.0449\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0078 - val_loss: 0.0233\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0112\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0045 - val_loss: 0.0070\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0055 - val_loss: 0.0073\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0035 - val_loss: 0.0108\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0029 - val_loss: 0.0171\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0034 - val_loss: 0.0251\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0024 - val_loss: 0.0295\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0364 - val_loss: 0.0838\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0150 - val_loss: 0.1378\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0033 - val_loss: 0.2071\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0096 - val_loss: 0.2614\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.2720\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0093 - val_loss: 0.2507\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0201 - val_loss: 0.0085\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0094 - val_loss: 0.0038\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0059 - val_loss: 0.0018\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0035 - val_loss: 0.0012\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0027\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0077 - val_loss: 0.0041\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0069 - val_loss: 0.0090\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0142\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0119 - val_loss: 0.0875\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0048 - val_loss: 0.1308\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0049 - val_loss: 0.1653\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0059 - val_loss: 0.1842\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.1823\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0064 - val_loss: 0.1648\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0108 - val_loss: 0.2035\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0085 - val_loss: 0.2214\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0048 - val_loss: 0.2527\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0032 - val_loss: 0.2898\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0024 - val_loss: 0.3199\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0033 - val_loss: 0.3365\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0935 - val_loss: 0.0590\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0558 - val_loss: 0.0306\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0295 - val_loss: 0.0125\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0123 - val_loss: 0.0033\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0084 - val_loss: 0.0023\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0136 - val_loss: 0.0046\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0215 - val_loss: 0.0064\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0185 - val_loss: 0.0055\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0123 - val_loss: 0.0041\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0079 - val_loss: 0.0025\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0065 - val_loss: 0.0023\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0081 - val_loss: 0.0047\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0069\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0076 - val_loss: 0.0056\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0048 - val_loss: 0.0043\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0283 - val_loss: 0.0442\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0204 - val_loss: 0.0696\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0071 - val_loss: 0.1273\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0040 - val_loss: 0.2042\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0060 - val_loss: 0.2528\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0081 - val_loss: 0.2595\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0630 - val_loss: 0.0847\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0321 - val_loss: 0.0398\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0168 - val_loss: 0.0140\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0127 - val_loss: 0.0038\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0077 - val_loss: 0.0021\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0079 - val_loss: 0.0032\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0139 - val_loss: 0.0046\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0140 - val_loss: 0.0053\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0084 - val_loss: 0.0062\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0107 - val_loss: 0.0097\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0057 - val_loss: 0.0229\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0041 - val_loss: 0.0294\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0047 - val_loss: 0.0368\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0055 - val_loss: 0.0426\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0076 - val_loss: 0.0435\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0413\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0332 - val_loss: 0.0246\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0179 - val_loss: 0.0367\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0099 - val_loss: 0.0612\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0098 - val_loss: 0.0962\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0110 - val_loss: 0.1322\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.1631\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0995 - val_loss: 0.0401\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0628 - val_loss: 0.0173\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0334 - val_loss: 0.0238\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0188 - val_loss: 0.0415\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0154 - val_loss: 0.0618\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0199 - val_loss: 0.0765\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0193 - val_loss: 0.0754\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2206 - val_loss: 0.0076\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1306 - val_loss: 0.0145\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0483 - val_loss: 0.0523\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0124 - val_loss: 0.1149\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.2100\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0104 - val_loss: 0.3006\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0946 - val_loss: 0.2302\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0813 - val_loss: 0.1824\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0571 - val_loss: 0.1109\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0398 - val_loss: 0.0705\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0300 - val_loss: 0.0549\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0226 - val_loss: 0.0451\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0158 - val_loss: 0.0387\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0141 - val_loss: 0.0367\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0131 - val_loss: 0.0405\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0123 - val_loss: 0.0565\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0123 - val_loss: 0.0855\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0123 - val_loss: 0.1262\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0126 - val_loss: 0.1936\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0291 - val_loss: 0.1219\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0220 - val_loss: 0.1258\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0149 - val_loss: 0.1586\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0153 - val_loss: 0.2611\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0114 - val_loss: 0.6209\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0072 - val_loss: 0.9710\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0313 - val_loss: 0.4788\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0227 - val_loss: 0.0738\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0181 - val_loss: 0.0450\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0405\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0156 - val_loss: 0.0365\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0123 - val_loss: 0.0314\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0099 - val_loss: 0.0246\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0086 - val_loss: 0.0161\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0068 - val_loss: 0.0065\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0043 - val_loss: 0.0017\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0053\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0080\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0048 - val_loss: 0.0053\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0048 - val_loss: 0.0023\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0115 - val_loss: 0.0016\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0042 - val_loss: 0.0042\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0048 - val_loss: 0.0080\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0043 - val_loss: 0.0102\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0041 - val_loss: 0.0105\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0036 - val_loss: 0.0090\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0051 - val_loss: 0.0160\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0046 - val_loss: 0.0139\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0057 - val_loss: 0.0128\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0042 - val_loss: 0.0124\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0132\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0031 - val_loss: 0.0139\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0033 - val_loss: 0.0159\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0023 - val_loss: 0.0193\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0217\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0040 - val_loss: 0.0244\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0021 - val_loss: 0.0260\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0032 - val_loss: 0.0257\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.0237\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0039 - val_loss: 0.0201\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0147\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0026 - val_loss: 0.0102\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0050 - val_loss: 0.0076\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0021 - val_loss: 0.0060\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0029 - val_loss: 0.0060\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0027 - val_loss: 0.0068\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0031 - val_loss: 0.0095\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 0.0100\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0427 - val_loss: 0.0070\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0309 - val_loss: 0.0058\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0204 - val_loss: 0.0135\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0075 - val_loss: 0.0486\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0039 - val_loss: 0.1093\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0030 - val_loss: 0.1261\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0061 - val_loss: 0.0734\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0656 - val_loss: 0.0628\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0458 - val_loss: 0.0310\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0294 - val_loss: 0.0179\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0180 - val_loss: 0.0095\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0143 - val_loss: 0.0039\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0138 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0121 - val_loss: 0.0020\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0108 - val_loss: 0.0022\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0137 - val_loss: 0.0029\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0108 - val_loss: 0.0038\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0122 - val_loss: 0.0050\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0277 - val_loss: 0.0673\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0141 - val_loss: 0.0687\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0096 - val_loss: 0.0711\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0110 - val_loss: 0.0739\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0106 - val_loss: 0.0766\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0771\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0145 - val_loss: 0.0787\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0101 - val_loss: 0.0849\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0082 - val_loss: 0.0913\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0061 - val_loss: 0.0981\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.1038\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0051 - val_loss: 0.1084\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0031 - val_loss: 0.0750\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0024 - val_loss: 0.0809\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0849\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0043 - val_loss: 0.0861\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0030 - val_loss: 0.0825\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0024 - val_loss: 0.0776\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0207 - val_loss: 0.0621\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0119 - val_loss: 0.0457\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0123 - val_loss: 0.0278\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0077 - val_loss: 0.0131\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.0053\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0033 - val_loss: 0.0028\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0021 - val_loss: 0.0051\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0028 - val_loss: 0.0097\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0037 - val_loss: 0.0139\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0145\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0089 - val_loss: 0.0101\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0237 - val_loss: 0.0075\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0203 - val_loss: 0.0085\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0160 - val_loss: 0.0135\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0090 - val_loss: 0.0208\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0072 - val_loss: 0.0273\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0290\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0060 - val_loss: 0.0359\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0075 - val_loss: 0.0314\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0066 - val_loss: 0.0238\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0084 - val_loss: 0.0200\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0166\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0044 - val_loss: 0.0141\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0038 - val_loss: 0.0122\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0107\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - val_loss: 0.0090\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0044 - val_loss: 0.0075\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0047 - val_loss: 0.0060\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0041 - val_loss: 0.0048\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0048 - val_loss: 0.0043\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0030 - val_loss: 0.0039\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0037 - val_loss: 0.0038\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0042 - val_loss: 0.0039\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0036 - val_loss: 0.0034\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0035 - val_loss: 0.0023\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0044 - val_loss: 0.0021\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0018\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0031 - val_loss: 0.0017\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0031 - val_loss: 0.0016\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 0.0016\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0030 - val_loss: 0.0016\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0023 - val_loss: 0.0015\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - val_loss: 0.0015\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0057 - val_loss: 0.0015\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0026 - val_loss: 0.0016\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0033 - val_loss: 0.0016\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0027 - val_loss: 0.0015\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0026 - val_loss: 0.0015\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 0.0019\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0110 - val_loss: 0.0014\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0106 - val_loss: 0.0019\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0105 - val_loss: 0.0035\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0085 - val_loss: 0.0054\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0044 - val_loss: 0.0066\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0032 - val_loss: 0.0077\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0069 - val_loss: 0.0083\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0031\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0064 - val_loss: 0.0028\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0038 - val_loss: 0.0039\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0033 - val_loss: 0.0048\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0036 - val_loss: 0.0050\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0029 - val_loss: 0.0045\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0029 - val_loss: 0.0040\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0061 - val_loss: 0.0033\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0046 - val_loss: 0.0030\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0048 - val_loss: 0.0027\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.0022\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0043 - val_loss: 0.0020\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0066 - val_loss: 0.0019\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0019\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0038 - val_loss: 0.0020\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0043 - val_loss: 0.0020\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 0.0012\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0027 - val_loss: 9.6938e-04\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 8.9677e-04\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0094 - val_loss: 9.5093e-04\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0021 - val_loss: 9.2242e-04\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0021 - val_loss: 8.8481e-04\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 8.7186e-04\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0025 - val_loss: 8.1722e-04\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 7.4100e-04\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 7.0771e-04\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 7.4162e-04\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0040 - val_loss: 8.0902e-04\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0021 - val_loss: 0.0011\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0031 - val_loss: 0.0013\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0031 - val_loss: 0.0016\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0034 - val_loss: 0.0017\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0036 - val_loss: 0.0019\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0024 - val_loss: 0.0032\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0202 - val_loss: 0.0033\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0156 - val_loss: 0.0038\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0092 - val_loss: 0.0069\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0048 - val_loss: 0.0139\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0039 - val_loss: 0.0237\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0040 - val_loss: 0.0332\n"
          ]
        }
      ],
      "source": [
        "histories = {}\n",
        "training_filter = model_config[\"training_filter\"]\n",
        "if train_models:\n",
        "  load_data()\n",
        "  for name in model_config[\"day_bar_models\"]:\n",
        "    if (len(training_filter)!=0 and not name in training_filter):\n",
        "      print(\"skipping: \", name)\n",
        "      continue\n",
        "    build_model_from_config(models, name, model_config)\n",
        "    print(\"training: \", name)\n",
        "    # todo - we need a training set type flag in config for 15m models to get the correct files/data\n",
        "    training_dfs = get_training_datasets_for_model(name)\n",
        "    print(\"training dfs:\", len(training_dfs))\n",
        "    count = 0\n",
        "    for df in training_dfs:\n",
        "      print(\"training: \", name, \" df: \", count)\n",
        "      count+=1\n",
        "      history = train_config_model_against_df(name, model_config, df)\n",
        "      if not name in histories:\n",
        "        histories[name] = []\n",
        "      histories[name].append(history)\n",
        "    if save_models:\n",
        "      print(\"saving:\", name)\n",
        "      if name in model_config[\"load_type\"] and model_config[\"load_type\"][name] == \"joblib\":\n",
        "        joblib.dump(models[name], model_path + \"/\" + name  + \"-\" + model_version_token + \".joblib\") \n",
        "      else:\n",
        "        models[name].save(model_path + \"/\" + name  + \"-\" + model_version_token + \".h15\")\n",
        "  lstm_15m = build_15m_model()\n",
        "  lstm_15m.save(model_path + \"/lstm_15m-2.h15\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXx4sqyHwFFO"
      },
      "source": [
        "## Train a single model against a single dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0gAspGyyxlIF"
      },
      "outputs": [],
      "source": [
        "#build_and_stash_all_config_models()\n",
        "#coin_dfs = get_raw_data_for_coin_list(180)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tpd2eCTCwACI"
      },
      "outputs": [],
      "source": [
        "#[model, history] = train_config_model_against_df(\"lstm_cv\", model_config, coin_dfs[\"FCON-USDT\"])\n",
        "#models[\"lstm_cv\"] = model\n",
        "#df_raw = get_coin_data_frames(180, \"FCON-USDT\")\n",
        "#test_name = \"lstm_ohlc\"\n",
        "#all_columns = model_config[\"column_sets\"][test_name]+gbl_target_column\n",
        "#[scaled_features, X, y, normal_features] = convert_to_training_dataset(df, columns=all_columns)  \n",
        "#[p_scaled, p] = predict_trade(models[test_name], test_name, \"FCON-USDT\", X, all_columns)\n",
        "#build_trade_model(p, normal_features, \"FCON-USDT\", test_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2gwuTvHwEeh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDDL-Sj8v86C"
      },
      "source": [
        "# Save all models to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv-3hoIZ-Uhu"
      },
      "outputs": [],
      "source": [
        "if save_models:\n",
        "  for name in model_config[\"day_bar_models\"]:\n",
        "    if (len(training_filter)!=0 and not name in training_filter):\n",
        "      print(\"skipping: \", name)\n",
        "      continue\n",
        "    print(\"saving:\", name)\n",
        "    if name in model_config[\"load_type\"] and model_config[\"load_type\"][name] == \"joblib\":\n",
        "      joblib.dump(models[name], model_path + \"/\" + name  + \"-\" + model_version_token + \".joblib\") \n",
        "    else:\n",
        "      models[name].save(model_path + \"/\" + name  + \"-\" + model_version_token + \".h15\")\n",
        " \n",
        "  print (\"models saved\")  \n",
        "else:\n",
        "  print (\"Not saving\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BScYqlck6ci6"
      },
      "source": [
        "# Visualize and Compare all Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = get_coin_data_frames(1500, \"BTC-USDT\")"
      ],
      "metadata": {
        "id": "be5b_ilLMbxu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IRenxiXDLJY"
      },
      "outputs": [],
      "source": [
        "backtest_filter = []\n",
        "[results, data, fig] = renderPredictions(df_raw, models, backtest_filter, False, False)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0owKG3b5lqHi",
        "outputId": "42d01aec-d715-41a0-d78a-68ff5d17a413"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date         Open        Close         High          Low  \\\n",
              "0    2023-01-22 22780.900000 22805.200000 23071.800000 22609.800000   \n",
              "1    2023-01-21 22668.800000 22780.900000 23369.900000 22417.000000   \n",
              "2    2023-01-20 21073.600000 22668.700000 22748.200000 20866.000000   \n",
              "3    2023-01-19 20676.700000 21073.500000 21199.200000 20659.600000   \n",
              "4    2023-01-18 21131.800000 20676.700000 21639.200000 20404.000000   \n",
              "...         ...          ...          ...          ...          ...   \n",
              "1495 2018-12-19  3651.644898  3664.467780  3899.965240  3623.959411   \n",
              "1496 2018-12-18  3509.804799  3651.644898  3669.542359  3438.437007   \n",
              "1497 2018-12-17  3226.444891  3511.733273  3581.900000  3218.550073   \n",
              "1498 2018-12-16  3214.032737  3229.359252  3285.806038  3210.745450   \n",
              "1499 2018-12-15  3219.345600  3214.246608  3261.407162  3160.000001   \n",
              "\n",
              "           Volume           amount  \n",
              "0     6604.317632 150918778.450203  \n",
              "1    10272.731368 235458722.819069  \n",
              "2     9876.527761 212945047.854365  \n",
              "3     6165.239500 128704497.315423  \n",
              "4     9782.348212 206164413.013461  \n",
              "...           ...              ...  \n",
              "1495   534.193179   1991870.358672  \n",
              "1496   314.954644   1112127.961140  \n",
              "1497   494.875964   1704568.758381  \n",
              "1498   223.992961    727775.558003  \n",
              "1499   162.152105    519974.180449  \n",
              "\n",
              "[1500 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3a2dc1c-9d06-4887-82ae-d688127f225b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-22</td>\n",
              "      <td>22780.900000</td>\n",
              "      <td>22805.200000</td>\n",
              "      <td>23071.800000</td>\n",
              "      <td>22609.800000</td>\n",
              "      <td>6604.317632</td>\n",
              "      <td>150918778.450203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-21</td>\n",
              "      <td>22668.800000</td>\n",
              "      <td>22780.900000</td>\n",
              "      <td>23369.900000</td>\n",
              "      <td>22417.000000</td>\n",
              "      <td>10272.731368</td>\n",
              "      <td>235458722.819069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-20</td>\n",
              "      <td>21073.600000</td>\n",
              "      <td>22668.700000</td>\n",
              "      <td>22748.200000</td>\n",
              "      <td>20866.000000</td>\n",
              "      <td>9876.527761</td>\n",
              "      <td>212945047.854365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-19</td>\n",
              "      <td>20676.700000</td>\n",
              "      <td>21073.500000</td>\n",
              "      <td>21199.200000</td>\n",
              "      <td>20659.600000</td>\n",
              "      <td>6165.239500</td>\n",
              "      <td>128704497.315423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-18</td>\n",
              "      <td>21131.800000</td>\n",
              "      <td>20676.700000</td>\n",
              "      <td>21639.200000</td>\n",
              "      <td>20404.000000</td>\n",
              "      <td>9782.348212</td>\n",
              "      <td>206164413.013461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>2018-12-19</td>\n",
              "      <td>3651.644898</td>\n",
              "      <td>3664.467780</td>\n",
              "      <td>3899.965240</td>\n",
              "      <td>3623.959411</td>\n",
              "      <td>534.193179</td>\n",
              "      <td>1991870.358672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>2018-12-18</td>\n",
              "      <td>3509.804799</td>\n",
              "      <td>3651.644898</td>\n",
              "      <td>3669.542359</td>\n",
              "      <td>3438.437007</td>\n",
              "      <td>314.954644</td>\n",
              "      <td>1112127.961140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>2018-12-17</td>\n",
              "      <td>3226.444891</td>\n",
              "      <td>3511.733273</td>\n",
              "      <td>3581.900000</td>\n",
              "      <td>3218.550073</td>\n",
              "      <td>494.875964</td>\n",
              "      <td>1704568.758381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>2018-12-16</td>\n",
              "      <td>3214.032737</td>\n",
              "      <td>3229.359252</td>\n",
              "      <td>3285.806038</td>\n",
              "      <td>3210.745450</td>\n",
              "      <td>223.992961</td>\n",
              "      <td>727775.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>2018-12-15</td>\n",
              "      <td>3219.345600</td>\n",
              "      <td>3214.246608</td>\n",
              "      <td>3261.407162</td>\n",
              "      <td>3160.000001</td>\n",
              "      <td>162.152105</td>\n",
              "      <td>519974.180449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3a2dc1c-9d06-4887-82ae-d688127f225b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3a2dc1c-9d06-4887-82ae-d688127f225b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3a2dc1c-9d06-4887-82ae-d688127f225b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvMTta84dZfO"
      },
      "source": [
        "# What has a buy indicator for tomorrow?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N887KFLZdios"
      },
      "outputs": [],
      "source": [
        "# Fetch the top 10 and see if they predict up\n",
        "df_products = get_all_products()\n",
        "df_products = df_products[df_products.id.str.endswith('USDT')]\n",
        "\n",
        "report_columns = [\"Product\",\n",
        "                  \"Model Name\",\n",
        "                  \"Close\",\n",
        "                  \"Target\",\n",
        "                  \"Predicted\",\n",
        "                  \"MSE\",\n",
        "                  \"Percent\",\n",
        "                  \"250Fees\",\n",
        "                  \"5kFees\",\n",
        "                  \"10kFees\",\n",
        "                  \"250Profit\",\n",
        "                  \"5kProfit\",\n",
        "                  \"10k0Profit\",\n",
        "                  \"Period\"]\n",
        "\n",
        "# we have a desired budget of 10k in trading capital to deploy. \n",
        "# \"volValue\": is the 24h total, the trading volume in quote currency of last 24 hours\n",
        "# Any markets we enter need to have a signifcantly higher trading value volume otherwise\n",
        "# we can't really trade there without breaking things up. As we grow our strat here will need to change.\n",
        "# for now we cut down our set to 1m in volVal\n",
        "volumeCutoff = 500000\n",
        "df_products[\"volValue\"] = [float(x) for x in df_products['volValue']]\n",
        "df_products = df_products[df_products[\"volValue\"] > volumeCutoff]\n",
        "df_products = df_products.sort_values(by = ['id'])\n",
        "\n",
        "models_in_play = [\n",
        "        \"lstm_cv\", \n",
        "        \"lstm_att_cv\", \n",
        "        \"lstm_cv_rvi\",\n",
        "        \"svm_cv\",\n",
        "        \"lstm_xgb_cols\"]\n",
        "if coin_base:\n",
        "  df_products = df_products[df_products.trading_disabled == False]\n",
        "  df_products = df_products[df_products.cancel_only == False]\n",
        "\n",
        "df_trades = pd.DataFrame();\n",
        "df_estc = pd.DataFrame(); #expected short term closes\n",
        "df_estc[\"Product\"] = [];\n",
        "df_estc[\"Est Close\"] = [];\n",
        "df_estc[\"Est Close Raw\"] = [];\n",
        "bars_long = 180\n",
        "bars_short = 30\n",
        "counter = 0;\n",
        "print(\"iterating through:\", len(df_products))\n",
        "tries = 3\n",
        "\n",
        "def downloadAndPredict(all_trades, product, length):\n",
        "  print(\"download day bars: \", product, \" bar set:\", length)\n",
        "  df_raw = get_coin_data_frames(length, product)\n",
        "  for name in models_in_play:\n",
        "    print(\"predicting trade:\", name, \"for\", product)\n",
        "    df_trade = predict_config_model_for_product(df_raw, name, product)\n",
        "    df_trade[\"Period\"] = [length]\n",
        "    df_trade = df_trade[report_columns]\n",
        "    print(\"predicted mse:\", name, \":{:.10f}\".format(df_trade[\"MSE\"].iloc[0]))\n",
        "    all_trades = all_trades.append(df_trade)\n",
        "  return all_trades\n",
        "\n",
        "def downloadAndPredict15(all_trades, product):\n",
        "  print(\"download 15 bars: \", product)\n",
        "  [predicted_scaled, predicted] = fetch_and_predict_short_term(lstm_15m,product)\n",
        "  df2 = pd.DataFrame({'Product': [product], 'Est Close': [predicted], 'Est Close Raw': predicted_scaled})\n",
        "  all_trades = all_trades.append(df2)\n",
        "  return all_trades\n",
        "\n",
        "\n",
        "for index, row in df_products.iterrows():\n",
        "    \n",
        "    loop = True\n",
        "    count = 0\n",
        "    while(loop):\n",
        "      try:\n",
        "        print(\"start day long\")\n",
        "        df_trades = downloadAndPredict(df_trades, row.id, bars_long)\n",
        "        time.sleep(1)\n",
        "        \n",
        "        print(\"start day short\")\n",
        "        df_trades = downloadAndPredict(df_trades, row.id, bars_short)\n",
        "        time.sleep(1)\n",
        "\n",
        "        print(\"start 15m\")\n",
        "        df_estc = downloadAndPredict15(df_estc, row.id)\n",
        "        time.sleep(1)\n",
        "        loop = False\n",
        "      except Exception as inst:\n",
        "        #raise inst\n",
        "        print(\"Error: \", inst)\n",
        "        time.sleep(1)\n",
        "        count = count+1\n",
        "        if count>tries:\n",
        "          loop = False\n",
        "\n",
        "df_trades.reset_index()\n",
        "df_trades_filtered = df_trades  # TODO: Filter again after see what the new mse's look like #df_trades.loc[(df_trades[\"Period\"] == 180) & (df_trades[\"MSE\"] < 0.00005) | (df_trades[\"Period\"] == 30) & (df_trades[\"MSE\"] < 0.0005)]\n",
        "df_buys = df_trades_filtered[df_trades_filtered['Percent'] > 0] \n",
        "df_shorts = df_trades_filtered[df_trades_filtered['Percent'] < 0] \n",
        "df_weighted = df_trades_filtered.groupby(\"Product\").apply(consensus_prediction)\n",
        "df_weighted = df_weighted.rename(\"Consensus Prediction\")\n",
        "df_trades_final = pd.merge(df_trades_filtered, df_weighted, left_on='Product', right_index=True)\n",
        "df_trades_final[\"Consensus Percent\"] = ((df_trades_final['Consensus Prediction'] - df_trades_final['Close']) / df_trades_final['Close']) * 100\n",
        "df_view = df_trades_final[[\"Product\",  \"Model Name\",  \"MSE\", \"Period\", \"Close\", \"Predicted\", \"Percent\",\"Consensus Percent\", \"Consensus Prediction\"]]\n",
        "df_view = df_view.sort_values(by=[\"Consensus Percent\", \"MSE\"], ascending=[True, False])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "5R-54Ju-qy5v",
        "outputId": "59baf0a5-973e-4a8e-81a2-9d9c781c59af"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Product     Model Name      MSE  Period    Close  Predicted  \\\n",
              "Date                                                                         \n",
              "2023-01-21  OCEAN-USDT    lstm_cv_rvi 0.001496      30 0.319500   0.258777   \n",
              "2023-01-21  OCEAN-USDT  lstm_xgb_cols 0.001468      30 0.319500   0.264971   \n",
              "2023-01-21  OCEAN-USDT    lstm_att_cv 0.001002      30 0.319500   0.263091   \n",
              "2023-01-21  OCEAN-USDT        lstm_cv 0.000829      30 0.319500   0.266081   \n",
              "2023-01-21  OCEAN-USDT  lstm_xgb_cols 0.000449     180 0.319500   0.259871   \n",
              "...                ...            ...      ...     ...      ...        ...   \n",
              "2023-01-21   BOND-USDT    lstm_cv_rvi 0.000325     180 5.122000   7.048556   \n",
              "2023-01-21   BOND-USDT    lstm_att_cv 0.000188     180 5.122000   7.088149   \n",
              "2023-01-21   BOND-USDT        lstm_cv 0.000136     180 5.122000   7.112312   \n",
              "2023-01-21   BOND-USDT         svm_cv 0.000015      30 5.122000   3.981187   \n",
              "2023-01-21   BOND-USDT         svm_cv 0.000009     180 5.122000   7.075875   \n",
              "\n",
              "              Percent  Consensus Percent  Consensus Prediction  \n",
              "Date                                                            \n",
              "2023-01-21 -19.005737         -16.028653              0.268288  \n",
              "2023-01-21 -17.066827         -16.028653              0.268288  \n",
              "2023-01-21 -17.655315         -16.028653              0.268288  \n",
              "2023-01-21 -16.719425         -16.028653              0.268288  \n",
              "2023-01-21 -18.663281         -16.028653              0.268288  \n",
              "...               ...                ...                   ...  \n",
              "2023-01-21  37.613346          13.771915              5.827397  \n",
              "2023-01-21  38.386350          13.771915              5.827397  \n",
              "2023-01-21  38.858100          13.771915              5.827397  \n",
              "2023-01-21 -22.272796          13.771915              5.827397  \n",
              "2023-01-21  38.146713          13.771915              5.827397  \n",
              "\n",
              "[1090 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-978b774f-fd90-4585-a048-c874199859b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Model Name</th>\n",
              "      <th>MSE</th>\n",
              "      <th>Period</th>\n",
              "      <th>Close</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Percent</th>\n",
              "      <th>Consensus Percent</th>\n",
              "      <th>Consensus Prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_cv_rvi</td>\n",
              "      <td>0.001496</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.258777</td>\n",
              "      <td>-19.005737</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_xgb_cols</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.264971</td>\n",
              "      <td>-17.066827</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_att_cv</td>\n",
              "      <td>0.001002</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.263091</td>\n",
              "      <td>-17.655315</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_cv</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.266081</td>\n",
              "      <td>-16.719425</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_xgb_cols</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>180</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.259871</td>\n",
              "      <td>-18.663281</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>lstm_cv_rvi</td>\n",
              "      <td>0.000325</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.048556</td>\n",
              "      <td>37.613346</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>lstm_att_cv</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.088149</td>\n",
              "      <td>38.386350</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>lstm_cv</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.112312</td>\n",
              "      <td>38.858100</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>svm_cv</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>30</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>3.981187</td>\n",
              "      <td>-22.272796</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>svm_cv</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.075875</td>\n",
              "      <td>38.146713</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1090 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-978b774f-fd90-4585-a048-c874199859b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-978b774f-fd90-4585-a048-c874199859b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-978b774f-fd90-4585-a048-c874199859b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_view"
      ],
      "metadata": {
        "id": "LWc99ylMK5wg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "d42620f9-4f43-46c0-9f06-4a01900eaddd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Product     Model Name      MSE  Period    Close  Predicted  \\\n",
              "Date                                                                         \n",
              "2023-01-21  OCEAN-USDT    lstm_cv_rvi 0.001496      30 0.319500   0.258777   \n",
              "2023-01-21  OCEAN-USDT  lstm_xgb_cols 0.001468      30 0.319500   0.264971   \n",
              "2023-01-21  OCEAN-USDT    lstm_att_cv 0.001002      30 0.319500   0.263091   \n",
              "2023-01-21  OCEAN-USDT        lstm_cv 0.000829      30 0.319500   0.266081   \n",
              "2023-01-21  OCEAN-USDT  lstm_xgb_cols 0.000449     180 0.319500   0.259871   \n",
              "...                ...            ...      ...     ...      ...        ...   \n",
              "2023-01-21   BOND-USDT    lstm_cv_rvi 0.000325     180 5.122000   7.048556   \n",
              "2023-01-21   BOND-USDT    lstm_att_cv 0.000188     180 5.122000   7.088149   \n",
              "2023-01-21   BOND-USDT        lstm_cv 0.000136     180 5.122000   7.112312   \n",
              "2023-01-21   BOND-USDT         svm_cv 0.000015      30 5.122000   3.981187   \n",
              "2023-01-21   BOND-USDT         svm_cv 0.000009     180 5.122000   7.075875   \n",
              "\n",
              "              Percent  Consensus Percent  Consensus Prediction  \n",
              "Date                                                            \n",
              "2023-01-21 -19.005737         -16.028653              0.268288  \n",
              "2023-01-21 -17.066827         -16.028653              0.268288  \n",
              "2023-01-21 -17.655315         -16.028653              0.268288  \n",
              "2023-01-21 -16.719425         -16.028653              0.268288  \n",
              "2023-01-21 -18.663281         -16.028653              0.268288  \n",
              "...               ...                ...                   ...  \n",
              "2023-01-21  37.613346          13.771915              5.827397  \n",
              "2023-01-21  38.386350          13.771915              5.827397  \n",
              "2023-01-21  38.858100          13.771915              5.827397  \n",
              "2023-01-21 -22.272796          13.771915              5.827397  \n",
              "2023-01-21  38.146713          13.771915              5.827397  \n",
              "\n",
              "[1090 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f462a6e6-87e7-495c-82ed-685e214d9fd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Model Name</th>\n",
              "      <th>MSE</th>\n",
              "      <th>Period</th>\n",
              "      <th>Close</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Percent</th>\n",
              "      <th>Consensus Percent</th>\n",
              "      <th>Consensus Prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_cv_rvi</td>\n",
              "      <td>0.001496</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.258777</td>\n",
              "      <td>-19.005737</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_xgb_cols</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.264971</td>\n",
              "      <td>-17.066827</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_att_cv</td>\n",
              "      <td>0.001002</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.263091</td>\n",
              "      <td>-17.655315</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_cv</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>30</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.266081</td>\n",
              "      <td>-16.719425</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>OCEAN-USDT</td>\n",
              "      <td>lstm_xgb_cols</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>180</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.259871</td>\n",
              "      <td>-18.663281</td>\n",
              "      <td>-16.028653</td>\n",
              "      <td>0.268288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>lstm_cv_rvi</td>\n",
              "      <td>0.000325</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.048556</td>\n",
              "      <td>37.613346</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>lstm_att_cv</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.088149</td>\n",
              "      <td>38.386350</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>lstm_cv</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.112312</td>\n",
              "      <td>38.858100</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>svm_cv</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>30</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>3.981187</td>\n",
              "      <td>-22.272796</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-21</th>\n",
              "      <td>BOND-USDT</td>\n",
              "      <td>svm_cv</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>180</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>7.075875</td>\n",
              "      <td>38.146713</td>\n",
              "      <td>13.771915</td>\n",
              "      <td>5.827397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1090 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f462a6e6-87e7-495c-82ed-685e214d9fd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f462a6e6-87e7-495c-82ed-685e214d9fd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f462a6e6-87e7-495c-82ed-685e214d9fd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pWlMqJ3OQwse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ae9f77f5-de72-4939-db8a-3e94644074ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Product  Est Close  Est Close Raw\n",
              "0   AAVE-USDT  88.896239       0.723582\n",
              "0    ACE-USDT   0.008610       0.673652\n",
              "0    ADA-USDT   0.382799       0.728841\n",
              "0   AGIX-USDT   0.197184       0.936661\n",
              "0   ALBT-USDT   0.110593       0.575007\n",
              "..        ...        ...            ...\n",
              "0    XMR-USDT 180.452771       0.883929\n",
              "0    XPR-USDT   0.002061       0.746450\n",
              "0    XRP-USDT   0.409741       0.876525\n",
              "0    ZEC-USDT  48.545110       0.947574\n",
              "0    ZIL-USDT   0.027752       0.949731\n",
              "\n",
              "[104 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0463b14e-b074-4f4f-866f-fc71702f236c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Est Close</th>\n",
              "      <th>Est Close Raw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAVE-USDT</td>\n",
              "      <td>88.896239</td>\n",
              "      <td>0.723582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACE-USDT</td>\n",
              "      <td>0.008610</td>\n",
              "      <td>0.673652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADA-USDT</td>\n",
              "      <td>0.382799</td>\n",
              "      <td>0.728841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AGIX-USDT</td>\n",
              "      <td>0.197184</td>\n",
              "      <td>0.936661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALBT-USDT</td>\n",
              "      <td>0.110593</td>\n",
              "      <td>0.575007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XMR-USDT</td>\n",
              "      <td>180.452771</td>\n",
              "      <td>0.883929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XPR-USDT</td>\n",
              "      <td>0.002061</td>\n",
              "      <td>0.746450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XRP-USDT</td>\n",
              "      <td>0.409741</td>\n",
              "      <td>0.876525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ZEC-USDT</td>\n",
              "      <td>48.545110</td>\n",
              "      <td>0.947574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ZIL-USDT</td>\n",
              "      <td>0.027752</td>\n",
              "      <td>0.949731</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0463b14e-b074-4f4f-866f-fc71702f236c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0463b14e-b074-4f4f-866f-fc71702f236c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0463b14e-b074-4f4f-866f-fc71702f236c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_estc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Qa0sDODdFhLb"
      },
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "today = now.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "if coin_base:\n",
        "  token = \"cb\"\n",
        "else:\n",
        "  token = \"ku\"\n",
        "\n",
        "df_buys.to_csv(data_path+\"/buy-\" + token + \"-\" + today + \".csv\")\n",
        "df_estc.to_csv(data_path+\"/15m-\" + token + \"-\" + today + \".csv\")\n",
        "df_shorts.to_csv(data_path+\"/shorts-\" + token + \"-\" + today + \".csv\")\n",
        "df_trades_final.to_csv(data_path+\"/final-\" + token + \"-\" + today + \".csv\")\n",
        "df_view.to_csv(data_path+\"/view-\" + token + \"-\" + today + \".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZm81Q20pf55"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1H8K_tenSjC-",
        "uCNok5EX8ax_",
        "EXx4sqyHwFFO"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}