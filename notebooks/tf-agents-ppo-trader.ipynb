{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"MO3iaffdNy31","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680300054333,"user_tz":240,"elapsed":32201,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}},"outputId":"96864bc2-5ef0-4788-cea0-c56db5dc021c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tf_agents\n","  Downloading tf_agents-0.16.0-py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygame==2.1.3\n","  Downloading pygame-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (3.20.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (1.16.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (1.22.4)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (1.14.1)\n","Requirement already satisfied: tensorflow-probability~=0.19.0 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (0.19.0)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (2.2.1)\n","Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (1.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (4.5.0)\n","Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from tf_agents) (0.5.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from tf_agents) (8.4.0)\n","Collecting gym<=0.23.0,>=0.17.0\n","  Downloading gym-0.23.0.tar.gz (624 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.9/dist-packages (from gym<=0.23.0,>=0.17.0->tf_agents) (6.1.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym<=0.23.0,>=0.17.0->tf_agents) (0.0.8)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability~=0.19.0->tf_agents) (0.1.8)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability~=0.19.0->tf_agents) (4.4.2)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability~=0.19.0->tf_agents) (0.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf_agents) (3.15.0)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697660 sha256=21157cb70dcc4fa0bd477fac018ada7ccbbdd21c22db1f4547a1e5e6001cff1a\n","  Stored in directory: /root/.cache/pip/wheels/96/b9/bb/994c1324b65e39dd1cd7b8ba92e5fb766dd77980929414a866\n","Successfully built gym\n","Installing collected packages: pygame, gym, tf_agents\n","  Attempting uninstall: pygame\n","    Found existing installation: pygame 2.3.0\n","    Uninstalling pygame-2.3.0:\n","      Successfully uninstalled pygame-2.3.0\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","Successfully installed gym-0.23.0 pygame-2.1.3 tf_agents-0.16.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: yfinance in /usr/local/lib/python3.9/dist-packages (0.2.14)\n","Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2.27.1)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (4.11.2)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.4.4)\n","Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.4.4)\n","Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.9/dist-packages (from yfinance) (40.0.1)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2.3.6)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.22.4)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.1)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2022.7.1)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (4.9.2)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/dist-packages (from yfinance) (0.0.11)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.9/dist-packages (0.19.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (1.22.4)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (1.4.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (0.1.8)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (2.2.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (4.4.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (1.16.0)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (0.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.9/dist-packages (0.16.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (8.4.0)\n","Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (2.1.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (1.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (4.5.0)\n","Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (0.23.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (1.14.1)\n","Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (3.20.3)\n","Requirement already satisfied: tensorflow-probability~=0.19.0 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (0.19.0)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (2.2.1)\n","Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (1.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (1.22.4)\n","Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (0.5.0)\n","Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tf-agents[reverb]) (2.12.0)\n","Collecting rlds\n","  Downloading rlds-0.1.7-py3-none-manylinux2010_x86_64.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dm-reverb~=0.11.0\n","  Downloading dm_reverb-0.11.0-cp39-cp39-manylinux2014_x86_64.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (0.1.8)\n","Requirement already satisfied: portpicker in /usr/local/lib/python3.9/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (1.3.9)\n","Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.9/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (6.1.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.53.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.32.0)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.3.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.3.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (67.6.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (16.0.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability~=0.19.0->tf-agents[reverb]) (4.4.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-agents[reverb]) (0.40.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (3.15.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (0.0.4)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.17.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.27.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.2.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.3.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.1.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.2.2)\n","Installing collected packages: rlds, dm-reverb\n","Successfully installed dm-reverb-0.11.0 rlds-0.1.7\n"]}],"source":["!pip install tf_agents\n","!pip install yfinance\n","!pip install tensorflow-probability\n","!pip install tf-agents[reverb]"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100820,"status":"ok","timestamp":1680300155148,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"},"user_tz":240},"id":"EZpUrmWiOb8l","outputId":"75779df9-d5aa-4e7c-ab56-1d60a49f8fe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","\n","sys.path.insert(0,'/content/drive/My Drive/ml-trde-notebooks')\n","data_path = '/content/drive/My Drive/ml-trde-notebooks/data'\n","model_path = \"/content/drive/My Drive/ml-trde-notebooks/models\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YD52woTyQUsM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680300159805,"user_tz":240,"elapsed":4659,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}},"outputId":"cc0d82be-da82-4bb9-a3da-90883ec3155f"},"outputs":[{"output_type":"stream","name":"stdout","text":["I has cores:  12\n"]}],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import reverb\n","import math\n","\n","import tf_agents\n","from tf_agents.environments import suite_gym, tf_py_environment\n","from tf_agents.networks import network, utils, categorical_projection_network\n","from tf_agents.agents.ppo import ppo_agent\n","from tf_agents.policies import actor_policy\n","from tf_agents.trajectories import trajectory\n","from tf_agents.specs import tensor_spec\n","from tf_agents.agents import tf_agent\n","from tf_agents.networks import actor_distribution_rnn_network\n","from tf_agents.networks import value_rnn_network\n","from tf_agents.utils import common\n","from tf_agents.environments import parallel_py_environment\n","from tf_agents.drivers import py_driver\n","from tf_agents.policies import py_tf_eager_policy\n","from tf_agents.replay_buffers import reverb_replay_buffer, tf_uniform_replay_buffer\n","from tf_agents.replay_buffers import reverb_utils\n","from tf_agents.policies import policy_saver\n","from tensorflow import keras\n","import tensorflow_probability as tfp\n","from tf_agents.utils import common\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","from scipy.stats import norm\n","\n","import multiprocessing\n","from itertools import cycle\n","\n","cores = multiprocessing.cpu_count()\n","print(\"I has cores: \", cores)\n","try:\n","  tf_agents.system.multiprocessing.enable_interactive_mode()\n","except Exception as inst:\n","  pass\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1866,"status":"ok","timestamp":1680300161669,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"},"user_tz":240},"id":"zrk7MuAYOXqd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70721617-f8bf-4de0-d9dc-601a8db1b9d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Modified\n","1679922395\n","1679922395.0\n","1679922395.0\n"]}],"source":["# Executes this notebook in our space, making all of its functions/globals available\n","%run -i '/content/drive/My Drive/ml-trde-notebooks/backtest-common.ipynb'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yhAiVGS6_bZG","executionInfo":{"status":"ok","timestamp":1680300161669,"user_tz":240,"elapsed":5,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}}},"outputs":[],"source":["logging_level = 0\n","def error(*args):\n","    if logging_level >= 0:\n","        print(*args)\n","\n","def info(*args):\n","    if logging_level >=1:\n","        print(*args)\n","\n","def verbose(*args):\n","    if logging_level >=2:\n","        print(*args)\n","\n","def debug(*args):\n","    if logging_level >=3:\n","        print(*args)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"X1VtA9cSRAEe","executionInfo":{"status":"ok","timestamp":1680300161669,"user_tz":240,"elapsed":4,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}}},"outputs":[],"source":["def download_stocks():\n","  # We don't want to train against crypto\n","  return get_all_stock_timerseries_for_csv(\"training_tickers3.csv\", 3500, 1)\n","\n","LENGTH_OF_STOCK_TRAINGING_DATA = 145 #I might need to fix this, but the model is tied to the number of symbols we trained on\n","def download_crypto():\n","  return get_all_product_timeseries(-1, 180, LENGTH_OF_STOCK_TRAINGING_DATA)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"neo9ZYMWQXUs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680300165037,"user_tz":240,"elapsed":3371,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}},"outputId":"40b8d6e0-9f73-48c9-e2bd-4e31ee2509ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading ticker:  XTSLA  count: 0 of: 164\n","\r[*********************100%***********************]  1 of 1 completed\n","\n","1 Failed download:\n","- XTSLA: No timezone found, symbol may be delisted\n","loading ticker:  XEL  count: 1 of: 164\n","[*********************100%***********************]  1 of 1 completed\n","loading ticker:  WU  count: 2 of: 164\n","symbols: 1\n","min length: 3500\n"]}],"source":["from_disk = False\n","use_crypto = False\n","\n","if from_disk:\n","  product_data = load_dict(use_crypto)\n","  first_key = list(product_data.keys())[0]\n","  length = len(product_data[first_key])\n","elif use_crypto:\n","  product_data = download_crypto()\n","  save_dict(product_data, True)\n","else:\n","  product_data = download_stocks()\n","  save_dict(product_data)\n","\n","min_len = min(len(df) for df in product_data.values())\n","print(\"symbols:\", len(product_data.keys()))\n","print(\"min length:\", min_len)\n","for name, df in product_data.items():\n","    product_data[name] = df.head(min_len)\n","\n","product_data = dict(sorted(product_data.items(), reverse=True))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"m4bShVXE1rZv","executionInfo":{"status":"ok","timestamp":1680300165037,"user_tz":240,"elapsed":19,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}}},"outputs":[],"source":["import numpy as np\n","from gym import spaces\n","from tf_agents.environments import py_environment\n","from tf_agents.specs import array_spec\n","from tf_agents.specs import tensor_spec\n","from tf_agents.trajectories import time_step as ts\n","\n","class TraderEnv(py_environment.PyEnvironment):\n","    \n","    def __init__(self, product, df):\n","        super(TraderEnv, self).__init__()\n","\n","        self._observation_spec = array_spec.BoundedArraySpec(\n","            shape=(4,), dtype=np.float64, minimum=np.float64(0), maximum=np.float64(np.inf), name='observation'\n","        )\n","\n","        # Define action spec\n","        self._action_spec = array_spec.BoundedArraySpec(\n","            shape=(), dtype=np.int32, minimum=0, maximum=2, name='action'\n","        )\n","        \n","        # Initialize environment state\n","        df = self.expand(df.copy())\n","\n","        self.orig_timeseries = df\n","        self.timeseries = self.scale(df[[\"Date\", \"Close\", \"weighted-volume\", \"trend\", \"prob_above_trend\"]])\n","        \n","        self._reset_vars()\n","        self.calculate_benchmark_metrics()\n","\n","\n","        # Don't add this here. Process the tickers into data files - you already have some.\n","        #self.lstm_internal = keras.models.load_model(model_path + \"/lstm_cv-4.h15\")\n","        #predictions = self.predict_trade(self.lstm_internal, self.timeseries[[\"Close\", \"weighted-volume\"]])\n","        #self.timeseries[\"predicted-price\"] = predictions\n","        \n","        self.product = product\n","        self.final = len(df)\n","    \n","    \n","    def calculate_benchmark_metrics(self):\n","      df = self.orig_timeseries\n","      row = df.iloc[0,:]\n","      price = self.get_price_with_slippage(row[\"Close\"])\n","      self.benchmark_position_shares = math.floor(self.initial_cash/price)\n","     \n","    def predict_trade(self, model, X):\n","      predicted = model.predict(X, verbose=0).flatten()\n","     \n","      return predicted\n","\n","    def expand(self, df):\n","      # Perform seasonal decomposition\n","      result = seasonal_decompose(df['Close'], model='additive', period=90, extrapolate_trend='freq')\n","\n","      # Add trend back to original time series\n","      df[\"trend\"] = result.trend\n","\n","      # Compute the residuals by subtracting the trend from the original time series\n","      residuals = result.resid\n","\n","      # Fit a Gaussian distribution to the residuals\n","      mu, std = norm.fit(residuals)\n","\n","      # Compute the probability of a value being above or below the trend line\n","      # for each point in the time series\n","      z_scores = residuals / std\n","      df[\"prob_above_trend\"] = 1 - norm.cdf(z_scores)\n","      df[\"weighted-volume\"] = df[\"Close\"] * df[\"Volume\"]\n","      return df\n","\n","    def scale(self, timeseries):\n","      df = timeseries.reset_index()  # Reset the index of the DataFrame\n","      dates = df['Date']\n","      data_to_scale = df.drop(['Date', 'index'], axis=1)\n","      self.scaler = MinMaxScaler()\n","      scaled_data = self.scaler.fit_transform(data_to_scale)\n","      scaled_df = pd.concat([dates, pd.DataFrame(scaled_data, columns=data_to_scale.columns)], axis=1)\n","      return scaled_df.set_index('Date')  # Set the index back to 'Date'\n","\n","    def make_ledger_row(self):\n","        ledger = pd.DataFrame()\n","        ledger[\"Date\"] = []\n","        ledger[\"Side\"] = []\n","        ledger[\"Action\"]  = []\n","        ledger[\"Price\"] = []\n","        ledger[\"Fee\"] = []\n","        return ledger\n","\n","    def action_spec(self):\n","        return self._action_spec\n","\n","    def observation_spec(self):\n","        return self._observation_spec\n","\n","    def _reset_vars(self):\n","        self._state = None\n","        self._episode_ended = False        \n","        self.ledger = self.make_ledger_row()\n","        self.slippage = .01\n","        self.fee = .0025\n","        self.current_index = 0\n","        self.cash = 5000\n","        self.initial_cash = self.cash\n","        self.position_shares = 0\n","        self.position_value = 0\n","        self.shares_owed = 0\n","        self.in_position = False\n","        self.in_long = False\n","        self.in_short = False\n","        self._state = self._get_initial_state()\n","\n","    def _reset(self):\n","        # Reset the environment and return the initial time step\n","        self._reset_vars()\n","        return ts.restart(self._state)\n","\n","    def _step(self, action):\n","        action = int(action)\n","        info(\"_step:\", action)\n","        \n","        if self._episode_ended:\n","            # The last action ended the episode. Ignore the current action and start a new episode.\n","            return self.reset()\n","\n","        # Apply the action and update the environment state\n","        self._apply_action(action)\n","        self._state = self._get_next_state()\n","\n","        if self._is_episode_ended():\n","            self._episode_ended = True\n","            reward = self._get_final_reward()\n","            return ts.termination(self._state, reward)\n","        else:\n","            reward = self._get_reward()\n","            return ts.transition(self._state, reward=reward, discount=1.0)\n","\n","    def _get_initial_state(self):\n","        # Return the initial state of the environment\n","        self.current_index = 0\n","        return self.env_block()\n","\n","    def total_value(self):\n","      return self.position_value + self.cash\n","\n","    def should_stop(self):\n","      # if cash is negative\n","      if (self.cash < 0):\n","        info(\"Bankrupt.\")\n","        return True\n","      return False\n","\n","\n","    def _apply_action(self, action):\n","        # Advance the environment by one time step and return the observation, reward, and done flag\n","        self.current_index += 1\n","        info(\"step:\", \"index:\", self.current_index, \" of: \", self.final-1, \"action: \", int(action))\n","        self.update_position_value()\n","        if (self.current_index >= self.final - 1 or  self.should_stop()):\n","          error(\"********MARKING DONE\", \"index:\", self.current_index, \" of: \", self.final-1, \" cash: \", self.cash, \" value: \", self.position_value)\n","          if (self.position_shares != 0):\n","            info(\"done so closing position\")\n","            self.close_position()\n","          self._episode_ended = True\n","        else:\n","          self._episode_ended = False\n","\n","        # AI says hold\n","        if (action == 0):\n","          info(\"holding action = 0.\")\n","        # AI says long but we're already in a position\n","        elif (action == 1 and self.in_long):\n","          info(\"holding long.\")\n","        # AI says long, we're not in a position, so buy\n","        elif (action == 1 and not self.in_position):\n","          info(\"opening long.\")\n","          self.open_position()\n","        #AI says long, but we're short. Close the short, open a long.\n","        elif (action == 1 and self.in_short):\n","          info(\"closing short to open long.\")\n","          self.close_short() \n","          self.open_position()\n","        #AI says short, but we're already short  \n","        elif (action == 2 and self.in_short):\n","          info(\"holding short.\")\n","        #AI says short and we're not in a position so exit \n","        elif (action == 2 and not self.in_position):\n","          info(\"opening short.\")\n","          self.open_short()\n","        #AI says short but we're long, close it\n","        elif (action == 2 and self.in_long):\n","          info(\"closing long to open short\")\n","          self.close_position()\n","          info(\"opening short.\")\n","          self.open_short()\n","        else: #assume hold\n","          info(\"unknown state! holding:\", action, self.in_position, self.in_long, self.in_short)      \n","        self.update_position_value()\n","    \n","    def _get_next_state(self):\n","        # Calculate and return the next state based on the current state and action taken\n","        return self.env_block()\n","\n","    def get_price_with_slippage(self, price):\n","        return price + (price * self.slippage)\n","\n","    def open_position(self):\n","      self.in_position = True\n","      self.in_long = True\n","      df = self.orig_timeseries\n","      row = df.iloc[self.current_index,:]\n","      price = self.get_price_with_slippage(row[\"Close\"])\n","      self.position_shares = math.floor(self.cash/price)\n","      self.cash = 0      \n","      ledger_row = self.make_ledger_row()\n","      ledger_row[\"Side\"] = [\"long\"]\n","      ledger_row[\"Action\"] = [\"enter\"]\n","      ledger_row[\"Price\"] = [price]\n","      ledger_row[\"Fee\"] = [self.fee]\n","      self.ledger = pd.concat([self.ledger, ledger_row])\n","\n","    def open_short(self):\n","      self.in_position = True\n","      self.in_short = True\n","      df = self.orig_timeseries\n","      row = df.iloc[self.current_index,:]\n","      price = self.get_price_with_slippage(row[\"Close\"])\n","      max_short_pos = math.floor(self.cash/price)\n","      self.shares_owed = max_short_pos\n","      self.cash = self.cash + (self.shares_owed * price)    \n","      info(\"Added cash on short: \", self.shares_owed * price, \" total: \", self.cash, \" took share debt:\", self.shares_owed)  \n","      ledger_row = self.make_ledger_row()\n","      ledger_row[\"Side\"] = [\"short\"]\n","      ledger_row[\"Action\"] = [\"enter\"]\n","      ledger_row[\"Price\"] = [price]\n","      ledger_row[\"Fee\"] = [self.fee]\n","      self.ledger = pd.concat([self.ledger, ledger_row])\n","\n","    def close_position(self):\n","      self.in_position = False\n","      self.in_long = False\n","      df = self.orig_timeseries\n","      row = df.iloc[self.current_index,:]\n","      price = self.get_price_with_slippage(row[\"Close\"])\n","      value = price * self.position_shares\n","      self.position_shares = 0\n","      self.cash = self.cash + value\n","      ledger_row = self.make_ledger_row()\n","      ledger_row[\"Side\"] = [\"long\"]\n","      ledger_row[\"Action\"] = [\"exit\"]\n","      ledger_row[\"Price\"] = [price]\n","      ledger_row[\"Fee\"] = [self.cash * self.fee]\n","      self.ledger = pd.concat([self.ledger, ledger_row])\n","\n","    def close_short(self):\n","      self.in_position = False\n","      self.in_short = False\n","      df = self.orig_timeseries\n","      row = df.iloc[self.current_index,:]\n","      price = self.get_price_with_slippage(row[\"Close\"])\n","      value = price * self.shares_owed\n","      self.shares_owed = 0\n","      self.cash = self.cash - value\n","      ledger_row = self.make_ledger_row()\n","      ledger_row[\"Side\"] = [\"short\"]\n","      ledger_row[\"Action\"] = [\"exit\"]\n","      ledger_row[\"Price\"] = [price]\n","      ledger_row[\"Fee\"] = [self.cash * self.fee]\n","      self.ledger = pd.concat([self.ledger, ledger_row])\n","\n","\n","    def _is_episode_ended(self):\n","        return self._episode_ended\n","        \n","    def update_position_value(self):\n","      df = self.orig_timeseries\n","      row = df.iloc[self.current_index,:]\n","      self.position_value = (row[\"Close\"] * self.position_shares) - (row[\"Close\"] * self.shares_owed)\n","      self.benchmark_value = row[\"Close\"] * self.benchmark_position_shares\n","      info(\"Calculating position value:\",\n","            \"current price:\", row[\"Close\"],\n","            \"long shares:\", self.position_shares,\n","            \"short shares:\", self.shares_owed,\n","            \"long value:\", row[\"Close\"] * self.position_shares,\n","            \"short debt:\", row[\"Close\"] * self.shares_owed,\n","            \"position net value:\", self.position_value)\n","\n","    def _get_reward(self):\n","        self.update_position_value()\n","        current_portfolio_value = self.total_value()\n","        #compare to what we started with:\n","        #percentage_change = (current_portfolio_value - self.initial_cash) / self.initial_cash\n","        \n","        #compare to a bench mark\n","        percentage_change = ((current_portfolio_value - self.benchmark_value) / self.benchmark_value) * 100\n","        info(\"reward states: \",\n","              \"position value: \", self.position_value,\n","              \"shares: \", self.position_shares,\n","              \"cash: \", self.cash,\n","              \"benchmark value:\", self.benchmark_value,\n","              \"percentage_change: \", percentage_change)\n","        \n","        return percentage_change\n","\n","    def _get_final_reward(self):\n","        # Calculate and return the final reward when the episode ends\n","        return self._get_reward()\n","\n","    def env_block(self):\n","      start_index = self.current_index\n","      end_index = self.current_index\n","      df = self.timeseries.reset_index().drop(['Date'], axis=1)\n","      block = df.iloc[start_index].to_numpy()\n","      return block\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"kAwC_JEZn__c","executionInfo":{"status":"error","timestamp":1680304029206,"user_tz":240,"elapsed":1378,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}},"colab":{"base_uri":"https://localhost:8080/","height":481},"outputId":"671e68c0-24e4-4b31-badb-5279847d9f6c"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Only tf.keras.optimizers.Optimiers are well supported, got a non-TF2 optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f517ac81a60>\n"]},{"output_type":"stream","name":"stdout","text":["\r[*********************100%***********************]  1 of 1 completed"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-1077d2059bc5>\u001b[0m in \u001b[0;36m<cell line: 116>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTraderEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CAT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[0meval_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_py_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFPyEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0msaved_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_tf_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/load.py\u001b[0m in \u001b[0;36m_read_legacy_metadata\u001b[0;34m(object_graph_def, metadata, path)\u001b[0m\n\u001b[1;32m    221\u001b[0m         ):\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    224\u001b[0m                     \u001b[0;34m\"Unable to create a Keras model from SavedModel at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;34mf\"{path}. This SavedModel was exported with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unable to create a Keras model from SavedModel at /content/drive/My Drive/ml-trde-notebooks/models/ppo-final. This SavedModel was exported with `tf.saved_model.save`, and lacks the Keras metadata file. Please save your Keras model by calling `model.save` or `tf.keras.models.save_model`. Note that you can still load this SavedModel with `tf.saved_model.load`."]}],"source":["import os\n","env_count = 0\n","num_parallel_envs = 4\n","learning_rate = 3e-4\n","num_epochs = 5 #25\n","discount_factor = 0.99\n","gradient_clipping = 0.5\n","entropy_regularization = 1e-2\n","value_pred_loss_coef = 0.5\n","use_gae = True\n","use_td_lambda_return = True\n","actor_loss_weight = 1.0\n","value_loss_weight = 0.5\n","log_interval = 5000\n","eval_interval = 100\n","train_model = False\n","\n","def create_env():\n","    global env_count\n","    products = list(product_data.keys())\n","    product = products[env_count]\n","    env = TraderEnv(product, product_data[product])\n","    env_count+=1\n","    return env\n","\n","def build_tf_uniform_replay_buffer(agent, batch_size):\n","    return tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","        data_spec=agent.collect_data_spec,\n","        batch_size=batch_size,\n","        max_length=100000,\n","    )\n","\n","def timestr():\n","  import datetime\n","  current_time = datetime.datetime.now()\n","  formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\") \n","  return formatted_time\n","\n","# Create the environment\n","all_envs = [create_env() for _ in range(len(product_data))]\n","sorted_envs = sorted(all_envs, key=lambda env: env.product)\n","all_envs = [tf_agents.environments.tf_py_environment.TFPyEnvironment(env) for env in sorted_envs]\n","#train_parallel_py_envs = [lambda: env for env in all_envs]\n","#train_parallel_env = parallel_py_environment.ParallelPyEnvironment(train_parallel_py_envs)\n","#train_env = tf_agents.environments.tf_py_environment.TFPyEnvironment(train_parallel_env)\n","#train_env = tf_agents.environments.tf_py_environment.TFPyEnvironment(create_env())\n","\n","\n","\n","# Create the actor and value networks\n","# Create an ActorDistributionRnnNetwork with LSTM layers\n","actor_net = actor_distribution_rnn_network.ActorDistributionRnnNetwork(\n","    all_envs[0].observation_spec(),\n","    all_envs[0].action_spec(),\n","    input_fc_layer_params=None,\n","    lstm_size=(64,),  # LSTM layer with 64 units\n","    output_fc_layer_params=None,\n",")\n","\n","# Create a ValueRnnNetwork with LSTM layers\n","value_net = value_rnn_network.ValueRnnNetwork(\n","    all_envs[0].observation_spec(),\n","    input_fc_layer_params=None,\n","    lstm_size=(64,),  # LSTM layer with 64 units\n","    output_fc_layer_params=None,\n",")\n","\n","\n","# Define optimizer, PPO hyperparameters, and create the PPO agent\n","#optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n","global_step = tf.compat.v1.train.get_or_create_global_step()\n","\n","clip_rho_threshold = 0.2\n","clip_pg_threshold = 0.2\n","\n","tf_agent = tf_agents.agents.PPOAgent(\n","    all_envs[0].time_step_spec(),\n","    all_envs[0].action_spec(),\n","    optimizer,\n","    actor_net=actor_net,\n","    value_net=value_net,\n","    num_epochs=num_epochs,\n","    discount_factor=discount_factor,\n","    importance_ratio_clipping=clip_pg_threshold,\n","    entropy_regularization=entropy_regularization,\n","    gradient_clipping=gradient_clipping,\n","    value_pred_loss_coef=value_pred_loss_coef,\n","    use_gae=True,\n","    train_step_counter=global_step\n",")\n","\n","# Initialize the policy\n","tf_agent.initialize()\n","\n","eval_policy = tf_agent.policy\n","collect_policy = tf_agent.collect_policy\n","\n","check_point_dir = os.path.join(model_path, \"ppo-checkpoint\")\n","train_checkpointer = common.Checkpointer(\n","    ckpt_dir=check_point_dir,\n","    agent=tf_agent,\n","    global_step=global_step)\n","\n","policy_checkpointer = common.Checkpointer(\n","    ckpt_dir=os.path.join(check_point_dir, 'policy'),\n","    policy=eval_policy,\n","    global_step=global_step)\n","saved_model = policy_saver.PolicySaver(\n","    eval_policy, train_step=global_step)\n","\n","save_model_path = os.path.join(model_path, \"ppo-final\")\n","train_checkpointer.initialize_or_restore()\n","\n","\n","if train_model:\n","\n","  # Main training loop\n","  num_iterations = 4\n","  collect_episodes_per_iteration = 2\n","\n","  tf_agent.train = common.function(tf_agent.train)\n","  \n","  train_env_count = 0\n","  for train_env in all_envs:\n","    #tf_agent.train_step_counter.assign(0)\n","    error(f\"training {sorted_envs[train_env_count].product} count: {train_env_count} of {len(all_envs)}\")\n","    replay_buffer = build_tf_uniform_replay_buffer(tf_agent, train_env.batch_size)\n","    rb_observer = replay_buffer.add_batch\n","\n","    time_step = train_env.reset()\n","    print(time_step)\n","    collect_driver = py_driver.PyDriver(\n","        train_env,\n","        py_tf_eager_policy.PyTFEagerPolicy(\n","          tf_agent.collect_policy, use_tf_function=True),\n","        [rb_observer],\n","        max_steps=collect_episodes_per_iteration)\n","\n","    dataset = replay_buffer.as_dataset(\n","        num_parallel_calls=3,\n","        sample_batch_size=64,\n","        num_steps=2).prefetch(3)\n","\n","    iterator = iter(dataset)\n","\n","    step = 0\n","    for _ in range(num_iterations):\n","\n","      # Collect a few steps and save to the replay buffer.\n","      debug(f\"running {step} at: \", timestr())\n","      time_step, _ = collect_driver.run(time_step)\n","      debug(\"step complete at: \", timestr())\n","\n","      # Sample a batch of data from the buffer and update the agent's network.\n","      debug(\"training at:\", timestr())\n","      experience, unused_info = next(iterator)\n","      train_loss = tf_agent.train(experience).loss\n","      debug(\"done training at:\", timestr())\n","\n","      step = tf_agent.train_step_counter.numpy()\n","\n","      if step % log_interval == 0:\n","        error('step = {0}: loss = {1}'.format(step, train_loss))\n","        train_checkpointer.save(global_step=step)\n","        policy_checkpointer.save(global_step=step)\n","        saved_model.save(save_model_path)\n","    \n","else:\n","  tickerObj = yf.download(tickers = \"CAT\", interval = \"1d\")\n","  cat_df = pd.DataFrame(tickerObj)\n","  cat_df = cat_df.reset_index()\n","\n","  env = TraderEnv(\"CAT\", cat_df)\n","  eval_env = tf_py_environment.TFPyEnvironment(env)\n","  saved_policy = tf.keras.models.load_model(save_model_path)\n","\n","  def run_episodes(policy, eval_tf_env):\n","    num_episodes = 3\n","    frames = []\n","    for _ in range(num_episodes):\n","      time_step = eval_tf_env.reset()\n","      while not time_step.is_last():\n","        action_step = policy.action(time_step)\n","        time_step = eval_tf_env.step(action_step.action)\n","  run_episodes(saved_policy, env)"]},{"cell_type":"code","source":["policy = tf_agent.policy\n","tf.saved_model.save(policy, model_path + \"/ppo-final\")"],"metadata":{"id":"lEf-z03sdjcC","executionInfo":{"status":"aborted","timestamp":1680300176924,"user_tz":240,"elapsed":4,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23ERDs3wx-F-","executionInfo":{"status":"aborted","timestamp":1680300176924,"user_tz":240,"elapsed":4,"user":{"displayName":"Joseph Mordetsky","userId":"12205681246264358771"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyORvno9lyD3fKNGy1f05n8J"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}